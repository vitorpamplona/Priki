<a href="/content/view.jf?idContent=5">Apresentando XP. Encante seus clientes com Extreme Programming</a></span>
		</h1>

		<div class="box-cont"><!-- area do javanews -->


<center>
Enviada em Quinta-Feira, 18 de Novembro de 2004 
</center>

<br>
<br><h1>Apresentando XP: Encante seus clientes com Extreme Programming </h1>

<p align="center"><a href="mailto:giovane@babaxp.org">Giovane Roslindo Kuhn</a></p>
<p align="center"><a href="mailto:vitor@babaxp.org">Vitor Fernando Pamplona</a></p>
<br>
<p align="center">
<b>Resumo:</b> Este artigo tem por objetivo apresentar a metodologia de desenvolvimento ágil de <i>software</i>
denominada <i>Extreme Programming. </i> Serão abordadas, de forma resumida, as práticas, valores, e os
papéis disponíveis a cada integrante de uma equipe de XP. Alguns comparativos com outras metodologias são feitas ao
decorrer do trabalho enaltecendo as propriedades que definem a <i>Extreme Programming.</i></p>

<p align="center">
<b>Palavras-chave:</b> <i>Extreme Programming</i>, Engenharia de
Software, Qualidade de Software, Metodologia de Desenvolvimento,
Processos Ágeis de Desenvolvimento, XP.</p>

<h2>Índice</h2>
<ul>
<li><a href="#introducao">1. Introdução</a></li>
<li><a href="#xp">2. Extreme Programming (XP)</a></li>
<ul>
<li><a href="#valores">2.1. Valores da XP</a></li>

<ul>
<li><a href="#feedback">2.1.1 Feedback</a></li>
<li><a href="#comunicacao">2.1.2 Comunicação</a></li>
<li><a href="#simplicidade">2.1.3. Simplicidade</a></li>
<li><a href="#coragem">2.1.4. Coragem</a></li>
</ul>
<li><a href="#praticas">2.2. Práticas</a></li>
<ul>
<li><a href="#cliente">2.2.1. Cliente Disponível ou Presente</a></li>
<li><a href="#planeja">2.2.2. Jogo do Planejamento</a></li>

<li><a href="#metting">2.2.3. Stand up meeting</a></li>
<li><a href="#par">2.2.4. Programação em par</a></li>
<li><a href="#refatoring">2.2.5. Refactoring</a></li>
<li><a href="#testes">2.2.6. Desenvolvimento guiado por testes</a></li>
<li><a href="#coletivo">2.2.7. Código coletivo</a></li>
<li><a href="#padroes">2.2.8. Padrões de desenvolvimento</a></li>
<li><a href="#design">2.2.9. Design Simples</a></li>
<li><a href="#metafora">2.2.10. Metáfora</a></li>
<li><a href="#ritmo">2.2.11. Ritmo Sustentável</a></li>

<li><a href="#integracao">2.2.12. Integração contínua</a></li>
<li><a href="#releases">2.2.13. Releases curtos</a></li>
</ul>
<li><a href="#equipe">2.3. Equipe XP</a></li>
<ul>
<li><a href="#gerente">2.3.1. Gerente de projeto</a></li>
<li><a href="#coach">2.3.2. Coach</a></li>
<li><a href="#analista">2.3.3. Analista de teste</a></li>
<li><a href="#redator">2.3.4. Redator técnico</a></li>
<li><a href="#desenv">2.3.5. Desenvolvedor</a></li>

</ul>
</ul>
<li><a href="#conclusoes">3. Conclusões</a></li>
<li><a href="#ref">4. Referências</a></li>
<li><a href="#autores">5. Autores</a></li>
</ul>
<br>

<a name="introducao"></a><h2>1. Introdução</h2>
<p>A
muito tempo a indústria de software vem passando por grandes
transformações e novos desafios, entre eles desenvolver
<i>softwares</i> com qualidade, no menor tempo possível e que
atendam as necessidades dos clientes.</p>

<p>Com
estes novos desafios a indústria de software passou a dar
valor a algumas áreas da informática, como a engenharia
de software e qualidade de software, com intuito de atender as
exigências do mercado. 
</p>

<p>A
indústria começou a utilizar metodologias de
desenvolvimento de software, adotou métricas e padrões
para alcançar níveis aceitáveis de qualidade,
prever custos e prazos em seus projetos. Porém ainda são
poucos os projetos que conseguem obter pleno sucesso em seu
desenvolvimento, onde prazo e orçamento estabelecidos e as
necessidades do cliente sejam realmente atendidas.
</p>

<p>Pesquisa
feitas pelo <i>Standish Group International</i> em 1994, um pouco
antes da adoção de metodologia de desenvolvimento pelas
indústrias, apontam que apenas 16,2% dos projetos de software
atingiam sucesso (prazo, orçamento e funcionalidades
atendidas). Em 2002 esta taxa havia subido para 34%, ou seja, um
aumento de 100% em 8 anos. Mas estas taxas ainda se encontram muito
aquém do esperado pelo mercado.</p>


<p>As
metodologias utilizadas nos projetos pesquisados eram as mais
variadas, podemos citar modelo em cascata, modelo iterativo e alguns
com modelo em prototipação. Neste trabalho será
utilizado o termo <i>desenvolvimento tradicional </i>para os projetos
que se utilizem do modelo em cascata e todos os outros que se baseiam
nele.</p>

<p>Analisando
os motivos para a baixa taxa de sucesso dos projetos desenvolvidos
com modelos tradicionais, cita-se os principais motivos e bastante
comuns entre eles:
</p>
<ul>
	<li><p>Tempo
	elevado entre cada fase do projeto, não acompanhando as
	mudanças de requisitos do projeto;</p>
	</li><li><p>Falta
	de conhecimento por parte do cliente da sua real necessidade, dando
	margem às especulações dos desenvolvedores;</p>
	</li><li><p>Forte linearidade no desenvolvimento do projeto;</p>
</li></ul>

<p>Focando
nas fragilidades do modelo tradicional, surgiram metodologias para
desenvolvimento ágil de software. Cita-se algumas
características destas metodologias:</p>

<ul>
	<li><p>Foco
	nas pessoas, não no processo, evitando especulações
	dos desenvolvedores;</p>
	</li><li><p>Atender
	as reais necessidades do cliente, na velocidade e praticidade por
	ele desejada;</p>
	</li><li><p>Ausência
	de linearidade no desenvolvimento do projeto;</p>
	</li><li><p>O
	cliente aprender a suas reais necessidades durante o projeto e
	repassar esta novas necessidades a equipe de desenvolvimento;</p>
</li></ul>
<br>
<p>Uma
destas metodologias de desenvolvimento ágil é o <i>Extreme
Programming</i>, metodologia que prima a qualidade do software
desenvolvido, que atenda as reais necessidades do cliente e seja
entregue dentro do prazo definido. Esta metodologia será
detalhada a seguir.</p>

<a name="xp"></a><h2>2. Extreme Programming (XP)</h2>
<p>XP é
uma metodologia para desenvolvimento de software ágil, com
qualidade e que atenda as necessidades do cliente. Alguns praticantes
definem a XP como a prática e a perseguição da
mais clara simplicidade, aplicado ao desenvolvimento de software.</p>
<p>Uma
metodologia voltada para projetos cujos requisitos mudem com
freqüência, utilizem desenvolvimento orientado a objetos,
equipes de até 12 desenvolvedores e desenvolvimento
incremental. 
</p>
<p>A
XP Busca o máximo de valor a cada dia de trabalho da equipe
para o seu cliente. Em um curto espaço de tempo o cliente terá
um produto que possa ser utilizado, podendo aprender com o mesmo e
reavaliar se o que foi desenvolvido é realmente o desejado.</p>
<p>Por
ser uma metodologia recente, a XP sofre mudanças em suas
concepções e, portanto, é comum encontrar
variações. A adaptação ao ambiente de
desenvolvimento deve ser levada em conta, se um valor trouxer mais
prejuízos do que benefícios é necessário
relavaliar a utilização desta metodologia.
</p>
<p>A
XP é organizada em torno de um conjunto de práticas e
valores que atuam perfeitamente para assegurar um alto retorno do
investimento efetuado pelo cliente. A seguir serão
apresentados os valores e em seguida as práticas.</p>
<a name="valores"></a><h3>2.1 Valores da XP </h3>
<p>Os
valores são as diretrizes da XP. Eles definirão as
atitudes das equipes e as principais prioridades da metodologia.   
</p>
<p>Para
uma empresa estar realmente utilizando o XP, ela deve respeitar e
utilizar todos os valores e práticas listadas nos próximos
capítulos e caso um destes valores ou práticas não
seja utilizado pela empresa, esta empresa não está
trabalhando com a metodologia XP.</p>

<a name="feedback"></a><h4>2.1.1 Feedback</h4>
<p>O
cliente aprende com o sistema que utiliza e com este aprendizado
consegue reavaliar o produto recebido, com isso pode realimentar a
equipe de desenvolvimento com as suas reais necessidades. Com o
<i>feedback</i>, o cliente conduz o desenvolvimento do seu produto,
estabelece prioridades e informa aquilo que é realmente
importante.</p>
<p>Analogamente,
há o <i>feedback</i> dado pelo desenvolvedor ao cliente, onde
o mesmo aponta riscos, estimativas e alternativas de <i>design</i>.
Este retorno é o aprendizado do desenvolvedor sobre o que o
cliente deseja.</p>
<p>Com
este valor, o tempo de defasagem entre as fases do projeto são
extremamente pequenos, o cliente está o tempo todo em contato
com a equipe de desenvolvimento, muito diferente dos modelos
tradicionais, onde o cliente entrava em contato com a equipe um bom
tempo depois do último <i>feedback</i> dado.</p>

<p>Um
ponto que muitas empresas de <i>software</i> falham é não
dar valor ao que o cliente realmente deseja, utilizam cegamente
metodologias e acabam esquecendo o real propósito de um
software: facilitar o trabalho de pessoas.</p>
<p>Com
isto muitos sistemas acabam dificultando e burocratizando as tarefas
das pessoas e como defesa as empresas alegam ter um produto genérico
e que atenda as normais legais.</p>
<a name="comunicacao"></a><h4>2.1.2 Comunicação</h4>
<p>Para
que o <i>feedback</i> entre cliente e desenvolvedor possa ser
efetuado com sucesso é necessário ter uma boa
comunicação entre eles. A XP prega que esta comunicação
ocorra da forma mais direta e eficaz possível, oferecendo
agilidade aos assuntos tratados. Recomenda-se o contato direto
(face-a-face) entre cliente e desenvolvedor, para evitar qualquer
tipo de especulação ou mal entendido entre as partes e
para que possíveis dúvidas possam ser resolvidas de
imediato.</p>
<p>Além
de sanar as dúvidas no desenvolvimento, o cliente deverá
estar disponível para a equipe, ou mesmo presente no ambiente
de trabalho da empresa. Isto fará com que o cliente   entenda
o sistema e enriquecerá os relacionamentos pessoais, criando
um elo de parceria e confiança mútua.</p>
<p>Algumas
equipes não se adaptam bem a este valor. Este problema deve
ser trabalhado em conjunto com a equipe. Enquanto não se
acostumarem a falar e a trocar idéias com seus companheiros o
sucesso da metodologia estará comprometido. Membros
introvertidos são deseconselháveis para equipes de XP.   

</p>
<a name="simplicidade"></a><h4>2.1.3 Simplicidade</h4>
<p>Para
que o cliente possa aprender durante o projeto e consiga dar o
<i>feedback</i> necessário à equipe, não basta
apenas uma boa comunicação, é necessário
que os desenvolvedores implementem da forma mais simples possível
o que o cliente deseja.   
</p>
<p>A
lei é: faça a coisa mais simples que pode funcionar.
Com esta filosofia, o cliente terá a funcionalidade
rapidamente e da forma desejada, dando um <i>feedback</i>
instantaneamente evitando  especulações. O
desenvolvedor deve implementar apenas o necessário para que o
cliente tenha seu pedido atendido.</p>
<p>Ser
simples não é um ato de desespero, é um ato de
consciência e absoluta precisão. Muitas pessoas
confundem simplicidade e facilidade. O mais simples nem sempre é
o mais fácil e também não é escrever
menos código. Simplicidade significa codificar o necessário
para que um requisito seja atendido e entregue ao cliente.   
</p>
<p>Evita-se
suposições, o futuro é incerto e por causa disso
não necessita atenção. Os requisitos evoluem
gradativamente em conjunto com o sistema e a arquitetura do projeto.
Algumas vezes, o que é necessário hoje será
descartado amanhã, e outras vezes o que seria necessário
num futuro próximo nunca será utilizado.</p>

<a name="coragem"></a><h4>2.1.4 Coragem</h4>
<p>Por
ser um processo de desenvolvimento novo e baseado em diversas
premissas que contrariam o modelo tradicional, o XP exige que os
desenvolvedores tenham coragem para:</p>
<ul>
	<li><p>Desenvolver
	software de forma incremental;</p>
	</li><li><p>Manter
	o sistema simples;</p>
	</li><li><p>Permitir
	que o cliente defina prioridades;</p>
	</li><li><p>Fazer
	desenvolvedores trabalharem em pares:   
	</p>

	</li><li><p>Investir
	tempo em <i>refactoring</i>;</p>
	</li><li><p>Investir
	tempo em testes automatizados;</p>
	</li><li><p>Estimar
	estórias na presença do cliente;</p>
	</li><li><p>Expor
	código a todos os membros da equipe;</p>
	</li><li><p>Integrar
	o sistema diversas vezes ao dia;</p>

	</li><li><p>Adotar
	ritmo sustentável de desenvolvimento;</p>
	</li><li><p>Abrir
	mão de documentos que servem como defesa;</p>
	</li><li><p>Propor
	contratos de escopo variável;</p>
	</li><li><p>Propor
	 a adoção de um processo novo.</p>
	</li><li><p>Assumir
	em relação ao cliente possíveis atrasos e
	problemas de implementação;</p>
	</li><li><p>Colocar
	desenvolvedores e clientes frente a frente;</p>

	</li><li><p>Implantar
	uma nova versão do sistema no cliente semanalmente;</p>
	</li><li><p>Apostar
	em seus colaboradores aumentando suas responsabilidades;</p>
	</li><li><p>Modelar
	e documentar apenas quando for de extrema necessidade.</p>
</li></ul>

<a name="praticas"></a><h3>2.2 Praticas da XP</h3>
<p>Como
o nome já diz, as práticas são um conjunto de
atividades que deverão ser seguidas pelas equipes que desejam
utilizar a XP.   
</p>
<p>Os
valores já apresentados somados a estas práticas são
um conjunto ?entrelaçado? de boas atitudes. A fraquesa de
umas é compensado por outra e assim fecha-se um ciclo
fortemente dependente.</p>

<a name="cliente"></a><h4>2.2.1 Cliente disponível ou presente</h4>
<p>O
XP trabalha com uma visão diferente do modelo tradicional em
relação ao cliente. O XP sugere que o cliente esteja no
dia-a-dia do projeto, acompanhando os passos dos desenvolvedores,
onde a sua ausência representa sérios riscos ao projeto.</p>
<p>As
funcionalidades do sistema são descritas brevemente em
estórias em conjunto com os testes conceituais e serão
estes os indicadores para uma boa implementação. No
momento que os desenvolvedores irão implementar as estórias
nada mais eficaz do que dialogar com o cliente para entender a
estória, fazendo-se necessária a presença do
cliente no ambiente de desenvolvimento.</p>
<p>Ao
terminar uma estória, com a presença do cliente, a
mesma poderá ser validada rapidamente e a equipe receber o
<i>feedback</i> necessário sobre a funcionalidade, criando
ciclos rápidos e precisos.</p>
<a name="planeja"></a><h4>2.2.2 Jogo de planejamento</h4>
<p>A
XP utiliza o planejamento para assegurar que a equipe de
desenvolvimento esteja trabalhando naquilo que gere o máximo
de valor para o cliente. Este planejamento é feito várias
vezes durante o projeto. é o momento onde o cliente solicita
as funcionalidades desejadas através de estórias, onde
a equipe estima o custo de cada estória e planeja as <i>releases</i>
e as iterações.</p>

<p>Todas
as funcionalidades do sistema são descritas em estórias,
pequenos cartões em que o cliente deve descrever o que deseja
com suas palavras e da forma mais simples possível. Lembrando
que a simplicidade também deve ser respeitada pelo cliente.</p>
<p>Após
a definição das estórias é necessário
estimar o tempo das mesmas para que o cliente priorize o que deve ser
implementado. A XP utiliza uma unidade chamada <i>ponto</i>, que
refere-se a um <i>dia de trabalho ideal</i> do desenvolvedor, onde o
mesmo não precisaria atender telefonemas, participar de
reuniões, ou seja, estaria preocupado apenas com a estória
em questão.</p>
<p>Muitas
vezes algumas estórias consomem semanas de trabalho,
oferecendo uma certa dificuldade de serem estimadas. A XP recomenda
que estas estórias sejam quebradas em tarefas menores e que as
mesmas não utilizem mais que alguns pontos de um
desenvolvedor, recomenda-se 4 pontos ao máximo.</p>
<p>Em
cada estória é escrita a quantidade de <i>pontos</i>
estimadas pelo desenvolvedor, o XP recomenda que as estimativas sejam
efetuadas em equipe e se possível com a presença do
cliente para que durante a estimativa eventuais dúvidas sejam
sanadas.</p>
<p>O
XP tem por objetivo gerar valor para o cliente ao longo do projeto,
para isto o software é desenvolvido de forma incremental, onde
a cada entrega o cliente possa utilizar o sistema e obter benefícios
do mesmo. Estas entregas o XP denomina como sendo <i>releases</i>,
pequenos intervalos de tempo, máximo 2 meses, onde
funcionalidades que gerem valor ao cliente sejam entregues.</p>

<p>A
divisão dos <i>releases</i> é efetuada no início
do projeto, geralmente com tamanhos fixos e pequenos. Após
esta divisão o cliente define as estórias que farão
parte dos <i>releases</i> e tenta-se evitar um planejamento muito
longo, pois na entrega de cada <i>release</i> o cliente aprenderá
com o sistema e possivelmente irá alterar as estórias
para o próximo <i>release</i>.</p>
<p>Mesmo
os <i>releases</i> sendo efetuados em curto espaço de tempo,
continua representando um tempo muito longo para o <i>feedback</i> do
cliente. Por esta razão os <i>releases </i>são
divididos em espaços menores, chamados de <i>iterações</i>.</p>

<p>Uma
iteração contêm um conjunto de estórias a
serem implementadas, com duração entre uma a três
semanas, onde ao final da mesma o cliente possa validar as
implementações efetuadas e fornecer o <i>feedback</i>
necessário à equipe.</p>
<a name="meeting"></a><h4><i>2.2.3 Stand up meeting</i></h4>
<p>O
dia de trabalho de uma equipe XP sempre começa com um <i>stand
up meeting</i>. é uma reunião rápida pela manhã,
com aproximadamente 20 minutos de duração e onde seus
integrantes permaneçam preferencialmente em pé.   
</p>
<p>Segundo
estudos uma reunião em pé é mais rápida,
evita bate-papos paralelos e faz os integrantes irem diretamente ao
assunto. Mais uma vez, ágil e simples.</p>
<p>A
reunião tem por objetivo atualizar a equipe sobre o que foi
implementado no dia anterior e trocar experiências das
dificuldades enfrentadas. Neste momento também são
decididas as estórias que serão implementadas no dia e
em conjunto definir os responsáveis por cada uma delas.</p>
<a name="par"></a><h4>2.2.4 Programação em par</h4>

<p>O
XP <b>exige</b> que todo e qualquer código implementado no
projeto seja efetuado em dupla, chamada de programação
em par. é uma técnica onde dois desenvolvedores
trabalham no mesmo problema, ao mesmo tempo e no mesmo computador. Um
deles é responsável pela digitação
(condutor) e outro acompanhando o trabalho do parceiro (navegador).</p>
<p>Esta
prática agrega diversas técnicas de programação,
enquanto o condutor codifica o problema o navegador permanentemente
revisa o código digitado, onde pequenos erros de programação
que demoraria algumas horas para serem depurados, facilmente são
percebidos pelo navegador da dupla.</p>
<p>Um
dos grandes benefícios da programação em par é
a troca de experiências e idéias entre os
desenvolvedores. A solução para um problema geralmente
é a soma das idéias da dupla, tornando uma solução
e codificação muito mais simples e eficaz.   
</p>
<p>é
com esta prática que o XP uniformiza o nível dos
desenvolvedores da equipe, através da troca de experiências.
Após alguns meses trabalhando em duplas todos os
desenvolvedores conhecerão todas rotinas do sistema, prontos
para qualquer modificação ou para auxiliar algum
iniciante.</p>
<p>Um
grande questionamento sobre esta prática é com questão
a produtividade dos desenvolvedores. Porém, é um erro
pensar que somente uma pessoa estará codificando enquanto o
outro apenas observa. O
membro que não está codificando não apenas
observa, mas também troca idéias, gera soluções
e evita praticamente todos erros de codificação além
de cobrar padrões de desenvolvimento da equipe.   
</p>
<p>Estudos
indicam que a produtividade de uma equipe que utiliza <i>pair
programming</i> e de equipes que tenham desenvolvedores sozinhos é
praticamente a mesma, porém a qualidade do código gera
facilidade de manutenção e outros ganhos a médio
e longo prazo.</p>

<a name="refatoring"></a><h4>2.2.5 Refactoring</h4>
<p>Um
desenvolvedor ao deparar com um código mal escrito ou pouco
legível mas que esteja funcionando, nos modelos tradicionais
de desenvolvimento, dificilmente efetuaria alterações
neste código, mesmo que tivesse que implementar novas
funcionalidades.   
</p>
<p>O
XP prega que todo desenvolvedor ao encontrar um código
duplicado, pouco legível, mal codificado, sem padronização,
lento, com código legado ou uso incorreto de outras
implementações, tem por obrigação alterar
este código deixando-o mais legível e simples, porém
esta alteração não pode mudar o comportamento do
código em questão.</p>
<p>Esta
prática anda de mãos dadas com o código
coletivo, já que todo desenvolvedor tem a possibilidade de
melhorar qualquer código do sistema.   
</p>
<p>A
padronização oferece facilidades aos desenvolvedores no
momento de implementar novas funcionalidades ou efetuar qualquer tipo
de manutenção, uma vez que o código se encontra
simples e claro.</p>
<p>Uma
questão importante é que a prática de
<i>refactoring</i> esta apoiada pelos testes automatizados, pois
facilmente o desenvolvedor terá um <i>feedback</i> se a
alteração por ele efetuada irá gerar qualquer
tipo de comportamento anormal no sistema, sofrendo o aprendizado
sobre a alteração por ele efetuada.</p>

<a name="testes"></a><h4>2.2.6 Desenvolvimento guiado por testes</h4>
<p>Esta
atividade é considerada extremamente chata e dispendiosa por
muitos desenvolvedores na modelagem tradicional, porém para os
desenvolvedores de uma equipe XP esta atividade deve ser encarada com
extrema naturalidade. Todo código implementando deve coexistir
com um teste automatizado, assim garantindo o pleno funcionamento da
nova funcionalidade.</p>
<p>é
com base nestes testes automatizados que qualquer desenvolvedor terá
coragem para alterar uma parte do código que não tenha
sido implementada por ele, já que executando os testes
automatizados poderá verificar instantaneamente se a
modificação efetuada alterou o comportamento do
sistema.    
</p>
<p>Com
a implementação de testes o desenvolvedor poderá
amadurecer o entendimento sobre o problema que irá solucionar,
já que os testes são codificados antes da nova
implementação.</p>
<p>No
XP existem dois tipos de testes, os testes de unidade e de aceitação.
 O teste de unidade tem por objetivo verificar se os resultados
gerados por cada classe estão corretos, já o teste de
aceitação tem por objetivo verificar se a interação
entre as classes que implementam uma funcionalidade (estória)
atendem a necessidade de forma correta. Os testes de aceitação
são descritos pelo cliente e implementados pelos
desenvolvedores, facilitando ainda mais a interação
entre as partes.</p>
<a name="coletivo"></a><h4>2.2.7 Código coletivo</h4>
<p>No
modelo tradicional de desenvolvimento, é comum dividir o
projeto em partes e colocar responsáveis por cada uma destas
partes. Porém apenas uma pessoa torna-se conhecedora daquela
parte.</p>
<p>Este
tipo de divisão traz sérios problemas ao projeto, uma
vez que se aquela parte necessitar inúmeras alterações,
apenas uma pessoa estará capacitada para alterá-la. Com
estas inúmeras alterações, esta pessoa pode se
tornar um gargalo no projeto.</p>
<p>O
XP trava uma batalha contra este tipo de divisão, já
que não existe uma pessoa responsável por uma parte do
código. Cada desenvolvedor tem acesso a qualquer parte do
sistema e tem liberdade para alterá-la a qualquer momento e
sem qualquer tipo de aviso.</p>

<p>Esta
prática tem como conseqüência um código
revisado por diversas pessoas e caso algo não esteja claro,
com certeza será alterado por alguma pessoa (<i>refactoring</i>)
para que o mesmo torne-se legível.</p>
<a name="padroes"></a><h4>2.2.8 Padrões de desenvolvimento</h4>
<p>Um
dos valores do XP é a comunicação, e o código
também é uma forma da equipe se comunicar. Uma forma
clara de se comunicar através do código, é
manter um padrão no projeto para que qualquer um possa
rapidamente entender o código lido.</p>
<p>O
XP recomenda a adoção de um padrão desde o
início do projeto, preferencialmente padrões utilizados
pela comunidade da linguagem de desenvolvimento. Havendo a
necessidade de modificações e adaptações
durante o projeto, que visam agilizar o desenvolvimento, as mesmas
devem ser efetuadas.</p>
<a name="design"></a><h4>2.2.9 <i>Design</i> simples</h4>
<p>Nota-se
que todas as práticas do XP focam que o maior valor possível
seja gerado para o cliente, para tal premissa ser verdadeira o XP
prega um <i>design</i> do sistema da forma mais simples possível
para que atenda a necessidade do cliente.</p>

<p>Umas
das premissas do desenvolvimento tradicional é que o custo de
uma alteração no sistema cresce exponencialmente ao
longo do projeto, com isto tenta-se criar soluções
genéricas preparando o sistema para futuras alterações.</p>
<p>Este
tipo de pensamento dá margens para especulações
e implementações que na maioria dos casos não
terá utilidade para o cliente. O XP parte do princípio
que o custo de uma alteração tende a crescer lentamente
e se estabilizar ao longo do projeto, esta premissa é dita em
função dos avanços nas linguagens e práticas
de programação, novos ambientes e ferramentas de
desenvolvimento, utilização de orientação
a objetos no desenvolvimento e em conjunto com estes novos avanços
existe o fruto das outras práticas XP, deixando o código
simples, legível e passível de alteração
a qualquer momento.</p>
<a name="metafora"></a><h4>2.2.10 Metáfora</h4>
<p>Muitas
vezes pessoas tentam explicar um assunto ou problema a outras pessoas
por um período sem obter o êxito necessário na
explicação dada, simplesmente as outras pessoas não
conseguem entender a mensagem que está se tentando repassar.</p>
<p>Ao
criar comparações e analogias com o assunto que está
em questão as pessoas passarão a entender deste assunto
de uma forma muito mais rápida e possivelmente não a
esquecerão mais. Este tipo de artifício é
chamado de <i>metáfora</i> no XP, e deve ser utilizado com
intensidade durante o projeto, uma vez que facilita a comunicação
e fixação dos assuntos entre as partes.</p>
<p>Esta
prática anda em conjunto com o ritmo sustentável, já
que para o desenvolvedor criar boas metáforas exige
criatividade e desenvolvimento de idéias, o que torna
necessário uma boa condição física e bem
estar por parte do desenvolvedor.</p>
<a name="ritmo"></a><h4>2.2.11 Ritmo sustentável</h4>

<p>Uma
grande problema nos projetos de software é a falta de tempo
para encerrar o mesmo, e uma das técnicas mais adotadas para
compensar a falta de tempo é submeter os desenvolvedores
(humanos) a trabalharem até mais tarde e muitas vezes
sacrificarem seus finais de semana.</p>
<p>Nos
primeiros momentos este tipo de atitude tem efeitos positivos, porém
passado alguns dias o rendimento da equipe cai drasticamente, dando
margens a erros pela falta de concentração no
desenvolvimento, justamente pelo cansaço físico do
desenvolvedor.</p>
<p>O
XP proíbe que os desenvolvedores trabalhem até mais
tarde. O XP sugere um ritmo sustentável de 40 horas semanais,
respeitando assim a individualidade e o físico de cada
desenvolvedor. Desta forma a equipe estará sempre concentrada
e muito menos propensa a pequenas falhas na implementação.</p>
<a name="integracao"></a><h4>2.2.12 Integração contínua</h4>
<p>No
desenvolvimento tradicional geralmente as equipes são
organizadas de modo que uma parte (módulo) fiquei sob
responsabilidade de um desenvolvedor, cabe a esta pessoa efetuar
testes e codificação que dizem respeito a sua parte.
Esta estratégia reduz a complexidade e as preocupações
de um desenvolvedor.</p>
<p>Interfaces
de integração são convencionadas para que
futuramente estas partes possam se comunicar, este tipo de
desenvolvimento esta propenso a sérios erros de integração,
uma vez que os períodos em que as partes são integradas
e testadas são extremamente longos.</p>
<p>O
XP propõe uma integração contínua, se
possível deve ser efetuada diversas vezes ao dia para que toda
a equipe tenha conhecimento do código recém
desenvolvido. Com esta prática o <i>feedback</i> sobre a
alteração efetuada será retornado em um menor
espaço de tempo.   
</p>

<a name="releases"></a><h4>2.2.13 <i>Releases</i> curtos</h4>
<p>No
modelo tradicional o projeto é dividido em fases, de um modo
que o cliente começará a ter benefício com o
sistema muito próximo de o mesmo estar finalizado. A maior
parte do investimento do projeto é feita antes mesmo de estar
concluído, sem ter gerado qualquer tipo de valor econômico
ao cliente.</p>
<p>O
XP recomenda que pequenos investimento sejam efetuados de forma
gradual e que busque grandes recompensas o mais rapidamente possível.
Com a prática de <i>releases </i>curtos, o XP pretende dar o
máximo de valor econômico ao cliente em um curto espaço
de tempo.</p>
<p><i>Release</i>
é um conjunto de funcionalidade bem definidas e que
representam algum valor para o cliente. Um projeto XP pode ter um ou
mais <i>releases</i> no seu ciclo de desenvolvimento.</p>

<a name="equipe"></a><h3>2.3 Equipe XP </h3>
<p>
Em uma equipe de XP existem papéis a serem desempenhados por um ou mais desenvolvedores. Estes papéis serão listados a seguir.
</p>
<a name="gerente"></a><h4>2.3.1 Gerente de projeto</h4>
<p>Pessoa
responsável pelos assuntos administrativos do projeto,
mantendo um forte relacionamento com o cliente para que o mesmo
participe das atividades do desenvolvimento.</p>
<p>O
gerente de projeto é responsável por filtrar assuntos
não relevantes aos desenvolvedores e aspectos que só
devam ser implementados em iterações futuras.</p>
<p>Para
um bom exercício de gerente de projeto é necessário
que a pessoa conheça e acredite nos valores e práticas
do XP para que possa cobrar isto da sua equipe.</p>
<a name="coach"></a><h4>2.3.2 Coach</h4>
<p>Pessoa
responsável pelas questões técnicas do projeto,
recomenda-se que esta pessoa seja a com maior conhecimento do
processo de desenvolvimento, dos valores e práticas do XP. é
de responsabilidade do <i>coach </i>verificar o comportamento da
equipe frente o processo XP, sinalizando os eventuais erros cometidos
pela equipe.   

</p>
<a name="analista"></a><h4>2.3.3 Analista de teste</h4>
<p>Pessoa
responsável em garantir a qualidade do sistema através
dos testes escritos. Ele deve ajudar o cliente a escrever os casos de
testes e no final de cada iteração verificar se o
software atende todos os casos de testes.</p>
<p>Recomenda-se
que esta pessoa não seja um desenvolvedor, para evitar uma
visão tendenciosa já que não conhece o código
desenvolvido. O analista de teste deve ter uma visão muito
parecida com a do cliente e em muitos projetos esta pessoa acaba
exercendo o papel de redator técnico.</p>
<a name="redator"></a><h4>2.3.4 Redator técnico</h4>
<p>Pessoa
responsável em documentar o sistema, evitando um forte
trabalho dos desenvolvedores neste tipo de atividade, permitindo uma
maior dedicação ao trabalho de codificação.</p>
<p>Esta
pessoa deve estar em plena sintonia com os desenvolvedores e cliente
para que a documentação reflita o código escrito
e as regras de negócio atendidas pelo sistema.</p>
<a name="desenv"></a><h4>2.3.5 Desenvolvedor</h4>
<p>Pessoa
responsável em analisar, projetar e codificar o sistema. No XP
não existe diferença entre analista, projetista e
programador uma vez que em vários momentos do projeto o
desenvolvedor estará exercendo alguma destas atividades.</p>

<p>Naturalmente
existe níveis distintos de desenvolvedores dentro de uma
equipe, mas com as práticas do XP, como <i>pair programming</i>,
a tendência é a equipe se tornar uniforme em suas
habilidades.</p>
<a name="conclusoes"></a><h2>3 Conclusões</h2>
<p>A
metodologia de desenvolvimento <i>Extreme Programming</i> pode ser
considerada extremamente nova, porém vem acompanhando as
necessidades <b>humanas</b> dos desenvolvedores pelo mundo.</p>
<p><i>Gurus</i>
da tecnologia da informação vem aprimorando as
concepções desta metodologia para atender as
necessidades do mercado e principalmente das pessoas.   

</p>
<p>Um
empresa ao utilizar este processo por completo, só estará
agregando valor aos seus negócios e melhorando o ambiente de
seus colaboradores e clientes, tratando-os como pessoas e parceiros.
Está é chave no mundo dos negócios, o bem estar
de seus colaboradores e a parceria entre o fornecedor e seus
clientes, criando um laço de confiança ou até
mesmo um sentimento de amizade.</p>
<p>Entender
as necessidades do cliente não é ciência, é
arte. Dar incentivo a ela é o mínimo que podemos fazer.</p>

<a name="ref"></a><h2>4 Referências</h2>
<p>AMBROSI, Cleison Vander; GRAHL, Everaldo Artur. <b>Extreme Programming: Um
modelo de processo para o desenvolvimento de software.</b> Blumenau ?
SC: Instituto Catarinense de Pós-Graduação.</p>
<p>ASTELS,
David; MILLER, Granville; NOVAK, Miroslav. <b>Extreme Programming:
Guia prático.</b> Rio de Janeiro ? RJ: Campus, 2002.</p>

<p>BECK, Kent. <b>Programação extrema (XP) explicada: acolha as
mudanças.</b> Porto Alegre ? RS: Bookman, 2004.</p>
<p>POHREN, Daniel. <b>XP Manager: Uma Ferramenta de Gerência de Projetos
Baseados em Extreme Programming.</b> Novo Hamburgo ? RS: Centro
Universitário Feevale, 2004.</p>
<p>TELES,
Vinícius Manhães. <b>Extreme Programming: Aprenda como
encantar seus usuários desenvolvendo software com agilidade e
alta qualidade.</b> São Paulo - SP: Novatec Editora Ltda,
2004.
</p>
<p>WUESTEFELD, Klaus. <b>Xispê: Extreme Programming. </b>Disponível em

<a href="http://www.xispe.com.br/index.html">http://www.xispe.com.br/index.html</a>.
Acesso em: 23/07/2004.</p>

<a name="autores"></a><h2>5 Autores</h2>
<p>
<b><a href="mailto=giovane@babaxp.org">Giovane Roslindo Kuhn</a></b> está cursando o 4º ano de graduação em Ciências da Computação da <a href="http://www.furb.br" target="_blank">Universidade Regional de Blumenau</a>. Atuando profissionalmente no Projeto Jakare da <a href="http://www.senior.com.br" target="_blank">Senior Sistemas</a>
, que consiste em um framework para desenvolvimento de 
aplicações J2EE e é um dos responsáveis do projeto <a href="http://www.babaxp.org" target="_Blank">Baba XP</a>.
Incentivador do uso de metodologias ágeis de desenvolvimento, especialmente XP e desing patterns.

</p>
<p>
<b><a href="mailto=vitor@babaxp.org">Vitor Fernando Pamplona</a></b> está cursando o 4º ano de graduação em Ciências da Computação da <a href="http://www.furb.br" target="_blank">Universidade Regional de Blumenau</a>. É entusiasta do <a href="http://www.prevayler.org" target="_blank">Prevayler, da </a><a href="http://www.xispe.com.br" target="_Blank">XP</a> e do Software Livre. Participa profissionalmente em um projeto com Swing, J2EE e Hibernate, é um dos responsáveis pelo projeto <a href="http://www.babaxp.org" target="_blank">Baba XP</a>, articulista do <a href="http://www.imasters.com.br" target="_Blank">iMasters</a>, um dos coordenadores do <a href="http://blumenau.javafree.org" target="_blank">JavaFree Blumenau JUG</a> e um dos administradores do portal sobre java e software livre, <a href="http://www.javafree.org" target="_blank">JavaFree.org</a>

</p>


All | General | Java | Baba XP | Free Software | JavaFree.org | M3GE

12/10/2005 - Java 5.0_6 BUG: JOptionPane.showInternalMessageDialog() killing methods
This week I found a bug in Sun's Java 5.0 update 6 and previous. It can to cause serious problems when using InternalDialogs. When the JOptionPane.showInternalMessageDialog method is called, the dialog locks the application correctly. But when the user answers the Dialog, the method that called it does not continue, simply leaves the method as if a return; was one after the call.

You can verify with the code above. There, the message "HI 1.0" is displayed, but "HI 2.0", "Someone alive??" and "Return now!" aren't.

import javax.swing.JDesktopPane;
import javax.swing.JFrame;
import javax.swing.JInternalFrame;
import javax.swing.JOptionPane;

public class TryTest {
    public static void main(String args[]) {
        JFrame frame = new JFrame("FODEU!");
        frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);
        frame.setVisible(true);
        frame.setBounds(10, 10, 400, 400);

        JDesktopPane desk = new JDesktopPane();
        frame.getContentPane().add(desk);

        JInternalFrame iframe = new JInternalFrame();

        iframe.setBounds(10, 10, 100, 100);

        desk.add(iframe);

        iframe.setVisible(true);

        frame.validate();

        JOptionPane.showInternalMessageDialog(iframe, "HI 1.0!");

        System.out.println("Someone alive??");

        JOptionPane.showInternalMessageDialog(iframe, "HI 2.0!");

        System.out.println("Return now!");
    }
}


But in another test, i could see an interesting thing. It doesn't work as if a return; command was on the next line of the call to JOptionPane, it works killing all method stack and after it stop, waiting the user do something. Like you can see above.

import javax.swing.JDesktopPane;
import javax.swing.JFrame;
import javax.swing.JInternalFrame;
import javax.swing.JOptionPane;

public class TryTest {

    public static void function() {
        JFrame frame = new JFrame("FODEU!");
        frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);
        frame.setVisible(true);
        frame.setBounds(10, 10, 400, 400);

        JDesktopPane desk = new JDesktopPane();
        frame.getContentPane().add(desk);

        JInternalFrame iframe = new JInternalFrame();

        iframe.setBounds(10, 10, 100, 100);

        desk.add(iframe);

        iframe.setVisible(true);

        frame.validate();

        JOptionPane.showInternalMessageDialog(iframe, "HI 1.0!");

        System.out.println("Someone alive??");

        JOptionPane.showInternalMessageDialog(iframe, "HI 2.0!");
    }

    public static void main(String args[]) {
	function();

        System.out.println("Return now!");
    }
}



This bug can kill many routines improperly. So be careful when using internal dialogs of JOptionPane, they don't work as they would have.

Checking the Sun's Bug Database, I found this bug that are in progress since 13-OCT-2004. Please Sun, this bug give me a big headache, mainly because the call was on a try finally block. Can you give more attention to it?

Permalink Comments [2]

12/03/2005 - JavaCC: becoming easy a compiler development
JavaCC is one of the best free projects that I already saw. Java Compiler Compiler [tm] (JavaCC [tm]) is the most popular parser generator for use with Java [tm] applications. The simple and powerful grammar files (.jj) allows the development of any compiler or parser that you can need. The real advantage is to put java code into the grammar file. So, with this access you can make everything while compiling the language. If you want send an e-mail after each token analysis, you can do it.

First I used JavaCC to create a compiler to an hypothetical language at university and a parser to an SQL/OQL language in SnailDB project. Today a use it to determine tokens, separate symbols and HTML tags and codes for my Wiki engine. All of it could be made with complex Regex structures using default classes contained into JRE package (java.util.regex). But, the complexity of the final expressions made me to give up the idea and search a better solution: JavaCC. So, today i have a compiler into a Wiki engine, running in every user post.

I'm participating of the Priki, The Prevalent Wiki development. Priki is a wiki engine based on a Prevayler persistence layer. This project will be the core of the JavaFreeCMS 2 project, a wiki based Content Management System (CMS).

Permalink Comments [0]

11/30/2005 - Relief Texture Mapping
What do you think about a 3D quality improvement in Doom 3? Impossible? :D
	I'm studying Relief Texture Mapping techniques to make 3D scenes more 3D. How? Well, basically, it maps a Relief Texture to 3D coordinates, creating polygons or meshes depending the viewer position. A Relief Texture is a normal texture with displacements per textel. This displacement values are the height of each textel from a 3D object. When Relief Textures are transformed into polygons, based in that heights, they assume all features of them, like: shadow, culling, view-motion-parallax, collision and others.
What are the goals of the idea? With this technique is possible to model an object with a few vertices and use 3D textures to improve the model, saving time to develop and to render the object. The best example is a brick wall. To show real 3D brick wall, the designers should draw each brick separately and, then, put it all together to make the wall. Thus, the bricks standing out of the wall and protruding dormers. But, anyone is crazy to draw each brick of a great wall only to give a 3D view of it. With the Relief Texture Mapping the wall is drew with only eight points and an image (JPG) of the bricks is associated to the object. This 3D image has a special vector for each textel, and with this vectors, the bricks are protruded out of the wall.

In the official site, you will find more about this technique and some examples. The most impressive is the improvement in 3D quality on doom 3, what can viewed in this video

Permalink Comments [0]

10/28/2005 - The first cell phone for deaf people
	Siemens Mobile and Brasil Telecom GSM will launch, on november 2005, the first cell phone for deaf people. The project called Ryberna stands for "communication" in Xavante, a Brazilian native language and was developed by one of the biggest Java Community in Brazil, the Brasilia Java Users Group. The software transforms voice into data and convert it to Flash animations composed with the typical symbols of the Brazilian Language of Signals (LIBRAS).
The application will be lauched for Siemens CX65 cell phone, but it's able to any cellular model compatible with Java. A demonstration of software can be viewed here (Click in the cellphone image).

Congrats, Ryberna TEAM!

Permalink Comments [0]

10/28/2005 - Java API Specifications in portuguese
Well, after a long time i'm here again and now with new ideas! :P

The first of all i am commemorating the brazilian joint force to translate the Java Specifications to Portuguese. The brazilian Java communities had received the notice with much enthusiasm. Sun Microsystems, or we (I don't know), will create a project in java.net and help the community to translate the javadocs. Briefly one of the only ones languages with documentation in Portuguese. Wonderful. This is a great evolution to Java in Brazil, mainly because of the beginning users, or users that can't understand english wery well. With the portuguese version of Java Spec another people will be reached and the language usage will grow.

We are looking for interested people to help the project. I'll be one of the translators, only one of the twenty people already interested in it. This group will grow when the project and the structure be ready for the use. We will begin with version J2SE 5.0.

We'll fight and win. :P

Permalink Comments [0]

07/24/2005 - RSSNotifier: An RSS Feeds Reader on System Tray
I would like to present my new free software project, the RSSNotifier. It is a small application that works from the System Tray just like Gmail Notifier does. It reads a list of RSS Feeds and shows the news in small windows. It aims to give the user real time news, based on news published using RSS files.

The application was designed to be loaded on Windows startup. It will look for a connection and will download all RSS feeds configured for it. When a new item is found it will show you a brief description. If you want more information about an item, right-click the tray icon and click the selected RSS item. Your default brower will open this item.

RSS Notifier has i18n files implemented in properties file. There are versions in english (USA) and portuguese (Brazil) for now. If your language isn't translated yet, please translate it and send it to us. It is a small file (30 statements)!

Some screens




Permalink Comments [0]

07/13/2005 - Solve your problems with ByeCycle
Byecycle is an auto-arranging dependency analysis plugin for Eclipse. Its goal is to make you feel sick when you see bad code and to make you feel happy when you see good code.

By Klaus Wuestefeld, Rodrigo B. de Oliveira, Kent Beck and others.

Byecycle requires Eclipse 3.1 running on Java 5. Plugin veterans, this is the Byecycle update site: http://priki.org/svn/byecycle/trunk/updatesite



Permalink Comments [1]

07/13/2005 - Google Maps on your Mobile?
	Mobile GMaps is a free piece of software that displays Google Maps and Keyhole satellite imagery on Java J2ME-enabled mobile phones or other devices.

Mobile GMaps is distributed under the Attribution/NonCommercial/NoDerivs Creative Commons license. You may download, use and distribute the application free of charge for non-commercial purposes. You may NOT use it for any commercial purpose.

I have updated MGMaps to successfully run on most J2ME 1.0 phones. However, I cannot make this solution public yet, please read this document for more details.

Source: Marcelo's blog
Permalink Comments [0]

07/10/2005 - SnailDB, the JDBC driver for Prevayler is running
Hi all...

For the last two weeks, I've worked in the SnailDB project. A JDBC driver for Prevayler. The driver is creating, inserting and selecting (BASIC select) data from a Prevayler database.

Now, Giovane and I (project owners) are working to improve the select command with named tables (alias) and data convertion types. The driver JDBC isn't work yet, but as soon as it is.

Now the following code is executing sucessfull.

Welcome to snailsql 1.0, the SnailDB interactive terminal.

> create table Customer (id integer, name varchar2(300), limitCredit float default 100);
Table created.
> insert into Customer (id, name) values (1, 'Xuxa');
Data inserted.
> insert into Customer values (2, 'Jô Soares', 100000);
Data inserted.
> insert into Customer (id, name) values (3, 'Bira');
Data inserted.
> select * from Customer where name = 'Xuxa';
  id  name  limitCredit
---------------------------------------------------
   1  Xuxa        100.0
---------------------------------------------------
> create table Seller (id integer, name varchar2(300), minToSell integer default 1000);
Table created.
> insert into Seller (id, name) values (5, 'Vitor Fernando Pamplona');
Data inserted.
> insert into Seller values (10, 'Paulo', 3000.00);
Data inserted.
> select * from Seller, Customer;
  id                     name  minToSell  id       name  limitCredit
---------------------------------------------------
   5  Vitor Fernando Pamplona     1000.0   1  Xuxa             100.0
   5  Vitor Fernando Pamplona     1000.0   2  Jô Soares     100000.0
   5  Vitor Fernando Pamplona     1000.0   3  Bira             100.0
  10  Paulo                       3000.0   1  Xuxa             100.0
  10  Paulo                       3000.0   2  Jô Soares     100000.0
  10  Paulo                       3000.0   3  Bira             100.0
---------------------------------------------------
> 



And it is generating, compiling, loading and saving these classes:

/*
 * GENERATED by SnailDB. DO NOT CHANGE!
 *
 * Created on 10/07/2005
 */
import java.io.*;
import java.math.*;
import java.util.*;
import org.snaildb.exception.*;
import org.snaildb.base.*;

/**
 * @author SnailDB
 */
public class Seller implements Serializable, Data {

    private static final long serialVersionUID = 1L;

	private Long id ;
	private String name ;
	private Long minToSell  = new Long(1000) ;

	public Seller() { super(); }

	public Long getId() { return id; }
	public String getName() { return name; }
	public Long getMinToSell() { return minToSell; }

	public void setId(Long id)  {
	    this.id = id; 
	}
	
	public void setName(String name) throws OutOfBoundsException  {
		if (name.length() > 300) {
			throw new OutOfBoundsException("name", name.length(), 300);
		}    			
	    this.name = name; 
	}
	
	public void setMinToSell(Long minToSell)  {
	    this.minToSell = minToSell; 
	}
	

	public String toString() {
		StringBuilder builder = new StringBuilder();
		builder.append("Seller");		
		builder.append("\n  id: ");
		builder.append(id);
		builder.append("\n  name: ");
		builder.append(name);
		builder.append("\n  minToSell: ");
		builder.append(minToSell);
		return builder.toString();
	}
}


and...

/*
 * GENERATED by SnailDB. DO NOT CHANGE!
 *
 * Created on 10/07/2005
 */
import java.io.*;
import java.math.*;
import java.util.*;
import org.snaildb.exception.*;
import org.snaildb.base.*;

/**
 * @author SnailDB
 */
public class Customer implements Serializable, Data {

    private static final long serialVersionUID = 1L;

	private Long id ;
	private String name ;
	private Double limitCredit  = new Double(100) ;

	public Customer() { super(); }

	public Long getId() { return id; }
	public String getName() { return name; }
	public Double getLimitCredit() { return limitCredit; }

	public void setId(Long id)  {
	    this.id = id; 
	}
	
	public void setName(String name) throws OutOfBoundsException  {
		if (name.length() > 300) {
			throw new OutOfBoundsException("name", name.length(), 300);
		}    			
	    this.name = name; 
	}
	
	public void setLimitCredit(Double limitCredit)  {
	    this.limitCredit = limitCredit; 
	}
	

	public String toString() {
		StringBuilder builder = new StringBuilder();
		builder.append("Customer");		
		builder.append("\n  id: ");
		builder.append(id);
		builder.append("\n  name: ");
		builder.append(name);
		builder.append("\n  limitCredit: ");
		builder.append(limitCredit);
		return builder.toString();
	}
}



As you can see, the basic architecture is implemented and working.

Any releases will be lauched now. If you want to be a developer, send me an e-mail and welcome :D

Permalink Comments [8]

06/18/2005 - JavaFreeCMS AJAXed
JavaFree is using DWR, an Asynchronous JavaScript Technology and XML (AJAX) framework, to make some links asynchronous. There are two links using it, at main page the links of each news and job offer.

This is only a test to analyze what our members think about this new technology. If aproved by members , we will put into all CMS.

Try it: JavaFree.org

Permalink Comments [6]

« JavaFreeCMS and JavaBB go live...

    * Home
    * About
    * Weblog
    * Fotolog
    * Projects
    * Curriculum 


Please, don't be afraid about the english on this blog. I'm learning yet.



Project+

    * Baba XP
    * ByeCicle
    * Eclipse
    * JForms
    * JavaBB
    * JavaFreeCMS
    * M3GE
    * OpenNuke
    * Prevayler
    * RSSNotifier
    * SnailDB
    * Tex-BR


Blog+

    * Carlos Villela
    * Dalton Camargo
    * Dave Johnson
    * Flávio R Bianchi
    * Jonathan Schwartz
    * Marcelo Eduardo
    * Matt Raible
    * Michael Nascimento Santos
    * Phillip Calçado
    * Rafael Steil
    * Rodrigo Bamboo


Cool+

    * Java.net
    * JavaFree.org
    * JavaLobby.org
    * The Server Side


Posts XML

    * Java 5.0_6 BUG: JOptionPane.showInternalMessageDialog() killing methods
    * JavaCC: becoming easy a compiler development
    * Relief Texture Mapping
    * The first cell phone for deaf people
    * Java API Specifications in portuguese
    * RSSNotifier: An RSS Feeds Reader on System Tray
    * Solve your problems with ByeCycle
    * Google Maps on your Mobile?
    * SnailDB, the JDBC driver for Prevayler is running
    * JavaFreeCMS AJAXed
    * JavaFreeCMS and JavaBB go live on JavaFree Community
    * Java vs .NET
    * JavaFreeCMS ON, WebWork + Prevayler
    * Camera and Textures in a Mobile 3D Game Engine?
    * reflection.Proxy
    * 3D on J2ME, it is running!
    * Master, new company or a better job?
    * Why Hibernate? Be Simple!
    * Who let the nerds out?
    * public threadable void process() { ... }
    * OR frameworks: Good or bad solution?
    * New Design :D
    * NYTimes: Brazil: Free Software's Biggest and Best Friend
    * Benchmarking M3G (Mobile 3D Graphics API)
    * Importing OBJ models in M3G (JSR-184)
    * New features at Hibernate 3
    * M3E, Mobile 3D Game Engine based on M3G (JSR-184)
    * SQL X OO
    * Google, can we live without you?
    * One hour more, please
    * Python is cool...
    * JavaBB, phpbb in Java.
    * SnailDB, JDBC Driver for Prevayler
    * Spring. We really need it?
    * Free Meeting, Great Wallpaper!
    * Make By Yourself and Teach All
    * Javac compiling a simple OQL
    * Interview with Klaus Wuestefeld, of Prevayler
    * No, please. Documents NO!
    * No Software Patents
    * Nokia 6630. I wanna it!
    * Java Web Services and J2ME
    * Interview with Gavin King at JavaFree.org
    * One nation under Linux, welcome to Brazil!
    * FC 2, sendmail-cf not installed
    * Mobile 3D Graphics API for J2ME
    * Baba XP: A Extreme Programming Projects Manager
    * Who is Vitor Fernando Pamplona?


Navegação

JRoller
comments
About
Weblog
Login
Desenvolvido por NONO ANDAR DESIGN.Todos os direitos Reservados a Vitor Pamplona.


Writing Mixins using AspectJ
by Mohan Radhakrishnan
12/15/2005

Contents
AspectJ Tooling
Crosscutting Concern
What Exactly Is a Mixin?
Inter-Type Declarations
or Introductions
The AOP Implementation
Without Mixins
AOP Mixin Implementation
AOP Mixin Implementation
with AspectJ 5 and JSE 5.0
Incremental Compilation Bug
Conclusion
Resources

Aspect-oriented programming complements object-oriented programming in many ways. One interesting complementary feature is behavior composability. This means that it should be possible to compose a class by adding behavior from different classes. OO uses inheritance and many patterns to add behavior to existing classes. AOP allows us to use mixins without changing the class inheritance hierarchy or otherwise changing the code.

Mixins enable us to uniformly extend a set of classes with a set of fields and methods. Java does not support mixin-based programming. This article shows what mixins are and explains how AOP constructs in AspectJ allow us to use this technique to isolate crosscutting concerns, with an example. It starts with a plain Java implementation and ends with an AspectJ 5 implementation.
AspectJ Tooling
AspectJ programs can be compiled either using the command-line compiler ajc, which is included in the AspectJ distribution, or by using better tooling support in the form of AspectJ Development Tools for Eclipse (AJDT). All of the benefits of an Integrated Development Environment are now also available for AspectJ projects. I used the latest versions of Eclipse and AJDT to compile these examples, which, as of the writing of this article, were Eclipse 3.1.1 and AJDT 1.2. See the Resources section for a very good description of AJDT and how to create AspectJ projects in Eclipse.
Crosscutting Concern

A class is the fundamental unit of manipulation in Java. Concerns that crosscut this modular unit could be isolated so that such code is not spread out across the codebase. This will make their modification easier. It should also be easy to add a concern without changing the code that this will affect.

Our crosscutting concern is the notification of changes to Java bean properties. JavaBeans can have bound properties. This means that we can register listeners to get notification when the value of the property changes. The java.beans package contains the classes and interfaces required to implement this functionality.

The following code shows the plain Java implementation.


import java.beans.PropertyChangeEvent;
import java.beans.PropertyChangeListener;
import java.beans.PropertyChangeSupport;
import java.io.Serializable;

public class Bean implements Serializable {

    private String name;

    private PropertyChangeSupport support =
                    new  PropertyChangeSupport(this);

    public void addPropertyChangeListener
                       (PropertyChangeListener listener){

            support.addPropertyChangeListener(listener);

    }

    public void addPropertyChangeListener
                            ( String propertyName,
                  PropertyChangeListener listener){

            support.addPropertyChangeListener(propertyName,
                                              listener);

    }

    public void removePropertyChangeListener
                            ( String propertyName,
              PropertyChangeListener listener) {

            support.removePropertyChangeListener( propertyName,
                                                  listener);

    }

    public void removePropertyChangeListener
                            (PropertyChangeListener listener) {

            support.removePropertyChangeListener(listener);

    }

    public void hasListeners( String propertyName ) {

            support.hasListeners(propertyName);

    }

    void firePropertyChange( Bean b,
                             String property,
                             String oldval,
                             String newval) {

            support.firePropertyChange( property,
                                        ( oldval == null ) ?
                                              oldval :
                                              new String(oldval),
                                              new String(newval));

    }

    public String getName() {

            return name;

    }

    public void setName( String name ) {

            firePropertyChange( this,
                                "name",
                                getName(),
                                name );
            this.name = name;

    }
}

The important points in the code are:

    * We can delegate listener maintenance tasks to the PropertyChangeSupport class.
    * The firePropertyChange method, which is called after the property changes, notifies the PropertyChangeListeners.

The code shown above mixes event listener code with a simple Java bean that declares properties and getter and setter methods for them. We could separate the event listener concern into a separate class that all JavaBeans must extend, but that does not ensure that the concern is truly separable. It is still linked by the OO inheritance hierarchy. This is where AOP complements OO, by introducing the concept of a mixin, which is not properly addressed by an object-oriented language like Java.

The following is the JUnit test case based on the self-shunt pattern (see Resources).


import java.beans.PropertyChangeEvent;
import java.beans.PropertyChangeListener;
import junit.framework.TestCase;

public class BeanTestCase extends TestCase
                 implements PropertyChangeListener{

       private String lastName;

       public void setUp() throws Exception{
               super.setUp();
       }

       public void TearDown() throws Exception{
               super.setUp();
       }

    public void propertyChange(PropertyChangeEvent e){
        System.out.println("Property [" +
                           e.getPropertyName() +
                           "[ changed from " +
                           e.getOldValue() + " to " +
                           e.getNewValue() );
         lastName = e.getNewValue() == null ? null :
                                 (String)e.getNewValue();
   }

       public void testPropertyChange(){
               Bean b = new Bean();
               b.addPropertyChangeListener( "name", this );
               b.setName( "Test" );
           if( lastName != null )assertEquals( b.getName() ,
                                               lastName );
           b.setName( "Test1" );
           if( lastName != null )assertEquals( b.getName() ,
                                           lastName );
       }
}

The JUnit TestCase shown above registers itself as a PropertyChangeListener so that when the bound property changes, it is notified via a propertyChange(PropertyChangeEvent e) method that is called. The parameter PropertyChangeEvent contains both the old and the new values. This test case plays the role of the listener, thereby obviating the need for a separate listener.

Now let us see how aspect-oriented mixin programming enables us to specify crosscutting concerns in one place and compose them with existing classes without changing the Java code.


Javalobby | EclipseZone | JavaForge | JDocs | JRoller | Javacrawl | JUGCentral | MyJavaServer | ADVERTISE
Username/Email: Password: SIGN IN | JOIN NOW!

    * Home
    * Features
          o Submit an article
          o Presentations and Articles
          o JavaPolis 2004 Online
          o JavaZone 2005
          o Announcements
          o Newsletters
    * Forums
          o Overview
          o Help & FAQ
          o Posting guidelines
          o Recent postings
          o Popular discussions
          o Who's online
    * Blogs
          o Popular blogs
          o Start your free blog
          o Recent blog entries
    * JL Network
          o Javalobby.org
          o Javacrawl.com
          o JDocs.com
          o JRoller.com
          o JUGCentral.com
          o MyJavaServer.com
          o Friends & Partners
    * Members Only
          o Control Panel
          o Subscriptions
          o Downloads
          o Benefits
          o Special Offers
    * About JL
          o Our story
          o Sites & Services
          o In the News
          o Privacy policy
          o Contact us
          o Advertising info
          o FAQ

About the Author
Marc Domenig - Consultant for international IT companies and banking corporations. Senior Vice President and Head of Web Engineering and Systems Engineering at UBS, the largest Swiss banking corporation. Founder and CEO of Canoo Engineering, provider of J2EE software and services.
Discuss this review with Marc
Spotlight Features
[Universal Logger Plugins for RCP Applications]
Universal Logger Plugins for RCP Applications
John Franey explains how RCP application and plug-in developers can incorporate logging using a variety of standard APIs. A group of logger plug-ins are created that can become part of your development toolbox.
[Rich Internet Applications and AJAX - Selecting the best product]
Rich Internet Applications and AJAX - Selecting the best product
There are hundreds of criteria for choosing RIA and AJAX products. It?s easy to lose focus and misjudge priorities. Marc Domenig of Canoo takes you through some of the decisions you have to make when choosing an RIA framework.
[Eclipse Data Tools Platform: History, Structure & Plans]
Eclipse Data Tools Platform: History, Structure & Plans
The Eclipse Data Tools Platform (DTP) project is a new top-level project at eclipse.org for managing data. Project leader John Graham provides a detailed look at the Data Tools Platform project in this article.
[Book Review: Eclipse Rich Client Platform]
Book Review: Eclipse Rich Client Platform
Wayne Beaton has just written a review of the new Eclipse Rich Client Platform book by Platform committers Jeff McAffer and Jean-Michel Lemieux. Every RCP developer should take a look at this.
[The Eclipse Add-In Provider Ecosystem - A Win For All]
The Eclipse Add-In Provider Ecosystem - A Win For All
The Eclipse Add-In Providers are a diverse group of software vendors. Understand how these members benefit from Eclipse while working hand in hand with their competitors in this guest article by Catalyst CEO Tracy Ragan.
Rich Internet Applications and AJAX - Selecting the best product

There are hundreds of criteria for evaluating RIA and AJAX products. So many that it?s easy to lose focus and misjudge priorities. This essay proposes a decision tree that leads through an evaluation process. It asks for the most distinctive requirements and product features in a top-down sequence, discussing the essential differences between technology options.

Figure 1: Decision Tree

The focus is entirely on questions you should answer when evaluating RIA products. There is no assessment of specific products, because the individual features of products tend to obscure fundamental issues. Notice that RIA and AJAX are sometimes used as synonyms. This is not entirely correct: AJAX is short for ?Asynchronous JavaScript And XML?, which essentially limits the term to the set of RIA solutions based on JavaScript. I will adhere to this latter definition, although I fully agree with authors who argue that the concepts proposed by AJAX are by no means limited to JavaScript [1].
Simple User Interface?

The first and most important question to ask is whether the user interface (UI) of your application is simple enough for HTML. If the answer is yes, then HTML is your best option because it enables ubiquitous end user access via browser.

Simple enough for HTML means that the UI has modest interactivity requirements. However, if any of the following features improves your UI, you should consider RIA technology:

    * Partial screen updates
    * Asynchronous communication
    * Server push
    * Widgets supporting direct manipulation
    * Multiple coordinated windows
    * Modal dialogs
    * Menus
    * Keyboard navigation 

RIA technology provides rich client capabilities in a web infrastructure. The goal is to combine the advantages of desktop applications with those of web applications. There are three fundamentally different technology options to achieve this: JavaScript, Java, and Flash. Their respective core advantages lead to the next level of the decision tree.
Ubiquity, Industrial Strength, or Fancy Animations?

Figure 2: RIA Technology Subtree

The question that differentiates RIA technology is whether unconditional end user access via browser (ubiquity), industrial strength, or fancy animations are most important. If ubiquity is the answer, a JavaScript/AJAX based solution will be the favorite, because JavaScript is available ?out-of-the-box? in every popular browser. If industrial strength characteristics like maintainability, reliability, availability, scalability, performance and security are the top requirements, a Java solution is likely to be the front-runner. Java is unquestionably superior to the scripting alternatives in these areas. Last but not least, if fancy animations are your primary requirement, the attractiveness of Flash may outweigh the arguments speaking for the alternatives. The following sections look closer at these three technology options and present questions you should ask when assessing corresponding products.
Ubiquity: JavaScript/AJAX

Figure 3: JavaScript/AJAX Branch

AJAX is neither a product nor a new technology but a new branding for RIA technology that is based on JavaScript, XML, and other technologies. Since most JavaScript based products have adopted the AJAX terminology, it?s reasonable to put them in a single category. JavaScript/AJAX products are appropriate in situations where the user expects an application to work unconditionally in browsers. When buying a DVD or booking a flight, for instance, nobody will want to install a plug-in.

Plain HTML remains the best solution for simple UI requirements. Yet, DVD stores or travel booking applications with simple UIs are often vexing or even useless. Anyone who has tried to book an itinerary with multiple flights, hotels, and rental cars will agree that current websites are painful to use. JavaScript/AJAX could help here. Unfortunately, there?s only a handful of ?killer? applications that show what?s possible: Google Suggest and Google Maps are among them. Cited as the key examples by Jesse James Garrett in his defining article on AJAX [2], they are arguably the most popular JavaScript based RIAs on the web.

Selecting RIA products based on JavaScript/AJAX is challenging. The issue is that JavaScript is hard to deal with. It?s no coincidence that it took the skills and funds of Google to come up with ?killer? applications. Internet giants like Amazon or Ebay are not leveraging the potential of JavaScript/AJAX, although the technology has been around for years and would potentially improve their websites substantially. Just imagine how their sites would profit by ?search as you type?, scrolling lists, partial screen updates, or browseable category trees.

The following questions will help in deciding whether an RIA product based on JavaScript/AJAX is suitable for your needs.
Browsers and OS supported?

JavaScript implementations are not standardized across browsers and operating systems. This means that programs must be aware of the browser, the operating system, and their respective versions. Programs must execute different code depending on specific combinations thereof, which is a developer?s nightmare. The most essential characteristic of a JavaScript/AJAX product is, therefore, how well it handles these combinations and shields the developer from the complexity of managing them in application code. The combinations supported by the Google applications may serve as a benchmark for evaluation. Google Maps and Google Suggest support:

    * IE 6.0+ on Windows
    * Firefox 0.8+ on Windows, Mac, Linux
    * Safari 1.2.4+ on Mac (Google Suggest 1.2.2 or newer)
    * Netscape 7.1+ on Windows, Mac, Linux
    * Mozilla 1.4+ on Windows, Mac, Linux
    * Opera 8+ on Windows, Mac, Linux (Google Suggest 7.5.4+) 

RIA Functions?

JavaScript was designed for scripting rather than full-fledged rich client development. For this reason, a JavaScript/AJAX product may not necessarily support all RIA functions mentioned. Partial screen updates, asynchronous communication, modal dialogs and menus will probably be available. But other RIA goodies may be severely limited in functionality or missing altogether. Typically, the set of rich UI widgets that supports direct manipulation will be poor compared to those we find in toolkits for desktop applications. Important questions to ask include:

    * how does the widget set compare to standard sets like those of Java Swing?
    * is the look&feel adaptable?
    * is there an API for the development of new widgets?
    * is it possible to integrate third-party widgets?
    * what is the market for third-party widgets?
    * is there support for Accessibility?

How Strong?

Industrial strength characteristics like maintainability, reliability, availability, scalability, performance and security are a challenge for JavaScript/AJAX products because they have to rely on a scripting language and must work in a heterogeneous set of execution environments. It is unrealistic to expect the kind of industrial strength that can be found in a homogeneous Java product. Yet, there is a wide range of options regarding the amount of code that needs to be executed in the shaky JavaScript environment. The complete range of architectures shown in Figure 4 is feasible.

Figure 4: RIA Architecture Options

JavaScript code can be limited to an application-independent presentation engine that comes with the product, as illustrated by the rightmost option in Figure 4. This pure thin-client approach has several advantages: applications can be written entirely in Java, with a single programming environment. Moreover, there is a homogeneous server-side programming model, and no need to distribute the application code between client and server, nor between different programming languages. This simplifies both development and testing substantially. Finally, the application code will execute primarily in the robust server-side environment.

Note that pure thin-client architectures are rare in JavaScript based UIs. The typical approach is to split the functionality between client and server individually for each application as shown by the three left-hand options in Figure 4: either within the presentation logic, within the business logic, or between business logic and data. The leftmost option represents a pure fat-client architecture where the entire application code is written in JavaScript. Fat-client or hybrid approaches may be appropriate for certain scenarios. But for industrial strength characteristics, a pure thin-client architecture is preferable. Crucial questions are, therefore:

    * what architecture is supported or enforced: thin, fat, or hybrid?
    * is the programming model server-side or distributed?
    * is application code written purely in Java or in a heterogeneous mixture of languages including JavaScript, Java, and proprietary XML languages?
    * how much of the product?s code is JavaScript?
    * how can security be handled? 

Industrial Strength: Java

Figure 5: Java Branch

RIA products that are based entirely on Java have the best foundation for industrial strength. Java?s solid standards base, homogeneous technology, broad choice in high-quality tooling, and bright perspective regarding future enhancements ensure that a well-designed product can be maintained cost effectively and for any length of time in the foreseeable future. Reliability, availability, scalability and security are given on a wide array of platforms.

Designed for full-fledged productivity applications, Java?s UI technology leaves nothing to be desired regarding rich-client functions. There are comprehensive, customizable widget toolkits for desktops as well as mobile devices, and numerous third-party libraries.

In contrast to many JavaScript products, Java RIA offerings typically follow a thin-client approach as shown by the rightmost picture in Figure 4: the client is an application independent presentation engine that can be executed either as an applet in a browser, or as a Java program on the desktop, or even on a PDA.

The questions that distinguish Java RIAs ask for the JREs (Java Runtime Environment) supported, the UI libraries employed, and leverage of Java standards.
JRE Versions Supported?

Compared to the execution environments for JavaScript, JRE implementations are more standardized. Programs written with a specific JDK (Java Developer?s Kit) will usually run in the corresponding JRE, irrespective of whether this JRE is running within a browser, on a desktop operating system, or on a device like a PDA. The version issue is primarily raised on the level of the JRE and the target environments that support that JRE.

Most RIA products support multiple JRE versions. Some are based on JDK 1.1 with its AWT widget library and will run on JRE 1.1 or later. Others are using Swing and will run on JRE 1.2 or later. The respective pros and cons of earlier or later versions must be evaluated carefully, because the earliest version supported defines the ?least common denominator?. A low ?denominator? product based on the low-level AWT will often run on more JREs because later Java versions are fairly downward compatible. A high ?denominator? product based on the higher-level Swing will be able to leverage the improvements of new Java versions. The most important questions are:

    * what are the target devices/environments for the end users?
    * which JREs are available and easily installable on the targets?
    * on which JREs does the product run?
    * which JRE is the ?least common denominator? of the product?
    * does the product leverage improvements of later JDK/JRE versions? 

UI Libraries Employed?

Java?s client-side UI technology has evolved substantially. The initial low-level library AWT has been complemented with the high-level Swing library, and the latter has substantially improved over the years. The Eclipse project has come up with its own low-level and high-level UI libraries SWT and JFace, respectively. RIA products offer the functionality of high-level libraries. Yet, some of them have chosen to implement the high-level functions themselves and use low-level libraries on the client. This has pros and cons. On the upside, a low-level approach can support multiple UI libraries on the client, under the condition that the functionality is limited to the ?common denominator? of these libraries. On the downside, the low-level approach will lead to a layer of proprietary software that needs to be maintained. With a high-level library, the proprietary depth of a product can be reduced to a minimum. Even the API can be taken from the standard library, as described by Bernhard Wagner in his article on ?Server-Side Swing? [3]. Such an RIA product will have a minimal proprietary footprint and will profit from enhancements of the standard Swing library as it evolves. Essential drill-down questions on the UI libraries are:

    * is the product based on low-level libraries (AWT, SWT) or high-level libraries (Swing, JFace)?
          o low: does it support multiple UI libraries on the client?
          o high: is the API proprietary or a server-side proxy approach? 
    * what is the proprietary footprint of the UI technology?
    * is there an extension API for the development of new widgets?
    * is it possible to integrate third-party widgets?
    * can the look&feel be customized?
    * is there support for Accessibility? 

Standards Leverage?

Java standards are a key driver for reducing the proprietary share in a software stack. We have seen that the proprietary footprint of an RIA product?s client-side UI technology can vary considerably. Similar assessments can be made for the server-side part of RIA products, and the communication between client and server. J2EE defines standards that limit client/server communication, for instance, to request/reply protocols and specific transports such as HTTP(S) or RMI/IIOP. Moreover, EJBs disallow multi-threading that is not managed by the container, thereby ensuring that scaling measures like clustering can be handled by the J2EE infrastructure. RIA products that come with their own servers/proxies or allow bi-directional communication violate these standards and will need proprietary software that replaces the corresponding functions of the standard infrastructure. In general, a product that fully leverages the Java standards should have no function of its own if that same function can be delegated to the standard infrastructure. The following questions help in assessing standards leverage:

    * is session handling delegated to the J2EE container or does the product come with a proprietary server/proxy?
    * is clustering supported and delegated to the J2EE platform?
    * is communication handled by J2EE compliant protocols?
    * is deployment configurable and possible both in a servlet container and an EJB container?
    * is deployment as a portlet possible, according to the JSR 168 standard?
    * can the client part and server part be run in a single process for stand-alone deployment, leveraging the Java VM standards? 

Fancy Animations: Flash

Figure 6: Flash Branch

Flash has its main strength in animations. This is not surprising, because it was created to animate websites. The core Flash technology includes an execution environment (the Flash player), a binary file format for movies (SWF), and a scripting language (ActionScript). Comfortable end-user tools that generate SWF and support ActionScript programming are available for designing movies and websites. Flash-based RIA products for application development are comparatively new. As a consequence, both the core technology and RIA tools are evolving. This emphasizes the importance of the version issue, not only for the execution environment, but the programming model and programming tools as well.

From an architectural perspective, the Flash-based approaches are close to those relying on JavaScript/AJAX. There is a scripting language that allows code to be sent to the client at run-time. Products can provide an array of architectural options, ranging from fat client to thin client as shown in Figure 4. The relevant questions are, therefore, close to those you should ask for JavaScript/AJAX.
Flash Versions Supported?

The core Flash technology is proprietary and tightly controlled by the vendor. Programs written for a specific version will run in the browsers and on the operating systems that are supported. The version issue is raised on the level of the Flash player, ActionScript, and the SWF format generated by an RIA product. The questions you need to ask are equivalent to those for the Java products:

    * what are the target devices/environments for the end users?
    * which Flash players are available and easily installable on the targets?
    * on which players does the product run?
    * which player is the ?least common denominator? of the product?
    * does the product leverage improvements of later ActionScript/SWF/player versions?

RIA Functions?

ActionScript, SWF and the Flash player were originally not designed for full-fledged rich client development. For this reason, you should ask the same questions as for JavaScript/AJAX products:

    * how does the widget set compare to standard sets like those of Java Swing?
    * is the look&feel adaptable?
    * is there an API for the development of new widgets?
    * is it possible to integrate third-party widgets?
    * what is the market for third-party widgets?
    * is there support for Accessibility? 

How strong?

Relying on a scripting language like the JavaScript/AJAX approaches, Flash-based products have a similar range of options regarding the execution of code in the client-side environment. ActionScript can be limited to an application independent presentation engine that comes with the product, enforcing a pure thin-client architecture as shown in the rightmost picture of Figure 4. Alternatively, the developer can be given the option to write arbitrary application code with ActionScript, allowing for hybrid or fat client architectures. In general, a thin-client architecture will lead to superior industrial strength, as discussed above.

Current Flash-based RIA products don?t support a pure thin-client architecture. They provide a heterogeneous programming model and require a hybrid set of tools for the various programming languages that need to be combined. This can be acceptable for industrial strength if their scope is limited to creating animations rather than transferring substantial parts of the application code to the client. Useful questions for an evaluation are:

    * what architecture is supported or enforced: thin, fat, or hybrid?
    * is the programming model server-side or distributed?
    * is application code written purely in Java or in a heterogeneous mixture of languages including ActionScript, Java, and proprietary XML languages?
    * how large, powerful and proprietary is the set of tools required?
    * is usage of ActionScript and proprietary tools limited to the presentation layer of applications?
    * how can security be handled? 

Conclusion

RIA and AJAX are new terms for a technology that has been around for years. Given the hype for these terms, it is difficult to differentiate between products. They vary substantially in their technical foundation and their suitability for specific requirements. Careful product evaluation is essential. The decision tree presented in this essay helps asking the right questions and leads through the most important decisions.
References

[1] Coach K. Wey: AJAX: Asynchronous Java + XML?
http://www.developer.com/design/article.php/3526681
[2] Jesse James Garrett: AJAX: A New Approach to Web Applications,
http://www.adaptivepath.com/publications/essays/archives/000385.php
[3] Bernhard Wagner: Server-Side Swing for Rich Internet Applications,
http://javadesktop.org/articles/canoo/index.html


Click Here! Get Firefox!  Powered by Jive Software Powered by Caucho Resin!


HIBERNATE - Relational Persistence for Idiomatic Java
Hibernate Reference Documentation

3.1

Table of Contents

Preface
1. Introduction to Hibernate

    1.1. Preface
    1.2. Part 1 - The first Hibernate Application

        1.2.1. The first class
        1.2.2. The mapping file
        1.2.3. Hibernate configuration
        1.2.4. Building with Ant
        1.2.5. Startup and helpers
        1.2.6. Loading and storing objects

    1.3. Part 2 - Mapping associations

        1.3.1. Mapping the Person class
        1.3.2. A unidirectional Set-based association
        1.3.3. Working the association
        1.3.4. Collection of values
        1.3.5. Bi-directional associations
        1.3.6. Working bi-directional links

    1.4. Part 3 - The EventManager web application

        1.4.1. Writing the basic servlet
        1.4.2. Processing and rendering
        1.4.3. Deploying and testing

    1.5. Summary

2. Architecture

    2.1. Overview
    2.2. Instance states
    2.3. JMX Integration
    2.4. JCA Support
    2.5. Contextual Sessions

3. Configuration

    3.1. Programmatic configuration
    3.2. Obtaining a SessionFactory
    3.3. JDBC connections
    3.4. Optional configuration properties

        3.4.1. SQL Dialects
        3.4.2. Outer Join Fetching
        3.4.3. Binary Streams
        3.4.4. Second-level and query cache
        3.4.5. Query Language Substitution
        3.4.6. Hibernate statistics

    3.5. Logging
    3.6. Implementing a NamingStrategy
    3.7. XML configuration file
    3.8. J2EE Application Server integration

        3.8.1. Transaction strategy configuration
        3.8.2. JNDI-bound SessionFactory
        3.8.3. Current Session context management with JTA
        3.8.4. JMX deployment

4. Persistent Classes

    4.1. A simple POJO example

        4.1.1. Implement a no-argument constructor
        4.1.2. Provide an identifier property (optional)
        4.1.3. Prefer non-final classes (optional)
        4.1.4. Declare accessors and mutators for persistent fields (optional)

    4.2. Implementing inheritance
    4.3. Implementing equals() and hashCode()
    4.4. Dynamic models
    4.5. Tuplizers

5. Basic O/R Mapping

    5.1. Mapping declaration

        5.1.1. Doctype
        5.1.2. hibernate-mapping
        5.1.3. class
        5.1.4. id

            5.1.4.1. Generator
            5.1.4.2. Hi/lo algorithm
            5.1.4.3. UUID algorithm
            5.1.4.4. Identity columns and sequences
            5.1.4.5. Assigned identifiers
            5.1.4.6. Primary keys assigned by triggers

        5.1.5. composite-id
        5.1.6. discriminator
        5.1.7. version (optional)
        5.1.8. timestamp (optional)
        5.1.9. property
        5.1.10. many-to-one
        5.1.11. one-to-one
        5.1.12. natural-id
        5.1.13. component, dynamic-component
        5.1.14. properties
        5.1.15. subclass
        5.1.16. joined-subclass
        5.1.17. union-subclass
        5.1.18. join
        5.1.19. key
        5.1.20. column and formula elements
        5.1.21. import
        5.1.22. any

    5.2. Hibernate Types

        5.2.1. Entities and values
        5.2.2. Basic value types
        5.2.3. Custom value types

    5.3. Mapping a class more than once
    5.4. SQL quoted identifiers
    5.5. Metadata alternatives

        5.5.1. Using XDoclet markup
        5.5.2. Using JDK 5.0 Annotations

    5.6. Generated Properties
    5.7. Auxiliary Database Objects

6. Collection Mapping

    6.1. Persistent collections
    6.2. Collection mappings

        6.2.1. Collection foreign keys
        6.2.2. Collection elements
        6.2.3. Indexed collections
        6.2.4. Collections of values and many-to-many associations
        6.2.5. One-to-many associations

    6.3. Advanced collection mappings

        6.3.1. Sorted collections
        6.3.2. Bidirectional associations
        6.3.3. Bidirectional associations with indexed collections
        6.3.4. Ternary associations
        6.3.5. Using an <idbag>

    6.4. Collection examples

7. Association Mappings

    7.1. Introduction
    7.2. Unidirectional associations

        7.2.1. many to one
        7.2.2. one to one
        7.2.3. one to many

    7.3. Unidirectional associations with join tables

        7.3.1. one to many
        7.3.2. many to one
        7.3.3. one to one
        7.3.4. many to many

    7.4. Bidirectional associations

        7.4.1. one to many / many to one
        7.4.2. one to one

    7.5. Bidirectional associations with join tables

        7.5.1. one to many / many to one
        7.5.2. one to one
        7.5.3. many to many

    7.6. More complex association mappings

8. Component Mapping

    8.1. Dependent objects
    8.2. Collections of dependent objects
    8.3. Components as Map indices
    8.4. Components as composite identifiers
    8.5. Dynamic components

9. Inheritance Mapping

    9.1. The Three Strategies

        9.1.1. Table per class hierarchy
        9.1.2. Table per subclass
        9.1.3. Table per subclass, using a discriminator
        9.1.4. Mixing table per class hierarchy with table per subclass
        9.1.5. Table per concrete class
        9.1.6. Table per concrete class, using implicit polymorphism
        9.1.7. Mixing implicit polymorphism with other inheritance mappings

    9.2. Limitations

10. Working with objects

    10.1. Hibernate object states
    10.2. Making objects persistent
    10.3. Loading an object
    10.4. Querying

        10.4.1. Executing queries

            10.4.1.1. Iterating results
            10.4.1.2. Queries that return tuples
            10.4.1.3. Scalar results
            10.4.1.4. Bind parameters
            10.4.1.5. Pagination
            10.4.1.6. Scrollable iteration
            10.4.1.7. Externalizing named queries

        10.4.2. Filtering collections
        10.4.3. Criteria queries
        10.4.4. Queries in native SQL

    10.5. Modifying persistent objects
    10.6. Modifying detached objects
    10.7. Automatic state detection
    10.8. Deleting persistent objects
    10.9. Replicating object between two different datastores
    10.10. Flushing the Session
    10.11. Transitive persistence
    10.12. Using metadata

11. Transactions And Concurrency

    11.1. Session and transaction scopes

        11.1.1. Unit of work
        11.1.2. Long conversations
        11.1.3. Considering object identity
        11.1.4. Common issues

    11.2. Database transaction demarcation

        11.2.1. Non-managed environment
        11.2.2. Using JTA
        11.2.3. Exception handling
        11.2.4. Transaction timeout

    11.3. Optimistic concurrency control

        11.3.1. Application version checking
        11.3.2. Extended session and automatic versioning
        11.3.3. Detached objects and automatic versioning
        11.3.4. Customizing automatic versioning

    11.4. Pessimistic Locking
    11.5. Connection Release Modes

12. Interceptors and events

    12.1. Interceptors
    12.2. Event system
    12.3. Hibernate declarative security

13. Batch processing

    13.1. Batch inserts
    13.2. Batch updates
    13.3. The StatelessSession interface
    13.4. DML-style operations

14. HQL: The Hibernate Query Language

    14.1. Case Sensitivity
    14.2. The from clause
    14.3. Associations and joins
    14.4. Forms of join syntax
    14.5. The select clause
    14.6. Aggregate functions
    14.7. Polymorphic queries
    14.8. The where clause
    14.9. Expressions
    14.10. The order by clause
    14.11. The group by clause
    14.12. Subqueries
    14.13. HQL examples
    14.14. Bulk update and delete
    14.15. Tips & Tricks

15. Criteria Queries

    15.1. Creating a Criteria instance
    15.2. Narrowing the result set
    15.3. Ordering the results
    15.4. Associations
    15.5. Dynamic association fetching
    15.6. Example queries
    15.7. Projections, aggregation and grouping
    15.8. Detached queries and subqueries
    15.9. Queries by natural identifier

16. Native SQL

    16.1. Using a SQLQuery
    16.2. Alias and property references
    16.3. Named SQL queries

        16.3.1. Using return-property to explicitly specify column/alias names
        16.3.2. Using stored procedures for querying

            16.3.2.1. Rules/limitations for using stored procedures

    16.4. Custom SQL for create, update and delete
    16.5. Custom SQL for loading

17. Filtering data

    17.1. Hibernate filters

18. XML Mapping

    18.1. Working with XML data

        18.1.1. Specifying XML and class mapping together
        18.1.2. Specifying only an XML mapping

    18.2. XML mapping metadata
    18.3. Manipulating XML data

19. Improving performance

    19.1. Fetching strategies

        19.1.1. Working with lazy associations
        19.1.2. Tuning fetch strategies
        19.1.3. Single-ended association proxies
        19.1.4. Initializing collections and proxies
        19.1.5. Using batch fetching
        19.1.6. Using subselect fetching
        19.1.7. Using lazy property fetching

    19.2. The Second Level Cache

        19.2.1. Cache mappings
        19.2.2. Strategy: read only
        19.2.3. Strategy: read/write
        19.2.4. Strategy: nonstrict read/write
        19.2.5. Strategy: transactional

    19.3. Managing the caches
    19.4. The Query Cache
    19.5. Understanding Collection performance

        19.5.1. Taxonomy
        19.5.2. Lists, maps, idbags and sets are the most efficient collections to update
        19.5.3. Bags and lists are the most efficient inverse collections
        19.5.4. One shot delete

    19.6. Monitoring performance

        19.6.1. Monitoring a SessionFactory
        19.6.2. Metrics

20. Toolset Guide

    20.1. Automatic schema generation

        20.1.1. Customizing the schema
        20.1.2. Running the tool
        20.1.3. Properties
        20.1.4. Using Ant
        20.1.5. Incremental schema updates
        20.1.6. Using Ant for incremental schema updates
        20.1.7. Schema validation
        20.1.8. Using Ant for schema validation

21. Example: Parent/Child

    21.1. A note about collections
    21.2. Bidirectional one-to-many
    21.3. Cascading lifecycle
    21.4. Cascades and unsaved-value
    21.5. Conclusion

22. Example: Weblog Application

    22.1. Persistent Classes
    22.2. Hibernate Mappings
    22.3. Hibernate Code

23. Example: Various Mappings

    23.1. Employer/Employee
    23.2. Author/Work
    23.3. Customer/Order/Product
    23.4. Miscellaneous example mappings

        23.4.1. "Typed" one-to-one association
        23.4.2. Composite key example
        23.4.3. Many-to-many with shared composite key attribute
        23.4.4. Content based discrimination
        23.4.5. Associations on alternate keys

24. Best Practices

Preface

Working with object-oriented software and a relational database can be cumbersome and time consuming in today's enterprise environments. Hibernate is an object/relational mapping tool for Java environments. The term object/relational mapping (ORM) refers to the technique of mapping a data representation from an object model to a relational data model with a SQL-based schema.

Hibernate not only takes care of the mapping from Java classes to database tables (and from Java data types to SQL data types), but also provides data query and retrieval facilities and can significantly reduce development time otherwise spent with manual data handling in SQL and JDBC.

Hibernates goal is to relieve the developer from 95 percent of common data persistence related programming tasks. Hibernate may not be the best solution for data-centric applications that only use stored-procedures to implement the business logic in the database, it is most useful with object-oriented domain models and business logic in the Java-based middle-tier. However, Hibernate can certainly help you to remove or encapsulate vendor-specific SQL code and will help with the common task of result set translation from a tabular representation to a graph of objects.

If you are new to Hibernate and Object/Relational Mapping or even Java, please follow these steps:

   1.

      Read Chapter 1, Introduction to Hibernate for a tutorial with step-by-step instructions. The source code for the tutorial is included in the distribution in the doc/reference/tutorial/ directory.
   2.

      Read Chapter 2, Architecture to understand the environments where Hibernate can be used.
   3.

      Have a look at the eg/ directory in the Hibernate distribution, it contains a simple standalone application. Copy your JDBC driver to the lib/ directory and edit etc/hibernate.properties, specifying correct values for your database. From a command prompt in the distribution directory, type ant eg (using Ant), or under Windows, type build eg.
   4.

      Use this reference documentation as your primary source of information. Consider reading Hibernate in Action (http://www.manning.com/bauer) if you need more help with application design or if you prefer a step-by-step tutorial. Also visit http://caveatemptor.hibernate.org and download the example application for Hibernate in Action.
   5.

      FAQs are answered on the Hibernate website.
   6.

      Third party demos, examples, and tutorials are linked on the Hibernate website.
   7.

      The Community Area on the Hibernate website is a good resource for design patterns and various integration solutions (Tomcat, JBoss AS, Struts, EJB, etc.). 

If you have questions, use the user forum linked on the Hibernate website. We also provide a JIRA issue trackings system for bug reports and feature requests. If you are interested in the development of Hibernate, join the developer mailing list. If you are interested in translating this documentation into your language, contact us on the developer mailing list.

Commercial development support, production support, and training for Hibernate is available through JBoss Inc. (see http://www.hibernate.org/SupportTraining/). Hibernate is a Professional Open Source project and a critical component of the JBoss Enterprise Middleware System (JEMS) suite of products.
Chapter 1. Introduction to Hibernate
1.1. Preface

This chapter is an introductory tutorial for new users of Hibernate. We start with a simple command line application using an in-memory database and develop it in easy to understand steps.

This tutorial is intended for new users of Hibernate but requires Java and SQL knowledge. It is based on a tutorial by Michael Gloegl, the third-party libraries we name are for JDK 1.4 and 5.0. You might need others for JDK 1.3.

The source code for the tutorial is included in the distribution in the doc/reference/tutorial/ directory.
1.2. Part 1 - The first Hibernate Application

First, we'll create a simple console-based Hibernate application. We use an Java database (HSQL DB), so we do not have to install any database server.

Let's assume we need a small database application that can store events we want to attend, and information about the hosts of these events.

The first thing we do, is set up our development directory and put all the Java libraries we need into it. Download the Hibernate distribution from the Hibernate website. Extract the package and place all required libraries found in /lib into into the /lib directory of your new development working directory. It should look like this:

.
+lib
  antlr.jar
  cglib.jar
  asm.jar
  asm-attrs.jars
  commons-collections.jar
  commons-logging.jar
  hibernate3.jar
  jta.jar
  dom4j.jar
  log4j.jar 

This is the minimum set of required libraries (note that we also copied hibernate3.jar, the main archive) for Hibernate. See the README.txt file in the lib/ directory of the Hibernate distribution for more information about required and optional third-party libraries. (Actually, Log4j is not required but preferred by many developers.)

Next we create a class that represents the event we want to store in database.
1.2.1. The first class

Our first persistent class is a simple JavaBean class with some properties:

package events;

import java.util.Date;

public class Event {
    private Long id;

    private String title;
    private Date date;

    public Event() {}

    public Long getId() {
        return id;
    }

    private void setId(Long id) {
        this.id = id;
    }

    public Date getDate() {
        return date;
    }

    public void setDate(Date date) {
        this.date = date;
    }

    public String getTitle() {
        return title;
    }

    public void setTitle(String title) {
        this.title = title;
    }
}

You can see that this class uses standard JavaBean naming conventions for property getter and setter methods, as well as private visibility for the fields. This is a recommended design - but not required. Hibernate can also access fields directly, the benefit of accessor methods is robustness for refactoring. The no-argument constructor is required to instantiate an object of this class through reflection.

The id property holds a unique identifier value for a particular event. All persistent entity classes (there are less important dependent classes as well) will need such an identifier property if we want to use the full feature set of Hibernate. In fact, most applications (esp. web applications) need to distinguish objects by identifier, so you should consider this a feature rather than a limitation. However, we usually don't manipulate the identity of an object, hence the setter method should be private. Only Hibernate will assign identifiers when an object is saved. You can see that Hibernate can access public, private, and protected accessor methods, as well as (public, private, protected) fields directly. The choice is up to you and you can match it to fit your application design.

The no-argument constructor is a requirement for all persistent classes; Hibernate has to create objects for you, using Java Reflection. The constructor can be private, however, package visibility is required for runtime proxy generation and efficient data retrieval without bytecode instrumentation.

Place this Java source file in a directory called src in the development folder, and in its correct package. The directory should now look like this:

.
+lib
  <Hibernate and third-party libraries>
+src
  +events
    Event.java

In the next step, we tell Hibernate about this persistent class.
1.2.2. The mapping file

Hibernate needs to know how to load and store objects of the persistent class. This is where the Hibernate mapping file comes into play. The mapping file tells Hibernate what table in the database it has to access, and what columns in that table it should use.

The basic structure of a mapping file looks like this:

<?xml version="1.0"?>
<!DOCTYPE hibernate-mapping PUBLIC
        "-//Hibernate/Hibernate Mapping DTD 3.0//EN"
        "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd">

<hibernate-mapping>
[...]
</hibernate-mapping>

Note that the Hibernate DTD is very sophisticated. You can use it for auto-completion of XML mapping elements and attributes in your editor or IDE. You also should open up the DTD file in your text editor - it's the easiest way to get an overview of all elements and attributes and to see the defaults, as well as some comments. Note that Hibernate will not load the DTD file from the web, but first look it up from the classpath of the application. The DTD file is included in hibernate3.jar as well as in the src/ directory of the Hibernate distribution.

We will omit the DTD declaration in future examples to shorten the code. It is of course not optional.

Between the two hibernate-mapping tags, include a class element. All persistent entity classes (again, there might be dependent classes later on, which are not first-class entities) need such a mapping, to a table in the SQL database:

<hibernate-mapping>

    <class name="events.Event" table="EVENTS">

    </class>

</hibernate-mapping>

So far we told Hibernate how to persist and load object of class Event to the table EVENTS, each instance represented by a row in that table. Now we continue with a mapping of the unique identifier property to the tables primary key. In addition, as we don't want to care about handling this identifier, we configure Hibernate's identifier generation strategy for a surrogate primary key column:

<hibernate-mapping>

    <class name="events.Event" table="EVENTS">
        <id name="id" column="EVENT_ID">
            <generator class="native"/>
        </id>
    </class>

</hibernate-mapping>

The id element is the declaration of the identifer property, name="id" declares the name of the Java property - Hibernate will use the getter and setter methods to access the property. The column attribute tells Hibernate which column of the EVENTS table we use for this primary key. The nested generator element specifies the identifier generation strategy, in this case we used native, which picks the best strategy depending on the configured database (dialect). Hibernate supports database generated, globally unique, as well as application assigned identifiers (or any strategy you have written an extension for).

Finally we include declarations for the persistent properties of the class in the mapping file. By default, no properties of the class are considered persistent:

<hibernate-mapping>

    <class name="events.Event" table="EVENTS">
        <id name="id" column="EVENT_ID">
            <generator class="native"/>
        </id>
        <property name="date" type="timestamp" column="EVENT_DATE"/>
        <property name="title"/>
    </class>

</hibernate-mapping>

Just as with the id element, the name attribute of the property element tells Hibernate which getter and setter methods to use. So, in this case, Hibernate will look for getDate()/setDate(), as well as getTitle()/setTitle().

Why does the date property mapping include the column attribute, but the title doesn't? Without the column attribute Hibernate by default uses the property name as the column name. This works fine for title. However, date is a reserved keyword in most database, so we better map it to a different name.

The next interesting thing is that the title mapping also lacks a type attribute. The types we declare and use in the mapping files are not, as you might expect, Java data types. They are also not SQL database types. These types are so called Hibernate mapping types, converters which can translate from Java to SQL data types and vice versa. Again, Hibernate will try to determine the correct conversion and mapping type itself if the type attribute is not present in the mapping. In some cases this automatic detection (using Reflection on the Java class) might not have the default you expect or need. This is the case with the date property. Hibernate can't know if the property (which is of java.util.Date) should map to a SQL date, timestamp, or time column. We preserve full date and time information by mapping the property with a timestamp converter.

This mapping file should be saved as Event.hbm.xml, right in the directory next to the Event Java class source file. The naming of mapping files can be arbitrary, however the hbm.xml suffix is a convention in the Hibernate developer community. The directory structure should now look like this:

.
+lib
  <Hibernate and third-party libraries>
+src
  +events
    Event.java
    Event.hbm.xml

We continue with the main configuration of Hibernate.
1.2.3. Hibernate configuration

We now have a persistent class and its mapping file in place. It is time to configure Hibernate. Before we do this, we will need a database. HSQL DB, a java-based SQL DBMS, can be downloaded from the HSQL DB website. Actually, you only need the hsqldb.jar from this download. Place this file in the lib/ directory of the development folder.

Create a directory called data in the root of the development directory - this is where HSQL DB will store its data files. Now start the database by running java -classpath lib/hsqldb.jar org.hsqldb.Server in your work directory. You can see it start up and bind to a TCP/IP socket, this is where our application will connect later. If you want to start with a fresh database during this tutorial, shutdown HSQL DB (press CTRL + C in the window), delete the data/ directory, and start HSQL DB again.

Hibernate is the layer in your application which connects to this database, so it needs connection information. The connections are made through a JDBC connection pool, which we also have to configure. The Hibernate distribution contains several open source JDBC connection pooling tools, but will use the Hibernate built-in connection pool for this tutorial. Note that you have to copy the required library into your classpath and use different connection pooling settings if you want to use a production-quality third party JDBC pooling software.

For Hibernate's configuration, we can use a simple hibernate.properties file, a slightly more sophisticated hibernate.cfg.xml file, or even complete programmatic setup. Most users prefer the XML configuration file:

<?xml version='1.0' encoding='utf-8'?>
<!DOCTYPE hibernate-configuration PUBLIC
        "-//Hibernate/Hibernate Configuration DTD 3.0//EN"
        "http://hibernate.sourceforge.net/hibernate-configuration-3.0.dtd">

<hibernate-configuration>

    <session-factory>

        <!-- Database connection settings -->
        <property name="connection.driver_class">org.hsqldb.jdbcDriver</property>
        <property name="connection.url">jdbc:hsqldb:hsql://localhost</property>
        <property name="connection.username">sa</property>
        <property name="connection.password"></property>

        <!-- JDBC connection pool (use the built-in) -->
        <property name="connection.pool_size">1</property>

        <!-- SQL dialect -->
        <property name="dialect">org.hibernate.dialect.HSQLDialect</property>

        <!-- Enable Hibernate's automatic session context management -->
        <property name="current_session_context_class">thread</property>

        <!-- Disable the second-level cache  -->
        <property name="cache.provider_class">org.hibernate.cache.NoCacheProvider</property>

        <!-- Echo all executed SQL to stdout -->
        <property name="show_sql">true</property>

        <!-- Drop and re-create the database schema on startup -->
        <property name="hbm2ddl.auto">create</property>

        <mapping resource="events/Event.hbm.xml"/>

    </session-factory>

</hibernate-configuration>

Note that this XML configuration uses a different DTD. We configure Hibernate's SessionFactory - a global factory responsible for a particular database. If you have several databases, use several <session-factory> configurations, usually in several configuration files (for easier startup).

The first four property elements contain the necessary configuration for the JDBC connection. The dialect property element specifies the particular SQL variant Hibernate generates. Hibernate's automatic session management for persistence contexts will come in handy as you will soon see. The hbm2ddl.auto option turns on automatic generation of database schemas - directly into the database. This can of course also be turned off (by removing the config option) or redirected to a file with the help of the SchemaExport Ant task. Finally, we add the mapping file(s) for persistent classes to the configuration.

Copy this file into the source directory, so it will end up in the root of the classpath. Hibernate automatically looks for a file called hibernate.cfg.xml in the root of the classpath, on startup.
1.2.4. Building with Ant

We'll now build the tutorial with Ant. You will need to have Ant installed - get it from the Ant download page. How to install Ant will not be covered here. Please refer to the Ant manual. After you have installed Ant, we can start to create the buildfile. It will be called build.xml and placed directly in the development directory.

A basic build file looks like this:

<project name="hibernate-tutorial" default="compile">

    <property name="sourcedir" value="${basedir}/src"/>
    <property name="targetdir" value="${basedir}/bin"/>
    <property name="librarydir" value="${basedir}/lib"/>

    <path id="libraries">
        <fileset dir="${librarydir}">
            <include name="*.jar"/>
        </fileset>
    </path>

    <target name="clean">
        <delete dir="${targetdir}"/>
        <mkdir dir="${targetdir}"/>
    </target>

    <target name="compile" depends="clean, copy-resources">
      <javac srcdir="${sourcedir}"
             destdir="${targetdir}"
             classpathref="libraries"/>
    </target>

    <target name="copy-resources">
        <copy todir="${targetdir}">
            <fileset dir="${sourcedir}">
                <exclude name="**/*.java"/>
            </fileset>
        </copy>
    </target>

</project>

This will tell Ant to add all files in the lib directory ending with .jar to the classpath used for compilation. It will also copy all non-Java source files to the target directory, e.g. configuration and Hibernate mapping files. If you now run Ant, you should get this output:

C:\hibernateTutorial\>ant
Buildfile: build.xml

copy-resources:
     [copy] Copying 2 files to C:\hibernateTutorial\bin

compile:
    [javac] Compiling 1 source file to C:\hibernateTutorial\bin

BUILD SUCCESSFUL
Total time: 1 second 

1.2.5. Startup and helpers

It's time to load and store some Event objects, but first we have to complete the setup with some infrastructure code. We have to startup Hibernate. This startup includes building a global SessionFactory object and to store it somewhere for easy access in application code. A SessionFactory can open up new Session's. A Session represents a single-threaded unit of work, the SessionFactory is a thread-safe global object, instantiated once.

We'll create a HibernateUtil helper class which takes care of startup and makes accessing a SessionFactory convenient. Let's have a look at the implementation:

package util;

import org.hibernate.*;
import org.hibernate.cfg.*;

public class HibernateUtil {

    private static final SessionFactory sessionFactory;

    static {
        try {
            // Create the SessionFactory from hibernate.cfg.xml
            sessionFactory = new Configuration().configure().buildSessionFactory();
        } catch (Throwable ex) {
            // Make sure you log the exception, as it might be swallowed
            System.err.println("Initial SessionFactory creation failed." + ex);
            throw new ExceptionInInitializerError(ex);
        }
    }

    public static SessionFactory getSessionFactory() {
        return sessionFactory;
    }

}

This class does not only produce the global SessionFactory in its static initializer (called once by the JVM when the class is loaded), but also hides the fact that it uses a static singleton. It might as well lookup the SessionFactory from JNDI in an application server.

If you give the SessionFactory a name in your configuration file, Hibernate will in fact try to bind it to JNDI after it has been built. To avoid this code completely you could also use JMX deployment and let the JMX-capable container instantiate and bind a HibernateService to JNDI. These advanced options are discussed in the Hibernate reference documentation.

Place HibernateUtil.java in the development source directory, in a package next to events:

.
+lib
  <Hibernate and third-party libraries>
+src
  +events
    Event.java
    Event.hbm.xml
  +util
    HibernateUtil.java
  hibernate.cfg.xml
+data
build.xml

This should again compile without problems. We finally need to configure a logging system - Hibernate uses commons logging and leaves you the choice between Log4j and JDK 1.4 logging. Most developers prefer Log4j: copy log4j.properties from the Hibernate distribution (it's in the etc/ directory) to your src directory, next to hibernate.cfg.xml. Have a look at the example configuration and change the settings if you like to have more verbose output. By default, only Hibernate startup message are shown on stdout.

The tutorial infrastructure is complete - and we are ready to do some real work with Hibernate.
1.2.6. Loading and storing objects

Finally, we can use Hibernate to load and store objects. We write an EventManager class with a main() method:

package events;
import org.hibernate.Session;

import java.util.Date;

import util.HibernateUtil;

public class EventManager {

    public static void main(String[] args) {
        EventManager mgr = new EventManager();

        if (args[0].equals("store")) {
            mgr.createAndStoreEvent("My Event", new Date());
        }

        HibernateUtil.getSessionFactory().close();
    }

    private void createAndStoreEvent(String title, Date theDate) {

        Session session = HibernateUtil.getSessionFactory().getCurrentSession();

        session.beginTransaction();

        Event theEvent = new Event();
        theEvent.setTitle(title);
        theEvent.setDate(theDate);

        session.save(theEvent);

        session.getTransaction().commit();
    }

}

We create a new Event object, and hand it over to Hibernate. Hibernate now takes care of the SQL and executes INSERTs on the database. Let's have a look at the Session and Transaction-handling code before we run this.

A Session is a single unit of work. For now we'll keep things simple and assume a one-to-one granularity between a Hibernate Session and a database transaction. To shield our code from the actual underlying transaction system (in this case plain JDBC, but it could also run with JTA) we use the Transaction API that is available on the Hibernate Session.

What does sessionFactory.getCurrentSession() do? First, you can call it as many times and anywhere you like, once you get hold of your SessionFactory (easy thanks to HibernateUtil). The getCurrentSession() method always returns the "current" unit of work. Remember that we switched the configuration option for this mechanism to "thread" in hibernate.cfg.xml? Hence, the scope of the current unit of work is the current Java thread that executes our application. However, this is not the full truth. A Session begins when it is first needed, when the first call to getCurrentSession() is made. It is then bound by Hibernate to the current thread. When the transaction ends, either committed or rolled back, Hibernate also unbinds the Session from the thread and closes it for you. If you call getCurrentSession() again, you get a new Session and can start a new unit of work. This thread-bound programming model is the most popular way of using Hibernate.

Have a look at Chapter 11, Transactions And Concurrency for more information about transaction handling and demarcation. We also skipped any error handling and rollback in the previous example.

To run this first routine we have to add a callable target to the Ant build file:

<target name="run" depends="compile">
    <java fork="true" classname="events.EventManager" classpathref="libraries">
        <classpath path="${targetdir}"/>
        <arg value="${action}"/>
    </java>
</target>

The value of the action argument is set on the command line when calling the target:

C:\hibernateTutorial\>ant run -Daction=store

You should see, after compilation, Hibernate starting up and, depending on your configuration, lots of log output. At the end you will find the following line:

[java] Hibernate: insert into EVENTS (EVENT_DATE, title, EVENT_ID) values (?, ?, ?)

This is the INSERT executed by Hibernate, the question marks represent JDBC bind parameters. To see the values bound as arguments, or to reduce the verbosity of the log, check your log4j.properties.

Now we'd like to list stored events as well, so we add an option to the main method:

if (args[0].equals("store")) {
    mgr.createAndStoreEvent("My Event", new Date());
}
else if (args[0].equals("list")) {
    List events = mgr.listEvents();
    for (int i = 0; i < events.size(); i++) {
        Event theEvent = (Event) events.get(i);
        System.out.println("Event: " + theEvent.getTitle() +
                           " Time: " + theEvent.getDate());
    }
}

We also add a new listEvents() method:

private List listEvents() {

    Session session = HibernateUtil.getSessionFactory().getCurrentSession();

    session.beginTransaction();

    List result = session.createQuery("from Event").list();

    session.getTransaction().commit();

    return result;
}

What we do here is use an HQL (Hibernate Query Language) query to load all existing Event objects from the database. Hibernate will generate the appropriate SQL, send it to the database and populate Event objects with the data. You can create more complex queries with HQL, of course.

Now, to execute and test all of this, follow these steps:

    *

      Run ant run -Daction=store to store something into the database and, of course, to generate the database schema before through hbm2ddl.
    *

      Now disable hbm2ddl by commenting out the property in your hibernate.cfg.xml file. Usually you only leave it turned on in continous unit testing, but another run of hbm2ddl would drop everything you have stored - the create configuration setting actually translates into "drop all tables from the schema, then re-create all tables, when the SessionFactory is build". 

If you now call Ant with -Daction=list, you should see the events you have stored so far. You can of course also call the store action a few times more.

Note: Most new Hibernate users fail at this point and we see questions about Table not found error messages regularly. However, if you follow the steps outlined above you will not have this problem, as hbm2ddl creates the database schema on the first run, and subsequent application restarts will use this schema. If you change the mapping and/or database schema, you have to re-enable hbm2ddl once again.
1.3. Part 2 - Mapping associations

We mapped a persistent entity class to a table. Let's build on this and add some class associations. First we'll add people to our application, and store a list of events they participate in.
1.3.1. Mapping the Person class

The first cut of the Person class is simple:

package events;

public class Person {

    private Long id;
    private int age;
    private String firstname;
    private String lastname;

    public Person() {}

    // Accessor methods for all properties, private setter for 'id'

}

Create a new mapping file called Person.hbm.xml (don't forget the DTD reference at the top):

<hibernate-mapping>

    <class name="events.Person" table="PERSON">
        <id name="id" column="PERSON_ID">
            <generator class="native"/>
        </id>
        <property name="age"/>
        <property name="firstname"/>
        <property name="lastname"/>
    </class>

</hibernate-mapping>

Finally, add the new mapping to Hibernate's configuration:

<mapping resource="events/Event.hbm.xml"/>
<mapping resource="events/Person.hbm.xml"/>

We'll now create an association between these two entities. Obviously, persons can participate in events, and events have participants. The design questions we have to deal with are: directionality, multiplicity, and collection behavior.
1.3.2. A unidirectional Set-based association

We'll add a collection of events to the Person class. That way we can easily navigate to the events for a particular person, without executing an explicit query - by calling aPerson.getEvents(). We use a Java collection, a Set, because the collection will not contain duplicate elements and the ordering is not relevant for us.

We need a unidirectional, many-valued associations, implemented with a Set. Let's write the code for this in the Java classes and then map it:

public class Person {

    private Set events = new HashSet();

    public Set getEvents() {
        return events;
    }

    public void setEvents(Set events) {
        this.events = events;
    }
}

Before we map this association, think about the other side. Clearly, we could just keep this unidirectional. Or, we could create another collection on the Event, if we want to be able to navigate it bi-directional, i.e. anEvent.getParticipants(). This is not necessary, from a functional perspective. You could always execute an explicit query to retrieve the participants for a particular event. This is a design choice left to you, but what is clear from this discussion is the multiplicity of the association: "many" valued on both sides, we call this a many-to-many association. Hence, we use Hibernate's many-to-many mapping:

<class name="events.Person" table="PERSON">
    <id name="id" column="PERSON_ID">
        <generator class="native"/>
    </id>
    <property name="age"/>
    <property name="firstname"/>
    <property name="lastname"/>

    <set name="events" table="PERSON_EVENT">
        <key column="PERSON_ID"/>
        <many-to-many column="EVENT_ID" class="Event"/>
    </set>

</class>

Hibernate supports all kinds of collection mappings, a <set> being most common. For a many-to-many association (or n:m entity relationship), an association table is needed. Each row in this table represents a link between a person and an event. The table name is configured with the table attribute of the set element. The identifier column name in the association, for the person's side, is defined with the <key> element, the column name for the event's side with the column attribute of the <many-to-many>. You also have to tell Hibernate the class of the objects in your collection (correct: the class on the other side of the collection of references).

The database schema for this mapping is therefore:

    _____________        __________________
   |             |      |                  |       _____________
   |   EVENTS    |      |   PERSON_EVENT   |      |             |
   |_____________|      |__________________|      |    PERSON   |
   |             |      |                  |      |_____________|
   | *EVENT_ID   | <--> | *EVENT_ID        |      |             |
   |  EVENT_DATE |      | *PERSON_ID       | <--> | *PERSON_ID  |
   |  TITLE      |      |__________________|      |  AGE        |
   |_____________|                                |  FIRSTNAME  |
                                                  |  LASTNAME   |
                                                  |_____________|
 

1.3.3. Working the association

Let's bring some people and events together in a new method in EventManager:

private void addPersonToEvent(Long personId, Long eventId) {

    Session session = HibernateUtil.getSessionFactory().getCurrentSession();
    session.beginTransaction();

    Person aPerson = (Person) session.load(Person.class, personId);
    Event anEvent = (Event) session.load(Event.class, eventId);

    aPerson.getEvents().add(anEvent);

    session.getTransaction().commit();
}

After loading a Person and an Event, simply modify the collection using the normal collection methods. As you can see, there is no explicit call to update() or save(), Hibernate automatically detects that the collection has been modified and needs to be updated. This is called automatic dirty checking, and you can also try it by modifying the name or the date property of any of your objects. As long as they are in persistent state, that is, bound to a particular Hibernate Session (i.e. they have been just loaded or saved in a unit of work), Hibernate monitors any changes and executes SQL in a write-behind fashion. The process of synchronizing the memory state with the database, usually only at the end of a unit of work, is called flushing. In our code, the unit of work ends with a commit (or rollback) of the database transaction - as defined by the thread configuration option for the CurrentSessionContext class.

You might of course load person and event in different units of work. Or you modify an object outside of a Session, when it is not in persistent state (if it was persistent before, we call this state detached). You can even modify a collection when it is detached:

private void addPersonToEvent(Long personId, Long eventId) {

    Session session = HibernateUtil.getSessionFactory().getCurrentSession();
    session.beginTransaction();

    Person aPerson = (Person) session
            .createQuery("select p from Person p left join fetch p.events where p.id = :pid")
            .setParameter("pid", personId)
            .uniqueResult(); // Eager fetch the collection so we can use it detached

    Event anEvent = (Event) session.load(Event.class, eventId);

    session.getTransaction().commit();

    // End of first unit of work

    aPerson.getEvents().add(anEvent); // aPerson (and its collection) is detached

    // Begin second unit of work

    Session session2 = HibernateUtil.getSessionFactory().getCurrentSession();
    session2.beginTransaction();

    session2.update(aPerson); // Reattachment of aPerson

    session2.getTransaction().commit();
}

The call to update makes a detached object persistent again, you could say it binds it to a new unit of work, so any modifications you made to it while detached can be saved to the database. This includes any modifications (additions/deletions) you made to a collection of that entity object.

Well, this is not much use in our current situation, but it's an important concept you can design into your own application. For now, complete this exercise by adding a new action to the EventManager's main method and call it from the command line. If you need the identifiers of a person and an event - the save() method returns it (you might have to modify some of the previous methods to return that identifier):

else if (args[0].equals("addpersontoevent")) {
    Long eventId = mgr.createAndStoreEvent("My Event", new Date());
    Long personId = mgr.createAndStorePerson("Foo", "Bar");
    mgr.addPersonToEvent(personId, eventId);
    System.out.println("Added person " + personId + " to event " + eventId);

This was an example of an association between two equally important classes, two entities. As mentioned earlier, there are other classes and types in a typical model, usually "less important". Some you have already seen, like an int or a String. We call these classes value types, and their instances depend on a particular entity. Instances of these types don't have their own identity, nor are they shared between entities (two persons don't reference the same firstname object, even if they have the same first name). Of course, value types can not only be found in the JDK (in fact, in a Hibernate application all JDK classes are considered value types), but you can also write dependent classes yourself, Address or MonetaryAmount, for example.

You can also design a collection of value types. This is conceptually very different from a collection of references to other entities, but looks almost the same in Java.
1.3.4. Collection of values

We add a collection of value typed objects to the Person entity. We want to store email addresses, so the type we use is String, and the collection is again a Set:

private Set emailAddresses = new HashSet();

public Set getEmailAddresses() {
    return emailAddresses;
}

public void setEmailAddresses(Set emailAddresses) {
    this.emailAddresses = emailAddresses;
}

The mapping of this Set:

<set name="emailAddresses" table="PERSON_EMAIL_ADDR">
    <key column="PERSON_ID"/>
    <element type="string" column="EMAIL_ADDR"/>
</set>

The difference compared with the earlier mapping is the element part, which tells Hibernate that the collection does not contain references to another entity, but a collection of elements of type String (the lowercase name tells you it's a Hibernate mapping type/converter). Once again, the table attribute of the set element determines the table name for the collection. The key element defines the foreign-key column name in the collection table. The column attribute in the element element defines the column name where the String values will actually be stored.

Have a look at the updated schema:

  _____________        __________________
 |             |      |                  |       _____________
 |   EVENTS    |      |   PERSON_EVENT   |      |             |       ___________________
 |_____________|      |__________________|      |    PERSON   |      |                   |
 |             |      |                  |      |_____________|      | PERSON_EMAIL_ADDR |
 | *EVENT_ID   | <--> | *EVENT_ID        |      |             |      |___________________|
 |  EVENT_DATE |      | *PERSON_ID       | <--> | *PERSON_ID  | <--> |  *PERSON_ID       |
 |  TITLE      |      |__________________|      |  AGE        |      |  *EMAIL_ADDR      |
 |_____________|                                |  FIRSTNAME  |      |___________________|
                                                |  LASTNAME   |
                                                |_____________|
 

You can see that the primary key of the collection table is in fact a composite key, using both columns. This also implies that there can't be duplicate email addresses per person, which is exactly the semantics we need for a set in Java.

You can now try and add elements to this collection, just like we did before by linking persons and events. It's the same code in Java:

private void addEmailToPerson(Long personId, String emailAddress) {

    Session session = HibernateUtil.getSessionFactory().getCurrentSession();
    session.beginTransaction();

    Person aPerson = (Person) session.load(Person.class, personId);

    // The getEmailAddresses() might trigger a lazy load of the collection
    aPerson.getEmailAddresses().add(emailAddress);

    session.getTransaction().commit();
}

This time we didnt' use a fetch query to initialize the collection. Hence, the call to its getter method will trigger an additional select to initialize it, so we can add an element to it. Monitor the SQL log and try to optimize this with an eager fetch.
1.3.5. Bi-directional associations

Next we are going to map a bi-directional association - making the association between person and event work from both sides in Java. Of course, the database schema doesn't change, we still have many-to-many multiplicity. A relational database is more flexible than a network programming language, so it doesn't need anything like a navigation direction - data can be viewed and retrieved in any possible way.

First, add a collection of participants to the Event Event class:

private Set participants = new HashSet();

public Set getParticipants() {
    return participants;
}

public void setParticipants(Set participants) {
    this.participants = participants;
}

Now map this side of the association too, in Event.hbm.xml.

<set name="participants" table="PERSON_EVENT" inverse="true">
    <key column="EVENT_ID"/>
    <many-to-many column="PERSON_ID" class="events.Person"/>
</set>

As you see, these are normal set mappings in both mapping documents. Notice that the column names in key and many-to-many are swapped in both mapping documents. The most important addition here is the inverse="true" attribute in the set element of the Event's collection mapping.

What this means is that Hibernate should take the other side - the Person class - when it needs to find out information about the link between the two. This will be a lot easier to understand once you see how the bi-directional link between our two entities is created .
1.3.6. Working bi-directional links

First, keep in mind that Hibernate does not affect normal Java semantics. How did we create a link between a Person and an Event in the unidirectional example? We added an instance of Event to the collection of event references, of an instance of Person. So, obviously, if we want to make this link working bi-directional, we have to do the same on the other side - adding a Person reference to the collection in an Event. This "setting the link on both sides" is absolutely necessary and you should never forget doing it.

Many developers program defensive and create a link management methods to correctly set both sides, e.g. in Person:

protected Set getEvents() {
    return events;
}

protected void setEvents(Set events) {
    this.events = events;
}

public void addToEvent(Event event) {
    this.getEvents().add(event);
    event.getParticipants().add(this);
}

public void removeFromEvent(Event event) {
    this.getEvents().remove(event);
    event.getParticipants().remove(this);
}

Notice that the get and set methods for the collection are now protected - this allows classes in the same package and subclasses to still access the methods, but prevents everybody else from messing with the collections directly (well, almost). You should probably do the same with the collection on the other side.

What about the inverse mapping attribute? For you, and for Java, a bi-directional link is simply a matter of setting the references on both sides correctly. Hibernate however doesn't have enough information to correctly arrange SQL INSERT and UPDATE statements (to avoid constraint violations), and needs some help to handle bi-directional associations properly. Making one side of the association inverse tells Hibernate to basically ignore it, to consider it a mirror of the other side. That's all that is necessary for Hibernate to work out all of the issues when transformation a directional navigation model to a SQL database schema. The rules you have to remember are straightforward: All bi-directional associations need one side as inverse. In a one-to-many association it has to be the many-side, in many-to-many association you can pick either side, there is no difference.

Let's turn this into a small web application.
1.4. Part 3 - The EventManager web application

A Hibernate web application uses Session and Transaction almost like a standalone application. However, some common patterns are useful. We now write an EventManagerServlet. This servlet can list all events stored in the database, and it provides an HTML form to enter new events.
1.4.1. Writing the basic servlet

Create a new class in your source directory, in the events package:

package events;

// Imports

public class EventManagerServlet extends HttpServlet {

    private final SimpleDateFormat dateFormatter =
                            new SimpleDateFormat("dd.MM.yyyy");

    // Servlet code
}

The dateFormatter is a tool we'll need later to convert Date objects from and to strings. It makes sense to only have one formatter as a member of the servlet.

The servlet handles HTTP GET requests only, hence, the method we implement is doGet():

protected void doGet(HttpServletRequest request,
                     HttpServletResponse response)
        throws ServletException, IOException {

    try {
        // Begin unit of work
        HibernateUtil.getSessionFactory()
                .getCurrentSession().beginTransaction();

        // Process request and render page...

        // End unit of work
        HibernateUtil.getSessionFactory()
                .getCurrentSession().getTransaction().commit();

    } catch (Exception ex) {
        HibernateUtil.getSessionFactory()
                .getCurrentSession().getTransaction().rollback();
        throw new ServletException(ex);
    }

}

The pattern we are applying here is called session-per-request. When a request hits the servlet, a new Hibernate Session is opened through the first call to getCurrentSession() on the SessionFactory. Then a database transaction is started?all data access as to occur inside a transaction, no matter if data is read or written (we don't use the auto-commit mode in applications).

Next, the possible actions of the request are processed and the response HTML is rendered. We'll get to that part soon.

Finally, the unit of work ends when processing and rendering is complete. If any problem occured during processing or rendering, an exception will be thrown and the database transaction rolled back. This completes the session-per-request pattern. Instead of the transaction demarcation code in every servlet you could also write a servlet filter. See the Hibernate website and Wiki for more information about this pattern, called Open Session in View?you'll need it as soon as you consider rendering your view in JSP, not in a servlet.
1.4.2. Processing and rendering

Let's implement the processing of the request and rendering of the page.

// Write HTML header
PrintWriter out = response.getWriter();
out.println("<html><head><title>Event Manager</title></head><body>");

// Handle actions
if ( "store".equals(request.getParameter("action")) ) {

    String eventTitle = request.getParameter("eventTitle");
    String eventDate = request.getParameter("eventDate");

    if ( "".equals(eventTitle) || "".equals(eventDate) ) {
        out.println("<b><i>Please enter event title and date.</i></b>");
    } else {
        createAndStoreEvent(eventTitle, dateFormatter.parse(eventDate));
        out.println("<b><i>Added event.</i></b>");
    }
}

// Print page
printEventForm(out);
listEvents(out);

// Write HTML footer
out.println("</body></html>");
out.flush();
out.close();

Granted, this coding style with a mix of Java and HTML would not scale in a more complex application?keep in mind that we are only illustrating basic Hibernate concepts in this tutorial. The code prints an HTML header and a footer. Inside this page, an HTML form for event entry and a list of all events in the database are printed. The first method is trivial and only outputs HTML:

private void printEventForm(PrintWriter out) {
    out.println("<h2>Add new event:</h2>");
    out.println("<form>");
    out.println("Title: <input name='eventTitle' length='50'/><br/>");
    out.println("Date (e.g. 24.12.2009): <input name='eventDate' length='10'/><br/>");
    out.println("<input type='submit' name='action' value='store'/>");
    out.println("</form>");
}

The listEvents() method uses the Hibernate Session bound to the current thread to execute a query:

private void listEvents(PrintWriter out) {
    List result = HibernateUtil.getSessionFactory()
                    .getCurrentSession().createCriteria(Event.class).list();
    if (result.size() > 0) {
        out.println("<h2>Events in database:</h2>");
        out.println("<table border='1'>");
        out.println("<tr>");
        out.println("<th>Event title</th>");
        out.println("<th>Event date</th>");
        out.println("</tr>");
        for (Iterator it = result.iterator(); it.hasNext();) {
            Event event = (Event) it.next();
            out.println("<tr>");
            out.println("<td>" + event.getTitle() + "</td>");
            out.println("<td>" + dateFormatter.format(event.getDate()) + "</td>");
            out.println("</tr>");
        }
        out.println("</table>");
    }
}

Finally, the store action is dispatched to the createAndStoreEvent() method, which also uses the Session of the current thread:

protected void createAndStoreEvent(String title, Date theDate) {
    Event theEvent = new Event();
    theEvent.setTitle(title);
    theEvent.setDate(theDate);

    HibernateUtil.getSessionFactory()
                    .getCurrentSession().save(theEvent);
}

That's it, the servlet is complete. A request to the servlet will be processed in a single Session and Transaction. As earlier in the standalone application, Hibernate can automatically bind these ojects to the current thread of execution. This gives you the freedom to layer your code and access the SessionFactory in any way you like. Usually you'd use a more sophisticated design and move the data access code into data access objects (the DAO pattern). See the Hibernate Wiki for more examples.
1.4.3. Deploying and testing

To deploy this application you have to create a web archive, a WAR. Add the following Ant target to your build.xml:

<target name="war" depends="compile">
    <war destfile="hibernate-tutorial.war" webxml="web.xml">
        <lib dir="${librarydir}">
          <exclude name="jsdk*.jar"/>
        </lib>

        <classes dir="${targetdir}"/>
    </war>
</target>

This target creates a file called hibernate-tutorial.war in your project directory. It packages all libraries and the web.xml descriptor, which is expected in the base directory of your project:

<?xml version="1.0" encoding="UTF-8"?>
<web-app version="2.4"
    xmlns="http://java.sun.com/xml/ns/j2ee"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd">

    <servlet>
        <servlet-name>Event Manager</servlet-name>
        <servlet-class>events.EventManagerServlet</servlet-class>
    </servlet>

    <servlet-mapping>
        <servlet-name>Event Manager</servlet-name>
        <url-pattern>/eventmanager</url-pattern>
    </servlet-mapping>
</web-app>

Before you compile and deploy the web application, note that an additional library is required: jsdk.jar. This is the Java servlet development kit, if you don't have this library already, get it from the Sun website and copy it to your library directory. However, it will be only used for compliation and excluded from the WAR package.

To build and deploy call ant war in your project directory and copy the hibernate-tutorial.war file into your Tomcat webapp directory. If you don't have Tomcat installed, download it and follow the installation instructions. You don't have to change any Tomcat configuration to deploy this application though.

Once deployed and Tomcat is running, access the application at http://localhost:8080/hibernate-tutorial/eventmanager. Make sure you watch the Tomcat log to see Hibernate initialize when the first request hits your servlet (the static initializer in HibernateUtil is called) and to get the detailed output if any exceptions occurs.
1.5. Summary

This tutorial covered the basics of writing a simple standalone Hibernate application and a small web application.

If you already feel confident with Hibernate, continue browsing through the reference documentation table of contents for topics you find interesting - most asked are transactional processing (Chapter 11, Transactions And Concurrency), fetch performance (Chapter 19, Improving performance), or the usage of the API (Chapter 10, Working with objects) and the query features (Section 10.4, ?Querying?).

Don't forget to check the Hibernate website for more (specialized) tutorials.
Chapter 2. Architecture
2.1. Overview

A (very) high-level view of the Hibernate architecture:

This diagram shows Hibernate using the database and configuration data to provide persistence services (and persistent objects) to the application.

We would like to show a more detailed view of the runtime architecture. Unfortunately, Hibernate is flexible and supports several approaches. We will show the two extremes. The "lite" architecture has the application provide its own JDBC connections and manage its own transactions. This approach uses a minimal subset of Hibernate's APIs:

The "full cream" architecture abstracts the application away from the underlying JDBC/JTA APIs and lets Hibernate take care of the details.

Heres some definitions of the objects in the diagrams:

SessionFactory (org.hibernate.SessionFactory)

    A threadsafe (immutable) cache of compiled mappings for a single database. A factory for Session and a client of ConnectionProvider. Might hold an optional (second-level) cache of data that is reusable between transactions, at a process- or cluster-level. 
Session (org.hibernate.Session)

    A single-threaded, short-lived object representing a conversation between the application and the persistent store. Wraps a JDBC connection. Factory for Transaction. Holds a mandatory (first-level) cache of persistent objects, used when navigating the object graph or looking up objects by identifier. 
Persistent objects and collections

    Short-lived, single threaded objects containing persistent state and business function. These might be ordinary JavaBeans/POJOs, the only special thing about them is that they are currently associated with (exactly one) Session. As soon as the Session is closed, they will be detached and free to use in any application layer (e.g. directly as data transfer objects to and from presentation). 
Transient and detached objects and collections

    Instances of persistent classes that are not currently associated with a Session. They may have been instantiated by the application and not (yet) persisted or they may have been instantiated by a closed Session. 
Transaction (org.hibernate.Transaction)

    (Optional) A single-threaded, short-lived object used by the application to specify atomic units of work. Abstracts application from underlying JDBC, JTA or CORBA transaction. A Session might span several Transactions in some cases. However, transaction demarcation, either using the underlying API or Transaction, is never optional! 
ConnectionProvider (org.hibernate.connection.ConnectionProvider)

    (Optional) A factory for (and pool of) JDBC connections. Abstracts application from underlying Datasource or DriverManager. Not exposed to application, but can be extended/implemented by the developer. 
TransactionFactory (org.hibernate.TransactionFactory)

    (Optional) A factory for Transaction instances. Not exposed to the application, but can be extended/implemented by the developer. 
Extension Interfaces

    Hibernate offers many optional extension interfaces you can implement to customize the behavior of your persistence layer. See the API documentation for details. 

Given a "lite" architecture, the application bypasses the Transaction/TransactionFactory and/or ConnectionProvider APIs to talk to JTA or JDBC directly.
2.2. Instance states

An instance of a persistent classes may be in one of three different states, which are defined with respect to a persistence context. The Hibernate Session object is the persistence context:

transient

    The instance is not, and has never been associated with any persistence context. It has no persistent identity (primary key value). 
persistent

    The instance is currently associated with a persistence context. It has a persistent identity (primary key value) and, perhaps, a corresponding row in the database. For a particular persistence context, Hibernate guarantees that persistent identity is equivalent to Java identity (in-memory location of the object). 
detached

    The instance was once associated with a persistence context, but that context was closed, or the instance was serialized to another process. It has a persistent identity and, perhaps, a corrsponding row in the database. For detached instances, Hibernate makes no guarantees about the relationship between persistent identity and Java identity. 

2.3. JMX Integration

JMX is the J2EE standard for management of Java components. Hibernate may be managed via a JMX standard service. We provide an MBean implementation in the distribution, org.hibernate.jmx.HibernateService.

For an example how to deploy Hibernate as a JMX service on the JBoss Application Server, please see the JBoss User Guide. On JBoss AS, you also get these benefits if you deploy using JMX:

    *

      Session Management: The Hibernate Session's lifecycle can be automatically bound to the scope of a JTA transaction. This means you no longer have to manually open and close the Session, this becomes the job of a JBoss EJB interceptor. You also don't have to worry about transaction demarcation in your code anymore (unless you'd like to write a portable persistence layer of course, use the optional Hibernate Transaction API for this). You call the HibernateContext to access a Session.
    *

      HAR deployment: Usually you deploy the Hibernate JMX service using a JBoss service deployment descriptor (in an EAR and/or SAR file), it supports all the usual configuration options of a Hibernate SessionFactory. However, you still have to name all your mapping files in the deployment descriptor. If you decide to use the optional HAR deployment, JBoss will automatically detect all mapping files in your HAR file. 

Consult the JBoss AS user guide for more information about these options.

Another feature available as a JMX service are runtime Hibernate statistics. See Section 3.4.6, ?Hibernate statistics?.
2.4. JCA Support

Hibernate may also be configured as a JCA connector. Please see the website for more details. Please note that Hibernate JCA support is still considered experimental.
2.5. Contextual Sessions

Most applications using Hibernate need some form of "contextual" sessions, where a given session is in effect throughout the scope of a given context. However, across applications the definition of what constitutes a context is typically different; and different contexts define different scopes to the notion of current. Applications using Hibernate prior to version 3.0 tended to utilize either home-grown ThreadLocal-based contextual sessions, helper classes such as HibernateUtil, or utilized third-party frameworks (such as Spring or Pico) which provided proxy/interception-based contextual sessions.

Starting with version 3.0.1, Hibernate added the SessionFactory.getCurrentSession() method. Initially, this assumed usage of JTA transactions, where the JTA transaction defined both the scope and context of a current session. The Hibernate team maintains that, given the maturity of the numerous stand-alone JTA TransactionManager implementations out there, most (if not all) applications should be using JTA transaction management whether or not they are deployed into a J2EE container. Based on that, the JTA-based contextual sessions is all you should ever need to use.

However, as of version 3.1, the processing behind SessionFactory.getCurrentSession() is now pluggable. To that end, a new extension interface (org.hibernate.context.CurrentSessionContext) and a new configuration parameter (hibernate.current_session_context_class) have been added to allow pluggability of the scope and context of defining current sessions.

See the Javadocs for the org.hibernate.context.CurrentSessionContext interface for a detailed discussion of its contract. It defines a single method, currentSession(), by which the implementation is responsible for tracking the current contextual session. Out-of-the-box, Hibernate comes with two implementations of this interface.

    *

      org.hibernate.context.JTASessionContext - current sessions are tracked and scoped by a JTA transaction. The processing here is exactly the same as in the older JTA-only approach. See the Javadocs for details.
    *

      org.hibernate.context.ThreadLocalSessionContext - current sessions are tracked by thread of execution. Again, see the Javadocs for details. 

Both implementations provide a "one session - one database transaction" programming model, also known and used as session-per-request. The beginning and end of a Hibernate session is defined by the duration of a database transaction. If you use programatic transaction demarcation (e.g. in pure J2SE or with JTA/UserTransaction/BMT), you are adviced to use the Hibernate Transaction API to hide the underlying transaction system from your code. If you execute in an EJB container that supports CMT, transaction boundaries are defined declaratively and you don't need any transaction or session demarcation operations in your code. Refer to Chapter 11, Transactions And Concurrency for more information and code examples.

The hibernate.current_session_context_class configuration parameter defines which org.hibernate.context.CurrentSessionContext implementation should be used. Note that for backwards compatibility, if this config param is not set but a org.hibernate.transaction.TransactionManagerLookup is configured, Hibernate will use the org.hibernate.context.JTASessionContext. Typically, the value of this parameter would just name the implementation class to use; for the two out-of-the-box implementations, however, there are two corresponding short names, "jta" and "thread".
Chapter 3. Configuration

Because Hibernate is designed to operate in many different environments, there are a large number of configuration parameters. Fortunately, most have sensible default values and Hibernate is distributed with an example hibernate.properties file in etc/ that shows the various options. Just put the example file in your classpath and customize it.
3.1. Programmatic configuration

An instance of org.hibernate.cfg.Configuration represents an entire set of mappings of an application's Java types to an SQL database. The Configuration is used to build an (immutable) SessionFactory. The mappings are compiled from various XML mapping files.

You may obtain a Configuration instance by instantiating it directly and specifying XML mapping documents. If the mapping files are in the classpath, use addResource():

Configuration cfg = new Configuration()
    .addResource("Item.hbm.xml")
    .addResource("Bid.hbm.xml");

An alternative (sometimes better) way is to specify the mapped class, and let Hibernate find the mapping document for you:

Configuration cfg = new Configuration()
    .addClass(org.hibernate.auction.Item.class)
    .addClass(org.hibernate.auction.Bid.class);

Then Hibernate will look for mapping files named /org/hibernate/auction/Item.hbm.xml and /org/hibernate/auction/Bid.hbm.xml in the classpath. This approach eliminates any hardcoded filenames.

A Configuration also allows you to specify configuration properties:

Configuration cfg = new Configuration()
    .addClass(org.hibernate.auction.Item.class)
    .addClass(org.hibernate.auction.Bid.class)
    .setProperty("hibernate.dialect", "org.hibernate.dialect.MySQLInnoDBDialect")
    .setProperty("hibernate.connection.datasource", "java:comp/env/jdbc/test")
    .setProperty("hibernate.order_updates", "true");

This is not the only way to pass configuration properties to Hibernate. The various options include:

   1.

      Pass an instance of java.util.Properties to Configuration.setProperties().
   2.

      Place hibernate.properties in a root directory of the classpath.
   3.

      Set System properties using java -Dproperty=value.
   4.

      Include <property> elements in hibernate.cfg.xml (discussed later). 

hibernate.properties is the easiest approach if you want to get started quickly.

The Configuration is intended as a startup-time object, to be discarded once a SessionFactory is created.
3.2. Obtaining a SessionFactory

When all mappings have been parsed by the Configuration, the application must obtain a factory for Session instances. This factory is intended to be shared by all application threads:

SessionFactory sessions = cfg.buildSessionFactory();

Hibernate does allow your application to instantiate more than one SessionFactory. This is useful if you are using more than one database.
3.3. JDBC connections

Usually, you want to have the SessionFactory create and pool JDBC connections for you. If you take this approach, opening a Session is as simple as:

Session session = sessions.openSession(); // open a new Session

As soon as you do something that requires access to the database, a JDBC connection will be obtained from the pool.

For this to work, we need to pass some JDBC connection properties to Hibernate. All Hibernate property names and semantics are defined on the class org.hibernate.cfg.Environment. We will now describe the most important settings for JDBC connection configuration.

Hibernate will obtain (and pool) connections using java.sql.DriverManager if you set the following properties:

Table 3.1. Hibernate JDBC Properties
Property name	Purpose
hibernate.connection.driver_class	jdbc driver class
hibernate.connection.url	jdbc URL
hibernate.connection.username	database user
hibernate.connection.password	database user password
hibernate.connection.pool_size	maximum number of pooled connections

Hibernate's own connection pooling algorithm is however quite rudimentary. It is intended to help you get started and is not intended for use in a production system or even for performance testing. You should use a third party pool for best performance and stability. Just replace the hibernate.connection.pool_size property with connection pool specific settings. This will turn off Hibernate's internal pool. For example, you might like to use C3P0.

C3P0 is an open source JDBC connection pool distributed along with Hibernate in the lib directory. Hibernate will use its C3P0ConnectionProvider for connection pooling if you set hibernate.c3p0.* properties. If you'd like to use Proxool refer to the packaged hibernate.properties and the Hibernate web site for more information.

Here is an example hibernate.properties file for C3P0:

hibernate.connection.driver_class = org.postgresql.Driver
hibernate.connection.url = jdbc:postgresql://localhost/mydatabase
hibernate.connection.username = myuser
hibernate.connection.password = secret
hibernate.c3p0.min_size=5
hibernate.c3p0.max_size=20
hibernate.c3p0.timeout=1800
hibernate.c3p0.max_statements=50
hibernate.dialect = org.hibernate.dialect.PostgreSQLDialect

For use inside an application server, you should almost always configure Hibernate to obtain connections from an application server Datasource registered in JNDI. You'll need to set at least one of the following properties:

Table 3.2. Hibernate Datasource Properties
Propery name	Purpose
hibernate.connection.datasource	datasource JNDI name
hibernate.jndi.url	URL of the JNDI provider (optional)
hibernate.jndi.class	class of the JNDI InitialContextFactory (optional)
hibernate.connection.username	database user (optional)
hibernate.connection.password	database user password (optional)

Here's an example hibernate.properties file for an application server provided JNDI datasource:

hibernate.connection.datasource = java:/comp/env/jdbc/test
hibernate.transaction.factory_class = \
    org.hibernate.transaction.JTATransactionFactory
hibernate.transaction.manager_lookup_class = \
    org.hibernate.transaction.JBossTransactionManagerLookup
hibernate.dialect = org.hibernate.dialect.PostgreSQLDialect

JDBC connections obtained from a JNDI datasource will automatically participate in the container-managed transactions of the application server.

Arbitrary connection properties may be given by prepending "hibernate.connnection" to the property name. For example, you may specify a charSet using hibernate.connection.charSet.

You may define your own plugin strategy for obtaining JDBC connections by implementing the interface org.hibernate.connection.ConnectionProvider. You may select a custom implementation by setting hibernate.connection.provider_class.
3.4. Optional configuration properties

There are a number of other properties that control the behaviour of Hibernate at runtime. All are optional and have reasonable default values.

Warning: some of these properties are "system-level" only. System-level properties can be set only via java -Dproperty=value or hibernate.properties. They may not be set by the other techniques described above.

Table 3.3. Hibernate Configuration Properties
Property name	Purpose
hibernate.dialect	The classname of a Hibernate Dialect which allows Hibernate to generate SQL optimized for a particular relational database.

eg. full.classname.of.Dialect
hibernate.show_sql	Write all SQL statements to console. This is an alternative to setting the log category org.hibernate.SQL to debug.

eg. true | false
hibernate.format_sql	Pretty print the SQL in the log and console.

eg. true | false
hibernate.default_schema	Qualify unqualified tablenames with the given schema/tablespace in generated SQL.

eg. SCHEMA_NAME
hibernate.default_catalog	Qualify unqualified tablenames with the given catalog in generated SQL.

eg. CATALOG_NAME
hibernate.session_factory_name	The SessionFactory will be automatically bound to this name in JNDI after it has been created.

eg. jndi/composite/name
hibernate.max_fetch_depth	Set a maximum "depth" for the outer join fetch tree for single-ended associations (one-to-one, many-to-one). A 0 disables default outer join fetching.

eg. recommended values between 0 and 3
hibernate.default_batch_fetch_size	Set a default size for Hibernate batch fetching of associations.

eg. recommended values 4, 8, 16
hibernate.default_entity_mode	Set a default mode for entity representation for all sessions opened from this SessionFactory

dynamic-map, dom4j, pojo
hibernate.order_updates	Force Hibernate to order SQL updates by the primary key value of the items being updated. This will result in fewer transaction deadlocks in highly concurrent systems.

eg. true | false
hibernate.generate_statistics	If enabled, Hibernate will collect statistics useful for performance tuning.

eg. true | false
hibernate.use_identifer_rollback	If enabled, generated identifier properties will be reset to default values when objects are deleted.

eg. true | false
hibernate.use_sql_comments	If turned on, Hibernate will generate comments inside the SQL, for easier debugging, defaults to false.

eg. true | false

Table 3.4. Hibernate JDBC and Connection Properties
Property name	Purpose
hibernate.jdbc.fetch_size	A non-zero value determines the JDBC fetch size (calls Statement.setFetchSize()).
hibernate.jdbc.batch_size	A non-zero value enables use of JDBC2 batch updates by Hibernate.

eg. recommended values between 5 and 30
hibernate.jdbc.batch_versioned_data	Set this property to true if your JDBC driver returns correct row counts from executeBatch() (it is usually safe to turn this option on). Hibernate will then use batched DML for automatically versioned data. Defaults to false.

eg. true | false
hibernate.jdbc.factory_class	Select a custom Batcher. Most applications will not need this configuration property.

eg. classname.of.Batcher
hibernate.jdbc.use_scrollable_resultset	Enables use of JDBC2 scrollable resultsets by Hibernate. This property is only necessary when using user supplied JDBC connections, Hibernate uses connection metadata otherwise.

eg. true | false
hibernate.jdbc.use_streams_for_binary	Use streams when writing/reading binary or serializable types to/from JDBC (system-level property).

eg. true | false
hibernate.jdbc.use_get_generated_keys	Enable use of JDBC3 PreparedStatement.getGeneratedKeys() to retrieve natively generated keys after insert. Requires JDBC3+ driver and JRE1.4+, set to false if your driver has problems with the Hibernate identifier generators. By default, tries to determine the driver capabilites using connection metadata.

eg. true|false
hibernate.connection.provider_class	The classname of a custom ConnectionProvider which provides JDBC connections to Hibernate.

eg. classname.of.ConnectionProvider
hibernate.connection.isolation	Set the JDBC transaction isolation level. Check java.sql.Connection for meaningful values but note that most databases do not support all isolation levels.

eg. 1, 2, 4, 8
hibernate.connection.autocommit	Enables autocommit for JDBC pooled connections (not recommended).

eg. true | false
hibernate.connection.release_mode	Specify when Hibernate should release JDBC connections. By default, a JDBC connection is held until the session is explicitly closed or disconnected. For an application server JTA datasource, you should use after_statement to aggressively release connections after every JDBC call. For a non-JTA connection, it often makes sense to release the connection at the end of each transaction, by using after_transaction. auto will choose after_statement for the JTA and CMT transaction strategies and after_transaction for the JDBC transaction strategy.

eg. on_close (default) | after_transaction | after_statement | auto
hibernate.connection.<propertyName>	Pass the JDBC property propertyName to DriverManager.getConnection().
hibernate.jndi.<propertyName>	Pass the property propertyName to the JNDI InitialContextFactory.

Table 3.5. Hibernate Cache Properties
Property name	Purpose
hibernate.cache.provider_class	The classname of a custom CacheProvider.

eg. classname.of.CacheProvider
hibernate.cache.use_minimal_puts	Optimize second-level cache operation to minimize writes, at the cost of more frequent reads. This setting is most useful for clustered caches and, in Hibernate3, is enabled by default for clustered cache implementations.

eg. true|false
hibernate.cache.use_query_cache	Enable the query cache, individual queries still have to be set cachable.

eg. true|false
hibernate.cache.use_second_level_cache	May be used to completely disable the second level cache, which is enabled by default for classes which specify a <cache> mapping.

eg. true|false
hibernate.cache.query_cache_factory	The classname of a custom QueryCache interface, defaults to the built-in StandardQueryCache.

eg. classname.of.QueryCache
hibernate.cache.region_prefix	A prefix to use for second-level cache region names.

eg. prefix
hibernate.cache.use_structured_entries	Forces Hibernate to store data in the second-level cache in a more human-friendly format.

eg. true|false

Table 3.6. Hibernate Transaction Properties
Property name	Purpose
hibernate.transaction.factory_class	The classname of a TransactionFactory to use with Hibernate Transaction API (defaults to JDBCTransactionFactory).

eg. classname.of.TransactionFactory
jta.UserTransaction	A JNDI name used by JTATransactionFactory to obtain the JTA UserTransaction from the application server.

eg. jndi/composite/name
hibernate.transaction.manager_lookup_class	The classname of a TransactionManagerLookup - required when JVM-level caching is enabled or when using hilo generator in a JTA environment.

eg. classname.of.TransactionManagerLookup
hibernate.transaction.flush_before_completion	If enabled, the session will be automatically flushed during the before completion phase of the transaction. Built-in and automatic session context management is preferred, see Section 2.5, ?Contextual Sessions?.

eg. true | false
hibernate.transaction.auto_close_session	If enabled, the session will be automatically closed during the after completion phase of the transaction. Built-in and utomatic session context management is preferred, see Section 2.5, ?Contextual Sessions?.

eg. true | false

Table 3.7. Miscellaneous Properties
Property name	Purpose
hibernate.current_session_context_class	Supply a (custom) strategy for the scoping of the "current" Session. See Section 2.5, ?Contextual Sessions? for more information about the built-in strategies.

eg. jta | thread | custom.Class
hibernate.query.factory_class	Chooses the HQL parser implementation.

eg. org.hibernate.hql.ast.ASTQueryTranslatorFactory or org.hibernate.hql.classic.ClassicQueryTranslatorFactory
hibernate.query.substitutions	Mapping from tokens in Hibernate queries to SQL tokens (tokens might be function or literal names, for example).

eg. hqlLiteral=SQL_LITERAL, hqlFunction=SQLFUNC
hibernate.hbm2ddl.auto	Automatically validate or export schema DDL to the database when the SessionFactory is created. With create-drop, the database schema will be dropped when the SessionFactory is closed explicitly.

eg. validate | update | create | create-drop
hibernate.cglib.use_reflection_optimizer	Enables use of CGLIB instead of runtime reflection (System-level property). Reflection can sometimes be useful when troubleshooting, note that Hibernate always requires CGLIB even if you turn off the optimizer. You can not set this property in hibernate.cfg.xml.

eg. true | false
3.4.1. SQL Dialects

You should always set the hibernate.dialect property to the correct org.hibernate.dialect.Dialect subclass for your database. If you specify a dialect, Hibernate will use sensible defaults for some of the other properties listed above, saving you the effort of specifying them manually.

Table 3.8. Hibernate SQL Dialects (hibernate.dialect)
RDBMS	Dialect
DB2	org.hibernate.dialect.DB2Dialect
DB2 AS/400	org.hibernate.dialect.DB2400Dialect
DB2 OS390	org.hibernate.dialect.DB2390Dialect
PostgreSQL	org.hibernate.dialect.PostgreSQLDialect
MySQL	org.hibernate.dialect.MySQLDialect
MySQL with InnoDB	org.hibernate.dialect.MySQLInnoDBDialect
MySQL with MyISAM	org.hibernate.dialect.MySQLMyISAMDialect
Oracle (any version)	org.hibernate.dialect.OracleDialect
Oracle 9i/10g	org.hibernate.dialect.Oracle9Dialect
Sybase	org.hibernate.dialect.SybaseDialect
Sybase Anywhere	org.hibernate.dialect.SybaseAnywhereDialect
Microsoft SQL Server	org.hibernate.dialect.SQLServerDialect
SAP DB	org.hibernate.dialect.SAPDBDialect
Informix	org.hibernate.dialect.InformixDialect
HypersonicSQL	org.hibernate.dialect.HSQLDialect
Ingres	org.hibernate.dialect.IngresDialect
Progress	org.hibernate.dialect.ProgressDialect
Mckoi SQL	org.hibernate.dialect.MckoiDialect
Interbase	org.hibernate.dialect.InterbaseDialect
Pointbase	org.hibernate.dialect.PointbaseDialect
FrontBase	org.hibernate.dialect.FrontbaseDialect
Firebird	org.hibernate.dialect.FirebirdDialect
3.4.2. Outer Join Fetching

If your database supports ANSI, Oracle or Sybase style outer joins, outer join fetching will often increase performance by limiting the number of round trips to and from the database (at the cost of possibly more work performed by the database itself). Outer join fetching allows a whole graph of objects connected by many-to-one, one-to-many, many-to-many and one-to-one associations to be retrieved in a single SQL SELECT.

Outer join fetching may be disabled globally by setting the property hibernate.max_fetch_depth to 0. A setting of 1 or higher enables outer join fetching for one-to-one and many-to-one associations which have been mapped with fetch="join".

See Section 19.1, ?Fetching strategies? for more information.
3.4.3. Binary Streams

Oracle limits the size of byte arrays that may be passed to/from its JDBC driver. If you wish to use large instances of binary or serializable type, you should enable hibernate.jdbc.use_streams_for_binary. This is a system-level setting only.
3.4.4. Second-level and query cache

The properties prefixed by hibernate.cache allow you to use a process or cluster scoped second-level cache system with Hibernate. See the Section 19.2, ?The Second Level Cache? for more details.
3.4.5. Query Language Substitution

You may define new Hibernate query tokens using hibernate.query.substitutions. For example:

hibernate.query.substitutions true=1, false=0

would cause the tokens true and false to be translated to integer literals in the generated SQL.

hibernate.query.substitutions toLowercase=LOWER

would allow you to rename the SQL LOWER function.
3.4.6. Hibernate statistics

If you enable hibernate.generate_statistics, Hibernate will expose a number of metrics that are useful when tuning a running system via SessionFactory.getStatistics(). Hibernate can even be configured to expose these statistics via JMX. Read the Javadoc of the interfaces in org.hibernate.stats for more information.
3.5. Logging

Hibernate logs various events using Apache commons-logging.

The commons-logging service will direct output to either Apache Log4j (if you include log4j.jar in your classpath) or JDK1.4 logging (if running under JDK1.4 or above). You may download Log4j from http://jakarta.apache.org. To use Log4j you will need to place a log4j.properties file in your classpath, an example properties file is distributed with Hibernate in the src/ directory.

We strongly recommend that you familiarize yourself with Hibernate's log messages. A lot of work has been put into making the Hibernate log as detailed as possible, without making it unreadable. It is an essential troubleshooting device. The most interesting log categories are the following:

Table 3.9. Hibernate Log Categories
Category	Function
org.hibernate.SQL	Log all SQL DML statements as they are executed
org.hibernate.type	Log all JDBC parameters
org.hibernate.tool.hbm2ddl	Log all SQL DDL statements as they are executed
org.hibernate.pretty	Log the state of all entities (max 20 entities) associated with the session at flush time
org.hibernate.cache	Log all second-level cache activity
org.hibernate.transaction	Log transaction related activity
org.hibernate.jdbc	Log all JDBC resource acquisition
org.hibernate.hql.ast.AST	Log HQL and SQL ASTs during query parsing
org.hibernate.secure	Log all JAAS authorization requests
org.hibernate	Log everything (a lot of information, but very useful for troubleshooting)

When developing applications with Hibernate, you should almost always work with debug enabled for the category org.hibernate.SQL, or, alternatively, the property hibernate.show_sql enabled.
3.6. Implementing a NamingStrategy

The interface org.hibernate.cfg.NamingStrategy allows you to specify a "naming standard" for database objects and schema elements.

You may provide rules for automatically generating database identifiers from Java identifiers or for processing "logical" column and table names given in the mapping file into "physical" table and column names. This feature helps reduce the verbosity of the mapping document, eliminating repetitive noise (TBL_ prefixes, for example). The default strategy used by Hibernate is quite minimal.

You may specify a different strategy by calling Configuration.setNamingStrategy() before adding mappings:

SessionFactory sf = new Configuration()
    .setNamingStrategy(ImprovedNamingStrategy.INSTANCE)
    .addFile("Item.hbm.xml")
    .addFile("Bid.hbm.xml")
    .buildSessionFactory();

org.hibernate.cfg.ImprovedNamingStrategy is a built-in strategy that might be a useful starting point for some applications.
3.7. XML configuration file

An alternative approach to configuration is to specify a full configuration in a file named hibernate.cfg.xml. This file can be used as a replacement for the hibernate.properties file or, if both are present, to override properties.

The XML configuration file is by default expected to be in the root o your CLASSPATH. Here is an example:

<?xml version='1.0' encoding='utf-8'?>
<!DOCTYPE hibernate-configuration PUBLIC
    "-//Hibernate/Hibernate Configuration DTD//EN"
    "http://hibernate.sourceforge.net/hibernate-configuration-3.0.dtd">

<hibernate-configuration>

    <!-- a SessionFactory instance listed as /jndi/name -->
    <session-factory
        name="java:hibernate/SessionFactory">

        <!-- properties -->
        <property name="connection.datasource">java:/comp/env/jdbc/MyDB</property>
        <property name="dialect">org.hibernate.dialect.MySQLDialect</property>
        <property name="show_sql">false</property>
        <property name="transaction.factory_class">
            org.hibernate.transaction.JTATransactionFactory
        </property>
        <property name="jta.UserTransaction">java:comp/UserTransaction</property>

        <!-- mapping files -->
        <mapping resource="org/hibernate/auction/Item.hbm.xml"/>
        <mapping resource="org/hibernate/auction/Bid.hbm.xml"/>

        <!-- cache settings -->
        <class-cache class="org.hibernate.auction.Item" usage="read-write"/>
        <class-cache class="org.hibernate.auction.Bid" usage="read-only"/>
        <collection-cache collection="org.hibernate.auction.Item.bids" usage="read-write"/>

    </session-factory>

</hibernate-configuration>

As you can see, the advantage of this approach is the externalization of the mapping file names to configuration. The hibernate.cfg.xml is also more convenient once you have to tune the Hibernate cache. Note that is your choice to use either hibernate.properties or hibernate.cfg.xml, both are equivalent, except for the above mentioned benefits of using the XML syntax.

With the XML configuration, starting Hibernate is then as simple as

SessionFactory sf = new Configuration().configure().buildSessionFactory();

You can pick a different XML configuration file using

SessionFactory sf = new Configuration()
    .configure("catdb.cfg.xml")
    .buildSessionFactory();

3.8. J2EE Application Server integration

Hibernate has the following integration points for J2EE infrastructure:

    *

      Container-managed datasources: Hibernate can use JDBC connections managed by the container and provided through JNDI. Usually, a JTA compatible TransactionManager and a ResourceManager take care of transaction management (CMT), esp. distributed transaction handling across several datasources. You may of course also demarcate transaction boundaries programatically (BMT) or you might want to use the optional Hibernate Transaction API for this to keep your code portable. 

    *

      Automatic JNDI binding: Hibernate can bind its SessionFactory to JNDI after startup. 

    *

      JTA Session binding: The Hibernate Session may be automatically bound to the scope of JTA transactions. Simply lookup the SessionFactory from JNDI and get the current Session. Let Hibernate take care of flushing and closing the Session when your JTA transaction completes. Transaction demarcation is either declarative (CMT) or programmatic (BMT/UserTransaction). 

    *

      JMX deployment: If you have a JMX capable application server (e.g. JBoss AS), you can chose to deploy Hibernate as a managed MBean. This saves you the one line startup code to build your SessionFactory from a Configuration. The container will startup your HibernateService, and ideally also take care of service dependencies (Datasource has to be available before Hibernate starts, etc). 

Depending on your environment, you might have to set the configuration option hibernate.connection.aggressive_release to true if your application server shows "connection containment" exceptions.
3.8.1. Transaction strategy configuration

The Hibernate Session API is independent of any transaction demarcation system in your architecture. If you let Hibernate use JDBC directly, through a connection pool, you may begin and end your transactions by calling the JDBC API. If you run in a J2EE application server, you might want to use bean-managed transactions and call the JTA API and UserTransaction when needed.

To keep your code portable between these two (and other) environments we recommend the optional Hibernate Transaction API, which wraps and hides the underlying system. You have to specify a factory class for Transaction instances by setting the Hibernate configuration property hibernate.transaction.factory_class.

There are three standard (built-in) choices:

org.hibernate.transaction.JDBCTransactionFactory

    delegates to database (JDBC) transactions (default)
org.hibernate.transaction.JTATransactionFactory

    delegates to container-managed transaction if an existing transaction is underway in this context (e.g. EJB session bean method), otherwise a new transaction is started and bean-managed transaction are used. 
org.hibernate.transaction.CMTTransactionFactory

    delegates to container-managed JTA transactions

You may also define your own transaction strategies (for a CORBA transaction service, for example).

Some features in Hibernate (i.e. the second level cache, Contextual Sessions with JTA, etc.) require access to the JTA TransactionManager in a managed environment. In an application server you have to specify how Hibernate should obtain a reference to the TransactionManager, since J2EE does not standardize a single mechanism:

Table 3.10. JTA TransactionManagers
Transaction Factory	Application Server
org.hibernate.transaction.JBossTransactionManagerLookup	JBoss
org.hibernate.transaction.WeblogicTransactionManagerLookup	Weblogic
org.hibernate.transaction.WebSphereTransactionManagerLookup	WebSphere
org.hibernate.transaction.WebSphereExtendedJTATransactionLookup	WebSphere 6
org.hibernate.transaction.OrionTransactionManagerLookup	Orion
org.hibernate.transaction.ResinTransactionManagerLookup	Resin
org.hibernate.transaction.JOTMTransactionManagerLookup	JOTM
org.hibernate.transaction.JOnASTransactionManagerLookup	JOnAS
org.hibernate.transaction.JRun4TransactionManagerLookup	JRun4
org.hibernate.transaction.BESTransactionManagerLookup	Borland ES
3.8.2. JNDI-bound SessionFactory

A JNDI bound Hibernate SessionFactory can simplify the lookup of the factory and the creation of new Sessions. Note that this is not related to a JNDI bound Datasource, both simply use the same registry!

If you wish to have the SessionFactory bound to a JNDI namespace, specify a name (eg. java:hibernate/SessionFactory) using the property hibernate.session_factory_name. If this property is omitted, the SessionFactory will not be bound to JNDI. (This is especially useful in environments with a read-only JNDI default implementation, e.g. Tomcat.)

When binding the SessionFactory to JNDI, Hibernate will use the values of hibernate.jndi.url, hibernate.jndi.class to instantiate an initial context. If they are not specified, the default InitialContext will be used.

Hibernate will automatically place the SessionFactory in JNDI after you call cfg.buildSessionFactory(). This means you will at least have this call in some startup code (or utility class) in your application, unless you use JMX deployment with the HibernateService (discussed later).

If you use a JNDI SessionFactory, an EJB or any other class may obtain the SessionFactory using a JNDI lookup.

We recommend that you bind the SessionFactory to JNDI in a managend environment and use a static singleton otherwise. To shield your application code from these details, we also recommend to hide the actual lookup code for a SessionFactory in a helper class, such as HibernateUtil.getSessionFactory(). Note that such a class is also a convenient way to startup Hibernate?see chapter 1.
3.8.3. Current Session context management with JTA

The easiest way to handle Sessions and transactions is Hibernates automatic "current" Session management. See the discussion of Section 2.5, ?Contextual Sessions?. Using the "jta" session context, if there is no Hibernate Session associated with the current JTA transaction, one will be started and associated with that JTA transaction the first time you call sessionFactory.getCurrentSession(). The Sessions retrieved via getCurrentSession() in "jta" context will be set to automatically flush before the transaction completes, close after the transaction completes, and aggressively release JDBC connections after each statement. This allows the Sessions to be managed by the lifecycle of the JTA transaction to which it is associated, keeping user code clean of such management concerns. Your code can either use JTA programmatically through UserTransaction, or (recommended for portable code) use the Hibernate Transaction API to set transaction boundaries. If you run in an EJB container, declarative transaction demarcation with CMT is preferred.
3.8.4. JMX deployment

The line cfg.buildSessionFactory() still has to be executed somewhere to get a SessionFactory into JNDI. You can do this either in a static initializer block (like the one in HibernateUtil) or you deploy Hibernate as a managed service.

Hibernate is distributed with org.hibernate.jmx.HibernateService for deployment on an application server with JMX capabilities, such as JBoss AS. The actual deployment and configuration is vendor specific. Here is an example jboss-service.xml for JBoss 4.0.x:

<?xml version="1.0"?>
<server>

<mbean code="org.hibernate.jmx.HibernateService"
    name="jboss.jca:service=HibernateFactory,name=HibernateFactory">

    <!-- Required services -->
    <depends>jboss.jca:service=RARDeployer</depends>
    <depends>jboss.jca:service=LocalTxCM,name=HsqlDS</depends>

    <!-- Bind the Hibernate service to JNDI -->
    <attribute name="JndiName">java:/hibernate/SessionFactory</attribute>

    <!-- Datasource settings -->
    <attribute name="Datasource">java:HsqlDS</attribute>
    <attribute name="Dialect">org.hibernate.dialect.HSQLDialect</attribute>

    <!-- Transaction integration -->
    <attribute name="TransactionStrategy">
        org.hibernate.transaction.JTATransactionFactory</attribute>
    <attribute name="TransactionManagerLookupStrategy">
        org.hibernate.transaction.JBossTransactionManagerLookup</attribute>
    <attribute name="FlushBeforeCompletionEnabled">true</attribute>
    <attribute name="AutoCloseSessionEnabled">true</attribute>

    <!-- Fetching options -->
    <attribute name="MaximumFetchDepth">5</attribute>

    <!-- Second-level caching -->
    <attribute name="SecondLevelCacheEnabled">true</attribute>
    <attribute name="CacheProviderClass">org.hibernate.cache.EhCacheProvider</attribute>
    <attribute name="QueryCacheEnabled">true</attribute>

    <!-- Logging -->
    <attribute name="ShowSqlEnabled">true</attribute>

    <!-- Mapping files -->
    <attribute name="MapResources">auction/Item.hbm.xml,auction/Category.hbm.xml</attribute>

</mbean>

</server>

This file is deployed in a directory called META-INF and packaged in a JAR file with the extension .sar (service archive). You also need to package Hibernate, its required third-party libraries, your compiled persistent classes, as well as your mapping files in the same archive. Your enterprise beans (usually session beans) may be kept in their own JAR file, but you may include this EJB JAR file in the main service archive to get a single (hot-)deployable unit. Consult the JBoss AS documentation for more information about JMX service and EJB deployment.
Chapter 4. Persistent Classes

Persistent classes are classes in an application that implement the entities of the business problem (e.g. Customer and Order in an E-commerce application). Not all instances of a persistent class are considered to be in the persistent state - an instance may instead be transient or detached.

Hibernate works best if these classes follow some simple rules, also known as the Plain Old Java Object (POJO) programming model. However, none of these rules are hard requirements. Indeed, Hibernate3 assumes very little about the nature of your persistent objects. You may express a domain model in other ways: using trees of Map instances, for example.
4.1. A simple POJO example

Most Java applications require a persistent class representing felines.

package eg;
import java.util.Set;
import java.util.Date;

public class Cat {
    private Long id; // identifier

    private Date birthdate;
    private Color color;
    private char sex;
    private float weight;
    private int litterId;

    private Cat mother;
    private Set kittens = new HashSet();

    private void setId(Long id) {
        this.id=id;
    }
    public Long getId() {
        return id;
    }

    void setBirthdate(Date date) {
        birthdate = date;
    }
    public Date getBirthdate() {
        return birthdate;
    }

    void setWeight(float weight) {
        this.weight = weight;
    }
    public float getWeight() {
        return weight;
    }

    public Color getColor() {
        return color;
    }
    void setColor(Color color) {
        this.color = color;
    }

    void setSex(char sex) {
        this.sex=sex;
    }
    public char getSex() {
        return sex;
    }

    void setLitterId(int id) {
        this.litterId = id;
    }
    public int getLitterId() {
        return litterId;
    }

    void setMother(Cat mother) {
        this.mother = mother;
    }
    public Cat getMother() {
        return mother;
    }
    void setKittens(Set kittens) {
        this.kittens = kittens;
    }
    public Set getKittens() {
        return kittens;
    }
    
    // addKitten not needed by Hibernate
    public void addKitten(Cat kitten) {
    	kitten.setMother(this);
	kitten.setLitterId( kittens.size() ); 
        kittens.add(kitten);
    }
}

There are four main rules to follow here:
4.1.1. Implement a no-argument constructor

Cat has a no-argument constructor. All persistent classes must have a default constructor (which may be non-public) so that Hibernate can instantiate them using Constructor.newInstance(). We strongly recommend having a default constructor with at least package visibility for runtime proxy generation in Hibernate.
4.1.2. Provide an identifier property (optional)

Cat has a property called id. This property maps to the primary key column of a database table. The property might have been called anything, and its type might have been any primitive type, any primitive "wrapper" type, java.lang.String or java.util.Date. (If your legacy database table has composite keys, you can even use a user-defined class with properties of these types - see the section on composite identifiers later.)

The identifier property is strictly optional. You can leave them off and let Hibernate keep track of object identifiers internally. We do not recommend this, however.

In fact, some functionality is available only to classes which declare an identifier property:

    *

      Transitive reattachment for detached objects (cascade update or cascade merge) - see Section 10.11, ?Transitive persistence?
    *

      Session.saveOrUpdate()
    *

      Session.merge() 

We recommend you declare consistently-named identifier properties on persistent classes. We further recommend that you use a nullable (ie. non-primitive) type.
4.1.3. Prefer non-final classes (optional)

A central feature of Hibernate, proxies, depends upon the persistent class being either non-final, or the implementation of an interface that declares all public methods.

You can persist final classes that do not implement an interface with Hibernate, but you won't be able to use proxies for lazy association fetching - which will limit your options for performance tuning.

You should also avoid declaring public final methods on the non-final classes. If you want to use a class with a public final method, you must explicitly disable proying by setting lazy="false".
4.1.4. Declare accessors and mutators for persistent fields (optional)

Cat declares accessor methods for all its persistent fields. Many other ORM tools directly persist instance variables. We believe it is better to provide an indirection between the relational schema and internal data structures of the class. By default, Hibernate persists JavaBeans style properties, and recognizes method names of the form getFoo, isFoo and setFoo. You may switch to direct field access for particular properties, if needed.

Properties need not be declared public - Hibernate can persist a property with a default, protected or private get / set pair.
4.2. Implementing inheritance

A subclass must also observe the first and second rules. It inherits its identifier property from the superclass, Cat.

package eg;

public class DomesticCat extends Cat {
        private String name;

        public String getName() {
                return name;
        }
        protected void setName(String name) {
                this.name=name;
        }
}

4.3. Implementing equals() and hashCode()

You have to override the equals() and hashCode() methods if you

    *

      intend to put instances of persistent classes in a Set (the recommended way to represent many-valued associations) and
    *

      intend to use reattachment of detached instances 

Hibernate guarantees equivalence of persistent identity (database row) and Java identity only inside a particular session scope. So as soon as we mix instances retrieved in different sessions, we must implement equals() and hashCode() if we wish to have meaningful semantics for Sets.

The most obvious way is to implement equals()/hashCode() by comparing the identifier value of both objects. If the value is the same, both must be the same database row, they are therefore equal (if both are added to a Set, we will only have one element in the Set). Unfortunately, we can't use that approach with generated identifiers! Hibernate will only assign identifier values to objects that are persistent, a newly created instance will not have any identifier value! Furthermore, if an instance is unsaved and currently in a Set, saving it will assign an identifier value to the object. If equals() and hashCode() are based on the identifier value, the hash code would change, breaking the contract of the Set. See the Hibernate website for a full discussion of this problem. Note that this is not a Hibernate issue, but normal Java semantics of object identity and equality.

We recommend implementing equals() and hashCode() using Business key equality. Business key equality means that the equals() method compares only the properties that form the business key, a key that would identify our instance in the real world (a natural candidate key):

public class Cat {

    ...
    public boolean equals(Object other) {
        if (this == other) return true;
        if ( !(other instanceof Cat) ) return false;

        final Cat cat = (Cat) other;

        if ( !cat.getLitterId().equals( getLitterId() ) ) return false;
        if ( !cat.getMother().equals( getMother() ) ) return false;

        return true;
    }

    public int hashCode() {
        int result;
        result = getMother().hashCode();
        result = 29 * result + getLitterId();
        return result;
    }

}

Note that a business key does not have to be as solid as a database primary key candidate (see Section 11.1.3, ?Considering object identity?). Immutable or unique properties are usually good candidates for a business key.
4.4. Dynamic models

Note that the following features are currently considered experimental and may change in the near future.

Persistent entities don't necessarily have to be represented as POJO classes or as JavaBean objects at runtime. Hibernate also supports dynamic models (using Maps of Maps at runtime) and the representation of entities as DOM4J trees. With this approach, you don't write persistent classes, only mapping files.

By default, Hibernate works in normal POJO mode. You may set a default entity representation mode for a particular SessionFactory using the default_entity_mode configuration option (see Table 3.3, ?Hibernate Configuration Properties?.

The following examples demonstrates the representation using Maps. First, in the mapping file, an entity-name has to be declared instead of (or in addition to) a class name:

<hibernate-mapping>

    <class entity-name="Customer">

        <id name="id"
            type="long"
            column="ID">
            <generator class="sequence"/>
        </id>

        <property name="name"
            column="NAME"
            type="string"/>

        <property name="address"
            column="ADDRESS"
            type="string"/>

        <many-to-one name="organization"
            column="ORGANIZATION_ID"
            class="Organization"/>

        <bag name="orders"
            inverse="true"
            lazy="false"
            cascade="all">
            <key column="CUSTOMER_ID"/>
            <one-to-many class="Order"/>
        </bag>

    </class>
    
</hibernate-mapping>

Note that even though associations are declared using target class names, the target type of an associations may also be a dynamic entity instead of a POJO.

After setting the default entity mode to dynamic-map for the SessionFactory, we can at runtime work with Maps of Maps:

Session s = openSession();
Transaction tx = s.beginTransaction();
Session s = openSession();

// Create a customer
Map david = new HashMap();
david.put("name", "David");

// Create an organization
Map foobar = new HashMap();
foobar.put("name", "Foobar Inc.");

// Link both
david.put("organization", foobar);

// Save both
s.save("Customer", david);
s.save("Organization", foobar);

tx.commit();
s.close();

The advantages of a dynamic mapping are quick turnaround time for prototyping without the need for entity class implementation. However, you lose compile-time type checking and will very likely deal with many exceptions at runtime. Thanks to the Hibernate mapping, the database schema can easily be normalized and sound, allowing to add a proper domain model implementation on top later on.

Entity representation modes can also be set on a per Session basis:

Session dynamicSession = pojoSession.getSession(EntityMode.MAP);

// Create a customer
Map david = new HashMap();
david.put("name", "David");
dynamicSession.save("Customer", david);
...
dynamicSession.flush();
dynamicSession.close()
...
// Continue on pojoSession

Please note that the call to getSession() using an EntityMode is on the Session API, not the SessionFactory. That way, the new Session shares the underlying JDBC connection, transaction, and other context information. This means you don't have tocall flush() and close() on the secondary Session, and also leave the transaction and connection handling to the primary unit of work.

More information about the XML representation capabilities can be found in Chapter 18, XML Mapping.
4.5. Tuplizers

org.hibernate.tuple.Tuplizer, and its sub-interfaces, are responsible for managing a particular representation of a piece of data, given that representation's org.hibernate.EntityMode. If a given piece of data is thought of as a data structure, then a tuplizer is the thing which knows how to create such a data structure and how to extract values from and inject values into such a data structure. For example, for the POJO entity mode, the correpsonding tuplizer knows how create the POJO through its constructor and how to access the POJO properties using the defined property accessors. There are two high-level types of Tuplizers, represented by the org.hibernate.tuple.EntityTuplizer and org.hibernate.tuple.ComponentTuplizer interfaces. EntityTuplizers are responsible for managing the above mentioned contracts in regards to entities, while ComponentTuplizers do the same for components.

Users may also plug in their own tuplizers. Perhaps you require that a java.util.Map implementation other than java.util.HashMap be used while in the dynamic-map entity-mode; or perhaps you need to define a different proxy generation strategy than the one used by default. Both would be achieved by defining a custom tuplizer implementation. Tuplizers definitions are attached to the entity or component mapping they are meant to manage. Going back to the example of our customer entity:

<hibernate-mapping>
    <class entity-name="Customer">
        <!--
            Override the dynamic-map entity-mode
            tuplizer for the customer entity
        -->
        <tuplizer entity-mode="dynamic-map"
                class="CustomMapTuplizerImpl"/>

        <id name="id" type="long" column="ID">
            <generator class="sequence"/>
        </id>

        <!-- other properties -->
        ...
    </class>
</hibernate-mapping>


public class CustomMapTuplizerImpl
        extends org.hibernate.tuple.DynamicMapEntityTuplizer {
    // override the buildInstantiator() method to plug in our custom map...
    protected final Instantiator buildInstantiator(
            org.hibernate.mapping.PersistentClass mappingInfo) {
        return new CustomMapInstantiator( mappingInfo );
    }

    private static final class CustomMapInstantiator
            extends org.hibernate.tuple.DynamicMapInstantitor {
        // override the generateMap() method to return our custom map...
	    protected final Map generateMap() {
		    return new CustomMap();
	    }
    }
}

TODO: Document user-extension framework in the property and proxy packages
Chapter 5. Basic O/R Mapping
5.1. Mapping declaration

Object/relational mappings are usually defined in an XML document. The mapping document is designed to be readable and hand-editable. The mapping language is Java-centric, meaning that mappings are constructed around persistent class declarations, not table declarations.

Note that, even though many Hibernate users choose to write the XML by hand, a number of tools exist to generate the mapping document, including XDoclet, Middlegen and AndroMDA.

Lets kick off with an example mapping:

<?xml version="1.0"?>
<!DOCTYPE hibernate-mapping PUBLIC
      "-//Hibernate/Hibernate Mapping DTD 3.0//EN"
          "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd">

<hibernate-mapping package="eg">

        <class name="Cat" 
            table="cats"
            discriminator-value="C">
                
                <id name="id">
                        <generator class="native"/>
                </id>

                <discriminator column="subclass" 
                     type="character"/>

                <property name="weight"/>

                <property name="birthdate"
                    type="date" 
                    not-null="true" 
                    update="false"/>

                <property name="color"
                    type="eg.types.ColorUserType"
                    not-null="true"
                    update="false"/>

                <property name="sex"
                    not-null="true" 
                    update="false"/>

                <property name="litterId"
                    column="litterId"
                    update="false"/>

                <many-to-one name="mother"
                    column="mother_id"
                    update="false"/>

                <set name="kittens"
                    inverse="true"
                    order-by="litter_id">
                        <key column="mother_id"/>
                        <one-to-many class="Cat"/>
                </set>

                <subclass name="DomesticCat"
                    discriminator-value="D">

                        <property name="name" 
                            type="string"/>

                </subclass>

        </class>

        <class name="Dog">
                <!-- mapping for Dog could go here -->
        </class>

</hibernate-mapping>

We will now discuss the content of the mapping document. We will only describe the document elements and attributes that are used by Hibernate at runtime. The mapping document also contains some extra optional attributes and elements that affect the database schemas exported by the schema export tool. (For example the not-null attribute.)
5.1.1. Doctype

All XML mappings should declare the doctype shown. The actual DTD may be found at the URL above, in the directory hibernate-x.x.x/src/org/hibernate or in hibernate3.jar. Hibernate will always look for the DTD in its classpath first. If you experience lookups of the DTD using an Internet connection, check your DTD declaration against the contents of your claspath.
5.1.2. hibernate-mapping

This element has several optional attributes. The schema and catalog attributes specify that tables referred to in this mapping belong to the named schema and/or catalog. If specified, tablenames will be qualified by the given schema and catalog names. If missing, tablenames will be unqualified. The default-cascade attribute specifies what cascade style should be assumed for properties and collections which do not specify a cascade attribute. The auto-import attribute lets us use unqualified class names in the query language, by default.

<hibernate-mapping
         schema="schemaName"                          (1)
         catalog="catalogName"                        (2)
         default-cascade="cascade_style"              (3)
         default-access="field|property|ClassName"    (4)
         default-lazy="true|false"                    (5)
         auto-import="true|false"                     (6)
         package="package.name"                       (7)
 />

(1)	

schema (optional): The name of a database schema.
(2)	

catalog (optional): The name of a database catalog.
(3)	

default-cascade (optional - defaults to none): A default cascade style.
(4)	

default-access (optional - defaults to property): The strategy Hibernate should use for accessing all properties. Can be a custom implementation of PropertyAccessor.
(5)	

default-lazy (optional - defaults to true): The default value for unspecifed lazy attributes of class and collection mappings.
(6)	

auto-import (optional - defaults to true): Specifies whether we can use unqualified class names (of classes in this mapping) in the query language.
(7)	

package (optional): Specifies a package prefix to assume for unqualified class names in the mapping document.

If you have two persistent classes with the same (unqualified) name, you should set auto-import="false". Hibernate will throw an exception if you attempt to assign two classes to the same "imported" name.

Note that the hibernate-mapping element allows you to nest several persistent <class> mappings, as shown above. It is however good practice (and expected by some tools) to map only a single persistent class (or a single class hierarchy) in one mapping file and name it after the persistent superclass, e.g. Cat.hbm.xml, Dog.hbm.xml, or if using inheritance, Animal.hbm.xml.
5.1.3. class

You may declare a persistent class using the class element:

<class
        name="ClassName"                              (1)
        table="tableName"                             (2)
        discriminator-value="discriminator_value"     (3)
        mutable="true|false"                          (4)
        schema="owner"                                (5)
        catalog="catalog"                             (6)
        proxy="ProxyInterface"                        (7)
        dynamic-update="true|false"                   (8)
        dynamic-insert="true|false"                   (9)
        select-before-update="true|false"             (10)
        polymorphism="implicit|explicit"              (11)
        where="arbitrary sql where condition"         (12)
        persister="PersisterClass"                    (13)
        batch-size="N"                                (14)
        optimistic-lock="none|version|dirty|all"      (15)
        lazy="true|false"                             (16)
        entity-name="EntityName"                      (17)
        check="arbitrary sql check condition"         (18)
        rowid="rowid"                                 (19)
        subselect="SQL expression"                    (20)
        abstract="true|false"                         (21)
        node="element-name"
/>

(1)	

name (optional): The fully qualified Java class name of the persistent class (or interface). If this attribute is missing, it is assumed that the mapping is for a non-POJO entity.
(2)	

table (optional - defaults to the unqualified class name): The name of its database table.
(3)	

discriminator-value (optional - defaults to the class name): A value that distiguishes individual subclasses, used for polymorphic behaviour. Acceptable values include null and not null.
(4)	

mutable (optional, defaults to true): Specifies that instances of the class are (not) mutable.
(5)	

schema (optional): Override the schema name specified by the root <hibernate-mapping> element.
(6)	

catalog (optional): Override the catalog name specified by the root <hibernate-mapping> element.
(7)	

proxy (optional): Specifies an interface to use for lazy initializing proxies. You may specify the name of the class itself.
(8)	

dynamic-update (optional, defaults to false): Specifies that UPDATE SQL should be generated at runtime and contain only those columns whose values have changed.
(9)	

dynamic-insert (optional, defaults to false): Specifies that INSERT SQL should be generated at runtime and contain only the columns whose values are not null.
(10)	

select-before-update (optional, defaults to false): Specifies that Hibernate should never perform an SQL UPDATE unless it is certain that an object is actually modified. In certain cases (actually, only when a transient object has been associated with a new session using update()), this means that Hibernate will perform an extra SQL SELECT to determine if an UPDATE is actually required.
(11)	

polymorphism (optional, defaults to implicit): Determines whether implicit or explicit query polymorphism is used.
(12)	

where (optional) specify an arbitrary SQL WHERE condition to be used when retrieving objects of this class
(13)	

persister (optional): Specifies a custom ClassPersister.
(14)	

batch-size (optional, defaults to 1) specify a "batch size" for fetching instances of this class by identifier.
(15)	

optimistic-lock (optional, defaults to version): Determines the optimistic locking strategy.
(16)	

lazy (optional): Lazy fetching may be completely disabled by setting lazy="false".
(17)	

entity-name (optional, defaults to the class name): Hibernate3 allows a class to be mapped multiple times (to different tables, potentially), and allows entity mappings that are represented by Maps or XML at the Java level. In these cases, you should provide an explicit arbitrary name for the entity. See Section 4.4, ?Dynamic models? and Chapter 18, XML Mapping for more information.
(18)	

check (optional): A SQL expression used to generate a multi-row check constraint for automatic schema generation.
(19)	

rowid (optional): Hibernate can use so called ROWIDs on databases which support. E.g. on Oracle, Hibernate can use the rowid extra column for fast updates if you set this option to rowid. A ROWID is an implementation detail and represents the physical location of a stored tuple.
(20)	

subselect (optional): Maps an immutable and read-only entity to a database subselect. Useful if you want to have a view instead of a base table, but don't. See below for more information.
(21)	

abstract (optional): Used to mark abstract superclasses in <union-subclass> hierarchies.

It is perfectly acceptable for the named persistent class to be an interface. You would then declare implementing classes of that interface using the <subclass> element. You may persist any static inner class. You should specify the class name using the standard form ie. eg.Foo$Bar.

Immutable classes, mutable="false", may not be updated or deleted by the application. This allows Hibernate to make some minor performance optimizations.

The optional proxy attribute enables lazy initialization of persistent instances of the class. Hibernate will initially return CGLIB proxies which implement the named interface. The actual persistent object will be loaded when a method of the proxy is invoked. See "Proxies for Lazy Initialization" below.

Implicit polymorphism means that instances of the class will be returned by a query that names any superclass or implemented interface or the class and that instances of any subclass of the class will be returned by a query that names the class itself. Explicit polymorphism means that class instances will be returned only by queries that explicitly name that class and that queries that name the class will return only instances of subclasses mapped inside this <class> declaration as a <subclass> or <joined-subclass>. For most purposes the default, polymorphism="implicit", is appropriate. Explicit polymorphism is useful when two different classes are mapped to the same table (this allows a "lightweight" class that contains a subset of the table columns).

The persister attribute lets you customize the persistence strategy used for the class. You may, for example, specify your own subclass of org.hibernate.persister.EntityPersister or you might even provide a completely new implementation of the interface org.hibernate.persister.ClassPersister that implements persistence via, for example, stored procedure calls, serialization to flat files or LDAP. See org.hibernate.test.CustomPersister for a simple example (of "persistence" to a Hashtable).

Note that the dynamic-update and dynamic-insert settings are not inherited by subclasses and so may also be specified on the <subclass> or <joined-subclass> elements. These settings may increase performance in some cases, but might actually decrease performance in others. Use judiciously.

Use of select-before-update will usually decrease performance. It is very useful to prevent a database update trigger being called unnecessarily if you reattach a graph of detached instances to a Session.

If you enable dynamic-update, you will have a choice of optimistic locking strategies:

    *

      version check the version/timestamp columns
    *

      all check all columns
    *

      dirty check the changed columns, allowing some concurrent updates
    *

      none do not use optimistic locking 

We very strongly recommend that you use version/timestamp columns for optimistic locking with Hibernate. This is the optimal strategy with respect to performance and is the only strategy that correctly handles modifications made to detached instances (ie. when Session.merge() is used).

There is no difference between a view and a base table for a Hibernate mapping, as expected this is transparent at the database level (note that some DBMS don't support views properly, especially with updates). Sometimes you want to use a view, but can't create one in the database (ie. with a legacy schema). In this case, you can map an immutable and read-only entity to a given SQL subselect expression:

<class name="Summary">
    <subselect>
        select item.name, max(bid.amount), count(*)
        from item
        join bid on bid.item_id = item.id
        group by item.name
    </subselect>
    <synchronize table="item"/>
    <synchronize table="bid"/>
    <id name="name"/>
    ...
</class>

Declare the tables to synchronize this entity with, ensuring that auto-flush happens correctly, and that queries against the derived entity do not return stale data. The <subselect> is available as both as an attribute and a nested mapping element.
5.1.4. id

Mapped classes must declare the primary key column of the database table. Most classes will also have a JavaBeans-style property holding the unique identifier of an instance. The <id> element defines the mapping from that property to the primary key column.

<id
        name="propertyName"                                          (1)
        type="typename"                                              (2)
        column="column_name"                                         (3)
        unsaved-value="null|any|none|undefined|id_value"             (4)
        access="field|property|ClassName">                           (5)
        node="element-name|@attribute-name|element/@attribute|."

        <generator class="generatorClass"/>
</id>

(1)	

name (optional): The name of the identifier property.
(2)	

type (optional): A name that indicates the Hibernate type.
(3)	

column (optional - defaults to the property name): The name of the primary key column.
(4)	

unsaved-value (optional - defaults to a "sensible" value): An identifier property value that indicates that an instance is newly instantiated (unsaved), distinguishing it from detached instances that were saved or loaded in a previous session.
(5)	

access (optional - defaults to property): The strategy Hibernate should use for accessing the property value.

If the name attribute is missing, it is assumed that the class has no identifier property.

The unsaved-value attribute is almost never needed in Hibernate3.

There is an alternative <composite-id> declaration to allow access to legacy data with composite keys. We strongly discourage its use for anything else.
5.1.4.1. Generator

The optional <generator> child element names a Java class used to generate unique identifiers for instances of the persistent class. If any parameters are required to configure or initialize the generator instance, they are passed using the <param> element.

<id name="id" type="long" column="cat_id">
        <generator class="org.hibernate.id.TableHiLoGenerator">
                <param name="table">uid_table</param>
                <param name="column">next_hi_value_column</param>
        </generator>
</id>

All generators implement the interface org.hibernate.id.IdentifierGenerator. This is a very simple interface; some applications may choose to provide their own specialized implementations. However, Hibernate provides a range of built-in implementations. There are shortcut names for the built-in generators:

increment

    generates identifiers of type long, short or int that are unique only when no other process is inserting data into the same table. Do not use in a cluster. 
identity

    supports identity columns in DB2, MySQL, MS SQL Server, Sybase and HypersonicSQL. The returned identifier is of type long, short or int. 
sequence

    uses a sequence in DB2, PostgreSQL, Oracle, SAP DB, McKoi or a generator in Interbase. The returned identifier is of type long, short or int 
hilo

    uses a hi/lo algorithm to efficiently generate identifiers of type long, short or int, given a table and column (by default hibernate_unique_key and next_hi respectively) as a source of hi values. The hi/lo algorithm generates identifiers that are unique only for a particular database. 
seqhilo

    uses a hi/lo algorithm to efficiently generate identifiers of type long, short or int, given a named database sequence. 
uuid

    uses a 128-bit UUID algorithm to generate identifiers of type string, unique within a network (the IP address is used). The UUID is encoded as a string of hexadecimal digits of length 32. 
guid

    uses a database-generated GUID string on MS SQL Server and MySQL. 
native

    picks identity, sequence or hilo depending upon the capabilities of the underlying database. 
assigned

    lets the application to assign an identifier to the object before save() is called. This is the default strategy if no <generator> element is specified. 
select

    retrieves a primary key assigned by a database trigger by selecting the row by some unique key and retrieving the primary key value. 
foreign

    uses the identifier of another associated object. Usually used in conjunction with a <one-to-one> primary key association. 

5.1.4.2. Hi/lo algorithm

The hilo and seqhilo generators provide two alternate implementations of the hi/lo algorithm, a favorite approach to identifier generation. The first implementation requires a "special" database table to hold the next available "hi" value. The second uses an Oracle-style sequence (where supported).

<id name="id" type="long" column="cat_id">
        <generator class="hilo">
                <param name="table">hi_value</param>
                <param name="column">next_value</param>
                <param name="max_lo">100</param>
        </generator>
</id>

<id name="id" type="long" column="cat_id">
        <generator class="seqhilo">
                <param name="sequence">hi_value</param>
                <param name="max_lo">100</param>
        </generator>
</id>

Unfortunately, you can't use hilo when supplying your own Connection to Hibernate. When Hibernate is using an application server datasource to obtain connections enlisted with JTA, you must properly configure the hibernate.transaction.manager_lookup_class.
5.1.4.3. UUID algorithm

The UUID contains: IP address, startup time of the JVM (accurate to a quarter second), system time and a counter value (unique within the JVM). It's not possible to obtain a MAC address or memory address from Java code, so this is the best we can do without using JNI.
5.1.4.4. Identity columns and sequences

For databases which support identity columns (DB2, MySQL, Sybase, MS SQL), you may use identity key generation. For databases that support sequences (DB2, Oracle, PostgreSQL, Interbase, McKoi, SAP DB) you may use sequence style key generation. Both these strategies require two SQL queries to insert a new object.

<id name="id" type="long" column="person_id">
        <generator class="sequence">
                <param name="sequence">person_id_sequence</param>
        </generator>
</id>

<id name="id" type="long" column="person_id" unsaved-value="0">
        <generator class="identity"/>
</id>

For cross-platform development, the native strategy will choose from the identity, sequence and hilo strategies, dependant upon the capabilities of the underlying database.
5.1.4.5. Assigned identifiers

If you want the application to assign identifiers (as opposed to having Hibernate generate them), you may use the assigned generator. This special generator will use the identifier value already assigned to the object's identifier property. This generator is used when the primary key is a natural key instead of a surrogate key. This is the default behavior if you do no specify a <generator> element.

Choosing the assigned generator makes Hibernate use unsaved-value="undefined", forcing Hibernate to go to the database to determine if an instance is transient or detached, unless there is a version or timestamp property, or you define Interceptor.isUnsaved().
5.1.4.6. Primary keys assigned by triggers

For legacy schemas only (Hibernate does not generate DDL with triggers).

<id name="id" type="long" column="person_id">
        <generator class="select">
                <param name="key">socialSecurityNumber</param>
        </generator>
</id>

In the above example, there is a unique valued property named socialSecurityNumber defined by the class, as a natural key, and a surrogate key named person_id whose value is generated by a trigger.
5.1.5. composite-id

<composite-id
        name="propertyName"
        class="ClassName"
        mapped="true|false"
        access="field|property|ClassName">
        node="element-name|."

        <key-property name="propertyName" type="typename" column="column_name"/>
        <key-many-to-one name="propertyName class="ClassName" column="column_name"/>
        ......
</composite-id>

For a table with a composite key, you may map multiple properties of the class as identifier properties. The <composite-id> element accepts <key-property> property mappings and <key-many-to-one> mappings as child elements.

<composite-id>
        <key-property name="medicareNumber"/>
        <key-property name="dependent"/>
</composite-id>

Your persistent class must override equals() and hashCode() to implement composite identifier equality. It must also implements Serializable.

Unfortunately, this approach to composite identifiers means that a persistent object is its own identifier. There is no convenient "handle" other than the object itself. You must instantiate an instance of the persistent class itself and populate its identifier properties before you can load() the persistent state associated with a composite key. We call this approach an embedded composite identifier, and discourage it for serious applications.

A second approach is what we call a mapped composite identifier, where the identifier properties named inside the <composite-id> element are duplicated on both the persistent class and a separate identifier class.

<composite-id class="MedicareId" mapped="true">
        <key-property name="medicareNumber"/>
        <key-property name="dependent"/>
</composite-id>

In this example, both the composite identifier class, MedicareId, and the entity class itself have properties named medicareNumber and dependent. The identifier class must override equals() and hashCode() and implement. Serializable. The disadvantage of this approach is quite obvious?code duplication.

The following attributes are used to specify a mapped composite identifier:

    *

      mapped (optional, defaults to false): indicates that a mapped composite identifier is used, and that the contained property mappings refer to both the entity class and the composite identifier class.
    *

      class (optional, but required for a mapped composite identifier): The class used as a composite identifier. 

We will describe a third, even more convenient approach where the composite identifier is implemented as a component class in Section 8.4, ?Components as composite identifiers?. The attributes described below apply only to this alternative approach:

    *

      name (optional, required for this approach): A property of component type that holds the composite identifier (see chapter 9).
    *

      access (optional - defaults to property): The strategy Hibernate should use for accessing the property value.
    *

      class (optional - defaults to the property type determined by reflection): The component class used as a composite identifier (see next section). 

This third approach, an identifier component is the one we recommend for almost all applications.
5.1.6. discriminator

The <discriminator> element is required for polymorphic persistence using the table-per-class-hierarchy mapping strategy and declares a discriminator column of the table. The discriminator column contains marker values that tell the persistence layer what subclass to instantiate for a particular row. A restricted set of types may be used: string, character, integer, byte, short, boolean, yes_no, true_false.

<discriminator
        column="discriminator_column"                      (1)
        type="discriminator_type"                          (2)
        force="true|false"                                 (3)
        insert="true|false"                                (4)
        formula="arbitrary sql expression"                 (5)
/>

(1)	

column (optional - defaults to class) the name of the discriminator column.
(2)	

type (optional - defaults to string) a name that indicates the Hibernate type
(3)	

force (optional - defaults to false) "force" Hibernate to specify allowed discriminator values even when retrieving all instances of the root class.
(4)	

insert (optional - defaults to true) set this to false if your discriminator column is also part of a mapped composite identifier. (Tells Hibernate to not include the column in SQL INSERTs.)
(5)	

formula (optional) an arbitrary SQL expression that is executed when a type has to be evaluated. Allows content-based discrimination.

Actual values of the discriminator column are specified by the discriminator-value attribute of the <class> and <subclass> elements.

The force attribute is (only) useful if the table contains rows with "extra" discriminator values that are not mapped to a persistent class. This will not usually be the case.

Using the formula attribute you can declare an arbitrary SQL expression that will be used to evaluate the type of a row:

<discriminator
    formula="case when CLASS_TYPE in ('a', 'b', 'c') then 0 else 1 end"
    type="integer"/>

5.1.7. version (optional)

The <version> element is optional and indicates that the table contains versioned data. This is particularly useful if you plan to use long transactions (see below).

<version
        column="version_column"                                      (1)
        name="propertyName"                                          (2)
        type="typename"                                              (3)
        access="field|property|ClassName"                            (4)
        unsaved-value="null|negative|undefined"                      (5)
        generated="never|always"                                     (6)
        insert="true|false"                                          (7)
        node="element-name|@attribute-name|element/@attribute|."
/>

(1)	

column (optional - defaults to the property name): The name of the column holding the version number.
(2)	

name: The name of a property of the persistent class.
(3)	

type (optional - defaults to integer): The type of the version number.
(4)	

access (optional - defaults to property): The strategy Hibernate should use for accessing the property value.
(5)	

unsaved-value (optional - defaults to undefined): A version property value that indicates that an instance is newly instantiated (unsaved), distinguishing it from detached instances that were saved or loaded in a previous session. (undefined specifies that the identifier property value should be used.)
(6)	

generated (optional - defaults to never): Specifies that this version property value is actually generated by the database. See the discussion of Section 5.6, ?Generated Properties?.
(7)	

insert (optional - defaults to true): Specifies whether the version column should be included in SQL insert statements. May be set to false if and only if the database column is defined with a default value of 0.

Version numbers may be of Hibernate type long, integer, short, timestamp or calendar.

A version or timestamp property should never be null for a detached instance, so Hibernate will detact any instance with a null version or timestamp as transient, no matter what other unsaved-value strategies are specified. Declaring a nullable version or timestamp property is an easy way to avoid any problems with transitive reattachment in Hibernate, especially useful for people using assigned identifiers or composite keys!
5.1.8. timestamp (optional)

The optional <timestamp> element indicates that the table contains timestamped data. This is intended as an alternative to versioning. Timestamps are by nature a less safe implementation of optimistic locking. However, sometimes the application might use the timestamps in other ways.

<timestamp
        column="timestamp_column"                                    (1)
        name="propertyName"                                          (2)
        access="field|property|ClassName"                            (3)
        unsaved-value="null|undefined"                               (4)
        source="vm|db"                                               (5)
        generated="never|always"                                     (6)
        node="element-name|@attribute-name|element/@attribute|."
/>

(1)	

column (optional - defaults to the property name): The name of a column holding the timestamp.
(2)	

name: The name of a JavaBeans style property of Java type Date or Timestamp of the persistent class.
(3)	

access (optional - defaults to property): The strategy Hibernate should use for accessing the property value.
(4)	

unsaved-value (optional - defaults to null): A version property value that indicates that an instance is newly instantiated (unsaved), distinguishing it from detached instances that were saved or loaded in a previous session. (undefined specifies that the identifier property value should be used.)
(5)	

source (optional - defaults to vm): From where should Hibernate retrieve the timestamp value? From the database, or from the current JVM? Database-based timestamps incur an overhead because Hibernate must hit the database in order to determine the "next value", but will be safer for use in clustered environments. Note also, that not all Dialects are known to support retrieving of the database's current timestamp, while others might be unsafe for usage in locking due to lack of precision (Oracle 8 for example).
(6)	

generated (optional - defaults to never): Specifies that this timestamp property value is actually generated by the database. See the discussion of Section 5.6, ?Generated Properties?.

Note that <timestamp> is equivalent to <version type="timestamp">. And <timestamp use-db="true"> is equivalent to <version type="dbtimestamp">
5.1.9. property

The <property> element declares a persistent, JavaBean style property of the class.

<property
        name="propertyName"                                          (1)
        column="column_name"                                         (2)
        type="typename"                                              (3)
        update="true|false"                                          (4)
        insert="true|false"                                          (4)
        formula="arbitrary SQL expression"                           (5)
        access="field|property|ClassName"                            (6)
        lazy="true|false"                                            (7)
        unique="true|false"                                          (8)
        not-null="true|false"                                        (9)
        optimistic-lock="true|false"                                 (10)
        generated="never|insert|always"                              (11)
        node="element-name|@attribute-name|element/@attribute|."
        index="index_name"
        unique_key="unique_key_id"
        length="L"
        precision="P"
        scale="S"
/>

(1)	

name: the name of the property, with an initial lowercase letter.
(2)	

column (optional - defaults to the property name): the name of the mapped database table column. This may also be specified by nested <column> element(s).
(3)	

type (optional): a name that indicates the Hibernate type.
(4)	

update, insert (optional - defaults to true) : specifies that the mapped columns should be included in SQL UPDATE and/or INSERT statements. Setting both to false allows a pure "derived" property whose value is initialized from some other property that maps to the same colum(s) or by a trigger or other application.
(5)	

formula (optional): an SQL expression that defines the value for a computed property. Computed properties do not have a column mapping of their own.
(6)	

access (optional - defaults to property): The strategy Hibernate should use for accessing the property value.
(7)	

lazy (optional - defaults to false): Specifies that this property should be fetched lazily when the instance variable is first accessed (requires build-time bytecode instrumentation).
(8)	

unique (optional): Enable the DDL generation of a unique constraint for the columns. Also, allow this to be the target of a property-ref.
(9)	

not-null (optional): Enable the DDL generation of a nullability constraint for the columns.
(10)	

optimistic-lock (optional - defaults to true): Specifies that updates to this property do or do not require acquisition of the optimistic lock. In other words, determines if a version increment should occur when this property is dirty.
(11)	

generated (optional - defaults to never): Specifies that this property value is actually generated by the database. See the discussion of Section 5.6, ?Generated Properties?.

typename could be:

   1.

      The name of a Hibernate basic type (eg. integer, string, character, date, timestamp, float, binary, serializable, object, blob).
   2.

      The name of a Java class with a default basic type (eg. int, float, char, java.lang.String, java.util.Date, java.lang.Integer, java.sql.Clob).
   3.

      The name of a serializable Java class.
   4.

      The class name of a custom type (eg. com.illflow.type.MyCustomType). 

If you do not specify a type, Hibernate will use reflection upon the named property to take a guess at the correct Hibernate type. Hibernate will try to interpret the name of the return class of the property getter using rules 2, 3, 4 in that order. However, this is not always enough. In certain cases you will still need the type attribute. (For example, to distinguish between Hibernate.DATE and Hibernate.TIMESTAMP, or to specify a custom type.)

The access attribute lets you control how Hibernate will access the property at runtime. By default, Hibernate will call the property get/set pair. If you specify access="field", Hibernate will bypass the get/set pair and access the field directly, using reflection. You may specify your own strategy for property access by naming a class that implements the interface org.hibernate.property.PropertyAccessor.

An especially powerful feature are derived properties. These properties are by definition read-only, the property value is computed at load time. You declare the computation as a SQL expression, this translates to a SELECT clause subquery in the SQL query that loads an instance:

<property name="totalPrice"
    formula="( SELECT SUM (li.quantity*p.price) FROM LineItem li, Product p
                WHERE li.productId = p.productId
                AND li.customerId = customerId
                AND li.orderNumber = orderNumber )"/>

Note that you can reference the entities own table by not declaring an alias on a particular column (customerId in the given example). Also note that you can use the nested <formula> mapping element if you don't like to use the attribute.
5.1.10. many-to-one

An ordinary association to another persistent class is declared using a many-to-one element. The relational model is a many-to-one association: a foreign key in one table is referencing the primary key column(s) of the target table.

<many-to-one
        name="propertyName"                                          (1)
        column="column_name"                                         (2)
        class="ClassName"                                            (3)
        cascade="cascade_style"                                      (4)
        fetch="join|select"                                          (5)
        update="true|false"                                          (6)
        insert="true|false"                                          (6)
        property-ref="propertyNameFromAssociatedClass"               (7)
        access="field|property|ClassName"                            (8)
        unique="true|false"                                          (9)
        not-null="true|false"                                        (10)
        optimistic-lock="true|false"                                 (11)
        lazy="proxy|no-proxy|false"                                  (12)
        not-found="ignore|exception"                                 (13)
        entity-name="EntityName"                                     (14)
        formula="arbitrary SQL expression"                           (15)
        node="element-name|@attribute-name|element/@attribute|."
        embed-xml="true|false"
        index="index_name"
        unique_key="unique_key_id"
        foreign-key="foreign_key_name"
/>

(1)	

name: The name of the property.
(2)	

column (optional): The name of the foreign key column. This may also be specified by nested <column> element(s).
(3)	

class (optional - defaults to the property type determined by reflection): The name of the associated class.
(4)	

cascade (optional): Specifies which operations should be cascaded from the parent object to the associated object.
(5)	

fetch (optional - defaults to select): Chooses between outer-join fetching or sequential select fetching.
(6)	

update, insert (optional - defaults to true) specifies that the mapped columns should be included in SQL UPDATE and/or INSERT statements. Setting both to false allows a pure "derived" association whose value is initialized from some other property that maps to the same colum(s) or by a trigger or other application.
(7)	

property-ref: (optional) The name of a property of the associated class that is joined to this foreign key. If not specified, the primary key of the associated class is used.
(8)	

access (optional - defaults to property): The strategy Hibernate should use for accessing the property value.
(9)	

unique (optional): Enable the DDL generation of a unique constraint for the foreign-key column. Also, allow this to be the target of a property-ref. This makes the association multiplicity effectively one to one.
(10)	

not-null (optional): Enable the DDL generation of a nullability constraint for the foreign key columns.
(11)	

optimistic-lock (optional - defaults to true): Specifies that updates to this property do or do not require acquisition of the optimistic lock. In other words, dertermines if a version increment should occur when this property is dirty.
(12)	

lazy (optional - defaults to proxy): By default, single point associations are proxied. lazy="no-proxy" specifies that the property should be fetched lazily when the instance variable is first accessed (requires build-time bytecode instrumentation). lazy="false" specifies that the association will always be eagerly fetched.
(13)	

not-found (optional - defaults to exception): Specifies how foreign keys that reference missing rows will be handled: ignore will treat a missing row as a null association.
(14)	

entity-name (optional): The entity name of the associated class.

Setting a value of the cascade attribute to any meaningful value other than none will propagate certain operations to the associated object. The meaningful values are the names of Hibernate's basic operations, persist, merge, delete, save-update, evict, replicate, lock, refresh, as well as the special values delete-orphan and all and comma-separated combinations of operation names, for example, cascade="persist,merge,evict" or cascade="all,delete-orphan". See Section 10.11, ?Transitive persistence? for a full explanation. Note that single valued associations (many-to-one and one-to-one associations) do not support orphan delete.

A typical many-to-one declaration looks as simple as this:

<many-to-one name="product" class="Product" column="PRODUCT_ID"/>

The property-ref attribute should only be used for mapping legacy data where a foreign key refers to a unique key of the associated table other than the primary key. This is an ugly relational model. For example, suppose the Product class had a unique serial number, that is not the primary key. (The unique attribute controls Hibernate's DDL generation with the SchemaExport tool.)

<property name="serialNumber" unique="true" type="string" column="SERIAL_NUMBER"/>

Then the mapping for OrderItem might use:

<many-to-one name="product" property-ref="serialNumber" column="PRODUCT_SERIAL_NUMBER"/>

This is certainly not encouraged, however.

If the referenced unique key comprises multiple properties of the associated entity, you should map the referenced properties inside a named <properties> element.

If the referenced unique key is the property of a component, you may specify a property path:

<many-to-one name="owner" property-ref="identity.ssn" column="OWNER_SSN"/>

5.1.11. one-to-one

A one-to-one association to another persistent class is declared using a one-to-one element.

<one-to-one
        name="propertyName"                                          (1)
        class="ClassName"                                            (2)
        cascade="cascade_style"                                      (3)
        constrained="true|false"                                     (4)
        fetch="join|select"                                          (5)
        property-ref="propertyNameFromAssociatedClass"               (6)
        access="field|property|ClassName"                            (7)
        formula="any SQL expression"                                 (8)
        lazy="proxy|no-proxy|false"                                  (9)
        entity-name="EntityName"                                     (10)
        node="element-name|@attribute-name|element/@attribute|."
        embed-xml="true|false"
        foreign-key="foreign_key_name"
/>

(1)	

name: The name of the property.
(2)	

class (optional - defaults to the property type determined by reflection): The name of the associated class.
(3)	

cascade (optional) specifies which operations should be cascaded from the parent object to the associated object.
(4)	

constrained (optional) specifies that a foreign key constraint on the primary key of the mapped table references the table of the associated class. This option affects the order in which save() and delete() are cascaded, and determines whether the association may be proxied (it is also used by the schema export tool).
(5)	

fetch (optional - defaults to select): Chooses between outer-join fetching or sequential select fetching.
(6)	

property-ref: (optional) The name of a property of the associated class that is joined to the primary key of this class. If not specified, the primary key of the associated class is used.
(7)	

access (optional - defaults to property): The strategy Hibernate should use for accessing the property value.
(8)	

formula (optional): Almost all one to one associations map to the primary key of the owning entity. In the rare case that this is not the case, you may specify a some other column, columns or expression to join on using an SQL formula. (See org.hibernate.test.onetooneformula for an example.)
(9)	

lazy (optional - defaults to proxy): By default, single point associations are proxied. lazy="no-proxy" specifies that the property should be fetched lazily when the instance variable is first accessed (requires build-time bytecode instrumentation). lazy="false" specifies that the association will always be eagerly fetched. Note that if constrained="false", proxying is impossible and Hibernate will eager fetch the association!
(10)	

entity-name (optional): The entity name of the associated class.

There are two varieties of one-to-one association:

    *

      primary key associations
    *

      unique foreign key associations 

Primary key associations don't need an extra table column; if two rows are related by the association then the two table rows share the same primary key value. So if you want two objects to be related by a primary key association, you must make sure that they are assigned the same identifier value!

For a primary key association, add the following mappings to Employee and Person, respectively.

<one-to-one name="person" class="Person"/>

<one-to-one name="employee" class="Employee" constrained="true"/>

Now we must ensure that the primary keys of related rows in the PERSON and EMPLOYEE tables are equal. We use a special Hibernate identifier generation strategy called foreign:

<class name="person" table="PERSON">
    <id name="id" column="PERSON_ID">
        <generator class="foreign">
            <param name="property">employee</param>
        </generator>
    </id>
    ...
    <one-to-one name="employee"
        class="Employee"
        constrained="true"/>
</class>

A newly saved instance of Person is then assigned the same primary key value as the Employee instance refered with the employee property of that Person.

Alternatively, a foreign key with a unique constraint, from Employee to Person, may be expressed as:

<many-to-one name="person" class="Person" column="PERSON_ID" unique="true"/>

And this association may be made bidirectional by adding the following to the Person mapping:

<one-to-one name"employee" class="Employee" property-ref="person"/>

5.1.12. natural-id

<natural-id mutable="true|false"/>
        <property ... />
        <many-to-one ... />
        ......
</natural-id>

Even though we recommend the use of surrogate keys as primary keys, you should still try to identify natural keys for all entities. A natural key is a property or combination of properties that is unique and non-null. If it is also immutable, even better. Map the properties of the natural key inside the <natural-id> element. Hibernate will generate the necessary unique key and nullability constraints, and your mapping will be more self-documenting.

We strongly recommend that you implement equals() and hashCode() to compare the natural key properties of the entity.

This mapping is not intended for use with entities with natural primary keys.

    *

      mutable (optional, defaults to false): By default, natural identifier properties as assumed to be immutable (constant). 

5.1.13. component, dynamic-component

The <component> element maps properties of a child object to columns of the table of a parent class. Components may, in turn, declare their own properties, components or collections. See "Components" below.

<component 
        name="propertyName"                 (1)
        class="className"                   (2)
        insert="true|false"                 (3)
        update="true|false"                 (4)
        access="field|property|ClassName"   (5)
        lazy="true|false"                   (6)
        optimistic-lock="true|false"        (7)
        unique="true|false"                 (8)
        node="element-name|."
>
        
        <property ...../>
        <many-to-one .... />
        ........
</component>

(1)	

name: The name of the property.
(2)	

class (optional - defaults to the property type determined by reflection): The name of the component (child) class.
(3)	

insert: Do the mapped columns appear in SQL INSERTs?
(4)	

update: Do the mapped columns appear in SQL UPDATEs?
(5)	

access (optional - defaults to property): The strategy Hibernate should use for accessing the property value.
(6)	

lazy (optional - defaults to false): Specifies that this component should be fetched lazily when the instance variable is first accessed (requires build-time bytecode instrumentation).
(7)	

optimistic-lock (optional - defaults to true): Specifies that updates to this component do or do not require acquisition of the optimistic lock. In other words, determines if a version increment should occur when this property is dirty.
(8)	

unique (optional - defaults to false): Specifies that a unique constraint exists upon all mapped columns of the component.

The child <property> tags map properties of the child class to table columns.

The <component> element allows a <parent> subelement that maps a property of the component class as a reference back to the containing entity.

The <dynamic-component> element allows a Map to be mapped as a component, where the property names refer to keys of the map, see Section 8.5, ?Dynamic components?.
5.1.14. properties

The <properties> element allows the definition of a named, logical grouping of properties of a class. The most important use of the construct is that it allows a combination of properties to be the target of a property-ref. It is also a convenient way to define a multi-column unique constraint.

<properties 
        name="logicalName"                  (1)
        insert="true|false"                 (2)
        update="true|false"                 (3)
        optimistic-lock="true|false"        (4)
        unique="true|false"                 (5)
>
        
        <property ...../>
        <many-to-one .... />
        ........
</properties>

(1)	

name: The logical name of the grouping - not an actual property name.
(2)	

insert: Do the mapped columns appear in SQL INSERTs?
(3)	

update: Do the mapped columns appear in SQL UPDATEs?
(4)	

optimistic-lock (optional - defaults to true): Specifies that updates to these properties do or do not require acquisition of the optimistic lock. In other words, determines if a version increment should occur when these properties are dirty.
(5)	

unique (optional - defaults to false): Specifies that a unique constraint exists upon all mapped columns of the component.

For example, if we have the following <properties> mapping:

<class name="Person">
    <id name="personNumber"/>
    ...
    <properties name="name" 
            unique="true" update="false">
        <property name="firstName"/>
        <property name="initial"/>
        <property name="lastName"/>
    </properties>
</class>

Then we might have some legacy data association which refers to this unique key of the Person table, instead of to the primary key:

<many-to-one name="person" 
         class="Person" property-ref="name">
    <column name="firstName"/>
    <column name="initial"/>
    <column name="lastName"/>
</many-to-one>

We don't recommend the use of this kind of thing outside the context of mapping legacy data.
5.1.15. subclass

Finally, polymorphic persistence requires the declaration of each subclass of the root persistent class. For the table-per-class-hierarchy mapping strategy, the <subclass> declaration is used.

<subclass
        name="ClassName"                              (1)
        discriminator-value="discriminator_value"     (2)
        proxy="ProxyInterface"                        (3)
        lazy="true|false"                             (4)
        dynamic-update="true|false"
        dynamic-insert="true|false"
        entity-name="EntityName"
        node="element-name"
        extends="SuperclassName">

        <property .... />
        .....
</subclass>

(1)	

name: The fully qualified class name of the subclass.
(2)	

discriminator-value (optional - defaults to the class name): A value that distiguishes individual subclasses.
(3)	

proxy (optional): Specifies a class or interface to use for lazy initializing proxies.
(4)	

lazy (optional, defaults to true): Setting lazy="false" disables the use of lazy fetching.

Each subclass should declare its own persistent properties and subclasses. <version> and <id> properties are assumed to be inherited from the root class. Each subclass in a heirarchy must define a unique discriminator-value. If none is specified, the fully qualified Java class name is used.

For information about inheritance mappings, see Chapter 9, Inheritance Mapping.
5.1.16. joined-subclass

Alternatively, each subclass may be mapped to its own table (table-per-subclass mapping strategy). Inherited state is retrieved by joining with the table of the superclass. We use the <joined-subclass> element.

<joined-subclass
        name="ClassName"                    (1)
        table="tablename"                   (2)
        proxy="ProxyInterface"              (3)
        lazy="true|false"                   (4)
        dynamic-update="true|false"
        dynamic-insert="true|false"
        schema="schema"
        catalog="catalog"
        extends="SuperclassName"
        persister="ClassName"
        subselect="SQL expression"
        entity-name="EntityName"
        node="element-name">

        <key .... >

        <property .... />
        .....
</joined-subclass>

(1)	

name: The fully qualified class name of the subclass.
(2)	

table: The name of the subclass table.
(3)	

proxy (optional): Specifies a class or interface to use for lazy initializing proxies.
(4)	

lazy (optional, defaults to true): Setting lazy="false" disables the use of lazy fetching.

No discriminator column is required for this mapping strategy. Each subclass must, however, declare a table column holding the object identifier using the <key> element. The mapping at the start of the chapter would be re-written as:

<?xml version="1.0"?>
<!DOCTYPE hibernate-mapping PUBLIC
        "-//Hibernate/Hibernate Mapping DTD//EN"
        "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd">

<hibernate-mapping package="eg">

        <class name="Cat" table="CATS">
                <id name="id" column="uid" type="long">
                        <generator class="hilo"/>
                </id>
                <property name="birthdate" type="date"/>
                <property name="color" not-null="true"/>
                <property name="sex" not-null="true"/>
                <property name="weight"/>
                <many-to-one name="mate"/>
                <set name="kittens">
                        <key column="MOTHER"/>
                        <one-to-many class="Cat"/>
                </set>
                <joined-subclass name="DomesticCat" table="DOMESTIC_CATS">
                    <key column="CAT"/>
                    <property name="name" type="string"/>
                </joined-subclass>
        </class>

        <class name="eg.Dog">
                <!-- mapping for Dog could go here -->
        </class>

</hibernate-mapping>

For information about inheritance mappings, see Chapter 9, Inheritance Mapping.
5.1.17. union-subclass

A third option is to map only the concrete classes of an inheritance hierarchy to tables, (the table-per-concrete-class strategy) where each table defines all persistent state of the class, including inherited state. In Hibernate, it is not absolutely necessary to explicitly map such inheritance hierarchies. You can simply map each class with a separate <class> declaration. However, if you wish use polymorphic associations (e.g. an association to the superclass of your hierarchy), you need to use the <union-subclass> mapping.

<union-subclass
        name="ClassName"                    (1)
        table="tablename"                   (2)
        proxy="ProxyInterface"              (3)
        lazy="true|false"                   (4)
        dynamic-update="true|false"
        dynamic-insert="true|false"
        schema="schema"
        catalog="catalog"
        extends="SuperclassName"
        abstract="true|false"
        persister="ClassName"
        subselect="SQL expression"
        entity-name="EntityName"
        node="element-name">

        <property .... />
        .....
</union-subclass>

(1)	

name: The fully qualified class name of the subclass.
(2)	

table: The name of the subclass table.
(3)	

proxy (optional): Specifies a class or interface to use for lazy initializing proxies.
(4)	

lazy (optional, defaults to true): Setting lazy="false" disables the use of lazy fetching.

No discriminator column or key column is required for this mapping strategy.

For information about inheritance mappings, see Chapter 9, Inheritance Mapping.
5.1.18. join

Using the <join> element, it is possible to map properties of one class to several tables.

<join
        table="tablename"                        (1)
        schema="owner"                           (2)
        catalog="catalog"                        (3)
        fetch="join|select"                      (4)
        inverse="true|false"                     (5)
        optional="true|false">                   (6)
        
        <key ... />
        
        <property ... />
        ...
</join>

(1)	

table: The name of the joined table.
(2)	

schema (optional): Override the schema name specified by the root <hibernate-mapping> element.
(3)	

catalog (optional): Override the catalog name specified by the root <hibernate-mapping> element.
(4)	

fetch (optional - defaults to join): If set to join, the default, Hibernate will use an inner join to retrieve a <join> defined by a class or its superclasses and an outer join for a <join> defined by a subclass. If set to select then Hibernate will use a sequential select for a <join> defined on a subclass, which will be issued only if a row turns out to represent an instance of the subclass. Inner joins will still be used to retrieve a <join> defined by the class and its superclasses.
(5)	

inverse (optional - defaults to false): If enabled, Hibernate will not try to insert or update the properties defined by this join.
(6)	

optional (optional - defaults to false): If enabled, Hibernate will insert a row only if the properties defined by this join are non-null and will always use an outer join to retrieve the properties.

For example, the address information for a person can be mapped to a separate table (while preserving value type semantics for all properties):

<class name="Person"
    table="PERSON">

    <id name="id" column="PERSON_ID">...</id>

    <join table="ADDRESS">
        <key column="ADDRESS_ID"/>
        <property name="address"/>
        <property name="zip"/>
        <property name="country"/>
    </join>
    ...

This feature is often only useful for legacy data models, we recommend fewer tables than classes and a fine-grained domain model. However, it is useful for switching between inheritance mapping strategies in a single hierarchy, as explained later.
5.1.19. key

We've seen the <key> element crop up a few times now. It appears anywhere the parent mapping element defines a join to a new table, and defines the foreign key in the joined table, that references the primary key of the original table.

<key
        column="columnname"                      (1)
        on-delete="noaction|cascade"             (2)
        property-ref="propertyName"              (3)
        not-null="true|false"                    (4)
        update="true|false"                      (5)
        unique="true|false"                      (6)
/>

(1)	

column (optional): The name of the foreign key column. This may also be specified by nested <column> element(s).
(2)	

on-delete (optional, defaults to noaction): Specifies whether the foreign key constraint has database-level cascade delete enabled.
(3)	

property-ref (optional): Specifies that the foreign key refers to columns that are not the primary key of the orginal table. (Provided for legacy data.)
(4)	

not-null (optional): Specifies that the foreign key columns are not nullable (this is implied whenever the foreign key is also part of the primary key).
(5)	

update (optional): Specifies that the foreign key should never be updated (this is implied whenever the foreign key is also part of the primary key).
(6)	

unique (optional): Specifies that the foreign key should have a unique constraint (this is implied whenever the foreign key is also the primary key).

We recommend that for systems where delete performance is important, all keys should be defined on-delete="cascade", and Hibernate will use a database-level ON CASCADE DELETE constraint, instead of many individual DELETE statements. Be aware that this feature bypasses Hibernate's usual optimistic locking strategy for versioned data.

The not-null and update attributes are useful when mapping a unidirectional one to many association. If you map a unidirectional one to many to a non-nullable foreign key, you must declare the key column using <key not-null="true">.
5.1.20. column and formula elements

Any mapping element which accepts a column attribute will alternatively accept a <column> subelement. Likewise, <formula> is an alternative to the formula attribute.

<column
        name="column_name"
        length="N"
        precision="N"
        scale="N"
        not-null="true|false"
        unique="true|false"
        unique-key="multicolumn_unique_key_name"
        index="index_name"
        sql-type="sql_type_name"
        check="SQL expression"
        default="SQL expression"/>

<formula>SQL expression</formula>

column and formula attributes may even be combined within the same property or association mapping to express, for example, exotic join conditions.

<many-to-one name="homeAddress" class="Address"
        insert="false" update="false">
    <column name="person_id" not-null="true" length="10"/>
    <formula>'MAILING'</formula>
</many-to-one>

5.1.21. import

Suppose your application has two persistent classes with the same name, and you don't want to specify the fully qualified (package) name in Hibernate queries. Classes may be "imported" explicitly, rather than relying upon auto-import="true". You may even import classes and interfaces that are not explicitly mapped.

<import class="java.lang.Object" rename="Universe"/>

<import
        class="ClassName"              (1)
        rename="ShortName"             (2)
/>

(1)	

class: The fully qualified class name of of any Java class.
(2)	

rename (optional - defaults to the unqualified class name): A name that may be used in the query language.
5.1.22. any

There is one further type of property mapping. The <any> mapping element defines a polymorphic association to classes from multiple tables. This type of mapping always requires more than one column. The first column holds the type of the associated entity. The remaining columns hold the identifier. It is impossible to specify a foreign key constraint for this kind of association, so this is most certainly not meant as the usual way of mapping (polymorphic) associations. You should use this only in very special cases (eg. audit logs, user session data, etc).

The meta-type attribute lets the application specify a custom type that maps database column values to persistent classes which have identifier properties of the type specified by id-type. You must specify the mapping from values of the meta-type to class names.

<any name="being" id-type="long" meta-type="string">
    <meta-value value="TBL_ANIMAL" class="Animal"/>
    <meta-value value="TBL_HUMAN" class="Human"/>
    <meta-value value="TBL_ALIEN" class="Alien"/>
    <column name="table_name"/>
    <column name="id"/>
</any>

<any
        name="propertyName"                      (1)
        id-type="idtypename"                     (2)
        meta-type="metatypename"                 (3)
        cascade="cascade_style"                  (4)
        access="field|property|ClassName"        (5)
        optimistic-lock="true|false"             (6)
>
        <meta-value ... />
        <meta-value ... />
        .....
        <column .... />
        <column .... />
        .....
</any>

(1)	

name: the property name.
(2)	

id-type: the identifier type.
(3)	

meta-type (optional - defaults to string): Any type that is allowed for a discriminator mapping.
(4)	

cascade (optional- defaults to none): the cascade style.
(5)	

access (optional - defaults to property): The strategy Hibernate should use for accessing the property value.
(6)	

optimistic-lock (optional - defaults to true): Specifies that updates to this property do or do not require acquisition of the optimistic lock. In other words, define if a version increment should occur if this property is dirty.
5.2. Hibernate Types
5.2.1. Entities and values

To understand the behaviour of various Java language-level objects with respect to the persistence service, we need to classify them into two groups:

An entity exists independently of any other objects holding references to the entity. Contrast this with the usual Java model where an unreferenced object is garbage collected. Entities must be explicitly saved and deleted (except that saves and deletions may be cascaded from a parent entity to its children). This is different from the ODMG model of object persistence by reachablity - and corresponds more closely to how application objects are usually used in large systems. Entities support circular and shared references. They may also be versioned.

An entity's persistent state consists of references to other entities and instances of value types. Values are primitives, collections (not what's inside a collection), components and certain immutable objects. Unlike entities, values (in particular collections and components) are persisted and deleted by reachability. Since value objects (and primitives) are persisted and deleted along with their containing entity they may not be independently versioned. Values have no independent identity, so they cannot be shared by two entities or collections.

Up until now, we've been using the term "persistent class" to refer to entities. We will continue to do that. Strictly speaking, however, not all user-defined classes with persistent state are entities. A component is a user defined class with value semantics. A Java property of type java.lang.String also has value semantics. Given this definition, we can say that all types (classes) provided by the JDK have value type semantics in Java, while user-defined types may be mapped with entity or value type semantics. This decision is up to the application developer. A good hint for an entity class in a domain model are shared references to a single instance of that class, while composition or aggregation usually translates to a value type.

We'll revisit both concepts throughout the documentation.

The challenge is to map the Java type system (and the developers' definition of entities and value types) to the SQL/database type system. The bridge between both systems is provided by Hibernate: for entities we use <class>, <subclass> and so on. For value types we use <property>, <component>, etc, usually with a type attribute. The value of this attribute is the name of a Hibernate mapping type. Hibernate provides many mappings (for standard JDK value types) out of the box. You can write your own mapping types and implement your custom conversion strategies as well, as you'll see later.

All built-in Hibernate types except collections support null semantics.
5.2.2. Basic value types

The built-in basic mapping types may be roughly categorized into

integer, long, short, float, double, character, byte, boolean, yes_no, true_false

    Type mappings from Java primitives or wrapper classes to appropriate (vendor-specific) SQL column types. boolean, yes_no and true_false are all alternative encodings for a Java boolean or java.lang.Boolean. 
string

    A type mapping from java.lang.String to VARCHAR (or Oracle VARCHAR2). 
date, time, timestamp

    Type mappings from java.util.Date and its subclasses to SQL types DATE, TIME and TIMESTAMP (or equivalent). 
calendar, calendar_date

    Type mappings from java.util.Calendar to SQL types TIMESTAMP and DATE (or equivalent). 
big_decimal, big_integer

    Type mappings from java.math.BigDecimal and java.math.BigInteger to NUMERIC (or Oracle NUMBER). 
locale, timezone, currency

    Type mappings from java.util.Locale, java.util.TimeZone and java.util.Currency to VARCHAR (or Oracle VARCHAR2). Instances of Locale and Currency are mapped to their ISO codes. Instances of TimeZone are mapped to their ID. 
class

    A type mapping from java.lang.Class to VARCHAR (or Oracle VARCHAR2). A Class is mapped to its fully qualified name. 
binary

    Maps byte arrays to an appropriate SQL binary type. 
text

    Maps long Java strings to a SQL CLOB or TEXT type. 
serializable

    Maps serializable Java types to an appropriate SQL binary type. You may also indicate the Hibernate type serializable with the name of a serializable Java class or interface that does not default to a basic type. 
clob, blob

    Type mappings for the JDBC classes java.sql.Clob and java.sql.Blob. These types may be inconvenient for some applications, since the blob or clob object may not be reused outside of a transaction. (Furthermore, driver support is patchy and inconsistent.) 
imm_date, imm_time, imm_timestamp, imm_calendar, imm_calendar_date, imm_serializable, imm_binary

    Type mappings for what are usually considered mutable Java types, where Hibernate makes certain optimizations appropriate only for immutable Java types, and the application treats the object as immutable. For example, you should not call Date.setTime() for an instance mapped as imm_timestamp. To change the value of the property, and have that change made persistent, the application must assign a new (nonidentical) object to the property. 

Unique identifiers of entities and collections may be of any basic type except binary, blob and clob. (Composite identifiers are also allowed, see below.)

The basic value types have corresponding Type constants defined on org.hibernate.Hibernate. For example, Hibernate.STRING represents the string type.
5.2.3. Custom value types

It is relatively easy for developers to create their own value types. For example, you might want to persist properties of type java.lang.BigInteger to VARCHAR columns. Hibernate does not provide a built-in type for this. But custom types are not limited to mapping a property (or collection element) to a single table column. So, for example, you might have a Java property getName()/setName() of type java.lang.String that is persisted to the columns FIRST_NAME, INITIAL, SURNAME.

To implement a custom type, implement either org.hibernate.UserType or org.hibernate.CompositeUserType and declare properties using the fully qualified classname of the type. Check out org.hibernate.test.DoubleStringType to see the kind of things that are possible.

<property name="twoStrings" type="org.hibernate.test.DoubleStringType">
    <column name="first_string"/>
    <column name="second_string"/>
</property>

Notice the use of <column> tags to map a property to multiple columns.

The CompositeUserType, EnhancedUserType, UserCollectionType, and UserVersionType interfaces provide support for more specialized uses.

You may even supply parameters to a UserType in the mapping file. To do this, your UserType must implement the org.hibernate.usertype.ParameterizedType interface. To supply parameters to your custom type, you can use the <type> element in your mapping files.

<property name="priority">
    <type name="com.mycompany.usertypes.DefaultValueIntegerType">
        <param name="default">0</param>
    </type>
</property>

The UserType can now retrieve the value for the parameter named default from the Properties object passed to it.

If you use a certain UserType very often, it may be useful to define a shorter name for it. You can do this using the <typedef> element. Typedefs assign a name to a custom type, and may also contain a list of default parameter values if the type is parameterized.

<typedef class="com.mycompany.usertypes.DefaultValueIntegerType" name="default_zero">
    <param name="default">0</param>
</typedef>

<property name="priority" type="default_zero"/>

It is also possible to override the parameters supplied in a typedef on a case-by-case basis by using type parameters on the property mapping.

Even though Hibernate's rich range of built-in types and support for components means you will very rarely need to use a custom type, it is nevertheless considered good form to use custom types for (non-entity) classes that occur frequently in your application. For example, a MonetaryAmount class is a good candidate for a CompositeUserType, even though it could easily be mapped as a component. One motivation for this is abstraction. With a custom type, your mapping documents would be future-proofed against possible changes in your way of representing monetary values.
5.3. Mapping a class more than once

It is possible to provide more than one mapping for a particular persistent class. In this case you must specify an entity name do disambiguate between instances of the two mapped entities. (By default, the entity name is the same as the class name.) Hibernate lets you specify the entity name when working with persistent objects, when writing queries, or when mapping associations to the named entity.

<class name="Contract" table="Contracts" 
        entity-name="CurrentContract">
    ...
    <set name="history" inverse="true" 
            order-by="effectiveEndDate desc">
        <key column="currentContractId"/>
        <one-to-many entity-name="HistoricalContract"/>
    </set>
</class>

<class name="Contract" table="ContractHistory" 
        entity-name="HistoricalContract">
    ...
    <many-to-one name="currentContract" 
            column="currentContractId" 
            entity-name="CurrentContract"/>
</class>

Notice how associations are now specified using entity-name instead of class.
5.4. SQL quoted identifiers

You may force Hibernate to quote an identifier in the generated SQL by enclosing the table or column name in backticks in the mapping document. Hibernate will use the correct quotation style for the SQL Dialect (usually double quotes, but brackets for SQL Server and backticks for MySQL).

<class name="LineItem" table="`Line Item`">
    <id name="id" column="`Item Id`"/><generator class="assigned"/></id>
    <property name="itemNumber" column="`Item #`"/>
    ...
</class>

5.5. Metadata alternatives

XML isn't for everyone, and so there are some alternative ways to define O/R mapping metadata in Hibernate.
5.5.1. Using XDoclet markup

Many Hibernate users prefer to embed mapping information directly in sourcecode using XDoclet @hibernate.tags. We will not cover this approach in this document, since strictly it is considered part of XDoclet. However, we include the following example of the Cat class with XDoclet mappings.

package eg;
import java.util.Set;
import java.util.Date;

/**
 * @hibernate.class
 *  table="CATS"
 */
public class Cat {
    private Long id; // identifier
    private Date birthdate;
    private Cat mother;
    private Set kittens
    private Color color;
    private char sex;
    private float weight;

    /*
     * @hibernate.id
     *  generator-class="native"
     *  column="CAT_ID"
     */
    public Long getId() {
        return id;
    }
    private void setId(Long id) {
        this.id=id;
    }

    /**
     * @hibernate.many-to-one
     *  column="PARENT_ID"
     */
    public Cat getMother() {
        return mother;
    }
    void setMother(Cat mother) {
        this.mother = mother;
    }

    /**
     * @hibernate.property
     *  column="BIRTH_DATE"
     */
    public Date getBirthdate() {
        return birthdate;
    }
    void setBirthdate(Date date) {
        birthdate = date;
    }
    /**
     * @hibernate.property
     *  column="WEIGHT"
     */
    public float getWeight() {
        return weight;
    }
    void setWeight(float weight) {
        this.weight = weight;
    }

    /**
     * @hibernate.property
     *  column="COLOR"
     *  not-null="true"
     */
    public Color getColor() {
        return color;
    }
    void setColor(Color color) {
        this.color = color;
    }
    /**
     * @hibernate.set
     *  inverse="true"
     *  order-by="BIRTH_DATE"
     * @hibernate.collection-key
     *  column="PARENT_ID"
     * @hibernate.collection-one-to-many
     */
    public Set getKittens() {
        return kittens;
    }
    void setKittens(Set kittens) {
        this.kittens = kittens;
    }
    // addKitten not needed by Hibernate
    public void addKitten(Cat kitten) {
        kittens.add(kitten);
    }

    /**
     * @hibernate.property
     *  column="SEX"
     *  not-null="true"
     *  update="false"
     */
    public char getSex() {
        return sex;
    }
    void setSex(char sex) {
        this.sex=sex;
    }
}

See the Hibernate web site for more examples of XDoclet and Hibernate.
5.5.2. Using JDK 5.0 Annotations

JDK 5.0 introduced XDoclet-style annotations at the language level, type-safe and checked at compile time. This mechnism is more powerful than XDoclet annotations and better supported by tools and IDEs. IntelliJ IDEA, for example, supports auto-completion and syntax highlighting of JDK 5.0 annotations. The new revision of the EJB specification (JSR-220) uses JDK 5.0 annotations as the primary metadata mechanism for entity beans. Hibernate3 implements the EntityManager of JSR-220 (the persistence API), support for mapping metadata is available via the Hibernate Annotations package, as a separate download. Both EJB3 (JSR-220) and Hibernate3 metadata is supported.

This is an example of a POJO class annotated as an EJB entity bean:

@Entity(access = AccessType.FIELD)
public class Customer implements Serializable {

    @Id;
    Long id;

    String firstName;
    String lastName;
    Date birthday;

    @Transient
    Integer age;

    @Embedded
    private Address homeAddress;

    @OneToMany(cascade=CascadeType.ALL)
    @JoinColumn(name="CUSTOMER_ID")
    Set<Order> orders;

    // Getter/setter and business methods
}

Note that support for JDK 5.0 Annotations (and JSR-220) is still work in progress and not completed. Please refer to the Hibernate Annotations module for more details.
5.6. Generated Properties

Generated properties are properties which have their values generated by the database. Typically, Hibernate applications needed to refresh objects which contain any properties for which the database was generating values. Marking properties as generated, however, lets the application delegate this responsibility to Hibernate. Essentially, whenever Hibernate issues an SQL INSERT or UPDATE for an entity which has defined generated properties, it immediately issues a select afterwards to retrieve the generated values.

Properties marked as generated must additionally be non-insertable and non-updateable. Only Section 5.1.7, ?version (optional)?, Section 5.1.8, ?timestamp (optional)?, and Section 5.1.9, ?property? can be marked as generated.

never (the default) - means that the given property value is not generated within the database.

insert - states that the given property value is generated on insert, but is not regenerated on subsequent updates. Things like created-date would fall into this category. Note that even thought Section 5.1.7, ?version (optional)? and Section 5.1.8, ?timestamp (optional)? properties can be marked as generated, this option is not available there...

always - states that the property value is generated both on insert and on update.
5.7. Auxiliary Database Objects

Allows CREATE and DROP of arbitrary database objects, in conjunction with Hibernate's schema evolution tools, to provide the ability to fully define a user schema within the Hibernate mapping files. Although designed specifically for creating and dropping things like triggers or stored procedures, really any SQL command that can be run via a java.sql.Statement.execute() method is valid here (ALTERs, INSERTS, etc). There are essentially two modes for defining auxiliary database objects...

The first mode is to explicitly list the CREATE and DROP commands out in the mapping file:

<hibernate-mapping>
    ...
    <database-object>
        <create>CREATE TRIGGER my_trigger ...</create>
        <drop>DROP TRIGGER my_trigger</drop>
    </database-object>
</hibernate-mapping>

The second mode is to supply a custom class which knows how to construct the CREATE and DROP commands. This custom class must implement the org.hibernate.mapping.AuxiliaryDatabaseObject interface.

<hibernate-mapping>
    ...
    <database-object>
        <definition class="MyTriggerDefinition"/>
    </database-object>
</hibernate-mapping>

Additionally, these database objects can be optionally scoped such that they only apply when certain dialects are used.

<hibernate-mapping>
    ...
    <database-object>
        <definition class="MyTriggerDefinition"/>
        <dialect-scope name="org.hibernate.dialect.Oracle9Dialect"/>
        <dialect-scope name="org.hibernate.dialect.OracleDialect"/>
    </database-object>
</hibernate-mapping>

Chapter 6. Collection Mapping
6.1. Persistent collections

Hibernate requires that persistent collection-valued fields be declared as an interface type, for example:

public class Product {
    private String serialNumber;
    private Set parts = new HashSet();
    
    public Set getParts() { return parts; }
    void setParts(Set parts) { this.parts = parts; }
    public String getSerialNumber() { return serialNumber; }
    void setSerialNumber(String sn) { serialNumber = sn; }
}

The actual interface might be java.util.Set, java.util.Collection, java.util.List, java.util.Map, java.util.SortedSet, java.util.SortedMap or ... anything you like! (Where "anything you like" means you will have to write an implementation of org.hibernate.usertype.UserCollectionType.)

Notice how we initialized the instance variable with an instance of HashSet. This is the best way to initialize collection valued properties of newly instantiated (non-persistent) instances. When you make the instance persistent - by calling persist(), for example - Hibernate will actually replace the HashSet with an instance of Hibernate's own implementation of Set. Watch out for errors like this:

Cat cat = new DomesticCat();
Cat kitten = new DomesticCat();
....
Set kittens = new HashSet();
kittens.add(kitten);
cat.setKittens(kittens);
session.persist(cat);
kittens = cat.getKittens(); // Okay, kittens collection is a Set
(HashSet) cat.getKittens(); // Error!

The persistent collections injected by Hibernate behave like HashMap, HashSet, TreeMap, TreeSet or ArrayList, depending upon the interface type.

Collections instances have the usual behavior of value types. They are automatically persisted when referenced by a persistent object and automatically deleted when unreferenced. If a collection is passed from one persistent object to another, its elements might be moved from one table to another. Two entities may not share a reference to the same collection instance. Due to the underlying relational model, collection-valued properties do not support null value semantics; Hibernate does not distinguish between a null collection reference and an empty collection.

You shouldn't have to worry much about any of this. Use persistent collections the same way you use ordinary Java collections. Just make sure you understand the semantics of bidirectional associations (discussed later).
6.2. Collection mappings

The Hibernate mapping element used for mapping a collection depends upon the type of the interface. For example, a <set> element is used for mapping properties of type Set.

<class name="Product">
    <id name="serialNumber" column="productSerialNumber"/>
    <set name="parts">
        <key column="productSerialNumber" not-null="true"/>
        <one-to-many class="Part"/>
    </set>
</class>

Apart from <set>, there is also <list>, <map>, <bag>, <array> and <primitive-array> mapping elements. The <map> element is representative:

<map
    name="propertyName"                                         (1)
    table="table_name"                                          (2)
    schema="schema_name"                                        (3)
    lazy="true|extra|false"                                     (4)
    inverse="true|false"                                        (5)
    cascade="all|none|save-update|delete|all-delete-orphan|delet(6)e-orphan"
    sort="unsorted|natural|comparatorClass"                     (7)
    order-by="column_name asc|desc"                             (8)
    where="arbitrary sql where condition"                       (9)
    fetch="join|select|subselect"                               (10)
    batch-size="N"                                              (11)
    access="field|property|ClassName"                           (12)
    optimistic-lock="true|false"                                (13)
    mutable="true|false"                                        (14)
    node="element-name|."
    embed-xml="true|false"
>

    <key .... />
    <map-key .... />
    <element .... />
</map>

(1)	

name the collection property name
(2)	

table (optional - defaults to property name) the name of the collection table (not used for one-to-many associations)
(3)	

schema (optional) the name of a table schema to override the schema declared on the root element
(4)	

lazy (optional - defaults to true) may be used to disable lazy fetching and specify that the association is always eagerly fetched, or to enable "extra-lazy" fetching where most operations do not initialize the collection (suitable for very large collections)
(5)	

inverse (optional - defaults to false) mark this collection as the "inverse" end of a bidirectional association
(6)	

cascade (optional - defaults to none) enable operations to cascade to child entities
(7)	

sort (optional) specify a sorted collection with natural sort order, or a given comparator class
(8)	

order-by (optional, JDK1.4 only) specify a table column (or columns) that define the iteration order of the Map, Set or bag, together with an optional asc or desc
(9)	

where (optional) specify an arbitrary SQL WHERE condition to be used when retrieving or removing the collection (useful if the collection should contain only a subset of the available data)
(10)	

fetch (optional, defaults to select) Choose between outer-join fetching, fetching by sequential select, and fetching by sequential subselect.
(11)	

batch-size (optional, defaults to 1) specify a "batch size" for lazily fetching instances of this collection.
(12)	

access (optional - defaults to property): The strategy Hibernate should use for accessing the collection property value.
(13)	

optimistic-lock (optional - defaults to true): Species that changes to the state of the collection results in increment of the owning entity's version. (For one to many associations, it is often reasonable to disable this setting.)
(14)	

mutable (optional - defaults to true): A value of false specifies that the elements of the collection never change (a minor performance optimization in some cases).
6.2.1. Collection foreign keys

Collection instances are distinguished in the database by the foreign key of the entity that owns the collection. This foreign key is referred to as the collection key column (or columns) of the collection table. The collection key column is mapped by the <key> element.

There may be a nullability constraint on the foreign key column. For most collections, this is implied. For unidirectional one to many associations, the foreign key column is nullable by default, so you might need to specify not-null="true".

<key column="productSerialNumber" not-null="true"/>

The foreign key constraint may use ON DELETE CASCADE.

<key column="productSerialNumber" on-delete="cascade"/>

See the previous chapter for a full definition of the <key> element.
6.2.2. Collection elements

Collections may contain almost any other Hibernate type, including all basic types, custom types, components, and of course, references to other entities. This is an important distinction: an object in a collection might be handled with "value" semantics (its lifecycle fully depends on the collection owner) or it might be a reference to another entity, with its own lifecycle. In the latter case, only the "link" between the two objects is considered to be state held by the collection.

The contained type is referred to as the collection element type. Collection elements are mapped by <element> or <composite-element>, or in the case of entity references, with <one-to-many> or <many-to-many>. The first two map elements with value semantics, the next two are used to map entity associations.
6.2.3. Indexed collections

All collection mappings, except those with set and bag semantics, need an index column in the collection table - a column that maps to an array index, or List index, or Map key. The index of a Map may be of any basic type, mapped with <map-key>, it may be an entity reference mapped with <map-key-many-to-many>, or it may be a composite type, mapped with <composite-map-key>. The index of an array or list is always of type integer and is mapped using the <list-index> element. The mapped column contains sequential integers (numbered from zero, by default).

<list-index 
        column="column_name"                (1)
        base="0|1|..."/>

(1)	

column_name (required): The name of the column holding the collection index values.
(1)	

base (optional, defaults to 0): The value of the index column that corresponds to the first element of the list or array.

<map-key 
        column="column_name"                (1)
        formula="any SQL expression"        (2)
        type="type_name"                    (3)
        node="@attribute-name"
        length="N"/>

(1)	

column (optional): The name of the column holding the collection index values.
(2)	

formula (optional): A SQL formula used to evaluate the key of the map.
(3)	

type (reguired): The type of the map keys.

<map-key-many-to-many
        column="column_name"                (1)
        formula="any SQL expression"        (2)(3)
        class="ClassName"
/>

(1)	

column (optional): The name of the foreign key column for the collection index values.
(2)	

formula (optional): A SQL formula used to evaluate the foreign key of the map key.
(3)	

class (required): The entity class used as the map key.

If your table doesn't have an index column, and you still wish to use List as the property type, you should map the property as a Hibernate <bag>. A bag does not retain its order when it is retrieved from the database, but it may be optionally sorted or ordered.

There are quite a range of mappings that can be generated for collections, covering many common relational models. We suggest you experiment with the schema generation tool to get a feeling for how various mapping declarations translate to database tables.
6.2.4. Collections of values and many-to-many associations

Any collection of values or many-to-many association requires a dedicated collection table with a foreign key column or columns, collection element column or columns and possibly an index column or columns.

For a collection of values, we use the <element> tag.

<element
        column="column_name"                     (1)
        formula="any SQL expression"             (2)
        type="typename"                          (3)
        length="L"
        precision="P"
        scale="S"
        not-null="true|false"
        unique="true|false"
        node="element-name"
/>

(1)	

column (optional): The name of the column holding the collection element values.
(2)	

formula (optional): An SQL formula used to evaluate the element.
(3)	

type (required): The type of the collection element.

A many-to-many association is specified using the <many-to-many> element.

<many-to-many
        column="column_name"                               (1)
        formula="any SQL expression"                       (2)
        class="ClassName"                                  (3)
        fetch="select|join"                                (4)
        unique="true|false"                                (5)
        not-found="ignore|exception"                       (6)
        entity-name="EntityName"                           (7)
        property-ref="propertyNameFromAssociatedClass"     (8)
        node="element-name"
        embed-xml="true|false"
    />

(1)	

column (optional): The name of the element foreign key column.
(2)	

formula (optional): An SQL formula used to evaluate the element foreign key value.
(3)	

class (required): The name of the associated class.
(4)	

fetch (optional - defaults to join): enables outer-join or sequential select fetching for this association. This is a special case; for full eager fetching (in a single SELECT) of an entity and its many-to-many relationships to other entities, you would enable join fetching not only of the collection itself, but also with this attribute on the <many-to-many> nested element.
(5)	

unique (optional): Enable the DDL generation of a unique constraint for the foreign-key column. This makes the association multiplicity effectively one to many.
(6)	

not-found (optional - defaults to exception): Specifies how foreign keys that reference missing rows will be handled: ignore will treat a missing row as a null association.
(7)	

entity-name (optional): The entity name of the associated class, as an alternative to class.
(8)	

property-ref: (optional) The name of a property of the associated class that is joined to this foreign key. If not specified, the primary key of the associated class is used.

Some examples, first, a set of strings:

<set name="names" table="person_names">
    <key column="person_id"/>
    <element column="person_name" type="string"/>
</set>

A bag containing integers (with an iteration order determined by the order-by attribute):

<bag name="sizes" 
        table="item_sizes" 
        order-by="size asc">
    <key column="item_id"/>
    <element column="size" type="integer"/>
</bag>

An array of entities - in this case, a many to many association:

<array name="addresses" 
        table="PersonAddress" 
        cascade="persist">
    <key column="personId"/>
    <list-index column="sortOrder"/>
    <many-to-many column="addressId" class="Address"/>
</array>

A map from string indices to dates:

<map name="holidays" 
        table="holidays" 
        schema="dbo" 
        order-by="hol_name asc">
    <key column="id"/>
    <map-key column="hol_name" type="string"/>
    <element column="hol_date" type="date"/>
</map>

A list of components (discussed in the next chapter):

<list name="carComponents" 
        table="CarComponents">
    <key column="carId"/>
    <list-index column="sortOrder"/>
    <composite-element class="CarComponent">
        <property name="price"/>
        <property name="type"/>
        <property name="serialNumber" column="serialNum"/>
    </composite-element>
</list>

6.2.5. One-to-many associations

A one to many association links the tables of two classes via a foreign key, with no intervening collection table. This mapping loses certain semantics of normal Java collections:

    *

      An instance of the contained entity class may not belong to more than one instance of the collection
    *

      An instance of the contained entity class may not appear at more than one value of the collection index 

An association from Product to Part requires existence of a foreign key column and possibly an index column to the Part table. A <one-to-many> tag indicates that this is a one to many association.

<one-to-many 
        class="ClassName"                                  (1)
        not-found="ignore|exception"                       (2)
        entity-name="EntityName"                           (3)
        node="element-name"
        embed-xml="true|false"
    />

(1)	

class (required): The name of the associated class.
(2)	

not-found (optional - defaults to exception): Specifies how cached identifiers that reference missing rows will be handled: ignore will treat a missing row as a null association.
(3)	

entity-name (optional): The entity name of the associated class, as an alternative to class.

Notice that the <one-to-many> element does not need to declare any columns. Nor is it necessary to specify the table name anywhere.

Very important note: If the foreign key column of a <one-to-many> association is declared NOT NULL, you must declare the <key> mapping not-null="true" or use a bidirectional association with the collection mapping marked inverse="true". See the discussion of bidirectional associations later in this chapter.

This example shows a map of Part entities by name (where partName is a persistent property of Part). Notice the use of a formula-based index.

<map name="parts"
        cascade="all">
    <key column="productId" not-null="true"/>
    <map-key formula="partName"/>
    <one-to-many class="Part"/>
</map>

6.3. Advanced collection mappings
6.3.1. Sorted collections

Hibernate supports collections implementing java.util.SortedMap and java.util.SortedSet. You must specify a comparator in the mapping file:

<set name="aliases" 
            table="person_aliases" 
            sort="natural">
    <key column="person"/>
    <element column="name" type="string"/>
</set>

<map name="holidays" sort="my.custom.HolidayComparator">
    <key column="year_id"/>
    <map-key column="hol_name" type="string"/>
    <element column="hol_date" type="date"/>
</map>

Allowed values of the sort attribute are unsorted, natural and the name of a class implementing java.util.Comparator.

Sorted collections actually behave like java.util.TreeSet or java.util.TreeMap.

If you want the database itself to order the collection elements use the order-by attribute of set, bag or map mappings. This solution is only available under JDK 1.4 or higher (it is implemented using LinkedHashSet or LinkedHashMap). This performs the ordering in the SQL query, not in memory.

<set name="aliases" table="person_aliases" order-by="lower(name) asc">
    <key column="person"/>
    <element column="name" type="string"/>
</set>

<map name="holidays" order-by="hol_date, hol_name">
    <key column="year_id"/>
    <map-key column="hol_name" type="string"/>
    <element column="hol_date type="date"/>
</map>

Note that the value of the order-by attribute is an SQL ordering, not a HQL ordering!

Associations may even be sorted by some arbitrary criteria at runtime using a collection filter().

sortedUsers = s.createFilter( group.getUsers(), "order by this.name" ).list();

6.3.2. Bidirectional associations

A bidirectional association allows navigation from both "ends" of the association. Two kinds of bidirectional association are supported:

one-to-many

    set or bag valued at one end, single-valued at the other 
many-to-many

    set or bag valued at both ends 

You may specify a bidirectional many-to-many association simply by mapping two many-to-many associations to the same database table and declaring one end as inverse (which one is your choice, but it can not be an indexed collection).

Here's an example of a bidirectional many-to-many association; each category can have many items and each item can be in many categories:

<class name="Category">
    <id name="id" column="CATEGORY_ID"/>
    ...
    <bag name="items" table="CATEGORY_ITEM">
        <key column="CATEGORY_ID"/>
        <many-to-many class="Item" column="ITEM_ID"/>
    </bag>
</class>

<class name="Item">
    <id name="id" column="CATEGORY_ID"/>
    ...

    <!-- inverse end -->
    <bag name="categories" table="CATEGORY_ITEM" inverse="true">
        <key column="ITEM_ID"/>
        <many-to-many class="Category" column="CATEGORY_ID"/>
    </bag>
</class>

Changes made only to the inverse end of the association are not persisted. This means that Hibernate has two representations in memory for every bidirectional association, one link from A to B and another link from B to A. This is easier to understand if you think about the Java object model and how we create a many-to-many relationship in Java:

category.getItems().add(item);          // The category now "knows" about the relationship
item.getCategories().add(category);     // The item now "knows" about the relationship

session.persist(item);                   // The relationship won't be saved!
session.persist(category);               // The relationship will be saved

The non-inverse side is used to save the in-memory representation to the database.

You may define a bidirectional one-to-many association by mapping a one-to-many association to the same table column(s) as a many-to-one association and declaring the many-valued end inverse="true".

<class name="Parent">
    <id name="id" column="parent_id"/>
    ....
    <set name="children" inverse="true">
        <key column="parent_id"/>
        <one-to-many class="Child"/>
    </set>
</class>

<class name="Child">
    <id name="id" column="child_id"/>
    ....
    <many-to-one name="parent" 
        class="Parent" 
        column="parent_id"
        not-null="true"/>
</class>

Mapping one end of an association with inverse="true" doesn't affect the operation of cascades, these are orthogonal concepts!
6.3.3. Bidirectional associations with indexed collections

A bidirectional association where one end is represented as a <list> or <map> requires special consideration. If there is a property of the child class which maps to the index column, no problem, we can continue using inverse="true" on the collection mapping:

<class name="Parent">
    <id name="id" column="parent_id"/>
    ....
    <map name="children" inverse="true">
        <key column="parent_id"/>
        <map-key column="name" 
            type="string"/>
        <one-to-many class="Child"/>
    </map>
</class>

<class name="Child">
    <id name="id" column="child_id"/>
    ....
    <property name="name" 
        not-null="true"/>
    <many-to-one name="parent" 
        class="Parent" 
        column="parent_id"
        not-null="true"/>
</class>

But, if there is no such property on the child class, we can't think of the association as truly bidirectional (there is information available at one end of the association that is not available at the other end). In this case, we can't map the collection inverse="true". Instead, we could use the following mapping:

<class name="Parent">
    <id name="id" column="parent_id"/>
    ....
    <map name="children">
        <key column="parent_id"
            not-null="true"/>
        <map-key column="name" 
            type="string"/>
        <one-to-many class="Child"/>
    </map>
</class>

<class name="Child">
    <id name="id" column="child_id"/>
    ....
    <many-to-one name="parent" 
        class="Parent" 
        column="parent_id"
        insert="false"
        update="false"
        not-null="true"/>
</class>

Note that in this mapping, the collection-valued end of the association is responsible for updates to the foreign key. TODO: Does this really result in some unnecessary update statements?
6.3.4. Ternary associations

There are three possible approaches to mapping a ternary association. One is to use a Map with an association as its index:

<map name="contracts">
    <key column="employer_id" not-null="true"/>
    <map-key-many-to-many column="employee_id" class="Employee"/>
    <one-to-many class="Contract"/>
</map>

<map name="connections">
    <key column="incoming_node_id"/>
    <map-key-many-to-many column="outgoing_node_id" class="Node"/>
    <many-to-many column="connection_id" class="Connection"/>
</map>

A second approach is to simply remodel the association as an entity class. This is the approach we use most commonly.

A final alternative is to use composite elements, which we will discuss later.
6.3.5. Using an <idbag>

If you've fully embraced our view that composite keys are a bad thing and that entities should have synthetic identifiers (surrogate keys), then you might find it a bit odd that the many to many associations and collections of values that we've shown so far all map to tables with composite keys! Now, this point is quite arguable; a pure association table doesn't seem to benefit much from a surrogate key (though a collection of composite values might). Nevertheless, Hibernate provides a feature that allows you to map many to many associations and collections of values to a table with a surrogate key.

The <idbag> element lets you map a List (or Collection) with bag semantics.

<idbag name="lovers" table="LOVERS">
    <collection-id column="ID" type="long">
        <generator class="sequence"/>
    </collection-id>
    <key column="PERSON1"/>
    <many-to-many column="PERSON2" class="Person" fetch="join"/>
</idbag>

As you can see, an <idbag> has a synthetic id generator, just like an entity class! A different surrogate key is assigned to each collection row. Hibernate does not provide any mechanism to discover the surrogate key value of a particular row, however.

Note that the update performance of an <idbag> is much better than a regular <bag>! Hibernate can locate individual rows efficiently and update or delete them individually, just like a list, map or set.

In the current implementation, the native identifier generation strategy is not supported for <idbag> collection identifiers.
6.4. Collection examples

The previous sections are pretty confusing. So lets look at an example. This class:

package eg;
import java.util.Set;

public class Parent {
    private long id;
    private Set children;

    public long getId() { return id; }
    private void setId(long id) { this.id=id; }

    private Set getChildren() { return children; }
    private void setChildren(Set children) { this.children=children; }

    ....
    ....
}

has a collection of Child instances. If each child has at most one parent, the most natural mapping is a one-to-many association:

<hibernate-mapping>

    <class name="Parent">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <set name="children">
            <key column="parent_id"/>
            <one-to-many class="Child"/>
        </set>
    </class>

    <class name="Child">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <property name="name"/>
    </class>

</hibernate-mapping>

This maps to the following table definitions:

create table parent ( id bigint not null primary key )
create table child ( id bigint not null primary key, name varchar(255), parent_id bigint )
alter table child add constraint childfk0 (parent_id) references parent

If the parent is required, use a bidirectional one-to-many association:

<hibernate-mapping>

    <class name="Parent">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <set name="children" inverse="true">
            <key column="parent_id"/>
            <one-to-many class="Child"/>
        </set>
    </class>

    <class name="Child">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <property name="name"/>
        <many-to-one name="parent" class="Parent" column="parent_id" not-null="true"/>
    </class>

</hibernate-mapping>

Notice the NOT NULL constraint:

create table parent ( id bigint not null primary key )
create table child ( id bigint not null
                     primary key,
                     name varchar(255),
                     parent_id bigint not null )
alter table child add constraint childfk0 (parent_id) references parent

Alternatively, if you absolutely insist that this association should be unidirectional, you can declare the NOT NULL constraint on the <key> mapping:

<hibernate-mapping>

    <class name="Parent">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <set name="children">
            <key column="parent_id" not-null="true"/>
            <one-to-many class="Child"/>
        </set>
    </class>

    <class name="Child">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <property name="name"/>
    </class>

</hibernate-mapping>

On the other hand, if a child might have multiple parents, a many-to-many association is appropriate:

<hibernate-mapping>

    <class name="Parent">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <set name="children" table="childset">
            <key column="parent_id"/>
            <many-to-many class="Child" column="child_id"/>
        </set>
    </class>

    <class name="Child">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <property name="name"/>
    </class>

</hibernate-mapping>

Table definitions:

create table parent ( id bigint not null primary key )
create table child ( id bigint not null primary key, name varchar(255) )
create table childset ( parent_id bigint not null,
                        child_id bigint not null,
                        primary key ( parent_id, child_id ) )
alter table childset add constraint childsetfk0 (parent_id) references parent
alter table childset add constraint childsetfk1 (child_id) references child

For more examples and a complete walk-through a parent/child relationship mapping, see Chapter 21, Example: Parent/Child.

Even more exotic association mappings are possible, we will catalog all possibilities in the next chapter.
Chapter 7. Association Mappings
7.1. Introduction

Association mappings are the often most difficult thing to get right. In this section we'll go through the canonical cases one by one, starting with unidirectional mappings, and then considering the bidirectional cases. We'll use Person and Address in all the examples.

We'll classify associations by whether or not they map to an intervening join table, and by multiplicity.

Nullable foreign keys are not considered good practice in traditional data modelling, so all our examples use not null foreign keys. This is not a requirement of Hibernate, and the mappings will all work if you drop the nullability constraints.
7.2. Unidirectional associations
7.2.1. many to one

A unidirectional many-to-one association is the most common kind of unidirectional association.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <many-to-one name="address" 
        column="addressId"
        not-null="true"/>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
</class>

create table Person ( personId bigint not null primary key, addressId bigint not null )
create table Address ( addressId bigint not null primary key )
        

7.2.2. one to one

A unidirectional one-to-one association on a foreign key is almost identical. The only difference is the column unique constraint.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <many-to-one name="address" 
        column="addressId" 
        unique="true"
        not-null="true"/>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
</class>

create table Person ( personId bigint not null primary key, addressId bigint not null unique )
create table Address ( addressId bigint not null primary key )
        

A unidirectional one-to-one association on a primary key usually uses a special id generator. (Notice that we've reversed the direction of the association in this example.)

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
</class>

<class name="Address">
    <id name="id" column="personId">
        <generator class="foreign">
            <param name="property">person</param>
        </generator>
    </id>
    <one-to-one name="person" constrained="true"/>
</class>

create table Person ( personId bigint not null primary key )
create table Address ( personId bigint not null primary key )
        

7.2.3. one to many

A unidirectional one-to-many association on a foreign key is a very unusual case, and is not really recommended.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <set name="addresses">
        <key column="personId" 
            not-null="true"/>
        <one-to-many class="Address"/>
    </set>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
</class>

create table Person ( personId bigint not null primary key )
create table Address ( addressId bigint not null primary key, personId bigint not null )
        

We think it's better to use a join table for this kind of association.
7.3. Unidirectional associations with join tables
7.3.1. one to many

A unidirectional one-to-many association on a join table is much preferred. Notice that by specifying unique="true", we have changed the multiplicity from many-to-many to one-to-many.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <set name="addresses" table="PersonAddress">
        <key column="personId"/>
        <many-to-many column="addressId"
            unique="true"
            class="Address"/>
    </set>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
</class>

create table Person ( personId bigint not null primary key )
create table PersonAddress ( personId not null, addressId bigint not null primary key )
create table Address ( addressId bigint not null primary key )
        

7.3.2. many to one

A unidirectional many-to-one association on a join table is quite common when the association is optional.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <join table="PersonAddress" 
        optional="true">
        <key column="personId" unique="true"/>
        <many-to-one name="address"
            column="addressId" 
            not-null="true"/>
    </join>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
</class>

create table Person ( personId bigint not null primary key )
create table PersonAddress ( personId bigint not null primary key, addressId bigint not null )
create table Address ( addressId bigint not null primary key )
        

7.3.3. one to one

A unidirectional one-to-one association on a join table is extremely unusual, but possible.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <join table="PersonAddress" 
        optional="true">
        <key column="personId" 
            unique="true"/>
        <many-to-one name="address"
            column="addressId" 
            not-null="true"
            unique="true"/>
    </join>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
</class>

create table Person ( personId bigint not null primary key )
create table PersonAddress ( personId bigint not null primary key, addressId bigint not null unique )
create table Address ( addressId bigint not null primary key )
        

7.3.4. many to many

Finally, we have a unidirectional many-to-many association.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <set name="addresses" table="PersonAddress">
        <key column="personId"/>
        <many-to-many column="addressId"
            class="Address"/>
    </set>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
</class>

create table Person ( personId bigint not null primary key )
create table PersonAddress ( personId bigint not null, addressId bigint not null, primary key (personId, addressId) )
create table Address ( addressId bigint not null primary key )
        

7.4. Bidirectional associations
7.4.1. one to many / many to one

A bidirectional many-to-one association is the most common kind of association. (This is the standard parent/child relationship.)

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <many-to-one name="address" 
        column="addressId"
        not-null="true"/>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
    <set name="people" inverse="true">
        <key column="addressId"/>
        <one-to-many class="Person"/>
    </set>
</class>

create table Person ( personId bigint not null primary key, addressId bigint not null )
create table Address ( addressId bigint not null primary key )
        

If you use a List (or other indexed collection) you need to set the key column of the foreign key to not null, and let Hibernate manage the association from the collections side to maintain the index of each element (making the other side virtually inverse by setting update="false" and insert="false"):

<class name="Person">
   <id name="id"/>
   ...
   <many-to-one name="address"
      column="addressId"
      not-null="true"
      insert="false"
      update="false"/>
</class>

<class name="Address">
   <id name="id"/>
   ...
   <list name="people">
      <key column="addressId" not-null="true"/>
      <list-index column="peopleIdx"/>
      <one-to-many class="Person"/>
   </list>
</class>

It is important that you define not-null="true" on the <key> element of the collection mapping if the underlying foreign key column is NOT NULL. Don't only declare not-null="true" on a possible nested <column> element, but on the <key> element.
7.4.2. one to one

A bidirectional one-to-one association on a foreign key is quite common.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <many-to-one name="address" 
        column="addressId" 
        unique="true"
        not-null="true"/>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
   <one-to-one name="person" 
        property-ref="address"/>
</class>

create table Person ( personId bigint not null primary key, addressId bigint not null unique )
create table Address ( addressId bigint not null primary key )
        

A bidirectional one-to-one association on a primary key uses the special id generator.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <one-to-one name="address"/>
</class>

<class name="Address">
    <id name="id" column="personId">
        <generator class="foreign">
            <param name="property">person</param>
        </generator>
    </id>
    <one-to-one name="person" 
        constrained="true"/>
</class>

create table Person ( personId bigint not null primary key )
create table Address ( personId bigint not null primary key )
        

7.5. Bidirectional associations with join tables
7.5.1. one to many / many to one

A bidirectional one-to-many association on a join table. Note that the inverse="true" can go on either end of the association, on the collection, or on the join.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <set name="addresses" 
        table="PersonAddress">
        <key column="personId"/>
        <many-to-many column="addressId"
            unique="true"
            class="Address"/>
    </set>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
    <join table="PersonAddress" 
        inverse="true" 
        optional="true">
        <key column="addressId"/>
        <many-to-one name="person"
            column="personId"
            not-null="true"/>
    </join>
</class>

create table Person ( personId bigint not null primary key )
create table PersonAddress ( personId bigint not null, addressId bigint not null primary key )
create table Address ( addressId bigint not null primary key )
        

7.5.2. one to one

A bidirectional one-to-one association on a join table is extremely unusual, but possible.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <join table="PersonAddress" 
        optional="true">
        <key column="personId" 
            unique="true"/>
        <many-to-one name="address"
            column="addressId" 
            not-null="true"
            unique="true"/>
    </join>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
    <join table="PersonAddress" 
        optional="true"
        inverse="true">
        <key column="addressId" 
            unique="true"/>
        <many-to-one name="person"
            column="personId" 
            not-null="true"
            unique="true"/>
    </join>
</class>

create table Person ( personId bigint not null primary key )
create table PersonAddress ( personId bigint not null primary key, addressId bigint not null unique )
create table Address ( addressId bigint not null primary key )
        

7.5.3. many to many

Finally, we have a bidirectional many-to-many association.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <set name="addresses" table="PersonAddress">
        <key column="personId"/>
        <many-to-many column="addressId"
            class="Address"/>
    </set>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
    <set name="people" inverse="true" table="PersonAddress">
        <key column="addressId"/>
        <many-to-many column="personId"
            class="Person"/>
    </set>
</class>

create table Person ( personId bigint not null primary key )
create table PersonAddress ( personId bigint not null, addressId bigint not null, primary key (personId, addressId) )
create table Address ( addressId bigint not null primary key )
        

7.6. More complex association mappings

More complex association joins are extremely rare. Hibernate makes it possible to handle more complex situations using SQL fragments embedded in the mapping document. For example, if a table with historical account information data defines accountNumber, effectiveEndDate and effectiveStartDatecolumns, mapped as follows:

<properties name="currentAccountKey">
    <property name="accountNumber" type="string" not-null="true"/>
    <property name="currentAccount" type="boolean">
        <formula>case when effectiveEndDate is null then 1 else 0 end</formula>
    </property>
</properties>
<property name="effectiveEndDate" type="date"/>
<property name="effectiveStateDate" type="date" not-null="true"/>

Then we can map an association to the current instance (the one with null effectiveEndDate) using:

<many-to-one name="currentAccountInfo" 
        property-ref="currentAccountKey"
        class="AccountInfo">
    <column name="accountNumber"/>
    <formula>'1'</formula>
</many-to-one>

In a more complex example, imagine that the association between Employee and Organization is maintained in an Employment table full of historical employment data. Then an association to the employee's most recent employer (the one with the most recent startDate) might be mapped this way:

<join>
    <key column="employeeId"/>
    <subselect>
        select employeeId, orgId 
        from Employments 
        group by orgId 
        having startDate = max(startDate)
    </subselect>
    <many-to-one name="mostRecentEmployer" 
            class="Organization" 
            column="orgId"/>
</join>

You can get quite creative with this functionality, but it is usually more practical to handle these kinds of cases using HQL or a criteria query.
Chapter 8. Component Mapping

The notion of a component is re-used in several different contexts, for different purposes, throughout Hibernate.
8.1. Dependent objects

A component is a contained object that is persisted as a value type, not an entity reference. The term "component" refers to the object-oriented notion of composition (not to architecture-level components). For example, you might model a person like this:

public class Person {
    private java.util.Date birthday;
    private Name name;
    private String key;
    public String getKey() {
        return key;
    }
    private void setKey(String key) {
        this.key=key;
    }
    public java.util.Date getBirthday() {
        return birthday;
    }
    public void setBirthday(java.util.Date birthday) {
        this.birthday = birthday;
    }
    public Name getName() {
        return name;
    }
    public void setName(Name name) {
        this.name = name;
    }
    ......
    ......
}

public class Name {
    char initial;
    String first;
    String last;
    public String getFirst() {
        return first;
    }
    void setFirst(String first) {
        this.first = first;
    }
    public String getLast() {
        return last;
    }
    void setLast(String last) {
        this.last = last;
    }
    public char getInitial() {
        return initial;
    }
    void setInitial(char initial) {
        this.initial = initial;
    }
}

Now Name may be persisted as a component of Person. Notice that Name defines getter and setter methods for its persistent properties, but doesn't need to declare any interfaces or identifier properties.

Our Hibernate mapping would look like:

<class name="eg.Person" table="person">
    <id name="Key" column="pid" type="string">
        <generator class="uuid"/>
    </id>
    <property name="birthday" type="date"/>
    <component name="Name" class="eg.Name"> <!-- class attribute optional -->
        <property name="initial"/>
        <property name="first"/>
        <property name="last"/>
    </component>
</class>

The person table would have the columns pid, birthday, initial, first and last.

Like all value types, components do not support shared references. In other words, two persons could have the same name, but the two person objects would contain two independent name ojects, only "the same" by value. The null value semantics of a component are ad hoc. When reloading the containing object, Hibernate will assume that if all component columns are null, then the entire component is null. This should be okay for most purposes.

The properties of a component may be of any Hibernate type (collections, many-to-one associations, other components, etc). Nested components should not be considered an exotic usage. Hibernate is intended to support a very fine-grained object model.

The <component> element allows a <parent> subelement that maps a property of the component class as a reference back to the containing entity.

<class name="eg.Person" table="person">
    <id name="Key" column="pid" type="string">
        <generator class="uuid"/>
    </id>
    <property name="birthday" type="date"/>
    <component name="Name" class="eg.Name" unique="true">
        <parent name="namedPerson"/> <!-- reference back to the Person -->
        <property name="initial"/>
        <property name="first"/>
        <property name="last"/>
    </component>
</class>

8.2. Collections of dependent objects

Collections of components are supported (eg. an array of type Name). Declare your component collection by replacing the <element> tag with a <composite-element> tag.

<set name="someNames" table="some_names" lazy="true">
    <key column="id"/>
    <composite-element class="eg.Name"> <!-- class attribute required -->
        <property name="initial"/>
        <property name="first"/>
        <property name="last"/>
    </composite-element>
</set>

Note: if you define a Set of composite elements, it is very important to implement equals() and hashCode() correctly.

Composite elements may contain components but not collections. If your composite element itself contains components, use the <nested-composite-element> tag. This is a pretty exotic case - a collection of components which themselves have components. By this stage you should be asking yourself if a one-to-many association is more appropriate. Try remodelling the composite element as an entity - but note that even though the Java model is the same, the relational model and persistence semantics are still slightly different.

Please note that a composite element mapping doesn't support null-able properties if you're using a <set>. Hibernate has to use each columns value to identify a record when deleting objects (there is no separate primary key column in the composite element table), which is not possible with null values. You have to either use only not-null properties in a composite-element or choose a <list>, <map>, <bag> or <idbag>.

A special case of a composite element is a composite element with a nested <many-to-one> element. A mapping like this allows you to map extra columns of a many-to-many association table to the composite element class. The following is a many-to-many association from Order to Item where purchaseDate, price and quantity are properties of the association:

<class name="eg.Order" .... >
    ....
    <set name="purchasedItems" table="purchase_items" lazy="true">
        <key column="order_id">
        <composite-element class="eg.Purchase">
            <property name="purchaseDate"/>
            <property name="price"/>
            <property name="quantity"/>
            <many-to-one name="item" class="eg.Item"/> <!-- class attribute is optional -->
        </composite-element>
    </set>
</class>

Of course, there can't be a reference to the purchae on the other side, for bidirectional association navigation. Remember that components are value types and don't allow shared references. A single Purchase can be in the set of an Order, but it can't be referenced by the Item at the same time.

Even ternary (or quaternary, etc) associations are possible:

<class name="eg.Order" .... >
    ....
    <set name="purchasedItems" table="purchase_items" lazy="true">
        <key column="order_id">
        <composite-element class="eg.OrderLine">
            <many-to-one name="purchaseDetails class="eg.Purchase"/>
            <many-to-one name="item" class="eg.Item"/>
        </composite-element>
    </set>
</class>

Composite elements may appear in queries using the same syntax as associations to other entities.
8.3. Components as Map indices

The <composite-map-key> element lets you map a component class as the key of a Map. Make sure you override hashCode() and equals() correctly on the component class.
8.4. Components as composite identifiers

You may use a component as an identifier of an entity class. Your component class must satisfy certain requirements:

    *

      It must implement java.io.Serializable.
    *

      It must re-implement equals() and hashCode(), consistently with the database's notion of composite key equality. 

Note: in Hibernate3, the second requirement is not an absolutely hard requirement of Hibernate. But do it anyway.

You can't use an IdentifierGenerator to generate composite keys. Instead the application must assign its own identifiers.

Use the <composite-id> tag (with nested <key-property> elements) in place of the usual <id> declaration. For example, the OrderLine class has a primary key that depends upon the (composite) primary key of Order.

<class name="OrderLine">
    
    <composite-id name="id" class="OrderLineId">
        <key-property name="lineId"/>
        <key-property name="orderId"/>
        <key-property name="customerId"/>
    </composite-id>
    
    <property name="name"/>
    
    <many-to-one name="order" class="Order"
            insert="false" update="false">
        <column name="orderId"/>
        <column name="customerId"/>
    </many-to-one>
    ....
    
</class>

Now, any foreign keys referencing the OrderLine table are also composite. You must declare this in your mappings for other classes. An association to OrderLine would be mapped like this:

<many-to-one name="orderLine" class="OrderLine">
<!-- the "class" attribute is optional, as usual -->
    <column name="lineId"/>
    <column name="orderId"/>
    <column name="customerId"/>
</many-to-one>

(Note that the <column> tag is an alternative to the column attribute everywhere.)

A many-to-many association to OrderLine also uses the composite foreign key:

<set name="undeliveredOrderLines">
    <key column name="warehouseId"/>
    <many-to-many class="OrderLine">
        <column name="lineId"/>
        <column name="orderId"/>
        <column name="customerId"/>
    </many-to-many>
</set>

The collection of OrderLines in Order would use:

<set name="orderLines" inverse="true">
    <key>
        <column name="orderId"/>
        <column name="customerId"/>
    </key>
    <one-to-many class="OrderLine"/>
</set>

(The <one-to-many> element, as usual, declares no columns.)

If OrderLine itself owns a collection, it also has a composite foreign key.

<class name="OrderLine">
    ....
    ....
    <list name="deliveryAttempts">
        <key>   <!-- a collection inherits the composite key type -->
            <column name="lineId"/>
            <column name="orderId"/>
            <column name="customerId"/>
        </key>
        <list-index column="attemptId" base="1"/>
        <composite-element class="DeliveryAttempt">
            ...
        </composite-element>
    </set>
</class>

8.5. Dynamic components

You may even map a property of type Map:

<dynamic-component name="userAttributes">
    <property name="foo" column="FOO" type="string"/>
    <property name="bar" column="BAR" type="integer"/>
    <many-to-one name="baz" class="Baz" column="BAZ_ID"/>
</dynamic-component>

The semantics of a <dynamic-component> mapping are identical to <component>. The advantage of this kind of mapping is the ability to determine the actual properties of the bean at deployment time, just by editing the mapping document. Runtime manipulation of the mapping document is also possible, using a DOM parser. Even better, you can access (and change) Hibernate's configuration-time metamodel via the Configuration object.
Chapter 9. Inheritance Mapping
9.1. The Three Strategies

Hibernate supports the three basic inheritance mapping strategies:

    *

      table per class hierarchy
    *

      table per subclass
    *

      table per concrete class 

In addition, Hibernate supports a fourth, slightly different kind of polymorphism:

    *

      implicit polymorphism 

It is possible to use different mapping strategies for different branches of the same inheritance hierarchy, and then make use of implicit polymorphism to achieve polymorphism across the whole hierarchy. However, Hibernate does not support mixing <subclass>, and <joined-subclass> and <union-subclass> mappings under the same root <class> element. It is possible to mix together the table per hierarchy and table per subclass strategies, under the the same <class> element, by combining the <subclass> and <join> elements (see below).

It is possible to define subclass, union-subclass, and joined-subclass mappings in separate mapping documents, directly beneath hibernate-mapping. This allows you to extend a class hierachy just by adding a new mapping file. You must specify an extends attribute in the subclass mapping, naming a previously mapped superclass. Note: Previously this feature made the ordering of the mapping documents important. Since Hibernate3, the ordering of mapping files does not matter when using the extends keyword. The ordering inside a single mapping file still needs to be defined as superclasses before subclasses.

 <hibernate-mapping>
     <subclass name="DomesticCat" extends="Cat" discriminator-value="D">
          <property name="name" type="string"/>
     </subclass>
 </hibernate-mapping>

9.1.1. Table per class hierarchy

Suppose we have an interface Payment, with implementors CreditCardPayment, CashPayment, ChequePayment. The table per hierarchy mapping would look like:

<class name="Payment" table="PAYMENT">
    <id name="id" type="long" column="PAYMENT_ID">
        <generator class="native"/>
    </id>
    <discriminator column="PAYMENT_TYPE" type="string"/>
    <property name="amount" column="AMOUNT"/>
    ...
    <subclass name="CreditCardPayment" discriminator-value="CREDIT">
        <property name="creditCardType" column="CCTYPE"/>
        ...
    </subclass>
    <subclass name="CashPayment" discriminator-value="CASH">
        ...
    </subclass>
    <subclass name="ChequePayment" discriminator-value="CHEQUE">
        ...
    </subclass>
</class>

Exactly one table is required. There is one big limitation of this mapping strategy: columns declared by the subclasses, such as CCTYPE, may not have NOT NULL constraints.
9.1.2. Table per subclass

A table per subclass mapping would look like:

<class name="Payment" table="PAYMENT">
    <id name="id" type="long" column="PAYMENT_ID">
        <generator class="native"/>
    </id>
    <property name="amount" column="AMOUNT"/>
    ...
    <joined-subclass name="CreditCardPayment" table="CREDIT_PAYMENT">
        <key column="PAYMENT_ID"/>
        <property name="creditCardType" column="CCTYPE"/>
        ...
    </joined-subclass>
    <joined-subclass name="CashPayment" table="CASH_PAYMENT">
        <key column="PAYMENT_ID"/>
        ...
    </joined-subclass>
    <joined-subclass name="ChequePayment" table="CHEQUE_PAYMENT">
        <key column="PAYMENT_ID"/>
        ...
    </joined-subclass>
</class>

Four tables are required. The three subclass tables have primary key associations to the superclass table (so the relational model is actually a one-to-one association).
9.1.3. Table per subclass, using a discriminator

Note that Hibernate's implementation of table per subclass requires no discriminator column. Other object/relational mappers use a different implementation of table per subclass which requires a type discriminator column in the superclass table. The approach taken by Hibernate is much more difficult to implement but arguably more correct from a relational point of view. If you would like to use a discriminator column with the table per subclass strategy, you may combine the use of <subclass> and <join>, as follow:

<class name="Payment" table="PAYMENT">
    <id name="id" type="long" column="PAYMENT_ID">
        <generator class="native"/>
    </id>
    <discriminator column="PAYMENT_TYPE" type="string"/>
    <property name="amount" column="AMOUNT"/>
    ...
    <subclass name="CreditCardPayment" discriminator-value="CREDIT">
        <join table="CREDIT_PAYMENT">
            <key column="PAYMENT_ID"/>
            <property name="creditCardType" column="CCTYPE"/>
            ...
        </join>
    </subclass>
    <subclass name="CashPayment" discriminator-value="CASH">
        <join table="CASH_PAYMENT">
            <key column="PAYMENT_ID"/>
            ...
        </join>
    </subclass>
    <subclass name="ChequePayment" discriminator-value="CHEQUE">
        <join table="CHEQUE_PAYMENT" fetch="select">
            <key column="PAYMENT_ID"/>
            ...
        </join>
    </subclass>
</class>

The optional fetch="select" declaration tells Hibernate not to fetch the ChequePayment subclass data using an outer join when querying the superclass.
9.1.4. Mixing table per class hierarchy with table per subclass

You may even mix the table per hierarchy and table per subclass strategies using this approach:

<class name="Payment" table="PAYMENT">
    <id name="id" type="long" column="PAYMENT_ID">
        <generator class="native"/>
    </id>
    <discriminator column="PAYMENT_TYPE" type="string"/>
    <property name="amount" column="AMOUNT"/>
    ...
    <subclass name="CreditCardPayment" discriminator-value="CREDIT">
        <join table="CREDIT_PAYMENT">
            <property name="creditCardType" column="CCTYPE"/>
            ...
        </join>
    </subclass>
    <subclass name="CashPayment" discriminator-value="CASH">
        ...
    </subclass>
    <subclass name="ChequePayment" discriminator-value="CHEQUE">
        ...
    </subclass>
</class>

For any of these mapping strategies, a polymorphic association to the root Payment class is mapped using <many-to-one>.

<many-to-one name="payment" column="PAYMENT_ID" class="Payment"/>

9.1.5. Table per concrete class

There are two ways we could go about mapping the table per concrete class strategy. The first is to use <union-subclass>.

<class name="Payment">
    <id name="id" type="long" column="PAYMENT_ID">
        <generator class="sequence"/>
    </id>
    <property name="amount" column="AMOUNT"/>
    ...
    <union-subclass name="CreditCardPayment" table="CREDIT_PAYMENT">
        <property name="creditCardType" column="CCTYPE"/>
        ...
    </union-subclass>
    <union-subclass name="CashPayment" table="CASH_PAYMENT">
        ...
    </union-subclass>
    <union-subclass name="ChequePayment" table="CHEQUE_PAYMENT">
        ...
    </union-subclass>
</class>

Three tables are involved for the subclasses. Each table defines columns for all properties of the class, including inherited properties.

The limitation of this approach is that if a property is mapped on the superclass, the column name must be the same on all subclass tables. (We might relax this in a future release of Hibernate.) The identity generator strategy is not allowed in union subclass inheritance, indeed the primary key seed has to be shared accross all unioned subclasses of a hierarchy.

If your superclass is abstract, map it with abstract="true". Of course, if it is not abstract, an additional table (defaults to PAYMENT in the example above) is needed to hold instances of the superclass.
9.1.6. Table per concrete class, using implicit polymorphism

An alternative approach is to make use of implicit polymorphism:

<class name="CreditCardPayment" table="CREDIT_PAYMENT">
    <id name="id" type="long" column="CREDIT_PAYMENT_ID">
        <generator class="native"/>
    </id>
    <property name="amount" column="CREDIT_AMOUNT"/>
    ...
</class>

<class name="CashPayment" table="CASH_PAYMENT">
    <id name="id" type="long" column="CASH_PAYMENT_ID">
        <generator class="native"/>
    </id>
    <property name="amount" column="CASH_AMOUNT"/>
    ...
</class>

<class name="ChequePayment" table="CHEQUE_PAYMENT">
    <id name="id" type="long" column="CHEQUE_PAYMENT_ID">
        <generator class="native"/>
    </id>
    <property name="amount" column="CHEQUE_AMOUNT"/>
    ...
</class>

Notice that nowhere do we mention the Payment interface explicitly. Also notice that properties of Payment are mapped in each of the subclasses. If you want to avoid duplication, consider using XML entities (e.g. [ <!ENTITY allproperties SYSTEM "allproperties.xml"> ] in the DOCTYPE declartion and &allproperties; in the mapping).

The disadvantage of this approach is that Hibernate does not generate SQL UNIONs when performing polymorphic queries.

For this mapping strategy, a polymorphic association to Payment is usually mapped using <any>.

<any name="payment" meta-type="string" id-type="long">
    <meta-value value="CREDIT" class="CreditCardPayment"/>
    <meta-value value="CASH" class="CashPayment"/>
    <meta-value value="CHEQUE" class="ChequePayment"/>
    <column name="PAYMENT_CLASS"/>
    <column name="PAYMENT_ID"/>
</any>

9.1.7. Mixing implicit polymorphism with other inheritance mappings

There is one further thing to notice about this mapping. Since the subclasses are each mapped in their own <class> element (and since Payment is just an interface), each of the subclasses could easily be part of another inheritance hierarchy! (And you can still use polymorphic queries against the Payment interface.)

<class name="CreditCardPayment" table="CREDIT_PAYMENT">
    <id name="id" type="long" column="CREDIT_PAYMENT_ID">
        <generator class="native"/>
    </id>
    <discriminator column="CREDIT_CARD" type="string"/>
    <property name="amount" column="CREDIT_AMOUNT"/>
    ...
    <subclass name="MasterCardPayment" discriminator-value="MDC"/>
    <subclass name="VisaPayment" discriminator-value="VISA"/>
</class>

<class name="NonelectronicTransaction" table="NONELECTRONIC_TXN">
    <id name="id" type="long" column="TXN_ID">
        <generator class="native"/>
    </id>
    ...
    <joined-subclass name="CashPayment" table="CASH_PAYMENT">
        <key column="PAYMENT_ID"/>
        <property name="amount" column="CASH_AMOUNT"/>
        ...
    </joined-subclass>
    <joined-subclass name="ChequePayment" table="CHEQUE_PAYMENT">
        <key column="PAYMENT_ID"/>
        <property name="amount" column="CHEQUE_AMOUNT"/>
        ...
    </joined-subclass>
</class>

Once again, we don't mention Payment explicitly. If we execute a query against the Payment interface - for example, from Payment - Hibernate automatically returns instances of CreditCardPayment (and its subclasses, since they also implement Payment), CashPayment and ChequePayment but not instances of NonelectronicTransaction.
9.2. Limitations

There are certain limitations to the "implicit polymorphism" approach to the table per concrete-class mapping strategy. There are somewhat less restrictive limitations to <union-subclass> mappings.

The following table shows the limitations of table per concrete-class mappings, and of implicit polymorphism, in Hibernate.

Table 9.1. Features of inheritance mappings
Inheritance strategy	Polymorphic many-to-one	Polymorphic one-to-one	Polymorphic one-to-many	Polymorphic many-to-many	Polymorphic load()/get()	Polymorphic queries	Polymorphic joins	Outer join fetching
table per class-hierarchy	<many-to-one>	<one-to-one>	<one-to-many>	<many-to-many>	s.get(Payment.class, id)	from Payment p	from Order o join o.payment p	supported
table per subclass	<many-to-one>	<one-to-one>	<one-to-many>	<many-to-many>	s.get(Payment.class, id)	from Payment p	from Order o join o.payment p	supported
table per concrete-class (union-subclass)	<many-to-one>	<one-to-one>	<one-to-many> (for inverse="true" only)	<many-to-many>	s.get(Payment.class, id)	from Payment p	from Order o join o.payment p	supported
table per concrete class (implicit polymorphism)	<any>	not supported	not supported	<many-to-any>	s.createCriteria(Payment.class).add( Restrictions.idEq(id) ).uniqueResult()	from Payment p	not supported	not supported
Chapter 10. Working with objects

Hibernate is a full object/relational mapping solution that not only shields the developer from the details of the underlying database management system, but also offers state management of objects. This is, contrary to the management of SQL statements in common JDBC/SQL persistence layers, a very natural object-oriented view of persistence in Java applications.

In other words, Hibernate application developers should always think about the state of their objects, and not necessarily about the execution of SQL statements. This part is taken care of by Hibernate and is only relevant for the application developer when tuning the performance of the system.
10.1. Hibernate object states

Hibernate defines and supports the following object states:

    *

      Transient - an object is transient if it has just been instantiated using the new operator, and it is not associated with a Hibernate Session. It has no persistent representation in the database and no identifier value has been assigned. Transient instances will be destroyed by the garbage collector if the application doesn't hold a reference anymore. Use the Hibernate Session to make an object persistent (and let Hibernate take care of the SQL statements that need to be executed for this transition).
    *

      Persistent - a persistent instance has a representation in the database and an identifier value. It might just have been saved or loaded, however, it is by definition in the scope of a Session. Hibernate will detect any changes made to an object in persistent state and synchronize the state with the database when the unit of work completes. Developers don't execute manual UPDATE statements, or DELETE statements when an object should be made transient.
    *

      Detached - a detached instance is an object that has been persistent, but its Session has been closed. The reference to the object is still valid, of course, and the detached instance might even be modified in this state. A detached instance can be reattached to a new Session at a later point in time, making it (and all the modifications) persistent again. This feature enables a programming model for long running units of work that require user think-time. We call them application transactions, i.e. a unit of work from the point of view of the user. 

We'll now discuss the states and state transitions (and the Hibernate methods that trigger a transition) in more detail.
10.2. Making objects persistent

Newly instantiated instances of a a persistent class are considered transient by Hibernate. We can make a transient instance persistent by associating it with a session:

DomesticCat fritz = new DomesticCat();
fritz.setColor(Color.GINGER);
fritz.setSex('M');
fritz.setName("Fritz");
Long generatedId = (Long) sess.save(fritz);

If Cat has a generated identifier, the identifier is generated and assigned to the cat when save() is called. If Cat has an assigned identifier, or a composite key, the identifier should be assigned to the cat instance before calling save(). You may also use persist() instead of save(), with the semantics defined in the EJB3 early draft.

Alternatively, you may assign the identifier using an overloaded version of save().

DomesticCat pk = new DomesticCat();
pk.setColor(Color.TABBY);
pk.setSex('F');
pk.setName("PK");
pk.setKittens( new HashSet() );
pk.addKitten(fritz);
sess.save( pk, new Long(1234) );

If the object you make persistent has associated objects (e.g. the kittens collection in the previous example), these objects may be made persistent in any order you like unless you have a NOT NULL constraint upon a foreign key column. There is never a risk of violating foreign key constraints. However, you might violate a NOT NULL constraint if you save() the objects in the wrong order.

Usually you don't bother with this detail, as you'll very likely use Hibernate's transitive persistence feature to save the associated objects automatically. Then, even NOT NULL constraint violations don't occur - Hibernate will take care of everything. Transitive persistence is discussed later in this chapter.
10.3. Loading an object

The load() methods of Session gives you a way to retrieve a persistent instance if you already know its identifier. load() takes a class object and will load the state into a newly instantiated instance of that class, in persistent state.

Cat fritz = (Cat) sess.load(Cat.class, generatedId);

// you need to wrap primitive identifiers
long id = 1234;
DomesticCat pk = (DomesticCat) sess.load( DomesticCat.class, new Long(id) );

Alternatively, you can load state into a given instance:

Cat cat = new DomesticCat();
// load pk's state into cat
sess.load( cat, new Long(pkId) );
Set kittens = cat.getKittens();

Note that load() will throw an unrecoverable exception if there is no matching database row. If the class is mapped with a proxy, load() just returns an uninitialized proxy and does not actually hit the database until you invoke a method of the proxy. This behaviour is very useful if you wish to create an association to an object without actually loading it from the database. It also allows multiple instances to be loaded as a batch if batch-size is defined for the class mapping.

If you are not certain that a matching row exists, you should use the get() method, which hits the database immediately and returns null if there is no matching row.

Cat cat = (Cat) sess.get(Cat.class, id);
if (cat==null) {
    cat = new Cat();
    sess.save(cat, id);
}
return cat;

You may even load an object using an SQL SELECT ... FOR UPDATE, using a LockMode. See the API documentation for more information.

Cat cat = (Cat) sess.get(Cat.class, id, LockMode.UPGRADE);

Note that any associated instances or contained collections are not selected FOR UPDATE, unless you decide to specify lock or all as a cascade style for the association.

It is possible to re-load an object and all its collections at any time, using the refresh() method. This is useful when database triggers are used to initialize some of the properties of the object.

sess.save(cat);
sess.flush(); //force the SQL INSERT
sess.refresh(cat); //re-read the state (after the trigger executes)

An important question usually appears at this point: How much does Hibernate load from the database and how many SQL SELECTs will it use? This depends on the fetching strategy and is explained in Section 19.1, ?Fetching strategies?.
10.4. Querying

If you don't know the identifiers of the objects you are looking for, you need a query. Hibernate supports an easy-to-use but powerful object oriented query language (HQL). For programmatic query creation, Hibernate supports a sophisticated Criteria and Example query feature (QBC and QBE). You may also express your query in the native SQL of your database, with optional support from Hibernate for result set conversion into objects.
10.4.1. Executing queries

HQL and native SQL queries are represented with an instance of org.hibernate.Query. This interface offers methods for parameter binding, result set handling, and for the execution of the actual query. You always obtain a Query using the current Session:

List cats = session.createQuery(
    "from Cat as cat where cat.birthdate < ?")
    .setDate(0, date)
    .list();

List mothers = session.createQuery(
    "select mother from Cat as cat join cat.mother as mother where cat.name = ?")
    .setString(0, name)
    .list();

List kittens = session.createQuery(
    "from Cat as cat where cat.mother = ?")
    .setEntity(0, pk)
    .list();

Cat mother = (Cat) session.createQuery(
    "select cat.mother from Cat as cat where cat = ?")
    .setEntity(0, izi)
    .uniqueResult();

A query is usually executed by invoking list(), the result of the query will be loaded completely into a collection in memory. Entity instances retrieved by a query are in persistent state. The uniqueResult() method offers a shortcut if you know your query will only return a single object.
10.4.1.1. Iterating results

Occasionally, you might be able to achieve better performance by executing the query using the iterate() method. This will only usually be the case if you expect that the actual entity instances returned by the query will already be in the session or second-level cache. If they are not already cached, iterate() will be slower than list() and might require many database hits for a simple query, usually 1 for the initial select which only returns identifiers, and n additional selects to initialize the actual instances.

// fetch ids
Iterator iter = sess.createQuery("from eg.Qux q order by q.likeliness").iterate();
while ( iter.hasNext() ) {
    Qux qux = (Qux) iter.next();  // fetch the object
    // something we couldnt express in the query
    if ( qux.calculateComplicatedAlgorithm() ) {
        // delete the current instance
        iter.remove();
        // dont need to process the rest
        break;
    }
}

10.4.1.2. Queries that return tuples

Hibernate queries sometimes return tuples of objects, in which case each tuple is returned as an array:

Iterator kittensAndMothers = sess.createQuery(
            "select kitten, mother from Cat kitten join kitten.mother mother")
            .list()
            .iterator();

while ( kittensAndMothers.hasNext() ) {
    Object[] tuple = (Object[]) kittensAndMothers.next();
    Cat kitten  = tuple[0];
    Cat mother  = tuple[1];
    ....
}

10.4.1.3. Scalar results

Queries may specify a property of a class in the select clause. They may even call SQL aggregate functions. Properties or aggregates are considered "scalar" results (and not entities in persistent state).

Iterator results = sess.createQuery(
        "select cat.color, min(cat.birthdate), count(cat) from Cat cat " +
        "group by cat.color")
        .list()
        .iterator();

while ( results.hasNext() ) {
    Object[] row = (Object[]) results.next();
    Color type = (Color) row[0];
    Date oldest = (Date) row[1];
    Integer count = (Integer) row[2];
    .....
}

10.4.1.4. Bind parameters

Methods on Query are provided for binding values to named parameters or JDBC-style ? parameters. Contrary to JDBC, Hibernate numbers parameters from zero. Named parameters are identifiers of the form :name in the query string. The advantages of named parameters are:

    *

      named parameters are insensitive to the order they occur in the query string
    *

      they may occur multiple times in the same query
    *

      they are self-documenting 

//named parameter (preferred)
Query q = sess.createQuery("from DomesticCat cat where cat.name = :name");
q.setString("name", "Fritz");
Iterator cats = q.iterate();

//positional parameter
Query q = sess.createQuery("from DomesticCat cat where cat.name = ?");
q.setString(0, "Izi");
Iterator cats = q.iterate();

//named parameter list
List names = new ArrayList();
names.add("Izi");
names.add("Fritz");
Query q = sess.createQuery("from DomesticCat cat where cat.name in (:namesList)");
q.setParameterList("namesList", names);
List cats = q.list();

10.4.1.5. Pagination

If you need to specify bounds upon your result set (the maximum number of rows you want to retrieve and / or the first row you want to retrieve) you should use methods of the Query interface:

Query q = sess.createQuery("from DomesticCat cat");
q.setFirstResult(20);
q.setMaxResults(10);
List cats = q.list();

Hibernate knows how to translate this limit query into the native SQL of your DBMS.
10.4.1.6. Scrollable iteration

If your JDBC driver supports scrollable ResultSets, the Query interface may be used to obtain a ScrollableResults object, which allows flexible navigation of the query results.

Query q = sess.createQuery("select cat.name, cat from DomesticCat cat " +
                            "order by cat.name");
ScrollableResults cats = q.scroll();
if ( cats.first() ) {

    // find the first name on each page of an alphabetical list of cats by name
    firstNamesOfPages = new ArrayList();
    do {
        String name = cats.getString(0);
        firstNamesOfPages.add(name);
    }
    while ( cats.scroll(PAGE_SIZE) );

    // Now get the first page of cats
    pageOfCats = new ArrayList();
    cats.beforeFirst();
    int i=0;
    while( ( PAGE_SIZE > i++ ) && cats.next() ) pageOfCats.add( cats.get(1) );

}
cats.close()

Note that an open database connection (and cursor) is required for this functionality, use setMaxResult()/setFirstResult() if you need offline pagination functionality.
10.4.1.7. Externalizing named queries

You may also define named queries in the mapping document. (Remember to use a CDATA section if your query contains characters that could be interpreted as markup.)

<query name="eg.DomesticCat.by.name.and.minimum.weight"><![CDATA[
    from eg.DomesticCat as cat
        where cat.name = ?
        and cat.weight > ?
] ]></query>

Parameter binding and executing is done programatically:

Query q = sess.getNamedQuery("eg.DomesticCat.by.name.and.minimum.weight");
q.setString(0, name);
q.setInt(1, minWeight);
List cats = q.list();

Note that the actual program code is independent of the query language that is used, you may also define native SQL queries in metadata, or migrate existing queries to Hibernate by placing them in mapping files.
10.4.2. Filtering collections

A collection filter is a special type of query that may be applied to a persistent collection or array. The query string may refer to this, meaning the current collection element.

Collection blackKittens = session.createFilter(
    pk.getKittens(), 
    "where this.color = ?")
    .setParameter( Color.BLACK, Hibernate.custom(ColorUserType.class) )
    .list()
);

The returned collection is considered a bag, and it's a copy of the given collection. The original collection is not modified (this is contrary to the implication of the name "filter", but consistent with expected behavior).

Observe that filters do not require a from clause (though they may have one if required). Filters are not limited to returning the collection elements themselves.

Collection blackKittenMates = session.createFilter(
    pk.getKittens(), 
    "select this.mate where this.color = eg.Color.BLACK.intValue")
    .list();

Even an empty filter query is useful, e.g. to load a subset of elements in a huge collection:

Collection tenKittens = session.createFilter(
    mother.getKittens(), "")
    .setFirstResult(0).setMaxResults(10)
    .list();

10.4.3. Criteria queries

HQL is extremely powerful but some developers prefer to build queries dynamically, using an object-oriented API, rather than building query strings. Hibernate provides an intuitive Criteria query API for these cases:

Criteria crit = session.createCriteria(Cat.class);
crit.add( Expression.eq( "color", eg.Color.BLACK ) );
crit.setMaxResults(10);
List cats = crit.list();

The Criteria and the associated Example API are discussed in more detail in Chapter 15, Criteria Queries.
10.4.4. Queries in native SQL

You may express a query in SQL, using createSQLQuery() and let Hibernate take care of the mapping from result sets to objects. Note that you may at any time call session.connection() and use the JDBC Connection directly. If you chose to use the Hibernate API, you must enclose SQL aliases in braces:

List cats = session.createSQLQuery(
    "SELECT {cat.*} FROM CAT {cat} WHERE ROWNUM<10",
    "cat",
    Cat.class
).list();

List cats = session.createSQLQuery(
    "SELECT {cat}.ID AS {cat.id}, {cat}.SEX AS {cat.sex}, " +
           "{cat}.MATE AS {cat.mate}, {cat}.SUBCLASS AS {cat.class}, ... " +
    "FROM CAT {cat} WHERE ROWNUM<10",
    "cat",
    Cat.class
).list()

SQL queries may contain named and positional parameters, just like Hibernate queries. More information about native SQL queries in Hibernate can be found in Chapter 16, Native SQL.
10.5. Modifying persistent objects

Transactional persistent instances (ie. objects loaded, saved, created or queried by the Session) may be manipulated by the application and any changes to persistent state will be persisted when the Session is flushed (discussed later in this chapter). There is no need to call a particular method (like update(), which has a different purpose) to make your modifications persistent. So the most straightforward way to update the state of an object is to load() it, and then manipulate it directly, while the Session is open:

DomesticCat cat = (DomesticCat) sess.load( Cat.class, new Long(69) );
cat.setName("PK");
sess.flush();  // changes to cat are automatically detected and persisted

Sometimes this programming model is inefficient since it would require both an SQL SELECT (to load an object) and an SQL UPDATE (to persist its updated state) in the same session. Therefore Hibernate offers an alternate approach, using detached instances.

Note that Hibernate does not offer its own API for direct execution of UPDATE or DELETE statements. Hibernate is a state management service, you don't have to think in statements to use it. JDBC is a perfect API for executing SQL statements, you can get a JDBC Connection at any time by calling session.connection(). Furthermore, the notion of mass operations conflicts with object/relational mapping for online transaction processing-oriented applications. Future versions of Hibernate may however provide special mass operation functions. See Chapter 13, Batch processing for some possible batch operation tricks.
10.6. Modifying detached objects

Many applications need to retrieve an object in one transaction, send it to the UI layer for manipulation, then save the changes in a new transaction. Applications that use this kind of approach in a high-concurrency environment usually use versioned data to ensure isolation for the "long" unit of work.

Hibernate supports this model by providing for reattachment of detached instances using the Session.update() or Session.merge() methods:

// in the first session
Cat cat = (Cat) firstSession.load(Cat.class, catId);
Cat potentialMate = new Cat();
firstSession.save(potentialMate);

// in a higher layer of the application
cat.setMate(potentialMate);

// later, in a new session
secondSession.update(cat);  // update cat
secondSession.update(mate); // update mate

If the Cat with identifier catId had already been loaded by secondSession when the application tried to reattach it, an exception would have been thrown.

Use update() if you are sure that the session does not contain an already persistent instance with the same identifier, and merge() if you want to merge your modifications at any time without consideration of the state of the session. In other words, update() is usually the first method you would call in a fresh session, ensuring that reattachment of your detached instances is the first operation that is executed.

The application should individually update() detached instances reachable from the given detached instance if and only if it wants their state also updated. This can be automated of course, using transitive persistence, see Section 10.11, ?Transitive persistence?.

The lock() method also allows an application to reassociate an object with a new session. However, the detached instance has to be unmodified!

//just reassociate:
sess.lock(fritz, LockMode.NONE);
//do a version check, then reassociate:
sess.lock(izi, LockMode.READ);
//do a version check, using SELECT ... FOR UPDATE, then reassociate:
sess.lock(pk, LockMode.UPGRADE);

Note that lock() can be used with various LockModes, see the API documentation and the chapter on transaction handling for more information. Reattachment is not the only usecase for lock().

Other models for long units of work are discussed in Section 11.3, ?Optimistic concurrency control?.
10.7. Automatic state detection

Hibernate users have requested a general purpose method that either saves a transient instance by generating a new identifier or updates/reattaches the detached instances associated with its current identifier. The saveOrUpdate() method implements this functionality.

// in the first session
Cat cat = (Cat) firstSession.load(Cat.class, catID);

// in a higher tier of the application
Cat mate = new Cat();
cat.setMate(mate);

// later, in a new session
secondSession.saveOrUpdate(cat);   // update existing state (cat has a non-null id)
secondSession.saveOrUpdate(mate);  // save the new instance (mate has a null id)

The usage and semantics of saveOrUpdate() seems to be confusing for new users. Firstly, so long as you are not trying to use instances from one session in another new session, you should not need to use update(), saveOrUpdate(), or merge(). Some whole applications will never use either of these methods.

Usually update() or saveOrUpdate() are used in the following scenario:

    *

      the application loads an object in the first session
    *

      the object is passed up to the UI tier
    *

      some modifications are made to the object
    *

      the object is passed back down to the business logic tier
    *

      the application persists these modifications by calling update() in a second session 

saveOrUpdate() does the following:

    *

      if the object is already persistent in this session, do nothing
    *

      if another object associated with the session has the same identifier, throw an exception
    *

      if the object has no identifier property, save() it
    *

      if the object's identifier has the value assigned to a newly instantiated object, save() it
    *

      if the object is versioned (by a <version> or <timestamp>), and the version property value is the same value assigned to a newly instantiated object, save() it
    *

      otherwise update() the object 

and merge() is very different:

    *

      if there is a persistent instance with the same identifier currently associated with the session, copy the state of the given object onto the persistent instance
    *

      if there is no persistent instance currently associated with the session, try to load it from the database, or create a new persistent instance
    *

      the persistent instance is returned
    *

      the given instance does not become associated with the session, it remains detached 

10.8. Deleting persistent objects

Session.delete() will remove an object's state from the database. Of course, your application might still hold a reference to a deleted object. It's best to think of delete() as making a persistent instance transient.

sess.delete(cat);

You may delete objects in any order you like, without risk of foreign key constraint violations. It is still possible to violate a NOT NULL constraint on a foreign key column by deleting objects in the wrong order, e.g. if you delete the parent, but forget to delete the children.
10.9. Replicating object between two different datastores

It is occasionally useful to be able to take a graph of persistent instances and make them persistent in a different datastore, without regenerating identifier values.

//retrieve a cat from one database
Session session1 = factory1.openSession();
Transaction tx1 = session1.beginTransaction();
Cat cat = session1.get(Cat.class, catId);
tx1.commit();
session1.close();

//reconcile with a second database
Session session2 = factory2.openSession();
Transaction tx2 = session2.beginTransaction();
session2.replicate(cat, ReplicationMode.LATEST_VERSION);
tx2.commit();
session2.close();

The ReplicationMode determines how replicate() will deal with conflicts with existing rows in the database.

    *

      ReplicationMode.IGNORE - ignore the object when there is an existing database row with the same identifier
    *

      ReplicationMode.OVERWRITE - overwrite any existing database row with the same identifier
    *

      ReplicationMode.EXCEPTION - throw an exception if there is an existing database row with the same identifier
    *

      ReplicationMode.LATEST_VERSION - overwrite the row if its version number is earlier than the version number of the object, or ignore the object otherwise 

Usecases for this feature include reconciling data entered into different database instances, upgrading system configuration information during product upgrades, rolling back changes made during non-ACID transactions and more.
10.10. Flushing the Session

From time to time the Session will execute the SQL statements needed to synchronize the JDBC connection's state with the state of objects held in memory. This process, flush, occurs by default at the following points

    *

      before some query executions
    *

      from org.hibernate.Transaction.commit()
    *

      from Session.flush() 

The SQL statements are issued in the following order

   1.

      all entity insertions, in the same order the corresponding objects were saved using Session.save()
   2.

      all entity updates
   3.

      all collection deletions
   4.

      all collection element deletions, updates and insertions
   5.

      all collection insertions
   6.

      all entity deletions, in the same order the corresponding objects were deleted using Session.delete() 

(An exception is that objects using native ID generation are inserted when they are saved.)

Except when you explicity flush(), there are absolutely no guarantees about when the Session executes the JDBC calls, only the order in which they are executed. However, Hibernate does guarantee that the Query.list(..) will never return stale data; nor will they return the wrong data.

It is possible to change the default behavior so that flush occurs less frequently. The FlushMode class defines three different modes: only flush at commit time (and only when the Hibernate Transaction API is used), flush automatically using the explained routine, or never flush unless flush() is called explicitly. The last mode is useful for long running units of work, where a Session is kept open and disconnected for a long time (see Section 11.3.2, ?Extended session and automatic versioning?).

sess = sf.openSession();
Transaction tx = sess.beginTransaction();
sess.setFlushMode(FlushMode.COMMIT); // allow queries to return stale state

Cat izi = (Cat) sess.load(Cat.class, id);
izi.setName(iznizi);

// might return stale data
sess.find("from Cat as cat left outer join cat.kittens kitten");

// change to izi is not flushed!
...
tx.commit(); // flush occurs
sess.close();

During flush, an exception might occur (e.g. if a DML operation violates a constraint). Since handling exceptions involves some understanding of Hibernate's transactional behavior, we discuss it in Chapter 11, Transactions And Concurrency.
10.11. Transitive persistence

It is quite cumbersome to save, delete, or reattach individual objects, especially if you deal with a graph of associated objects. A common case is a parent/child relationship. Consider the following example:

If the children in a parent/child relationship would be value typed (e.g. a collection of addresses or strings), their lifecycle would depend on the parent and no further action would be required for convenient "cascading" of state changes. When the parent is saved, the value-typed child objects are saved as well, when the parent is deleted, the children will be deleted, etc. This even works for operations such as the removal of a child from the collection; Hibernate will detect this and, since value-typed objects can't have shared references, delete the child from the database.

Now consider the same scenario with parent and child objects being entities, not value-types (e.g. categories and items, or parent and child cats). Entities have their own lifecycle, support shared references (so removing an entity from the collection does not mean it can be deleted), and there is by default no cascading of state from one entity to any other associated entities. Hibernate does not implement persistence by reachability by default.

For each basic operation of the Hibernate session - including persist(), merge(), saveOrUpdate(), delete(), lock(), refresh(), evict(), replicate() - there is a corresponding cascade style. Respectively, the cascade styles are named create, merge, save-update, delete, lock, refresh, evict, replicate. If you want an operation to be cascaded along an association, you must indicate that in the mapping document. For example:

<one-to-one name="person" cascade="persist"/>

Cascade styles my be combined:

<one-to-one name="person" cascade="persist,delete,lock"/>

You may even use cascade="all" to specify that all operations should be cascaded along the association. The default cascade="none" specifies that no operations are to be cascaded.

A special cascade style, delete-orphan, applies only to one-to-many associations, and indicates that the delete() operation should be applied to any child object that is removed from the association.

Recommendations:

    *

      It doesn't usually make sense to enable cascade on a <many-to-one> or <many-to-many> association. Cascade is often useful for <one-to-one> and <one-to-many> associations.
    *

      If the child object's lifespan is bounded by the lifespan of the of the parent object make it a lifecycle object by specifying cascade="all,delete-orphan".
    *

      Otherwise, you might not need cascade at all. But if you think that you will often be working with the parent and children together in the same transaction, and you want to save yourself some typing, consider using cascade="persist,merge,save-update". 

Mapping an association (either a single valued association, or a collection) with cascade="all" marks the association as a parent/child style relationship where save/update/delete of the parent results in save/update/delete of the child or children.

Futhermore, a mere reference to a child from a persistent parent will result in save/update of the child. This metaphor is incomplete, however. A child which becomes unreferenced by its parent is not automatically deleted, except in the case of a <one-to-many> association mapped with cascade="delete-orphan". The precise semantics of cascading operations for a parent/child relationship are as follows:

    *

      If a parent is passed to persist(), all children are passed to persist()
    *

      If a parent is passed to merge(), all children are passed to merge()
    *

      If a parent is passed to save(), update() or saveOrUpdate(), all children are passed to saveOrUpdate()
    *

      If a transient or detached child becomes referenced by a persistent parent, it is passed to saveOrUpdate()
    *

      If a parent is deleted, all children are passed to delete()
    *

      If a child is dereferenced by a persistent parent, nothing special happens - the application should explicitly delete the child if necessary - unless cascade="delete-orphan", in which case the "orphaned" child is deleted. 

Finally, note that cascading of operations can be applied to an object graph at call time or at flush time. All operations, if enabled, are cascaded to associated entities reachable when the operation is executed. However, save-upate and delete-orphan are transitive for all associated entities reachable during flush of the Session.
10.12. Using metadata

Hibernate requires a very rich meta-level model of all entity and value types. From time to time, this model is very useful to the application itself. For example, the application might use Hibernate's metadata to implement a "smart" deep-copy algorithm that understands which objects should be copied (eg. mutable value types) and which should not (eg. immutable value types and, possibly, associated entities).

Hibernate exposes metadata via the ClassMetadata and CollectionMetadata interfaces and the Type hierarchy. Instances of the metadata interfaces may be obtained from the SessionFactory.

Cat fritz = ......;
ClassMetadata catMeta = sessionfactory.getClassMetadata(Cat.class);

Object[] propertyValues = catMeta.getPropertyValues(fritz);
String[] propertyNames = catMeta.getPropertyNames();
Type[] propertyTypes = catMeta.getPropertyTypes();

// get a Map of all properties which are not collections or associations
Map namedValues = new HashMap();
for ( int i=0; i<propertyNames.length; i++ ) {
    if ( !propertyTypes[i].isEntityType() && !propertyTypes[i].isCollectionType() ) {
        namedValues.put( propertyNames[i], propertyValues[i] );
    }
}

Chapter 11. Transactions And Concurrency

The most important point about Hibernate and concurrency control is that it is very easy to understand. Hibernate directly uses JDBC connections and JTA resources without adding any additional locking behavior. We highly recommend you spend some time with the JDBC, ANSI, and transaction isolation specification of your database management system.

Hibernate does not lock objects in memory. Your application can expect the behavior as defined by the isolation level of your database transactions. Note that thanks to the Session, which is also a transaction-scoped cache, Hibernate provides repeatable reads for lookup by identifier and entity queries (not reporting queries that return scalar values).

In addition to versioning for automatic optimistic concurrency control, Hibernate also offers a (minor) API for pessimistic locking of rows, using the SELECT FOR UPDATE syntax. Optimistic concurrency control and this API are discussed later in this chapter.

We start the discussion of concurrency control in Hibernate with the granularity of Configuration, SessionFactory, and Session, as well as database transactions and long conversations.
11.1. Session and transaction scopes

A SessionFactory is an expensive-to-create, threadsafe object intended to be shared by all application threads. It is created once, usually on application startup, from a Configuration instance.

A Session is an inexpensive, non-threadsafe object that should be used once, for a single request, a conversation, single unit of work, and then discarded. A Session will not obtain a JDBC Connection (or a Datasource) unless it is needed, hence consume no resources until used.

To complete this picture you also have to think about database transactions. A database transaction has to be as short as possible, to reduce lock contention in the database. Long database transactions will prevent your application from scaling to highly concurrent load. Hence, it is almost never good design to hold a database transaction open during user think time, until the unit of work is complete.

What is the scope of a unit of work? Can a single Hibernate Session span several database transactions or is this a one-to-one relationship of scopes? When should you open and close a Session and how do you demarcate the database transaction boundaries?
11.1.1. Unit of work

First, don't use the session-per-operation antipattern, that is, don't open and close a Session for every simple database call in a single thread! Of course, the same is true for database transactions. Database calls in an application are made using a planned sequence, they are grouped into atomic units of work. (Note that this also means that auto-commit after every single SQL statement is useless in an application, this mode is intended for ad-hoc SQL console work. Hibernate disables, or expects the application server to do so, auto-commit mode immediately.) Database transactions are never optional, all communication with a database has to occur inside a transaction, no matter if you read or write data. As explained, auto-commit behavior for reading data should be avoided, as many small transactions are unlikely to perform better than one clearly defined unit of work. The latter is also much more maintainable and extensible.

The most common pattern in a multi-user client/server application is session-per-request. In this model, a request from the client is send to the server (where the Hibernate persistence layer runs), a new Hibernate Session is opened, and all database operations are executed in this unit of work. Once the work has been completed (and the response for the client has been prepared), the session is flushed and closed. You would also use a single database transaction to serve the clients request, starting and committing it when you open and close the Session. The relationship between the two is one-to-one and this model is a perfect fit for many applications.

The challenge lies in the implementation. Hibernate provides built-in management of the "current session" to simplify this pattern. All you have to do is start a transaction when a server request has to be processed, and end the transaction before the response is send to the client. You can do this in any way you like, common solutions are ServletFilter, AOP interceptor with a pointcut on the service methods, or a proxy/interception container. An EJB container is a standardized way to implement cross-cutting aspects such as transaction demarcation on EJB session beans, declaratively with CMT. If you decide to use programmatic transaction demarcation, prefer the Hibernate Transaction API shown later in this chapter, for ease of use and code portability.

Your application code can access a "current session" to process the request by simply calling sessionFactory.getCurrentSession() anywhere and as often as needed. You will always get a Session scoped to the current database transaction. This has to be configured for either resource-local or JTA environments, see Section 2.5, ?Contextual Sessions?.

Sometimes it is convenient to extend the scope of a Session and database transaction until the "view has been rendered". This is especially useful in servlet applications that utilize a separate rendering phase after the request has been processed. Extending the database transaction until view rendering is complete is easy to do if you implement your own interceptor. However, it is not easily doable if you rely on EJBs with container-managed transactions, as a transaction will be completed when an EJB method returns, before rendering of any view can start. See the Hibernate website and forum for tips and examples around this Open Session in View pattern.
11.1.2. Long conversations

The session-per-request pattern is not the only useful concept you can use to design units of work. Many business processes require a whole series of interactions with the user interleaved with database accesses. In web and enterprise applications it is not acceptable for a database transaction to span a user interaction. Consider the following example:

    *

      The first screen of a dialog opens, the data seen by the user has been loaded in a particular Session and database transaction. The user is free to modify the objects.
    *

      The user clicks "Save" after 5 minutes and expects his modifications to be made persistent; he also expects that he was the only person editing this information and that no conflicting modification can occur. 

We call this unit of work, from the point of view of the user, a long running conversation (or application transaction). There are many ways how you can implement this in your application.

A first naive implementation might keep the Session and database transaction open during user think time, with locks held in the database to prevent concurrent modification, and to guarantee isolation and atomicity. This is of course an anti-pattern, since lock contention would not allow the application to scale with the number of concurrent users.

Clearly, we have to use several database transactions to implement the converastion. In this case, maintaining isolation of business processes becomes the partial responsibility of the application tier. A single conversation usually spans several database transactions. It will be atomic if only one of these database transactions (the last one) stores the updated data, all others simply read data (e.g. in a wizard-style dialog spanning several request/response cycles). This is easier to implement than it might sound, especially if you use Hibernate's features:

    *

      Automatic Versioning - Hibernate can do automatic optimistic concurrency control for you, it can automatically detect if a concurrent modification occured during user think time. Usually we only check at the end of the conversation.
    *

      Detached Objects - If you decide to use the already discussed session-per-request pattern, all loaded instances will be in detached state during user think time. Hibernate allows you to reattach the objects and persist the modifications, the pattern is called session-per-request-with-detached-objects. Automatic versioning is used to isolate concurrent modifications.
    *

      Extended (or Long) Session - The Hibernate Session may be disconnected from the underlying JDBC connection after the database transaction has been committed, and reconnected when a new client request occurs. This pattern is known as session-per-conversation and makes even reattachment unnecessary. Automatic versioning is used to isolate concurrent modifications and the Session is usually not allowed to be flushed automatically, but explicitely. 

Both session-per-request-with-detached-objects and session-per-conversation have advantages and disadvantages, we discuss them later in this chapter in the context of optimistic concurrency control.
11.1.3. Considering object identity

An application may concurrently access the same persistent state in two different Sessions. However, an instance of a persistent class is never shared between two Session instances. Hence there are two different notions of identity:

Database Identity

    foo.getId().equals( bar.getId() ) 
JVM Identity

    foo==bar 

Then for objects attached to a particular Session (i.e. in the scope of a Session) the two notions are equivalent, and JVM identity for database identity is guaranteed by Hibernate. However, while the application might concurrently access the "same" (persistent identity) business object in two different sessions, the two instances will actually be "different" (JVM identity). Conflicts are resolved using (automatic versioning) at flush/commit time, using an optimistic approach.

This approach leaves Hibernate and the database to worry about concurrency; it also provides the best scalability, since guaranteeing identity in single-threaded units of work only doesn't need expensive locking or other means of synchronization. The application never needs to synchronize on any business object, as long as it sticks to a single thread per Session. Within a Session the application may safely use == to compare objects.

However, an application that uses == outside of a Session, might see unexpected results. This might occur even in some unexpected places, for example, if you put two detached instances into the same Set. Both might have the same database identity (i.e. they represent the same row), but JVM identity is by definition not guaranteed for instances in detached state. The developer has to override the equals() and hashCode() methods in persistent classes and implement his own notion of object equality. There is one caveat: Never use the database identifier to implement equality, use a business key, a combination of unique, usually immutable, attributes. The database identifier will change if a transient object is made persistent. If the transient instance (usually together with detached instances) is held in a Set, changing the hashcode breaks the contract of the Set. Attributes for business keys don't have to be as stable as database primary keys, you only have to guarantee stability as long as the objects are in the same Set. See the Hibernate website for a more thorough discussion of this issue. Also note that this is not a Hibernate issue, but simply how Java object identity and equality has to be implemented.
11.1.4. Common issues

Never use the anti-patterns session-per-user-session or session-per-application (of course, there are rare exceptions to this rule). Note that some of the following issues might also appear with the recommended patterns, make sure you understand the implications before making a design decision:

    *

      A Session is not thread-safe. Things which are supposed to work concurrently, like HTTP requests, session beans, or Swing workers, will cause race conditions if a Session instance would be shared. If you keep your Hibernate Session in your HttpSession (discussed later), you should consider synchronizing access to your Http session. Otherwise, a user that clicks reload fast enough may use the same Session in two concurrently running threads.
    *

      An exception thrown by Hibernate means you have to rollback your database transaction and close the Session immediately (discussed later in more detail). If your Session is bound to the application, you have to stop the application. Rolling back the database transaction doesn't put your business objects back into the state they were at the start of the transaction. This means the database state and the business objects do get out of sync. Usually this is not a problem, because exceptions are not recoverable and you have to start over after rollback anyway.
    *

      The Session caches every object that is in persistent state (watched and checked for dirty state by Hibernate). This means it grows endlessly until you get an OutOfMemoryException, if you keep it open for a long time or simply load too much data. One solution for this is to call clear() and evict() to manage the Session cache, but you most likely should consider a Stored Procedure if you need mass data operations. Some solutions are shown in Chapter 13, Batch processing. Keeping a Session open for the duration of a user session also means a high probability of stale data. 

11.2. Database transaction demarcation

Datatabase (or system) transaction boundaries are always necessary. No communication with the database can occur outside of a database transaction (this seems to confuse many developers who are used to the auto-commit mode). Always use clear transaction boundaries, even for read-only operations. Depending on your isolation level and database capabilities this might not be required but there is no downside if you always demarcate transactions explicitly. Certainly, a single database transaction is going to perform better than many small transactions, even for reading data.

A Hibernate application can run in non-managed (i.e. standalone, simple Web- or Swing applications) and managed J2EE environments. In a non-managed environment, Hibernate is usually responsible for its own database connection pool. The application developer has to manually set transaction boundaries, in other words, begin, commit, or rollback database transactions himself. A managed environment usually provides container-managed transactions (CMT), with the transaction assembly defined declaratively in deployment descriptors of EJB session beans, for example. Programmatic transaction demarcation is then no longer necessary.

However, it is often desirable to keep your persistence layer portable between non-managed resource-local environments, and systems that can rely on JTA but use BMT instead of CMT. In both cases you'd use programmatic transaction demaracation. Hibernate offers a wrapper API called Transaction that translates into the native transaction system of your deployment environment. This API is actually optional, but we strongly encourage its use unless you are in a CMT session bean.

Usually, ending a Session involves four distinct phases:

    *

      flush the session
    *

      commit the transaction
    *

      close the session
    *

      handle exceptions 

Flushing the session has been discussed earlier, we'll now have a closer look at transaction demarcation and exception handling in both managed- and non-managed environments.
11.2.1. Non-managed environment

If a Hibernate persistence layer runs in a non-managed environment, database connections are usually handled by simple (i.e. non-DataSource) connection pools from which Hibernate obtains connections as needed. The session/transaction handling idiom looks like this:

// Non-managed environment idiom
Session sess = factory.openSession();
Transaction tx = null;
try {
    tx = sess.beginTransaction();

    // do some work
    ...

    tx.commit();
}
catch (RuntimeException e) {
    if (tx != null) tx.rollback();
    throw e; // or display error message
}
finally {
    sess.close();
}

You don't have to flush() the Session explicitly - the call to commit() automatically triggers the synchronization (depending upon the Section 10.10, ?Flushing the Session? for the session. A call to close() marks the end of a session. The main implication of close() is that the JDBC connection will be relinquished by the session. This Java code is portable and runs in both non-managed and JTA environments.

A much more flexible solution is Hibernate's built-in "current session" context management, as described earlier:

// Non-managed environment idiom with getCurrentSession()
try {
    factory.getCurrentSession().beginTransaction();

    // do some work
    ...

    factory.getCurrentSession().getTransaction().commit();
}
catch (RuntimeException e) {
    factory.getCurrentSession().getTransaction().rollback();
    throw e; // or display error message
}

You will very likely never see these code snippets in a regular application; fatal (system) exceptions should always be caught at the "top". In other words, the code that executes Hibernate calls (in the persistence layer) and the code that handles RuntimeException (and usually can only clean up and exit) are in different layers. The current context management by Hibernate can significantly simplify this design, as all you need is access to a SessionFactory. Exception handling is discussed later in this chapter.

Note that you should select org.hibernate.transaction.JDBCTransactionFactory (which is the default), and for the second example "thread" as your hibernate.current_session_context_class.
11.2.2. Using JTA

If your persistence layer runs in an application server (e.g. behind EJB session beans), every datasource connection obtained by Hibernate will automatically be part of the global JTA transaction. Hibernate offers two strategies for this integration.

If you use bean-managed transactions (BMT) Hibernate will tell the application server to start and end a BMT transaction if you use the Transaction API. So, the transaction management code is identical to the non-managed environment.

// BMT idiom
Session sess = factory.openSession();
Transaction tx = null;
try {
    tx = sess.beginTransaction();

    // do some work
    ...

    tx.commit();
}
catch (RuntimeException e) {
    if (tx != null) tx.rollback();
    throw e; // or display error message
}
finally {
    sess.close();
}

Or with automatic session context management:

// BMT idiom with getCurrentSession()
try {
    factory.getCurrentSession().beginTransaction();

    // do some work
    ...

    factory.getCurrentSession().getTransaction().commit();
}
catch (RuntimeException e) {
    factory.getCurrentSession().getTransaction().rollback();
    throw e; // or display error message
}

With CMT, transaction demarcation is done in session bean deployment descriptors, not programatically, hence, the code is reduced to:

// CMT idiom
 Session sess = factory.getCurrentSession();

 // do some work
 ...

In a CMT?EJB even rollback happens automatically, since an unhandled RuntimeException thrown by a session bean method tells the container to set the global transaction to rollback. This means you do not need to use the Hibernate Transaction API at all in CMT.

Note that you should choose org.hibernate.transaction.JTATransactionFactory in a BMT session bean, and org.hibernate.transaction.CMTTransactionFactory in a CMT session bean, when you configure Hibernate's transaction factory. Remember to also set hibernate.transaction.manager_lookup_class. Furthermore, make sure that your hibernate.current_session_context_class is either unset (backwards compatiblity), or set to "jta".

The getCurrentSession() operation has one downside in a JTA environment. There is one caveat to the use of after_statement connection release mode, which is then used by default. Due to a silly limitation of the JTA spec, it is not possible for Hibernate to automatically clean up any unclosed ScrollableResults or Iterator instances returned by scroll() or iterate(). You must release the underlying database cursor by calling ScrollableResults.close() or Hibernate.close(Iterator) explicity from a finally block. (Of course, most applications can easily avoid using scroll() or iterate() at all from the CMT code.)
11.2.3. Exception handling

If the Session throws an exception (including any SQLException), you should immediately rollback the database transaction, call Session.close() and discard the Session instance. Certain methods of Session will not leave the session in a consistent state. No exception thrown by Hibernate can be treated as recoverable. Ensure that the Session will be closed by calling close() in a finally block.

The HibernateException, which wraps most of the errors that can occur in a Hibernate persistence layer, is an unchecked exception (it wasn't in older versions of Hibernate). In our opinion, we shouldn't force the application developer to catch an unrecoverable exception at a low layer. In most systems, unchecked and fatal exceptions are handled in one of the first frames of the method call stack (i.e. in higher layers) and an error message is presented to the application user (or some other appropriate action is taken). Note that Hibernate might also throw other unchecked exceptions which are not a HibernateException. These are, again, not recoverable and appropriate action should be taken.

Hibernate wraps SQLExceptions thrown while interacting with the database in a JDBCException. In fact, Hibernate will attempt to convert the eexception into a more meningful subclass of JDBCException. The underlying SQLException is always available via JDBCException.getCause(). Hibernate converts the SQLException into an appropriate JDBCException subclass using the SQLExceptionConverter attached to the SessionFactory. By default, the SQLExceptionConverter is defined by the configured dialect; however, it is also possible to plug in a custom implementation (see the javadocs for the SQLExceptionConverterFactory class for details). The standard JDBCException subtypes are:

    *

      JDBCConnectionException - indicates an error with the underlying JDBC communication.
    *

      SQLGrammarException - indicates a grammar or syntax problem with the issued SQL.
    *

      ConstraintViolationException - indicates some form of integrity constraint violation.
    *

      LockAcquisitionException - indicates an error acquiring a lock level necessary to perform the requested operation.
    *

      GenericJDBCException - a generic exception which did not fall into any of the other categories. 

11.2.4. Transaction timeout

One extremely important feature provided by a managed environment like EJB that is never provided for non-managed code is transaction timeout. Transaction timeouts ensure that no misbehaving transaction can indefinitely tie up resources while returning no response to the user. Outside a managed (JTA) environment, Hibernate cannot fully provide this functionality. However, Hibernate can at least control data access operations, ensuring that database level deadlocks and queries with huge result sets are limited by a defined timeout. In a managed environment, Hibernate can delegate transaction timeout to JTA. This functioanlity is abstracted by the Hibernate Transaction object.

Session sess = factory.openSession();
try {
    //set transaction timeout to 3 seconds
    sess.getTransaction().setTimeout(3);
    sess.getTransaction().begin();

    // do some work
    ...

    sess.getTransaction().commit()
}
catch (RuntimeException e) {
    sess.getTransaction().rollback();
    throw e; // or display error message
}
finally {
    sess.close();
}

Note that setTimeout() may not be called in a CMT bean, where transaction timeouts must be defined declaratively.
11.3. Optimistic concurrency control

The only approach that is consistent with high concurrency and high scalability is optimistic concurrency control with versioning. Version checking uses version numbers, or timestamps, to detect conflicting updates (and to prevent lost updates). Hibernate provides for three possible approaches to writing application code that uses optimistic concurrency. The use cases we show are in the context of long conversations, but version checking also has the benefit of preventing lost updates in single database transactions.
11.3.1. Application version checking

In an implementation without much help from Hibernate, each interaction with the database occurs in a new Session and the developer is responsible for reloading all persistent instances from the database before manipulating them. This approach forces the application to carry out its own version checking to ensure conversation transaction isolation. This approach is the least efficient in terms of database access. It is the approach most similar to entity EJBs.

// foo is an instance loaded by a previous Session
session = factory.openSession();
Transaction t = session.beginTransaction();

int oldVersion = foo.getVersion();
session.load( foo, foo.getKey() ); // load the current state
if ( oldVersion!=foo.getVersion ) throw new StaleObjectStateException();
foo.setProperty("bar");

t.commit();
session.close();

The version property is mapped using <version>, and Hibernate will automatically increment it during flush if the entity is dirty.

Of course, if you are operating in a low-data-concurrency environment and don't require version checking, you may use this approach and just skip the version check. In that case, last commit wins will be the default strategy for your long conversations. Keep in mind that this might confuse the users of the application, as they might experience lost updates without error messages or a chance to merge conflicting changes.

Clearly, manual version checking is only feasible in very trivial circumstances and not practical for most applications. Often not only single instances, but complete graphs of modified ojects have to be checked. Hibernate offers automatic version checking with either an extended Session or detached instances as the design paradigm.
11.3.2. Extended session and automatic versioning

A single Session instance and its persistent instances are used for the whole conversation, known as session-per-conversation. Hibernate checks instance versions at flush time, throwing an exception if concurrent modification is detected. It's up to the developer to catch and handle this exception (common options are the opportunity for the user to merge changes or to restart the business conversation with non-stale data).

The Session is disconnected from any underlying JDBC connection when waiting for user interaction. This approach is the most efficient in terms of database access. The application need not concern itself with version checking or with reattaching detached instances, nor does it have to reload instances in every database transaction.

// foo is an instance loaded earlier by the old session
Transaction t = session.beginTransaction(); // Obtain a new JDBC connection, start transaction

foo.setProperty("bar");

session.flush();    // Only for last transaction in conversation
t.commit();         // Also return JDBC connection
session.close();    // Only for last transaction in conversation

The foo object still knows which Session it was loaded in. Beginning a new database transaction on an old session obtains a new connection and resumes the session. Committing a database transaction disconnects a session from the JDBC connection and returns the connection to the pool. After reconnection, to force a version check on data you aren't updating, you may call Session.lock() with LockMode.READ on any objects that might have been updated by another transaction. You don't need to lock any data that you are updating. Usually you would set FlushMode.NEVER on an extended Session, so that only the last database transaction cycle is allowed to actually persist all modifications made in this conversation. Hence, only this last database transaction would include the flush() operation, and then also close() the session to end the conversation.

This pattern is problematic if the Session is too big to be stored during user think time, e.g. an HttpSession should be kept as small as possible. As the Session is also the (mandatory) first-level cache and contains all loaded objects, we can probably use this strategy only for a few request/response cycles. You should use a Session only for a single conversation, as it will soon also have stale data.

(Note that earlier Hibernate versions required explicit disconnection and reconnection of a Session. These methods are deprecated, as beginning and ending a transaction has the same effect.)

Also note that you should keep the disconnected Session close to the persistence layer. In other words, use an EJB stateful session bean to hold the Session in a three-tier environment, and don't transfer it to the web layer (or even serialize it to a separate tier) to store it in the HttpSession.

The extended session pattern, or session-per-conversation, is more difficult to implement with automatic current session context management. You need to supply your own implementation of the CurrentSessionContext for this, see the Hibernate Wiki for examples.
11.3.3. Detached objects and automatic versioning

Each interaction with the persistent store occurs in a new Session. However, the same persistent instances are reused for each interaction with the database. The application manipulates the state of detached instances originally loaded in another Session and then reattaches them using Session.update(), Session.saveOrUpdate(), or Session.merge().

// foo is an instance loaded by a previous Session
foo.setProperty("bar");
session = factory.openSession();
Transaction t = session.beginTransaction();
session.saveOrUpdate(foo); // Use merge() if "foo" might have been loaded already
t.commit();
session.close();

Again, Hibernate will check instance versions during flush, throwing an exception if conflicting updates occured.

You may also call lock() instead of update() and use LockMode.READ (performing a version check, bypassing all caches) if you are sure that the object has not been modified.
11.3.4. Customizing automatic versioning

You may disable Hibernate's automatic version increment for particular properties and collections by setting the optimistic-lock mapping attribute to false. Hibernate will then no longer increment versions if the property is dirty.

Legacy database schemas are often static and can't be modified. Or, other applications might also access the same database and don't know how to handle version numbers or even timestamps. In both cases, versioning can't rely on a particular column in a table. To force a version check without a version or timestamp property mapping, with a comparison of the state of all fields in a row, turn on optimistic-lock="all" in the <class> mapping. Note that this concepetually only works if Hibernate can compare the old and new state, i.e. if you use a single long Session and not session-per-request-with-detached-objects.

Sometimes concurrent modification can be permitted as long as the changes that have been made don't overlap. If you set optimistic-lock="dirty" when mapping the <class>, Hibernate will only compare dirty fields during flush.

In both cases, with dedicated version/timestamp columns or with full/dirty field comparison, Hibernate uses a single UPDATE statement (with an appropriate WHERE clause) per entity to execute the version check and update the information. If you use transitive persistence to cascade reattachment to associated entities, Hibernate might execute uneccessary updates. This is usually not a problem, but on update triggers in the database might be executed even when no changes have been made to detached instances. You can customize this behavior by setting select-before-update="true" in the <class> mapping, forcing Hibernate to SELECT the instance to ensure that changes did actually occur, before updating the row.
11.4. Pessimistic Locking

It is not intended that users spend much time worring about locking strategies. Its usually enough to specify an isolation level for the JDBC connections and then simply let the database do all the work. However, advanced users may sometimes wish to obtain exclusive pessimistic locks, or re-obtain locks at the start of a new transaction.

Hibernate will always use the locking mechanism of the database, never lock objects in memory!

The LockMode class defines the different lock levels that may be acquired by Hibernate. A lock is obtained by the following mechanisms:

    *

      LockMode.WRITE is acquired automatically when Hibernate updates or inserts a row.
    *

      LockMode.UPGRADE may be acquired upon explicit user request using SELECT ... FOR UPDATE on databases which support that syntax.
    *

      LockMode.UPGRADE_NOWAIT may be acquired upon explicit user request using a SELECT ... FOR UPDATE NOWAIT under Oracle.
    *

      LockMode.READ is acquired automatically when Hibernate reads data under Repeatable Read or Serializable isolation level. May be re-acquired by explicit user request.
    *

      LockMode.NONE represents the absence of a lock. All objects switch to this lock mode at the end of a Transaction. Objects associated with the session via a call to update() or saveOrUpdate() also start out in this lock mode. 

The "explicit user request" is expressed in one of the following ways:

    *

      A call to Session.load(), specifying a LockMode.
    *

      A call to Session.lock().
    *

      A call to Query.setLockMode(). 

If Session.load() is called with UPGRADE or UPGRADE_NOWAIT, and the requested object was not yet loaded by the session, the object is loaded using SELECT ... FOR UPDATE. If load() is called for an object that is already loaded with a less restrictive lock than the one requested, Hibernate calls lock() for that object.

Session.lock() performs a version number check if the specified lock mode is READ, UPGRADE or UPGRADE_NOWAIT. (In the case of UPGRADE or UPGRADE_NOWAIT, SELECT ... FOR UPDATE is used.)

If the database does not support the requested lock mode, Hibernate will use an appropriate alternate mode (instead of throwing an exception). This ensures that applications will be portable.
11.5. Connection Release Modes

The legacy (2.x) behavior of Hibernate in regards to JDBC connection management was that a Session would obtain a connection when it was first needed and then hold unto that connection until the session was closed. Hibernate 3.x introduced the notion of connection release modes to tell a session how to handle its JDBC connections. Note that the following discussion is pertinent only to connections provided through a configured ConnectionProvider; user-supplied connections are outside the breadth of this discussion. The different release modes are identified by the enumerated values of org.hibernate.ConnectionReleaseMode:

    *

      ON_CLOSE - is essentially the legacy behavior described above. The Hibernate session obatins a connection when it first needs to perform some JDBC access and holds unto that connection until the session is closed.
    *

      AFTER_TRANSACTION - says to release connections after a org.hibernate.Transaction has completed.
    *

      AFTER_STATEMENT (also referred to as aggressive release) - says to release connections after each and every statement execution. This aggressive releasing is skipped if that statement leaves open resources associated with the given session; currently the only situation where this occurs is through the use of org.hibernate.ScrollableResults. 

The configuration parameter hibernate.connection.release_mode is used to specify which release mode to use. The possible values:

    *

      auto (the default) - this choice delegates to the release mode returned by the org.hibernate.transaction.TransactionFactory.getDefaultReleaseMode() method. For JTATransactionFactory, this returns ConnectionReleaseMode.AFTER_STATEMENT; for JDBCTransactionFactory, this returns ConnectionReleaseMode.AFTER_TRANSACTION. It is rarely a good idea to change this default behavior as failures due to the value of this setting tend to indicate bugs and/or invalid assumptions in user code.
    *

      on_close - says to use ConnectionReleaseMode.ON_CLOSE. This setting is left for backwards compatibility, but its use is highly discouraged.
    *

      after_transaction - says to use ConnectionReleaseMode.AFTER_TRANSACTION. This setting should not be used in JTA environments. Also note that with ConnectionReleaseMode.AFTER_TRANSACTION, if a session is considered to be in auto-commit mode connections will be released as if the release mode were AFTER_STATEMENT.
    *

      after_statement - says to use ConnectionReleaseMode.AFTER_STATEMENT. Additionally, the configured ConnectionProvider is consulted to see if it supports this setting (supportsAggressiveRelease()). If not, the release mode is reset to ConnectionReleaseMode.AFTER_TRANSACTION. This setting is only safe in environments where we can either re-acquire the same underlying JDBC connection each time we make a call into ConnectionProvider.getConnection() or in auto-commit environments where it does not matter whether we get back the same connection. 

Chapter 12. Interceptors and events

It is often useful for the application to react to certain events that occur inside Hibernate. This allows implementation of certain kinds of generic functionality, and extension of Hibernate functionality.
12.1. Interceptors

The Interceptor interface provides callbacks from the session to the application allowing the application to inspect and/or manipulate properties of a persistent object before it is saved, updated, deleted or loaded. One possible use for this is to track auditing information. For example, the following Interceptor automatically sets the createTimestamp when an Auditable is created and updates the lastUpdateTimestamp property when an Auditable is updated.

You may either implement Interceptor directly or (better) extend EmptyInterceptor.

package org.hibernate.test;

import java.io.Serializable;
import java.util.Date;
import java.util.Iterator;

import org.hibernate.EmptyInterceptor;

import org.hibernate.Transaction;
import org.hibernate.type.Type;

public class AuditInterceptor extends EmptyInterceptor {

    private int updates;
    private int creates;

    private int loads;

    public void onDelete(Object entity,
                         Serializable id,
                         Object[] state,
                         String[] propertyNames,
                         Type[] types) {
        // do nothing
    }

    public boolean onFlushDirty(Object entity,
                                Serializable id,
                                Object[] currentState,
                                Object[] previousState,
                                String[] propertyNames,
                                Type[] types) {

        if ( entity instanceof Auditable ) {
            updates++;
            for ( int i=0; i < propertyNames.length; i++ ) {
                if ( "lastUpdateTimestamp".equals( propertyNames[i] ) ) {
                    currentState[i] = new Date();
                    return true;
                }
            }
        }
        return false;
    }

    public boolean onLoad(Object entity,
                          Serializable id,
                          Object[] state,
                          String[] propertyNames,
                          Type[] types) {
        if ( entity instanceof Auditable ) {

            loads++;

        }

        return false;
    }

    public boolean onSave(Object entity,
                          Serializable id,
                          Object[] state,
                          String[] propertyNames,
                          Type[] types) {

        if ( entity instanceof Auditable ) {
            creates++;
            for ( int i=0; i<propertyNames.length; i++ ) {
                if ( "createTimestamp".equals( propertyNames[i] ) ) {
                    state[i] = new Date();
                    return true;
                }
            }
        }
        return false;
    }

    public void afterTransactionCompletion(Transaction tx) {

        if ( tx.wasCommitted() ) {
            System.out.println("Creations: " + creates + ", Updates: " + updates, "Loads: " + loads);

        }
        updates=0;

        creates=0;

        loads=0;

    }

}

The interceptor would be specified when a session is created.

Session session = sf.openSession( new AuditInterceptor() );

You may also set an interceptor on a global level, using the Configuration. In this case, the interceptor must be threadsafe.

new Configuration().setInterceptor( new AuditInterceptor() );

12.2. Event system

If you have to react to particular events in your persistence layer, you may also use the Hibernate3 event architecture. The event system can be used in addition or as a replacement for interceptors.

Essentially all of the methods of the Session interface correlate to an event. You have a LoadEvent, a FlushEvent, etc (consult the XML configuration-file DTD or the org.hibernate.event package for the full list of defined event types). When a request is made of one of these methods, the Hibernate Session generates an appropriate event and passes it to the configured event listener for that type. Out-of-the-box, these listeners implement the same processing in which those methods always resulted. However, you are free to implement a customization of one of the listener interfaces (i.e., the LoadEvent is processed by the registered implemenation of the LoadEventListener interface), in which case their implementation would be responsible for processing any load() requests made of the Session.

The listeners should be considered effectively singletons; meaning, they are shared between requests, and thus should not save any state as instance variables.

A custom listener should implement the appropriate interface for the event it wants to process and/or extend one of the convenience base classes (or even the default event listeners used by Hibernate out-of-the-box as these are declared non-final for this purpose). Custom listeners can either be registered programmatically through the Configuration object, or specified in the Hibernate configuration XML (declarative configuration through the properties file is not supported). Here's an example of a custom load event listener:

public class MyLoadListener implements LoadEventListener {
    // this is the single method defined by the LoadEventListener interface
    public void onLoad(LoadEvent event, LoadEventListener.LoadType loadType)
            throws HibernateException {
        if ( !MySecurity.isAuthorized( event.getEntityClassName(), event.getEntityId() ) ) {
            throw MySecurityException("Unauthorized access");
        }
    }
}

You also need a configuration entry telling Hibernate to use the listener in addition to the default listener:

<hibernate-configuration>
    <session-factory>
        ...
        <event type="load">

            <listener class="com.eg.MyLoadListener"/>

            <listener class="org.hibernate.event.def.DefaultLoadEventListener"/>

        </event>
    </session-factory>
</hibernate-configuration>

Instead, you may register it programmatically:

Configuration cfg = new Configuration();
LoadEventListener[] stack = { new MyLoadListener(), new DefaultLoadEventListener() };

cfg.EventListeners().setLoadEventListeners(stack);

Listeners registered declaratively cannot share instances. If the same class name is used in multiple <listener/> elements, each reference will result in a separate instance of that class. If you need the capability to share listener instances between listener types you must use the programmatic registration approach.

Why implement an interface and define the specific type during configuration? Well, a listener implementation could implement multiple event listener interfaces. Having the type additionally defined during registration makes it easier to turn custom listeners on or off during configuration.
12.3. Hibernate declarative security

Usually, declarative security in Hibernate applications is managed in a session facade layer. Now, Hibernate3 allows certain actions to be permissioned via JACC, and authorized via JAAS. This is optional functionality built on top of the event architecture.

First, you must configure the appropriate event listeners, to enable the use of JAAS authorization.

<listener type="pre-delete" class="org.hibernate.secure.JACCPreDeleteEventListener"/>
<listener type="pre-update" class="org.hibernate.secure.JACCPreUpdateEventListener"/>
<listener type="pre-insert" class="org.hibernate.secure.JACCPreInsertEventListener"/>
<listener type="pre-load" class="org.hibernate.secure.JACCPreLoadEventListener"/>

Note that <listener type="..." class="..."/> is just a shorthand for <event type="..."><listener class="..."/></event> when there is exactly one listener for a particular event type.

Next, still in hibernate.cfg.xml, bind the permissions to roles:

<grant role="admin" entity-name="User" actions="insert,update,read"/>
<grant role="su" entity-name="User" actions="*"/>

The role names are the roles understood by your JACC provider.
Chapter 13. Batch processing

A naive approach to inserting 100 000 rows in the database using Hibernate might look like this:

Session session = sessionFactory.openSession();
Transaction tx = session.beginTransaction();
for ( int i=0; i<100000; i++ ) {
    Customer customer = new Customer(.....);
    session.save(customer);
}
tx.commit();
session.close();

This would fall over with an OutOfMemoryException somewhere around the 50 000th row. That's because Hibernate caches all the newly inserted Customer instances in the session-level cache.

In this chapter we'll show you how to avoid this problem. First, however, if you are doing batch processing, it is absolutely critical that you enable the use of JDBC batching, if you intend to achieve reasonable performance. Set the JDBC batch size to a reasonable number (say, 10-50):

hibernate.jdbc.batch_size 20

You also might like to do this kind of work in a process where interaction with the second-level cache is completely disabled:

hibernate.cache.use_second_level_cache false

However, this is not absolutely necessary, since we can explicitly set the CacheMode to disable interaction with the second-level cache.
13.1. Batch inserts

When making new objects persistent, you must flush() and then clear() the session regularly, to control the size of the first-level cache.

Session session = sessionFactory.openSession();
Transaction tx = session.beginTransaction();
   
for ( int i=0; i<100000; i++ ) {
    Customer customer = new Customer(.....);
    session.save(customer);
    if ( i % 20 == 0 ) { //20, same as the JDBC batch size
        //flush a batch of inserts and release memory:
        session.flush();
        session.clear();
    }
}
   
tx.commit();
session.close();

13.2. Batch updates

For retrieving and updating data the same ideas apply. In addition, you need to use scroll() to take advantage of server-side cursors for queries that return many rows of data.

Session session = sessionFactory.openSession();
Transaction tx = session.beginTransaction();
   
ScrollableResults customers = session.getNamedQuery("GetCustomers")
    .setCacheMode(CacheMode.IGNORE)
    .scroll(ScrollMode.FORWARD_ONLY);
int count=0;
while ( customers.next() ) {
    Customer customer = (Customer) customers.get(0);
    customer.updateStuff(...);
    if ( ++count % 20 == 0 ) {
        //flush a batch of updates and release memory:
        session.flush();
        session.clear();
    }
}
   
tx.commit();
session.close();

13.3. The StatelessSession interface

Alternatively, Hibernate provides a command-oriented API that may be used for streaming data to and from the database in the form of detached objects. A StatelessSession has no persistence context associated with it and does not provide many of the higher-level lifecycle semantics. In particular, a stateless session does not implement a first-level cache nor interact with any second-level or query cache. It does not implement transactional write-behind or automatic dirty checking. Operations performed using a stateless session do not ever cascade to associated instances. Collections are ignored by a stateless session. Operations performed via a stateless session bypass Hibernate's event model and interceptors. Stateless sessions are vulnerable to data aliasing effects, due to the lack of a first-level cache. A stateless session is a lower-level abstraction, much closer to the underlying JDBC.

StatelessSession session = sessionFactory.openStatelessSession();
Transaction tx = session.beginTransaction();
   
ScrollableResults customers = session.getNamedQuery("GetCustomers")
    .scroll(ScrollMode.FORWARD_ONLY);
while ( customers.next() ) {
    Customer customer = (Customer) customers.get(0);
    customer.updateStuff(...);
    session.update(customer);
}
   
tx.commit();
session.close();

Note that in this code example, the Customer instances returned by the query are immediately detached. They are never associated with any persistence context.

The insert(), update() and delete() operations defined by the StatelessSession interface are considered to be direct database row-level operations, which result in immediate execution of a SQL INSERT, UPDATE or DELETE respectively. Thus, they have very different semantics to the save(), saveOrUpdate() and delete() operations defined by the Session interface.
13.4. DML-style operations

As already discussed, automatic and transparent object/relational mapping is concerned with the management of object state. This implies that the object state is available in memory, hence manipulating (using the SQL Data Manipulation Language (DML) statements: INSERT, UPDATE, DELETE) data directly in the database will not affect in-memory state. However, Hibernate provides methods for bulk SQL-style DML statement execution which are performed through the Hibernate Query Language (Chapter 14, HQL: The Hibernate Query Language).

The pseudo-syntax for UPDATE and DELETE statements is: ( UPDATE | DELETE ) FROM? EntityName (WHERE where_conditions)?. Some points to note:

    *

      In the from-clause, the FROM keyword is optional
    *

      There can only be a single entity named in the from-clause; it can optionally be aliased. If the entity name is aliased, then any property references must be qualified using that alias; if the entity name is not aliased, then it is illegal for any property references to be qualified.
    *

      No Section 14.4, ?Forms of join syntax? (either implicit or explicit) can be specified in a bulk HQL query. Sub-queries may be used in the where-clause; the subqueries, themselves, may contain joins.
    *

      The where-clause is also optional. 

As an example, to execute an HQL UPDATE, use the Query.executeUpdate() method (the method is named for those familiar with JDBC's PreparedStatement.executeUpdate()):

Session session = sessionFactory.openSession();
Transaction tx = session.beginTransaction();

String hqlUpdate = "update Customer c set c.name = :newName where c.name = :oldName";
// or String hqlUpdate = "update Customer set name = :newName where name = :oldName";
int updatedEntities = s.createQuery( hqlUpdate )
        .setString( "newName", newName )
        .setString( "oldName", oldName )
        .executeUpdate();
tx.commit();
session.close();

To execute an HQL DELETE, use the same Query.executeUpdate() method:

Session session = sessionFactory.openSession();
Transaction tx = session.beginTransaction();

String hqlDelete = "delete Customer c where c.name = :oldName";
// or String hqlDelete = "delete Customer where name = :oldName";
int deletedEntities = s.createQuery( hqlDelete )
        .setString( "oldName", oldName )
        .executeUpdate();
tx.commit();
session.close();

The int value returned by the Query.executeUpdate() method indicate the number of entities effected by the operation. Consider this may or may not correlate to the number of rows effected in the database. An HQL bulk operation might result in multiple actual SQL statements being executed, for joined-subclass, for example. The returned number indicates the number of actual entities affected by the statement. Going back to the example of joined-subclass, a delete against one of the subclasses may actually result in deletes against not just the table to which that subclass is mapped, but also the "root" table and potentially joined-subclass tables further down the inheritence hierarchy.

The pseudo-syntax for INSERT statements is: INSERT INTO EntityName properties_list select_statement. Some points to note:

    *

      Only the INSERT INTO ... SELECT ... form is supported; not the INSERT INTO ... VALUES ... form.

      The properties_list is analogous to the column speficiation in the SQL INSERT statement. For entities involved in mapped inheritence, only properties directly defined on that given class-level can be used in the properties_list. Superclass properties are not allowed; and subclass properties do not make sense. In other words, INSERT statements are inherently non-polymorphic.
    *

      select_statement can be any valid HQL select query, with the caveat that the return types must match the types expected by the insert. Currently, this is checked during query compilation rather than allowing the check to relegate to the database. Note however that this might cause problems between Hibernate Types which are equivalent as opposed to equal. This might cause issues with mismatches between a property defined as a org.hibernate.type.DateType and a property defined as a org.hibernate.type.TimestampType, even though the database might not make a distinction or might be able to handle the conversion.
    *

      For the id property, the insert statement gives you two options. You can either explicitly specify the id property in the properties_list (in which case its value is taken from the corresponding select expression) or omit it from the properties_list (in which case a generated value is used). This later option is only available when using id generators that operate in the database; attempting to use this option with any "in memory" type generators will cause an exception during parsing. Note that for the purposes of this discussion, in-database generators are considered to be org.hibernate.id.SequenceGenerator (and its subclasses) and any implementors of org.hibernate.id.PostInsertIdentifierGenerator. The most notable exception here is org.hibernate.id.TableHiLoGenerator, which cannot be used because it does not expose a selectable way to get its values.
    *

      For properties mapped as either version or timestamp, the insert statement gives you two options. You can either specify the property in the properties_list (in which case its value is taken from the corresponding select expressions) or omit it from the properties_list (in which case the seed value defined by the org.hibernate.type.VersionType is used). 

An example HQL INSERT statement execution:

Session session = sessionFactory.openSession();
Transaction tx = session.beginTransaction();

String hqlInsert = "insert into DelinquentAccount (id, name) select c.id, c.name from Customer c where ...";
int createdEntities = s.createQuery( hqlInsert )
        .executeUpdate();
tx.commit();
session.close();

Chapter 14. HQL: The Hibernate Query Language

Hibernate is equipped with an extremely powerful query language that (quite intentionally) looks very much like SQL. But don't be fooled by the syntax; HQL is fully object-oriented, understanding notions like inheritence, polymorphism and association.
14.1. Case Sensitivity

Queries are case-insensitive, except for names of Java classes and properties. So SeLeCT is the same as sELEct is the same as SELECT but org.hibernate.eg.FOO is not org.hibernate.eg.Foo and foo.barSet is not foo.BARSET.

This manual uses lowercase HQL keywords. Some users find queries with uppercase keywords more readable, but we find this convention ugly when embedded in Java code.
14.2. The from clause

The simplest possible Hibernate query is of the form:

from eg.Cat

which simply returns all instances of the class eg.Cat. We don't usually need to qualify the class name, since auto-import is the default. So we almost always just write:

from Cat

Most of the time, you will need to assign an alias, since you will want to refer to the Cat in other parts of the query.

from Cat as cat

This query assigns the alias cat to Cat instances, so we could use that alias later in the query. The as keyword is optional; we could also write:

from Cat cat

Multiple classes may appear, resulting in a cartesian product or "cross" join.

from Formula, Parameter

from Formula as form, Parameter as param

It is considered good practice to name query aliases using an initial lowercase, consistent with Java naming standards for local variables (eg. domesticCat).
14.3. Associations and joins

We may also assign aliases to associated entities, or even to elements of a collection of values, using a join.

from Cat as cat 
    inner join cat.mate as mate
    left outer join cat.kittens as kitten

from Cat as cat left join cat.mate.kittens as kittens

from Formula form full join form.parameter param

The supported join types are borrowed from ANSI SQL

    *

      inner join
    *

      left outer join
    *

      right outer join
    *

      full join (not usually useful) 

The inner join, left outer join and right outer join constructs may be abbreviated.

from Cat as cat 
    join cat.mate as mate
    left join cat.kittens as kitten

You may supply extra join conditions using the HQL with keyword.

from Cat as cat 
    left join cat.kittens as kitten 
        with kitten.bodyWeight > 10.0

In addition, a "fetch" join allows associations or collections of values to be initialized along with their parent objects, using a single select. This is particularly useful in the case of a collection. It effectively overrides the outer join and lazy declarations of the mapping file for associations and collections. See Section 19.1, ?Fetching strategies? for more information.

from Cat as cat 
    inner join fetch cat.mate
    left join fetch cat.kittens

A fetch join does not usually need to assign an alias, because the associated objects should not be used in the where clause (or any other clause). Also, the associated objects are not returned directly in the query results. Instead, they may be accessed via the parent object. The only reason we might need an alias is if we are recursively join fetching a further collection:

from Cat as cat 
    inner join fetch cat.mate
    left join fetch cat.kittens child
    left join fetch child.kittens

Note that the fetch construct may not be used in queries called using scroll() or iterate(). Nor should fetch be used together with setMaxResults() or setFirstResult(). Nor may fetch be used together with an ad hoc with condition. It is possible to create a cartesian product by join fetching more than one collection in a query, so take care in this case. Join fetching multiple collection roles also sometimes gives unexpected results for bag mappings, so be careful about how you formulate your queries in this case. Finally, note that full join fetch and right join fetch are not meaningful.

If you are using property-level lazy fetching (with bytecode instrumentation), it is possible to force Hibernate to fetch the lazy properties immediately (in the first query) using fetch all properties.

from Document fetch all properties order by name

from Document doc fetch all properties where lower(doc.name) like '%cats%'

14.4. Forms of join syntax

HQL supports two forms of association joining: implicit and explicit.

The queries shown in the previous section all use the explicit form where the join keyword is explicitly used in the from clause. This is the recommended form.

The implicit form does not use the join keyword. Instead, the associations are "dereferenced" using dot-notation. implicit joins can appear in any of the HQL clauses. implicit join result in inner joins in the resulting SQL statement.

from Cat as cat where cat.mate.name like '%s%'

14.5. The select clause

The select clause picks which objects and properties to return in the query result set. Consider:

select mate 
from Cat as cat 
    inner join cat.mate as mate

The query will select mates of other Cats. Actually, you may express this query more compactly as:

select cat.mate from Cat cat

Queries may return properties of any value type including properties of component type:

select cat.name from DomesticCat cat
where cat.name like 'fri%'

select cust.name.firstName from Customer as cust

Queries may return multiple objects and/or properties as an array of type Object[],

select mother, offspr, mate.name 
from DomesticCat as mother
    inner join mother.mate as mate
    left outer join mother.kittens as offspr

or as a List,

select new list(mother, offspr, mate.name)
from DomesticCat as mother
    inner join mother.mate as mate
    left outer join mother.kittens as offspr

or as an actual typesafe Java object,

select new Family(mother, mate, offspr)
from DomesticCat as mother
    join mother.mate as mate
    left join mother.kittens as offspr

assuming that the class Family has an appropriate constructor.

You may assign aliases to selected expressions using as:

select max(bodyWeight) as max, min(bodyWeight) as min, count(*) as n
from Cat cat

This is most useful when used together with select new map:

select new map( max(bodyWeight) as max, min(bodyWeight) as min, count(*) as n )
from Cat cat

This query returns a Map from aliases to selected values.
14.6. Aggregate functions

HQL queries may even return the results of aggregate functions on properties:

select avg(cat.weight), sum(cat.weight), max(cat.weight), count(cat)
from Cat cat

The supported aggregate functions are

    *

      avg(...), sum(...), min(...), max(...)
    *

      count(*)
    *

      count(...), count(distinct ...), count(all...) 

You may use arithmetic operators, concatenation, and recognized SQL functions in the select clause:

select cat.weight + sum(kitten.weight) 
from Cat cat 
    join cat.kittens kitten
group by cat.id, cat.weight

select firstName||' '||initial||' '||upper(lastName) from Person

The distinct and all keywords may be used and have the same semantics as in SQL.

select distinct cat.name from Cat cat

select count(distinct cat.name), count(cat) from Cat cat

14.7. Polymorphic queries

A query like:

from Cat as cat

returns instances not only of Cat, but also of subclasses like DomesticCat. Hibernate queries may name any Java class or interface in the from clause. The query will return instances of all persistent classes that extend that class or implement the interface. The following query would return all persistent objects:

from java.lang.Object o

The interface Named might be implemented by various persistent classes:

from Named n, Named m where n.name = m.name

Note that these last two queries will require more than one SQL SELECT. This means that the order by clause does not correctly order the whole result set. (It also means you can't call these queries using Query.scroll().)
14.8. The where clause

The where clause allows you to narrow the list of instances returned. If no alias exists, you may refer to properties by name:

from Cat where name='Fritz'

If there is an alias, use a qualified property name:

from Cat as cat where cat.name='Fritz'

returns instances of Cat named 'Fritz'.

select foo 
from Foo foo, Bar bar
where foo.startDate = bar.date

will return all instances of Foo for which there exists an instance of bar with a date property equal to the startDate property of the Foo. Compound path expressions make the where clause extremely powerful. Consider:

from Cat cat where cat.mate.name is not null

This query translates to an SQL query with a table (inner) join. If you were to write something like

from Foo foo  
where foo.bar.baz.customer.address.city is not null

you would end up with a query that would require four table joins in SQL.

The = operator may be used to compare not only properties, but also instances:

from Cat cat, Cat rival where cat.mate = rival.mate

select cat, mate 
from Cat cat, Cat mate
where cat.mate = mate

The special property (lowercase) id may be used to reference the unique identifier of an object. (You may also use its property name.)

from Cat as cat where cat.id = 123

from Cat as cat where cat.mate.id = 69

The second query is efficient. No table join is required!

Properties of composite identifiers may also be used. Suppose Person has a composite identifier consisting of country and medicareNumber.

from bank.Person person
where person.id.country = 'AU' 
    and person.id.medicareNumber = 123456

from bank.Account account
where account.owner.id.country = 'AU' 
    and account.owner.id.medicareNumber = 123456

Once again, the second query requires no table join.

Likewise, the special property class accesses the discriminator value of an instance in the case of polymorphic persistence. A Java class name embedded in the where clause will be translated to its discriminator value.

from Cat cat where cat.class = DomesticCat

You may also specify properties of components or composite user types (and of components of components, etc). Never try to use a path-expression that ends in a property of component type (as opposed to a property of a component). For example, if store.owner is an entity with a component address

store.owner.address.city    // okay
store.owner.address         // error!

An "any" type has the special properties id and class, allowing us to express a join in the following way (where AuditLog.item is a property mapped with <any>).

from AuditLog log, Payment payment 
where log.item.class = 'Payment' and log.item.id = payment.id

Notice that log.item.class and payment.class would refer to the values of completely different database columns in the above query.
14.9. Expressions

Expressions allowed in the where clause include most of the kind of things you could write in SQL:

    *

      mathematical operators +, -, *, /
    *

      binary comparison operators =, >=, <=, <>, !=, like
    *

      logical operations and, or, not
    *

      Parentheses ( ), indicating grouping
    *

      in, not in, between, is null, is not null, is empty, is not empty, member of and not member of
    *

      "Simple" case, case ... when ... then ... else ... end, and "searched" case, case when ... then ... else ... end
    *

      string concatenation ...||... or concat(...,...)
    *

      current_date(), current_time(), current_timestamp()
    *

      second(...), minute(...), hour(...), day(...), month(...), year(...),
    *

      Any function or operator defined by EJB-QL 3.0: substring(), trim(), lower(), upper(), length(), locate(), abs(), sqrt(), bit_length(), mod()
    *

      coalesce() and nullif()
    *

      str() for converting numeric or temporal values to a readable string
    *

      cast(... as ...), where the second argument is the name of a Hibernate type, and extract(... from ...) if ANSI cast() and extract() is supported by the underlying database
    *

      the HQL index() function, that applies to aliases of a joined indexed collection
    *

      HQL functions that take collection-valued path expressions: size(), minelement(), maxelement(), minindex(), maxindex(), along with the special elements() and indices functions which may be quantified using some, all, exists, any, in.
    *

      Any database-supported SQL scalar function like sign(), trunc(), rtrim(), sin()
    *

      JDBC-style positional parameters ?
    *

      named parameters :name, :start_date, :x1
    *

      SQL literals 'foo', 69, 6.66E+2, '1970-01-01 10:00:01.0'
    *

      Java public static final constants eg.Color.TABBY 

in and between may be used as follows:

from DomesticCat cat where cat.name between 'A' and 'B'

from DomesticCat cat where cat.name in ( 'Foo', 'Bar', 'Baz' )

and the negated forms may be written

from DomesticCat cat where cat.name not between 'A' and 'B'

from DomesticCat cat where cat.name not in ( 'Foo', 'Bar', 'Baz' )

Likewise, is null and is not null may be used to test for null values.

Booleans may be easily used in expressions by declaring HQL query substitutions in Hibernate configuration:

<property name="hibernate.query.substitutions">true 1, false 0</property>

This will replace the keywords true and false with the literals 1 and 0 in the translated SQL from this HQL:

from Cat cat where cat.alive = true

You may test the size of a collection with the special property size, or the special size() function.

from Cat cat where cat.kittens.size > 0

from Cat cat where size(cat.kittens) > 0

For indexed collections, you may refer to the minimum and maximum indices using minindex and maxindex functions. Similarly, you may refer to the minimum and maximum elements of a collection of basic type using the minelement and maxelement functions.

from Calendar cal where maxelement(cal.holidays) > current_date

from Order order where maxindex(order.items) > 100

from Order order where minelement(order.items) > 10000

The SQL functions any, some, all, exists, in are supported when passed the element or index set of a collection (elements and indices functions) or the result of a subquery (see below).

select mother from Cat as mother, Cat as kit
where kit in elements(foo.kittens)

select p from NameList list, Person p
where p.name = some elements(list.names)

from Cat cat where exists elements(cat.kittens)

from Player p where 3 > all elements(p.scores)

from Show show where 'fizard' in indices(show.acts)

Note that these constructs - size, elements, indices, minindex, maxindex, minelement, maxelement - may only be used in the where clause in Hibernate3.

Elements of indexed collections (arrays, lists, maps) may be referred to by index (in a where clause only):

from Order order where order.items[0].id = 1234

select person from Person person, Calendar calendar
where calendar.holidays['national day'] = person.birthDay
    and person.nationality.calendar = calendar

select item from Item item, Order order
where order.items[ order.deliveredItemIndices[0] ] = item and order.id = 11

select item from Item item, Order order
where order.items[ maxindex(order.items) ] = item and order.id = 11

The expression inside [] may even be an arithmetic expression.

select item from Item item, Order order
where order.items[ size(order.items) - 1 ] = item

HQL also provides the built-in index() function, for elements of a one-to-many association or collection of values.

select item, index(item) from Order order 
    join order.items item
where index(item) < 5

Scalar SQL functions supported by the underlying database may be used

from DomesticCat cat where upper(cat.name) like 'FRI%'

If you are not yet convinced by all this, think how much longer and less readable the following query would be in SQL:

select cust
from Product prod,
    Store store
    inner join store.customers cust
where prod.name = 'widget'
    and store.location.name in ( 'Melbourne', 'Sydney' )
    and prod = all elements(cust.currentOrder.lineItems)

Hint: something like

SELECT cust.name, cust.address, cust.phone, cust.id, cust.current_order
FROM customers cust,
    stores store,
    locations loc,
    store_customers sc,
    product prod
WHERE prod.name = 'widget'
    AND store.loc_id = loc.id
    AND loc.name IN ( 'Melbourne', 'Sydney' )
    AND sc.store_id = store.id
    AND sc.cust_id = cust.id
    AND prod.id = ALL(
        SELECT item.prod_id
        FROM line_items item, orders o
        WHERE item.order_id = o.id
            AND cust.current_order = o.id
    )

14.10. The order by clause

The list returned by a query may be ordered by any property of a returned class or components:

from DomesticCat cat
order by cat.name asc, cat.weight desc, cat.birthdate

The optional asc or desc indicate ascending or descending order respectively.
14.11. The group by clause

A query that returns aggregate values may be grouped by any property of a returned class or components:

select cat.color, sum(cat.weight), count(cat) 
from Cat cat
group by cat.color

select foo.id, avg(name), max(name) 
from Foo foo join foo.names name
group by foo.id

A having clause is also allowed.

select cat.color, sum(cat.weight), count(cat) 
from Cat cat
group by cat.color 
having cat.color in (eg.Color.TABBY, eg.Color.BLACK)

SQL functions and aggregate functions are allowed in the having and order by clauses, if supported by the underlying database (eg. not in MySQL).

select cat
from Cat cat
    join cat.kittens kitten
group by cat
having avg(kitten.weight) > 100
order by count(kitten) asc, sum(kitten.weight) desc

Note that neither the group by clause nor the order by clause may contain arithmetic expressions.
14.12. Subqueries

For databases that support subselects, Hibernate supports subqueries within queries. A subquery must be surrounded by parentheses (often by an SQL aggregate function call). Even correlated subqueries (subqueries that refer to an alias in the outer query) are allowed.

from Cat as fatcat 
where fatcat.weight > ( 
    select avg(cat.weight) from DomesticCat cat 
)

from DomesticCat as cat 
where cat.name = some ( 
    select name.nickName from Name as name 
)

from Cat as cat 
where not exists ( 
    from Cat as mate where mate.mate = cat 
)

from DomesticCat as cat 
where cat.name not in ( 
    select name.nickName from Name as name 
)

select cat.id, (select max(kit.weight) from cat.kitten kit) 
from Cat as cat

Note that HQL subqueries may occur only in the select or where clauses.

For subqueries with more than one expression in the select list, you can use a tuple constructor:

from Cat as cat 
where not ( cat.name, cat.color ) in ( 
    select cat.name, cat.color from DomesticCat cat 
)

Note that on some databases (but not Oracle or HSQL), you can use tuple constructors in other contexts, for example when querying components or composite user types:

from Person where name = ('Gavin', 'A', 'King')

Which is equivalent to the more verbose:

from Person where name.first = 'Gavin' and name.initial = 'A' and name.last = 'King')

There are two good reasons you might not want to do this kind of thing: first, it is not completely portable between database platforms; second, the query is now dependent upon the ordering of properties in the mapping document.
14.13. HQL examples

Hibernate queries can be quite powerful and complex. In fact, the power of the query language is one of Hibernate's main selling points. Here are some example queries very similar to queries that I used on a recent project. Note that most queries you will write are much simpler than these!

The following query returns the order id, number of items and total value of the order for all unpaid orders for a particular customer and given minimum total value, ordering the results by total value. In determining the prices, it uses the current catalog. The resulting SQL query, against the ORDER, ORDER_LINE, PRODUCT, CATALOG and PRICE tables has four inner joins and an (uncorrelated) subselect.

select order.id, sum(price.amount), count(item)
from Order as order
    join order.lineItems as item
    join item.product as product,
    Catalog as catalog
    join catalog.prices as price
where order.paid = false
    and order.customer = :customer
    and price.product = product
    and catalog.effectiveDate < sysdate
    and catalog.effectiveDate >= all (
        select cat.effectiveDate 
        from Catalog as cat
        where cat.effectiveDate < sysdate
    )
group by order
having sum(price.amount) > :minAmount
order by sum(price.amount) desc

What a monster! Actually, in real life, I'm not very keen on subqueries, so my query was really more like this:

select order.id, sum(price.amount), count(item)
from Order as order
    join order.lineItems as item
    join item.product as product,
    Catalog as catalog
    join catalog.prices as price
where order.paid = false
    and order.customer = :customer
    and price.product = product
    and catalog = :currentCatalog
group by order
having sum(price.amount) > :minAmount
order by sum(price.amount) desc

The next query counts the number of payments in each status, excluding all payments in the AWAITING_APPROVAL status where the most recent status change was made by the current user. It translates to an SQL query with two inner joins and a correlated subselect against the PAYMENT, PAYMENT_STATUS and PAYMENT_STATUS_CHANGE tables.

select count(payment), status.name 
from Payment as payment 
    join payment.currentStatus as status
    join payment.statusChanges as statusChange
where payment.status.name <> PaymentStatus.AWAITING_APPROVAL
    or (
        statusChange.timeStamp = ( 
            select max(change.timeStamp) 
            from PaymentStatusChange change 
            where change.payment = payment
        )
        and statusChange.user <> :currentUser
    )
group by status.name, status.sortOrder
order by status.sortOrder

If I would have mapped the statusChanges collection as a list, instead of a set, the query would have been much simpler to write.

select count(payment), status.name 
from Payment as payment
    join payment.currentStatus as status
where payment.status.name <> PaymentStatus.AWAITING_APPROVAL
    or payment.statusChanges[ maxIndex(payment.statusChanges) ].user <> :currentUser
group by status.name, status.sortOrder
order by status.sortOrder

The next query uses the MS SQL Server isNull() function to return all the accounts and unpaid payments for the organization to which the current user belongs. It translates to an SQL query with three inner joins, an outer join and a subselect against the ACCOUNT, PAYMENT, PAYMENT_STATUS, ACCOUNT_TYPE, ORGANIZATION and ORG_USER tables.

select account, payment
from Account as account
    left outer join account.payments as payment
where :currentUser in elements(account.holder.users)
    and PaymentStatus.UNPAID = isNull(payment.currentStatus.name, PaymentStatus.UNPAID)
order by account.type.sortOrder, account.accountNumber, payment.dueDate

For some databases, we would need to do away with the (correlated) subselect.

select account, payment
from Account as account
    join account.holder.users as user
    left outer join account.payments as payment
where :currentUser = user
    and PaymentStatus.UNPAID = isNull(payment.currentStatus.name, PaymentStatus.UNPAID)
order by account.type.sortOrder, account.accountNumber, payment.dueDate

14.14. Bulk update and delete

HQL now supports update, delete and insert ... select ... statements. See Section 13.4, ?DML-style operations? for details.
14.15. Tips & Tricks

You can count the number of query results without actually returning them:

( (Integer) session.iterate("select count(*) from ....").next() ).intValue()

To order a result by the size of a collection, use the following query:

select usr.id, usr.name
from User as usr 
    left join usr.messages as msg
group by usr.id, usr.name
order by count(msg)

If your database supports subselects, you can place a condition upon selection size in the where clause of your query:

from User usr where size(usr.messages) >= 1

If your database doesn't support subselects, use the following query:

select usr.id, usr.name
from User usr.name
    join usr.messages msg
group by usr.id, usr.name
having count(msg) >= 1

As this solution can't return a User with zero messages because of the inner join, the following form is also useful:

select usr.id, usr.name
from User as usr
    left join usr.messages as msg
group by usr.id, usr.name
having count(msg) = 0

Properties of a JavaBean can be bound to named query parameters:

Query q = s.createQuery("from foo Foo as foo where foo.name=:name and foo.size=:size");
q.setProperties(fooBean); // fooBean has getName() and getSize()
List foos = q.list();

Collections are pageable by using the Query interface with a filter:

Query q = s.createFilter( collection, "" ); // the trivial filter
q.setMaxResults(PAGE_SIZE);
q.setFirstResult(PAGE_SIZE * pageNumber);
List page = q.list();

Collection elements may be ordered or grouped using a query filter:

Collection orderedCollection = s.filter( collection, "order by this.amount" );
Collection counts = s.filter( collection, "select this.type, count(this) group by this.type" );

You can find the size of a collection without initializing it:

( (Integer) session.iterate("select count(*) from ....").next() ).intValue();

Chapter 15. Criteria Queries

Hibernate features an intuitive, extensible criteria query API.
15.1. Creating a Criteria instance

The interface org.hibernate.Criteria represents a query against a particular persistent class. The Session is a factory for Criteria instances.

Criteria crit = sess.createCriteria(Cat.class);
crit.setMaxResults(50);
List cats = crit.list();

15.2. Narrowing the result set

An individual query criterion is an instance of the interface org.hibernate.criterion.Criterion. The class org.hibernate.criterion.Restrictions defines factory methods for obtaining certain built-in Criterion types.

List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.like("name", "Fritz%") )
    .add( Restrictions.between("weight", minWeight, maxWeight) )
    .list();

Restrictions may be grouped logically.

List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.like("name", "Fritz%") )
    .add( Restrictions.or(
        Restrictions.eq( "age", new Integer(0) ),
        Restrictions.isNull("age")
    ) )
    .list();

List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.in( "name", new String[] { "Fritz", "Izi", "Pk" } ) )
    .add( Restrictions.disjunction()
        .add( Restrictions.isNull("age") )
        .add( Restrictions.eq("age", new Integer(0) ) )
        .add( Restrictions.eq("age", new Integer(1) ) )
        .add( Restrictions.eq("age", new Integer(2) ) )
    ) )
    .list();

There are quite a range of built-in criterion types (Restrictions subclasses), but one that is especially useful lets you specify SQL directly.

List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.sqlRestriction("lower({alias}.name) like lower(?)", "Fritz%", Hibernate.STRING) )
    .list();

The {alias} placeholder with be replaced by the row alias of the queried entity.

An alternative approach to obtaining a criterion is to get it from a Property instance. You can create a Property by calling Property.forName().

Property age = Property.forName("age");
List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.disjunction()
        .add( age.isNull() )
        .add( age.eq( new Integer(0) ) )
        .add( age.eq( new Integer(1) ) )
        .add( age.eq( new Integer(2) ) )
    ) )
    .add( Property.forName("name").in( new String[] { "Fritz", "Izi", "Pk" } ) )
    .list();

15.3. Ordering the results

You may order the results using org.hibernate.criterion.Order.

List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.like("name", "F%")
    .addOrder( Order.asc("name") )
    .addOrder( Order.desc("age") )
    .setMaxResults(50)
    .list();

List cats = sess.createCriteria(Cat.class)
    .add( Property.forName("name").like("F%") )
    .addOrder( Property.forName("name").asc() )
    .addOrder( Property.forName("age").desc() )
    .setMaxResults(50)
    .list();

15.4. Associations

You may easily specify constraints upon related entities by navigating associations using createCriteria().

List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.like("name", "F%") )
    .createCriteria("kittens")
        .add( Restrictions.like("name", "F%") )
    .list();

note that the second createCriteria() returns a new instance of Criteria, which refers to the elements of the kittens collection.

The following, alternate form is useful in certain circumstances.

List cats = sess.createCriteria(Cat.class)
    .createAlias("kittens", "kt")
    .createAlias("mate", "mt")
    .add( Restrictions.eqProperty("kt.name", "mt.name") )
    .list();

(createAlias() does not create a new instance of Criteria.)

Note that the kittens collections held by the Cat instances returned by the previous two queries are not pre-filtered by the criteria! If you wish to retrieve just the kittens that match the criteria, you must use a ResultTransformer.

List cats = sess.createCriteria(Cat.class)
    .createCriteria("kittens", "kt")
        .add( Restrictions.eq("name", "F%") )
    .setResultTransformer(Criteria.ALIAS_TO_ENTITY_MAP)
    .list();
Iterator iter = cats.iterator();
while ( iter.hasNext() ) {
    Map map = (Map) iter.next();
    Cat cat = (Cat) map.get(Criteria.ROOT_ALIAS);
    Cat kitten = (Cat) map.get("kt");
}

15.5. Dynamic association fetching

You may specify association fetching semantics at runtime using setFetchMode().

List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.like("name", "Fritz%") )
    .setFetchMode("mate", FetchMode.EAGER)
    .setFetchMode("kittens", FetchMode.EAGER)
    .list();

This query will fetch both mate and kittens by outer join. See Section 19.1, ?Fetching strategies? for more information.
15.6. Example queries

The class org.hibernate.criterion.Example allows you to construct a query criterion from a given instance.

Cat cat = new Cat();
cat.setSex('F');
cat.setColor(Color.BLACK);
List results = session.createCriteria(Cat.class)
    .add( Example.create(cat) )
    .list();

Version properties, identifiers and associations are ignored. By default, null valued properties are excluded.

You can adjust how the Example is applied.

Example example = Example.create(cat)
    .excludeZeroes()           //exclude zero valued properties
    .excludeProperty("color")  //exclude the property named "color"
    .ignoreCase()              //perform case insensitive string comparisons
    .enableLike();             //use like for string comparisons
List results = session.createCriteria(Cat.class)
    .add(example)
    .list();

You can even use examples to place criteria upon associated objects.

List results = session.createCriteria(Cat.class)
    .add( Example.create(cat) )
    .createCriteria("mate")
        .add( Example.create( cat.getMate() ) )
    .list();

15.7. Projections, aggregation and grouping

The class org.hibernate.criterion.Projections is a factory for Projection instances. We apply a projection to a query by calling setProjection().

List results = session.createCriteria(Cat.class)
    .setProjection( Projections.rowCount() )
    .add( Restrictions.eq("color", Color.BLACK) )
    .list();

List results = session.createCriteria(Cat.class)
    .setProjection( Projections.projectionList()
        .add( Projections.rowCount() )
        .add( Projections.avg("weight") )
        .add( Projections.max("weight") )
        .add( Projections.groupProperty("color") )
    )
    .list();

There is no explicit "group by" necessary in a criteria query. Certain projection types are defined to be grouping projections, which also appear in the SQL group by clause.

An alias may optionally be assigned to a projection, so that the projected value may be referred to in restrictions or orderings. Here are two different ways to do this:

List results = session.createCriteria(Cat.class)
    .setProjection( Projections.alias( Projections.groupProperty("color"), "colr" ) )
    .addOrder( Order.asc("colr") )
    .list();

List results = session.createCriteria(Cat.class)
    .setProjection( Projections.groupProperty("color").as("colr") )
    .addOrder( Order.asc("colr") )
    .list();

The alias() and as() methods simply wrap a projection instance in another, aliased, instance of Projection. As a shortcut, you can assign an alias when you add the projection to a projection list:

List results = session.createCriteria(Cat.class)
    .setProjection( Projections.projectionList()
        .add( Projections.rowCount(), "catCountByColor" )
        .add( Projections.avg("weight"), "avgWeight" )
        .add( Projections.max("weight"), "maxWeight" )
        .add( Projections.groupProperty("color"), "color" )
    )
    .addOrder( Order.desc("catCountByColor") )
    .addOrder( Order.desc("avgWeight") )
    .list();

List results = session.createCriteria(Domestic.class, "cat")
    .createAlias("kittens", "kit")
    .setProjection( Projections.projectionList()
        .add( Projections.property("cat.name"), "catName" )
        .add( Projections.property("kit.name"), "kitName" )
    )
    .addOrder( Order.asc("catName") )
    .addOrder( Order.asc("kitName") )
    .list();

You can also use Property.forName() to express projections:

List results = session.createCriteria(Cat.class)
    .setProjection( Property.forName("name") )
    .add( Property.forName("color").eq(Color.BLACK) )
    .list();

List results = session.createCriteria(Cat.class)
    .setProjection( Projections.projectionList()
        .add( Projections.rowCount().as("catCountByColor") )
        .add( Property.forName("weight").avg().as("avgWeight") )
        .add( Property.forName("weight").max().as("maxWeight") )
        .add( Property.forName("color").group().as("color" )
    )
    .addOrder( Order.desc("catCountByColor") )
    .addOrder( Order.desc("avgWeight") )
    .list();

15.8. Detached queries and subqueries

The DetachedCriteria class lets you create a query outside the scope of a session, and then later execute it using some arbitrary Session.

DetachedCriteria query = DetachedCriteria.forClass(Cat.class)
    .add( Property.forName("sex").eq('F') );
    
Session session = ....;
Transaction txn = session.beginTransaction();
List results = query.getExecutableCriteria(session).setMaxResults(100).list();
txn.commit();
session.close();

A DetachedCriteria may also be used to express a subquery. Criterion instances involving subqueries may be obtained via Subqueries or Property.

DetachedCriteria avgWeight = DetachedCriteria.forClass(Cat.class)
    .setProjection( Property.forName("weight").avg() );
session.createCriteria(Cat.class)
    .add( Property.forName("weight).gt(avgWeight) )
    .list();

DetachedCriteria weights = DetachedCriteria.forClass(Cat.class)
    .setProjection( Property.forName("weight") );
session.createCriteria(Cat.class)
    .add( Subqueries.geAll("weight", weights) )
    .list();

Even correlated subqueries are possible:

DetachedCriteria avgWeightForSex = DetachedCriteria.forClass(Cat.class, "cat2")
    .setProjection( Property.forName("weight").avg() )
    .add( Property.forName("cat2.sex").eqProperty("cat.sex") );
session.createCriteria(Cat.class, "cat")
    .add( Property.forName("weight).gt(avgWeightForSex) )
    .list();

15.9. Queries by natural identifier

For most queries, including criteria queries, the query cache is not very efficient, because query cache invalidation occurs too frequently. However, there is one special kind of query where we can optimize the cache invalidation algorithm: lookups by a constant natural key. In some applications, this kind of query occurs frequently. The criteria API provides special provision for this use case.

First, you should map the natural key of your entity using <natural-id>, and enable use of the second-level cache.

<class name="User">
    <cache usage="read-write"/>
    <id name="id">
        <generator class="increment"/>
    </id>
    <natural-id>
        <property name="name"/>
        <property name="org"/>
    </natural-id>
    <property name="password"/>
</class>

Note that this functionality is not intended for use with entities with mutable natural keys.

Next, enable the Hibernate query cache.

Now, Restrictions.naturalId() allows us to make use of the more efficient cache algorithm.

session.createCriteria(User.class)
    .add( Restrictions.naturalId()
        .set("name", "gavin")
        .set("org", "hb") 
    ).setCacheable(true)
    .uniqueResult();

Chapter 16. Native SQL

You may also express queries in the native SQL dialect of your database. This is useful if you want to utilize database specific features such as query hints or the CONNECT keyword in Oracle. It also provides a clean migration path from a direct SQL/JDBC based application to Hibernate.

Hibernate3 allows you to specify handwritten SQL (including stored procedures) for all create, update, delete, and load operations.
16.1. Using a SQLQuery

Execution of native SQL queries is controlled via the SQLQuery interface, which is obtained by calling Session.createSQLQuery(). In extremely simple cases, we can use the following form:

List cats = sess.createSQLQuery("select * from cats")
    .addEntity(Cat.class)
    .list();

This query specified:

    *

      the SQL query string
    *

      the entity returned by the query

Here, the result set column names are assumed to be the same as the column names specified in the mapping document. This can be problematic for SQL queries which join multiple tables, since the same column names may appear in more than one table. The following form is not vulnerable to column name duplication:

List cats = sess.createSQLQuery("select {cat.*} from cats cat")
    .addEntity("cat", Cat.class)
    .list();

This query specified:

    *

      the SQL query string, with a placeholder for Hibernate to inject the column aliases
    *

      the entity returned by the query, and its SQL table alias

The addEntity() method associates the SQL table alias with the returned entity class, and determines the shape of the query result set.

The addJoin() method may be used to load associations to other entities and collections.

List cats = sess.createSQLQuery(
        "select {cat.*}, {kitten.*} from cats cat, cats kitten where kitten.mother = cat.id"
    )
    .addEntity("cat", Cat.class)
    .addJoin("kitten", "cat.kittens")
    .list();

A native SQL query might return a simple scalar value or a combination of scalars and entities.

Double max = (Double) sess.createSQLQuery("select max(cat.weight) as maxWeight from cats cat")
        .addScalar("maxWeight", Hibernate.DOUBLE);
        .uniqueResult();

You can alternatively describe the resultset mapping informations in your hbm files and use them for your queries

List cats = sess.createSQLQuery(
        "select {cat.*}, {kitten.*} from cats cat, cats kitten where kitten.mother = cat.id"
    )
    .setResultSetMapping("catAndKitten")
    .list();

16.2. Alias and property references

The {cat.*} notation used above is a shorthand for "all properties". Alternatively, you may list the columns explicity, but even this case we let Hibernate inject the SQL column aliases for each property. The placeholder for a column alias is just the property name qualified by the table alias. In the following example, we retrieve Cats from a different table (cat_log) to the one declared in the mapping metadata. Notice that we may even use the property aliases in the where clause if we like.

The {}-syntax is not required for named queries. See Section 16.3, ?Named SQL queries?

String sql = "select cat.originalId as {cat.id}, " +
    "cat.mateid as {cat.mate}, cat.sex as {cat.sex}, " +
    "cat.weight*10 as {cat.weight}, cat.name as {cat.name} " +
    "from cat_log cat where {cat.mate} = :catId"

List loggedCats = sess.createSQLQuery(sql)
    .addEntity("cat", Cat.class)
    .setLong("catId", catId)
    .list();

Note: if you list each property explicitly, you must include all properties of the class and its subclasses!

The following table shows the different possibilities of using the alias injection. Note: the alias names in the result are examples, each alias will have a unique and probably different name when used.

Table 16.1. Alias injection names
Description	Syntax	Example	 
A simple property	{[aliasname].[propertyname]	A_NAME as {item.name}	 
A composite property	{[aliasname].[componentname].[propertyname]}	CURRENCY as {item.amount.currency}, VALUE as {item.amount.value}	 
Discriminator of an entity	{[aliasname].class}	DISC as {item.class}	 
All properties of an entity	{[aliasname].*}	{item.*}	 
A collection key	{[aliasname].key}	ORGID as {coll.key}	 
The id of an collection	{[aliasname].id}	EMPID as {coll.id}	 
The element of an collection	{[aliasname].element}	XID as {coll.element}	 
Property of the element in the collection	{[aliasname].element.[propertyname]}	NAME as {coll.element.name}	 
All properties of the element in the collection	{[aliasname].element.*}	{coll.element.*}	 
All properties of the the collection	{[aliasname].*}	{coll.*}	 
16.3. Named SQL queries

Named SQL queries may be defined in the mapping document and called in exactly the same way as a named HQL query. In this case, we do not need to call addEntity().

<sql-query name="persons">
    <return alias="person" class="eg.Person"/>
    SELECT person.NAME AS {person.name},
           person.AGE AS {person.age},
           person.SEX AS {person.sex}
    FROM PERSON person
    WHERE person.NAME LIKE :namePattern
</sql-query>

List people = sess.getNamedQuery("persons")
    .setString("namePattern", namePattern)
    .setMaxResults(50)
    .list();

The <return-join> and <load-collection> elements are used to join associations and define queries which initialize collections, respectively.

<sql-query name="personsWith">
    <return alias="person" class="eg.Person"/>
    <return-join alias="address" property="person.mailingAddress"/>
    SELECT person.NAME AS {person.name},
           person.AGE AS {person.age},
           person.SEX AS {person.sex},
           adddress.STREET AS {address.street},
           adddress.CITY AS {address.city},
           adddress.STATE AS {address.state},
           adddress.ZIP AS {address.zip}
    FROM PERSON person
    JOIN ADDRESS adddress
        ON person.ID = address.PERSON_ID AND address.TYPE='MAILING'
    WHERE person.NAME LIKE :namePattern
</sql-query>

A named SQL query may return a scalar value. You must declare the column alias and Hibernate type using the <return-scalar> element:

<sql-query name="mySqlQuery">
    <return-scalar column="name" type="string"/>
    <return-scalar column="age" type="long"/>
    SELECT p.NAME AS name,
           p.AGE AS age,
    FROM PERSON p WHERE p.NAME LIKE 'Hiber%'
</sql-query>

You can externalize the resultset mapping informations in a <resultset> element to either reuse them accross several named queries or through the setResultSetMapping() API.

<resultset name="personAddress">
    <return alias="person" class="eg.Person"/>
    <return-join alias="address" property="person.mailingAddress"/>
</resultset>

<sql-query name="personsWith" resultset-ref="personAddress">
    SELECT person.NAME AS {person.name},
           person.AGE AS {person.age},
           person.SEX AS {person.sex},
           adddress.STREET AS {address.street},
           adddress.CITY AS {address.city},
           adddress.STATE AS {address.state},
           adddress.ZIP AS {address.zip}
    FROM PERSON person
    JOIN ADDRESS adddress
        ON person.ID = address.PERSON_ID AND address.TYPE='MAILING'
    WHERE person.NAME LIKE :namePattern
</sql-query>

16.3.1. Using return-property to explicitly specify column/alias names

With <return-property> you can explicitly tell Hibernate what column aliases to use, instead of using the {}-syntax to let Hibernate inject its own aliases.

<sql-query name="mySqlQuery">
    <return alias="person" class="eg.Person">
        <return-property name="name" column="myName"/>
        <return-property name="age" column="myAge"/>
        <return-property name="sex" column="mySex"/>
    </return>
    SELECT person.NAME AS myName,
           person.AGE AS myAge,
           person.SEX AS mySex,
    FROM PERSON person WHERE person.NAME LIKE :name
</sql-query>

<return-property> also works with multiple columns. This solves a limitation with the {}-syntax which can not allow fine grained control of multi-column properties.

<sql-query name="organizationCurrentEmployments">
    <return alias="emp" class="Employment">
        <return-property name="salary">
            <return-column name="VALUE"/>
            <return-column name="CURRENCY"/>
        </return-property>
        <return-property name="endDate" column="myEndDate"/>
    </return>
        SELECT EMPLOYEE AS {emp.employee}, EMPLOYER AS {emp.employer},
        STARTDATE AS {emp.startDate}, ENDDATE AS {emp.endDate},
        REGIONCODE as {emp.regionCode}, EID AS {emp.id}, VALUE, CURRENCY
        FROM EMPLOYMENT
        WHERE EMPLOYER = :id AND ENDDATE IS NULL
        ORDER BY STARTDATE ASC
</sql-query>

Notice that in this example we used <return-property> in combination with the {}-syntax for injection. Allowing users to choose how they want to refer column and properties.

If your mapping has a discriminator you must use <return-discriminator> to specify the discriminator column.
16.3.2. Using stored procedures for querying

Hibernate 3 introduces support for queries via stored procedures and functions. Most of the following documentation is equivalent for both. The stored procedure/function must return a resultset as the first out-parameter to be able to work with Hibernate. An example of such a stored function in Oracle 9 and higher is as follows:

CREATE OR REPLACE FUNCTION selectAllEmployments
    RETURN SYS_REFCURSOR
AS
    st_cursor SYS_REFCURSOR;
BEGIN
    OPEN st_cursor FOR
 SELECT EMPLOYEE, EMPLOYER,
 STARTDATE, ENDDATE,
 REGIONCODE, EID, VALUE, CURRENCY
 FROM EMPLOYMENT;
      RETURN  st_cursor;
 END;

To use this query in Hibernate you need to map it via a named query.

<sql-query name="selectAllEmployees_SP" callable="true">
    <return alias="emp" class="Employment">
        <return-property name="employee" column="EMPLOYEE"/>
        <return-property name="employer" column="EMPLOYER"/>
        <return-property name="startDate" column="STARTDATE"/>
        <return-property name="endDate" column="ENDDATE"/>
        <return-property name="regionCode" column="REGIONCODE"/>
        <return-property name="id" column="EID"/>
        <return-property name="salary">
            <return-column name="VALUE"/>
            <return-column name="CURRENCY"/>
        </return-property>
    </return>
    { ? = call selectAllEmployments() }
</sql-query>

Notice stored procedures currently only return scalars and entities. <return-join> and <load-collection> are not supported.
16.3.2.1. Rules/limitations for using stored procedures

To use stored procedures with Hibernate the procedures/functions have to follow some rules. If they do not follow those rules they are not usable with Hibernate. If you still want to use these procedures you have to execute them via session.connection(). The rules are different for each database, since database vendors have different stored procedure semantics/syntax.

Stored procedure queries can't be paged with setFirstResult()/setMaxResults().

Recommended call form is standard SQL92: { ? = call functionName(<parameters>) } or { ? = call procedureName(<parameters>}. Native call syntax is not supported.

For Oracle the following rules apply:

    *

      A function must return a result set. The first parameter of a procedure must be an OUT that returns a result set. This is done by using a SYS_REFCURSOR type in Oracle 9 or 10. In Oracle you need to define a REF CURSOR type, see Oracle literature.

For Sybase or MS SQL server the following rules apply:

    *

      The procedure must return a result set. Note that since these servers can/will return multiple result sets and update counts, Hibernate will iterate the results and take the first result that is a result set as its return value. Everything else will be discarded.
    *

      If you can enable SET NOCOUNT ON in your procedure it will probably be more efficient, but this is not a requirement.

16.4. Custom SQL for create, update and delete

Hibernate3 can use custom SQL statements for create, update, and delete operations. The class and collection persisters in Hibernate already contain a set of configuration time generated strings (insertsql, deletesql, updatesql etc.). The mapping tags <sql-insert>, <sql-delete>, and <sql-update> override these strings:

<class name="Person">
    <id name="id">
        <generator class="increment"/>
    </id>
    <property name="name" not-null="true"/>
    <sql-insert>INSERT INTO PERSON (NAME, ID) VALUES ( UPPER(?), ? )</sql-insert>
    <sql-update>UPDATE PERSON SET NAME=UPPER(?) WHERE ID=?</sql-update>
    <sql-delete>DELETE FROM PERSON WHERE ID=?</sql-delete>
</class>

The SQL is directly executed in your database, so you are free to use any dialect you like. This will of course reduce the portability of your mapping if you use database specific SQL.

Stored procedures are supported if the callable attribute is set:

<class name="Person">
    <id name="id">
        <generator class="increment"/>
    </id>
    <property name="name" not-null="true"/>
    <sql-insert callable="true">{call createPerson (?, ?)}</sql-insert>
    <sql-delete callable="true">{? = call deletePerson (?)}</sql-delete>
    <sql-update callable="true">{? = call updatePerson (?, ?)}</sql-update>
</class>

The order of the positional parameters are currently vital, as they must be in the same sequence as Hibernate expects them.

You can see the expected order by enabling debug logging for the org.hibernate.persister.entity level. With this level enabled Hibernate will print out the static SQL that is used to create, update, delete etc. entities. (To see the expected sequence, remember to not include your custom SQL in the mapping files as that will override the Hibernate generated static sql.)

The stored procedures are in most cases (read: better do it than not) required to return the number of rows inserted/updated/deleted, as Hibernate has some runtime checks for the success of the statement. Hibernate always registers the first statement parameter as a numeric output parameter for the CUD operations:

CREATE OR REPLACE FUNCTION updatePerson (uid IN NUMBER, uname IN VARCHAR2)
    RETURN NUMBER IS
BEGIN

    update PERSON
    set
        NAME = uname,
    where
        ID = uid;

    return SQL%ROWCOUNT;

END updatePerson;

16.5. Custom SQL for loading

You may also declare your own SQL (or HQL) queries for entity loading:

<sql-query name="person">
    <return alias="pers" class="Person" lock-mode="upgrade"/>
    SELECT NAME AS {pers.name}, ID AS {pers.id}
    FROM PERSON
    WHERE ID=?
    FOR UPDATE
</sql-query>

This is just a named query declaration, as discussed earlier. You may reference this named query in a class mapping:

<class name="Person">
    <id name="id">
        <generator class="increment"/>
    </id>
    <property name="name" not-null="true"/>
    <loader query-ref="person"/>
</class>

This even works with stored procedures.

You may even define a query for collection loading:

<set name="employments" inverse="true">
    <key/>
    <one-to-many class="Employment"/>
    <loader query-ref="employments"/>
</set>

<sql-query name="employments">
    <load-collection alias="emp" role="Person.employments"/>
    SELECT {emp.*}
    FROM EMPLOYMENT emp
    WHERE EMPLOYER = :id
    ORDER BY STARTDATE ASC, EMPLOYEE ASC
</sql-query>

You could even define an entity loader that loads a collection by join fetching:

<sql-query name="person">
    <return alias="pers" class="Person"/>
    <return-join alias="emp" property="pers.employments"/>
    SELECT NAME AS {pers.*}, {emp.*}
    FROM PERSON pers
    LEFT OUTER JOIN EMPLOYMENT emp
        ON pers.ID = emp.PERSON_ID
    WHERE ID=?
</sql-query>

Chapter 17. Filtering data

Hibernate3 provides an innovative new approach to handling data with "visibility" rules. A Hibernate filter is a global, named, parameterized filter that may be enabled or disabled for a particular Hibernate session.
17.1. Hibernate filters

Hibernate3 adds the ability to pre-define filter criteria and attach those filters at both a class and a collection level. A filter criteria is the ability to define a restriction clause very similiar to the existing "where" attribute available on the class and various collection elements. Except these filter conditions can be parameterized. The application can then make the decision at runtime whether given filters should be enabled and what their parameter values should be. Filters can be used like database views, but parameterized inside the application.

In order to use filters, they must first be defined and then attached to the appropriate mapping elements. To define a filter, use the <filter-def/> element within a <hibernate-mapping/> element:

<filter-def name="myFilter">
    <filter-param name="myFilterParam" type="string"/>
</filter-def>

Then, this filter can be attached to a class:

<class name="myClass" ...>
    ...
    <filter name="myFilter" condition=":myFilterParam = MY_FILTERED_COLUMN"/>
</class>

or, to a collection:

<set ...>
    <filter name="myFilter" condition=":myFilterParam = MY_FILTERED_COLUMN"/>
</set>

or, even to both (or multiples of each) at the same time.

The methods on Session are: enableFilter(String filterName), getEnabledFilter(String filterName), and disableFilter(String filterName). By default, filters are not enabled for a given session; they must be explcitly enabled through use of the Session.enabledFilter() method, which returns an instance of the Filter interface. Using the simple filter defined above, this would look like:

session.enableFilter("myFilter").setParameter("myFilterParam", "some-value");

Note that methods on the org.hibernate.Filter interface do allow the method-chaining common to much of Hibernate.

A full example, using temporal data with an effective record date pattern:

<filter-def name="effectiveDate">
    <filter-param name="asOfDate" type="date"/>
</filter-def>

<class name="Employee" ...>
...
    <many-to-one name="department" column="dept_id" class="Department"/>
    <property name="effectiveStartDate" type="date" column="eff_start_dt"/>
    <property name="effectiveEndDate" type="date" column="eff_end_dt"/>
...
    <!--
        Note that this assumes non-terminal records have an eff_end_dt set to
        a max db date for simplicity-sake
    -->
    <filter name="effectiveDate"
            condition=":asOfDate BETWEEN eff_start_dt and eff_end_dt"/>
</class>

<class name="Department" ...>
...
    <set name="employees" lazy="true">
        <key column="dept_id"/>
        <one-to-many class="Employee"/>
        <filter name="effectiveDate"
                condition=":asOfDate BETWEEN eff_start_dt and eff_end_dt"/>
    </set>
</class>

Then, in order to ensure that you always get back currently effective records, simply enable the filter on the session prior to retrieving employee data:

Session session = ...;
session.enabledFilter("effectiveDate").setParameter("asOfDate", new Date());
List results = session.createQuery("from Employee as e where e.salary > :targetSalary")
         .setLong("targetSalary", new Long(1000000))
         .list();

In the HQL above, even though we only explicitly mentioned a salary constraint on the results, because of the enabled filter the query will return only currently active employees who have a salary greater than a million dollars.

Note: if you plan on using filters with outer joining (either through HQL or load fetching) be careful of the direction of the condition expression. Its safest to set this up for left outer joining; in general, place the parameter first followed by the column name(s) after the operator.
Chapter 18. XML Mapping

Note that this is an experimental feature in Hibernate 3.0 and is under extremely active development.
18.1. Working with XML data

Hibernate lets you work with persistent XML data in much the same way you work with persistent POJOs. A parsed XML tree can be thought of as just another way to represent the relational data at the object level, instead of POJOs.

Hibernate supports dom4j as API for manipulating XML trees. You can write queries that retrieve dom4j trees from the database and have any modification you make to the tree automatically synchronized to the database. You can even take an XML document, parse it using dom4j, and write it to the database with any of Hibernate's basic operations: persist(), saveOrUpdate(), merge(), delete(), replicate() (merging is not yet supported).

This feature has many applications including data import/export, externalization of entity data via JMS or SOAP and XSLT-based reporting.

A single mapping may be used to simultaneously map properties of a class and nodes of an XML document to the database, or, if there is no class to map, it may be used to map just the XML.
18.1.1. Specifying XML and class mapping together

Here is an example of mapping a POJO and XML simultaneously:

<class name="Account" 
        table="ACCOUNTS" 
        node="account">
        
    <id name="accountId" 
            column="ACCOUNT_ID" 
            node="@id"/>
            
    <many-to-one name="customer" 
            column="CUSTOMER_ID" 
            node="customer/@id" 
            embed-xml="false"/>
            
    <property name="balance" 
            column="BALANCE" 
            node="balance"/>
            
    ...
    
</class>

18.1.2. Specifying only an XML mapping

Here is an example where there is no POJO class:

<class entity-name="Account" 
        table="ACCOUNTS" 
        node="account">
        
    <id name="id" 
            column="ACCOUNT_ID" 
            node="@id" 
            type="string"/>
            
    <many-to-one name="customerId" 
            column="CUSTOMER_ID" 
            node="customer/@id" 
            embed-xml="false" 
            entity-name="Customer"/>
            
    <property name="balance" 
            column="BALANCE" 
            node="balance" 
            type="big_decimal"/>
            
    ...
    
</class>

This mapping allows you to access the data as a dom4j tree, or as a graph of property name/value pairs (java Maps). The property names are purely logical constructs that may be referred to in HQL queries.
18.2. XML mapping metadata

Many Hibernate mapping elements accept the node attribute. This let's you specify the name of an XML attribute or element that holds the property or entity data. The format of the node attribute must be one of the following:

    *

      "element-name" - map to the named XML element
    *

      "@attribute-name" - map to the named XML attribute
    *

      "." - map to the parent element
    *

      "element-name/@attribute-name" - map to the named attribute of the named element 

For collections and single valued associations, there is an additional embed-xml attribute. If embed-xml="true", the default, the XML tree for the associated entity (or collection of value type) will be embedded directly in the XML tree for the entity that owns the association. Otherwise, if embed-xml="false", then only the referenced identifier value will appear in the XML for single point associations and collections will simply not appear at all.

You should be careful not to leave embed-xml="true" for too many associations, since XML does not deal well with circularity!

<class name="Customer" 
        table="CUSTOMER" 
        node="customer">
        
    <id name="id" 
            column="CUST_ID" 
            node="@id"/>
            
    <map name="accounts" 
            node="." 
            embed-xml="true">
        <key column="CUSTOMER_ID" 
                not-null="true"/>
        <map-key column="SHORT_DESC" 
                node="@short-desc" 
                type="string"/>
        <one-to-many entity-name="Account"
                embed-xml="false" 
                node="account"/>
    </map>
    
    <component name="name" 
            node="name">
        <property name="firstName" 
                node="first-name"/>
        <property name="initial" 
                node="initial"/>
        <property name="lastName" 
                node="last-name"/>
    </component>
    
    ...
    
</class>

in this case, we have decided to embed the collection of account ids, but not the actual account data. The following HQL query:

from Customer c left join fetch c.accounts where c.lastName like :lastName

Would return datasets such as this:

<customer id="123456789">
    <account short-desc="Savings">987632567</account>
    <account short-desc="Credit Card">985612323</account>
    <name>
        <first-name>Gavin</first-name>
        <initial>A</initial>
        <last-name>King</last-name>
    </name>
    ...
</customer>

If you set embed-xml="true" on the <one-to-many> mapping, the data might look more like this:

<customer id="123456789">
    <account id="987632567" short-desc="Savings">
        <customer id="123456789"/>
        <balance>100.29</balance>
    </account>
    <account id="985612323" short-desc="Credit Card">
        <customer id="123456789"/>
        <balance>-2370.34</balance>
    </account>
    <name>
        <first-name>Gavin</first-name>
        <initial>A</initial>
        <last-name>King</last-name>
    </name>
    ...
</customer>

18.3. Manipulating XML data

Let's rearead and update XML documents in the application. We do this by obtaining a dom4j session:

Document doc = ....;
       
Session session = factory.openSession();
Session dom4jSession = session.getSession(EntityMode.DOM4J);
Transaction tx = session.beginTransaction();

List results = dom4jSession
    .createQuery("from Customer c left join fetch c.accounts where c.lastName like :lastName")
    .list();
for ( int i=0; i<results.size(); i++ ) {
    //add the customer data to the XML document
    Element customer = (Element) results.get(i);
    doc.add(customer);
}

tx.commit();
session.close();

Session session = factory.openSession();
Session dom4jSession = session.getSession(EntityMode.DOM4J);
Transaction tx = session.beginTransaction();

Element cust = (Element) dom4jSession.get("Customer", customerId);
for ( int i=0; i<results.size(); i++ ) {
    Element customer = (Element) results.get(i);
    //change the customer name in the XML and database
    Element name = customer.element("name");
    name.element("first-name").setText(firstName);
    name.element("initial").setText(initial);
    name.element("last-name").setText(lastName);
}

tx.commit();
session.close();

It is extremely useful to combine this feature with Hibernate's replicate() operation to implement XML-based data import/export.
Chapter 19. Improving performance
19.1. Fetching strategies

A fetching strategy is the strategy Hibernate will use for retrieving associated objects if the application needs to navigate the association. Fetch strategies may be declared in the O/R mapping metadata, or over-ridden by a particular HQL or Criteria query.

Hibernate3 defines the following fetching strategies:

    *

      Join fetching - Hibernate retrieves the associated instance or collection in the same SELECT, using an OUTER JOIN.
    *

      Select fetching - a second SELECT is used to retrieve the associated entity or collection. Unless you explicitly disable lazy fetching by specifying lazy="false", this second select will only be executed when you actually access the association.
    *

      Subselect fetching - a second SELECT is used to retrieve the associated collections for all entities retrieved in a previous query or fetch. Unless you explicitly disable lazy fetching by specifying lazy="false", this second select will only be executed when you actually access the association.
    *

      Batch fetching - an optimization strategy for select fetching - Hibernate retrieves a batch of entity instances or collections in a single SELECT, by specifying a list of primary keys or foreign keys. 

Hibernate also distinguishes between:

    *

      Immediate fetching - an association, collection or attribute is fetched immediately, when the owner is loaded.
    *

      Lazy collection fetching - a collection is fetched when the application invokes an operation upon that collection. (This is the default for collections.)
    *

      "Extra-lazy" collection fetching - individual elements of the collection are accessed from the database as needed. Hibernate tries not to fetch the whole collection into memory unless absolutely needed (suitable for very large collections)
    *

      Proxy fetching - a single-valued association is fetched when a method other than the identifier getter is invoked upon the associated object.
    *

      "No-proxy" fetching - a single-valued association is fetched when the instance variable is accessed. Compared to proxy fetching, this approach is less lazy (the association is fetched even when only the identifier is accessed) but more transparent, since no proxy is visible to the application. This approach requires buildtime bytecode instrumentation and is rarely necessary.
    *

      Lazy attribute fetching - an attribute or single valued association is fetched when the instance variable is accessed. This approach requires buildtime bytecode instrumentation and is rarely necessary. 

We have two orthogonal notions here: when is the association fetched, and how is it fetched (what SQL is used). Don't confuse them! We use fetch to tune performance. We may use lazy to define a contract for what data is always available in any detached instance of a particular class.
19.1.1. Working with lazy associations

By default, Hibernate3 uses lazy select fetching for collections and lazy proxy fetching for single-valued associations. These defaults make sense for almost all associations in almost all applications.

Note: if you set hibernate.default_batch_fetch_size, Hibernate will use the batch fetch optimization for lazy fetching (this optimization may also be enabled at a more granular level).

However, lazy fetching poses one problem that you must be aware of. Access to a lazy association outside of the context of an open Hibernate session will result in an exception. For example:

s = sessions.openSession();
Transaction tx = s.beginTransaction();
            
User u = (User) s.createQuery("from User u where u.name=:userName")
    .setString("userName", userName).uniqueResult();
Map permissions = u.getPermissions();

tx.commit();
s.close();

Integer accessLevel = (Integer) permissions.get("accounts");  // Error!

Since the permissions collection was not initialized when the Session was closed, the collection will not be able to load its state. Hibernate does not support lazy initialization for detached objects. The fix is to move the code that reads from the collection to just before the transaction is committed.

Alternatively, we could use a non-lazy collection or association, by specifying lazy="false" for the association mapping. However, it is intended that lazy initialization be used for almost all collections and associations. If you define too many non-lazy associations in your object model, Hibernate will end up needing to fetch the entire database into memory in every transaction!

On the other hand, we often want to choose join fetching (which is non-lazy by nature) instead of select fetching in a particular transaction. We'll now see how to customize the fetching strategy. In Hibernate3, the mechanisms for choosing a fetch strategy are identical for single-valued associations and collections.
19.1.2. Tuning fetch strategies

Select fetching (the default) is extremely vulnerable to N+1 selects problems, so we might want to enable join fetching in the mapping document:

<set name="permissions" 
            fetch="join">
    <key column="userId"/>
    <one-to-many class="Permission"/>
</set

<many-to-one name="mother" class="Cat" fetch="join"/>

The fetch strategy defined in the mapping document affects:

    *

      retrieval via get() or load()
    *

      retrieval that happens implicitly when an association is navigated
    *

      Criteria queries
    *

      HQL queries if subselect fetching is used 

No matter what fetching strategy you use, the defined non-lazy graph is guaranteed to be loaded into memory. Note that this might result in several immediate selects being used to execute a particular HQL query.

Usually, we don't use the mapping document to customize fetching. Instead, we keep the default behavior, and override it for a particular transaction, using left join fetch in HQL. This tells Hibernate to fetch the association eagerly in the first select, using an outer join. In the Criteria query API, you would use setFetchMode(FetchMode.JOIN).

If you ever feel like you wish you could change the fetching strategy used by get() or load(), simply use a Criteria query, for example:

User user = (User) session.createCriteria(User.class)
                .setFetchMode("permissions", FetchMode.JOIN)
                .add( Restrictions.idEq(userId) )
                .uniqueResult();

(This is Hibernate's equivalent of what some ORM solutions call a "fetch plan".)

A completely different way to avoid problems with N+1 selects is to use the second-level cache.
19.1.3. Single-ended association proxies

Lazy fetching for collections is implemented using Hibernate's own implementation of persistent collections. However, a different mechanism is needed for lazy behavior in single-ended associations. The target entity of the association must be proxied. Hibernate implements lazy initializing proxies for persistent objects using runtime bytecode enhancement (via the excellent CGLIB library).

By default, Hibernate3 generates proxies (at startup) for all persistent classes and uses them to enable lazy fetching of many-to-one and one-to-one associations.

The mapping file may declare an interface to use as the proxy interface for that class, with the proxy attribute. By default, Hibernate uses a subclass of the class. Note that the proxied class must implement a default constructor with at least package visibility. We recommend this constructor for all persistent classes!

There are some gotchas to be aware of when extending this approach to polymorphic classes, eg.

<class name="Cat" proxy="Cat">
    ......
    <subclass name="DomesticCat">
        .....
    </subclass>
</class>

Firstly, instances of Cat will never be castable to DomesticCat, even if the underlying instance is an instance of DomesticCat:

Cat cat = (Cat) session.load(Cat.class, id);  // instantiate a proxy (does not hit the db)
if ( cat.isDomesticCat() ) {                  // hit the db to initialize the proxy
    DomesticCat dc = (DomesticCat) cat;       // Error!
    ....
}

Secondly, it is possible to break proxy ==.

Cat cat = (Cat) session.load(Cat.class, id);            // instantiate a Cat proxy
DomesticCat dc = 
        (DomesticCat) session.load(DomesticCat.class, id);  // acquire new DomesticCat proxy!
System.out.println(cat==dc);                            // false

However, the situation is not quite as bad as it looks. Even though we now have two references to different proxy objects, the underlying instance will still be the same object:

cat.setWeight(11.0);  // hit the db to initialize the proxy
System.out.println( dc.getWeight() );  // 11.0

Third, you may not use a CGLIB proxy for a final class or a class with any final methods.

Finally, if your persistent object acquires any resources upon instantiation (eg. in initializers or default constructor), then those resources will also be acquired by the proxy. The proxy class is an actual subclass of the persistent class.

These problems are all due to fundamental limitations in Java's single inheritance model. If you wish to avoid these problems your persistent classes must each implement an interface that declares its business methods. You should specify these interfaces in the mapping file. eg.

<class name="CatImpl" proxy="Cat">
    ......
    <subclass name="DomesticCatImpl" proxy="DomesticCat">
        .....
    </subclass>
</class>

where CatImpl implements the interface Cat and DomesticCatImpl implements the interface DomesticCat. Then proxies for instances of Cat and DomesticCat may be returned by load() or iterate(). (Note that list() does not usually return proxies.)

Cat cat = (Cat) session.load(CatImpl.class, catid);
Iterator iter = session.iterate("from CatImpl as cat where cat.name='fritz'");
Cat fritz = (Cat) iter.next();

Relationships are also lazily initialized. This means you must declare any properties to be of type Cat, not CatImpl.

Certain operations do not require proxy initialization

    *

      equals(), if the persistent class does not override equals()
    *

      hashCode(), if the persistent class does not override hashCode()
    *

      The identifier getter method 

Hibernate will detect persistent classes that override equals() or hashCode().

By choosing lazy="no-proxy" instead of the default lazy="proxy", we can avoid the problems associated with typecasting. However, we will require buildtime bytecode instrumentation, and all operations will result in immediate proxy initialization.
19.1.4. Initializing collections and proxies

A LazyInitializationException will be thrown by Hibernate if an uninitialized collection or proxy is accessed outside of the scope of the Session, ie. when the entity owning the collection or having the reference to the proxy is in the detached state.

Sometimes we need to ensure that a proxy or collection is initialized before closing the Session. Of course, we can alway force initialization by calling cat.getSex() or cat.getKittens().size(), for example. But that is confusing to readers of the code and is not convenient for generic code.

The static methods Hibernate.initialize() and Hibernate.isInitialized() provide the application with a convenient way of working with lazily initialized collections or proxies. Hibernate.initialize(cat) will force the initialization of a proxy, cat, as long as its Session is still open. Hibernate.initialize( cat.getKittens() ) has a similar effect for the collection of kittens.

Another option is to keep the Session open until all needed collections and proxies have been loaded. In some application architectures, particularly where the code that accesses data using Hibernate, and the code that uses it are in different application layers or different physical processes, it can be a problem to ensure that the Session is open when a collection is initialized. There are two basic ways to deal with this issue:

    *

      In a web-based application, a servlet filter can be used to close the Session only at the very end of a user request, once the rendering of the view is complete (the Open Session in View pattern). Of course, this places heavy demands on the correctness of the exception handling of your application infrastructure. It is vitally important that the Session is closed and the transaction ended before returning to the user, even when an exception occurs during rendering of the view. See the Hibernate Wiki for examples of this "Open Session in View" pattern.
    *

      In an application with a separate business tier, the business logic must "prepare" all collections that will be needed by the web tier before returning. This means that the business tier should load all the data and return all the data already initialized to the presentation/web tier that is required for a particular use case. Usually, the application calls Hibernate.initialize() for each collection that will be needed in the web tier (this call must occur before the session is closed) or retrieves the collection eagerly using a Hibernate query with a FETCH clause or a FetchMode.JOIN in Criteria. This is usually easier if you adopt the Command pattern instead of a Session Facade.
    *

      You may also attach a previously loaded object to a new Session with merge() or lock() before accessing uninitialized collections (or other proxies). No, Hibernate does not, and certainly should not do this automatically, since it would introduce ad hoc transaction semantics! 

Sometimes you don't want to initialize a large collection, but still need some information about it (like its size) or a subset of the data.

You can use a collection filter to get the size of a collection without initializing it:

( (Integer) s.createFilter( collection, "select count(*)" ).list().get(0) ).intValue()

The createFilter() method is also used to efficiently retrieve subsets of a collection without needing to initialize the whole collection:

s.createFilter( lazyCollection, "").setFirstResult(0).setMaxResults(10).list();

19.1.5. Using batch fetching

Hibernate can make efficient use of batch fetching, that is, Hibernate can load several uninitialized proxies if one proxy is accessed (or collections. Batch fetching is an optimization of the lazy select fetching strategy. There are two ways you can tune batch fetching: on the class and the collection level.

Batch fetching for classes/entities is easier to understand. Imagine you have the following situation at runtime: You have 25 Cat instances loaded in a Session, each Cat has a reference to its owner, a Person. The Person class is mapped with a proxy, lazy="true". If you now iterate through all cats and call getOwner() on each, Hibernate will by default execute 25 SELECT statements, to retrieve the proxied owners. You can tune this behavior by specifying a batch-size in the mapping of Person:

<class name="Person" batch-size="10">...</class>

Hibernate will now execute only three queries, the pattern is 10, 10, 5.

You may also enable batch fetching of collections. For example, if each Person has a lazy collection of Cats, and 10 persons are currently loaded in the Sesssion, iterating through all persons will generate 10 SELECTs, one for every call to getCats(). If you enable batch fetching for the cats collection in the mapping of Person, Hibernate can pre-fetch collections:

<class name="Person">
    <set name="cats" batch-size="3">
        ...
    </set>
</class>

With a batch-size of 8, Hibernate will load 3, 3, 3, 1 collections in four SELECTs. Again, the value of the attribute depends on the expected number of uninitialized collections in a particular Session.

Batch fetching of collections is particularly useful if you have a nested tree of items, ie. the typical bill-of-materials pattern. (Although a nested set or a materialized path might be a better option for read-mostly trees.)
19.1.6. Using subselect fetching

If one lazy collection or single-valued proxy has to be fetched, Hibernate loads all of them, re-running the original query in a subselect. This works in the same way as batch-fetching, without the piecemeal loading.
19.1.7. Using lazy property fetching

Hibernate3 supports the lazy fetching of individual properties. This optimization technique is also known as fetch groups. Please note that this is mostly a marketing feature, as in practice, optimizing row reads is much more important than optimization of column reads. However, only loading some properties of a class might be useful in extreme cases, when legacy tables have hundreds of columns and the data model can not be improved.

To enable lazy property loading, set the lazy attribute on your particular property mappings:

<class name="Document">
       <id name="id">
        <generator class="native"/>
    </id>
    <property name="name" not-null="true" length="50"/>
    <property name="summary" not-null="true" length="200" lazy="true"/>
    <property name="text" not-null="true" length="2000" lazy="true"/>
</class>

Lazy property loading requires buildtime bytecode instrumentation! If your persistent classes are not enhanced, Hibernate will silently ignore lazy property settings and fall back to immediate fetching.

For bytecode instrumentation, use the following Ant task:

<target name="instrument" depends="compile">
    <taskdef name="instrument" classname="org.hibernate.tool.instrument.InstrumentTask">
        <classpath path="${jar.path}"/>
        <classpath path="${classes.dir}"/>
        <classpath refid="lib.class.path"/>
    </taskdef>

    <instrument verbose="true">
        <fileset dir="${testclasses.dir}/org/hibernate/auction/model">
            <include name="*.class"/>
        </fileset>
    </instrument>
</target>

A different (better?) way to avoid unnecessary column reads, at least for read-only transactions is to use the projection features of HQL or Criteria queries. This avoids the need for buildtime bytecode processing and is certainly a prefered solution.

You may force the usual eager fetching of properties using fetch all properties in HQL.
19.2. The Second Level Cache

A Hibernate Session is a transaction-level cache of persistent data. It is possible to configure a cluster or JVM-level (SessionFactory-level) cache on a class-by-class and collection-by-collection basis. You may even plug in a clustered cache. Be careful. Caches are never aware of changes made to the persistent store by another application (though they may be configured to regularly expire cached data).

By default, Hibernate uses EHCache for JVM-level caching. (JCS support is now deprecated and will be removed in a future version of Hibernate.) You may choose a different implementation by specifying the name of a class that implements org.hibernate.cache.CacheProvider using the property hibernate.cache.provider_class.

Table 19.1. Cache Providers
Cache	Provider class	Type	Cluster Safe	Query Cache Supported
Hashtable (not intended for production use)	org.hibernate.cache.HashtableCacheProvider	memory	 	yes
EHCache	org.hibernate.cache.EhCacheProvider	memory, disk	 	yes
OSCache	org.hibernate.cache.OSCacheProvider	memory, disk	 	yes
SwarmCache	org.hibernate.cache.SwarmCacheProvider	clustered (ip multicast)	yes (clustered invalidation)	 
JBoss TreeCache	org.hibernate.cache.TreeCacheProvider	clustered (ip multicast), transactional	yes (replication)	yes (clock sync req.)
19.2.1. Cache mappings

The <cache> element of a class or collection mapping has the following form:

<cache 
    usage="transactional|read-write|nonstrict-read-write|read-only"  (1)
    region="RegionName"                                              (2)
    include="all|non-lazy"                                           (3)
/>

(1)	

usage (required) specifies the caching strategy: transactional, read-write, nonstrict-read-write or read-only
(2)	

region (optional, defaults to the class or collection role name) specifies the name of the second level cache region
(3)	

include (optional, defaults to all) non-lazy specifies that properties of the entity mapped with lazy="true" may not be cached when attribute-level lazy fetching is enabled

Alternatively (preferrably?), you may specify <class-cache> and <collection-cache> elements in hibernate.cfg.xml.

The usage attribute specifies a cache concurrency strategy.
19.2.2. Strategy: read only

If your application needs to read but never modify instances of a persistent class, a read-only cache may be used. This is the simplest and best performing strategy. It's even perfectly safe for use in a cluster.

<class name="eg.Immutable" mutable="false">
    <cache usage="read-only"/>
    ....
</class>

19.2.3. Strategy: read/write

If the application needs to update data, a read-write cache might be appropriate. This cache strategy should never be used if serializable transaction isolation level is required. If the cache is used in a JTA environment, you must specify the property hibernate.transaction.manager_lookup_class, naming a strategy for obtaining the JTA TransactionManager. In other environments, you should ensure that the transaction is completed when Session.close() or Session.disconnect() is called. If you wish to use this strategy in a cluster, you should ensure that the underlying cache implementation supports locking. The built-in cache providers do not.

<class name="eg.Cat" .... >
    <cache usage="read-write"/>
    ....
    <set name="kittens" ... >
        <cache usage="read-write"/>
        ....
    </set>
</class>

19.2.4. Strategy: nonstrict read/write

If the application only occasionally needs to update data (ie. if it is extremely unlikely that two transactions would try to update the same item simultaneously) and strict transaction isolation is not required, a nonstrict-read-write cache might be appropriate. If the cache is used in a JTA environment, you must specify hibernate.transaction.manager_lookup_class. In other environments, you should ensure that the transaction is completed when Session.close() or Session.disconnect() is called.
19.2.5. Strategy: transactional

The transactional cache strategy provides support for fully transactional cache providers such as JBoss TreeCache. Such a cache may only be used in a JTA environment and you must specify hibernate.transaction.manager_lookup_class.

None of the cache providers support all of the cache concurrency strategies. The following table shows which providers are compatible with which concurrency strategies.

Table 19.2. Cache Concurrency Strategy Support
Cache	read-only	nonstrict-read-write	read-write	transactional
Hashtable (not intended for production use)	yes	yes	yes	 
EHCache	yes	yes	yes	 
OSCache	yes	yes	yes	 
SwarmCache	yes	yes	 	 
JBoss TreeCache	yes	 	 	yes
19.3. Managing the caches

Whenever you pass an object to save(), update() or saveOrUpdate() and whenever you retrieve an object using load(), get(), list(), iterate() or scroll(), that object is added to the internal cache of the Session.

When flush() is subsequently called, the state of that object will be synchronized with the database. If you do not want this synchronization to occur or if you are processing a huge number of objects and need to manage memory efficiently, the evict() method may be used to remove the object and its collections from the first-level cache.

ScrollableResult cats = sess.createQuery("from Cat as cat").scroll(); //a huge result set
while ( cats.next() ) {
    Cat cat = (Cat) cats.get(0);
    doSomethingWithACat(cat);
    sess.evict(cat);
}

The Session also provides a contains() method to determine if an instance belongs to the session cache.

To completely evict all objects from the session cache, call Session.clear()

For the second-level cache, there are methods defined on SessionFactory for evicting the cached state of an instance, entire class, collection instance or entire collection role.

sessionFactory.evict(Cat.class, catId); //evict a particular Cat
sessionFactory.evict(Cat.class);  //evict all Cats
sessionFactory.evictCollection("Cat.kittens", catId); //evict a particular collection of kittens
sessionFactory.evictCollection("Cat.kittens"); //evict all kitten collections

The CacheMode controls how a particular session interacts with the second-level cache.

    *

      CacheMode.NORMAL - read items from and write items to the second-level cache
    *

      CacheMode.GET - read items from the second-level cache, but don't write to the second-level cache except when updating data
    *

      CacheMode.PUT - write items to the second-level cache, but don't read from the second-level cache
    *

      CacheMode.REFRESH - write items to the second-level cache, but don't read from the second-level cache, bypass the effect of hibernate.cache.use_minimal_puts, forcing a refresh of the second-level cache for all items read from the database 

To browse the contents of a second-level or query cache region, use the Statistics API:

Map cacheEntries = sessionFactory.getStatistics()
        .getSecondLevelCacheStatistics(regionName)
        .getEntries();

You'll need to enable statistics, and, optionally, force Hibernate to keep the cache entries in a more human-understandable format:

hibernate.generate_statistics true
hibernate.cache.use_structured_entries true

19.4. The Query Cache

Query result sets may also be cached. This is only useful for queries that are run frequently with the same parameters. To use the query cache you must first enable it:

hibernate.cache.use_query_cache true

This setting causes the creation of two new cache regions - one holding cached query result sets (org.hibernate.cache.StandardQueryCache), the other holding timestamps of the most recent updates to queryable tables (org.hibernate.cache.UpdateTimestampsCache). Note that the query cache does not cache the state of the actual entities in the result set; it caches only identifier values and results of value type. So the query cache should always be used in conjunction with the second-level cache.

Most queries do not benefit from caching, so by default queries are not cached. To enable caching, call Query.setCacheable(true). This call allows the query to look for existing cache results or add its results to the cache when it is executed.

If you require fine-grained control over query cache expiration policies, you may specify a named cache region for a particular query by calling Query.setCacheRegion().

List blogs = sess.createQuery("from Blog blog where blog.blogger = :blogger")
    .setEntity("blogger", blogger)
    .setMaxResults(15)
    .setCacheable(true)
    .setCacheRegion("frontpages")
    .list();

If the query should force a refresh of its query cache region, you should call Query.setCacheMode(CacheMode.REFRESH). This is particularly useful in cases where underlying data may have been updated via a separate process (i.e., not modified through Hibernate) and allows the application to selectively refresh particular query result sets. This is a more efficient alternative to eviction of a query cache region via SessionFactory.evictQueries().
19.5. Understanding Collection performance

We've already spent quite some time talking about collections. In this section we will highlight a couple more issues about how collections behave at runtime.
19.5.1. Taxonomy

Hibernate defines three basic kinds of collections:

    *

      collections of values
    *

      one to many associations
    *

      many to many associations

This classification distinguishes the various table and foreign key relationships but does not tell us quite everything we need to know about the relational model. To fully understand the relational structure and performance characteristics, we must also consider the structure of the primary key that is used by Hibernate to update or delete collection rows. This suggests the following classification:

    *

      indexed collections
    *

      sets
    *

      bags

All indexed collections (maps, lists, arrays) have a primary key consisting of the <key> and <index> columns. In this case collection updates are usually extremely efficient - the primary key may be efficiently indexed and a particular row may be efficiently located when Hibernate tries to update or delete it.

Sets have a primary key consisting of <key> and element columns. This may be less efficient for some types of collection element, particularly composite elements or large text or binary fields; the database may not be able to index a complex primary key as efficently. On the other hand, for one to many or many to many associations, particularly in the case of synthetic identifiers, it is likely to be just as efficient. (Side-note: if you want SchemaExport to actually create the primary key of a <set> for you, you must declare all columns as not-null="true".)

<idbag> mappings define a surrogate key, so they are always very efficient to update. In fact, they are the best case.

Bags are the worst case. Since a bag permits duplicate element values and has no index column, no primary key may be defined. Hibernate has no way of distinguishing between duplicate rows. Hibernate resolves this problem by completely removing (in a single DELETE) and recreating the collection whenever it changes. This might be very inefficient.

Note that for a one-to-many association, the "primary key" may not be the physical primary key of the database table - but even in this case, the above classification is still useful. (It still reflects how Hibernate "locates" individual rows of the collection.)
19.5.2. Lists, maps, idbags and sets are the most efficient collections to update

From the discussion above, it should be clear that indexed collections and (usually) sets allow the most efficient operation in terms of adding, removing and updating elements.

There is, arguably, one more advantage that indexed collections have over sets for many to many associations or collections of values. Because of the structure of a Set, Hibernate doesn't ever UPDATE a row when an element is "changed". Changes to a Set always work via INSERT and DELETE (of individual rows). Once again, this consideration does not apply to one to many associations.

After observing that arrays cannot be lazy, we would conclude that lists, maps and idbags are the most performant (non-inverse) collection types, with sets not far behind. Sets are expected to be the most common kind of collection in Hibernate applications. This is because the "set" semantics are most natural in the relational model.

However, in well-designed Hibernate domain models, we usually see that most collections are in fact one-to-many associations with inverse="true". For these associations, the update is handled by the many-to-one end of the association, and so considerations of collection update performance simply do not apply.
19.5.3. Bags and lists are the most efficient inverse collections

Just before you ditch bags forever, there is a particular case in which bags (and also lists) are much more performant than sets. For a collection with inverse="true" (the standard bidirectional one-to-many relationship idiom, for example) we can add elements to a bag or list without needing to initialize (fetch) the bag elements! This is because Collection.add() or Collection.addAll() must always return true for a bag or List (unlike a Set). This can make the following common code much faster.

Parent p = (Parent) sess.load(Parent.class, id);
Child c = new Child();
c.setParent(p);
p.getChildren().add(c);  //no need to fetch the collection!
sess.flush();

19.5.4. One shot delete

Occasionally, deleting collection elements one by one can be extremely inefficient. Hibernate isn't completely stupid, so it knows not to do that in the case of an newly-empty collection (if you called list.clear(), for example). In this case, Hibernate will issue a single DELETE and we are done!

Suppose we add a single element to a collection of size twenty and then remove two elements. Hibernate will issue one INSERT statement and two DELETE statements (unless the collection is a bag). This is certainly desirable.

However, suppose that we remove eighteen elements, leaving two and then add thee new elements. There are two possible ways to proceed

    *

      delete eighteen rows one by one and then insert three rows
    *

      remove the whole collection (in one SQL DELETE) and insert all five current elements (one by one)

Hibernate isn't smart enough to know that the second option is probably quicker in this case. (And it would probably be undesirable for Hibernate to be that smart; such behaviour might confuse database triggers, etc.)

Fortunately, you can force this behaviour (ie. the second strategy) at any time by discarding (ie. dereferencing) the original collection and returning a newly instantiated collection with all the current elements. This can be very useful and powerful from time to time.

Of course, one-shot-delete does not apply to collections mapped inverse="true".
19.6. Monitoring performance

Optimization is not much use without monitoring and access to performance numbers. Hibernate provides a full range of figures about its internal operations. Statistics in Hibernate are available per SessionFactory.
19.6.1. Monitoring a SessionFactory

You can access SessionFactory metrics in two ways. Your first option is to call sessionFactory.getStatistics() and read or display the Statistics yourself.

Hibernate can also use JMX to publish metrics if you enable the StatisticsService MBean. You may enable a single MBean for all your SessionFactory or one per factory. See the following code for minimalistic configuration examples:

// MBean service registration for a specific SessionFactory
Hashtable tb = new Hashtable();
tb.put("type", "statistics");
tb.put("sessionFactory", "myFinancialApp");
ObjectName on = new ObjectName("hibernate", tb); // MBean object name

StatisticsService stats = new StatisticsService(); // MBean implementation
stats.setSessionFactory(sessionFactory); // Bind the stats to a SessionFactory
server.registerMBean(stats, on); // Register the Mbean on the server

// MBean service registration for all SessionFactory's
Hashtable tb = new Hashtable();
tb.put("type", "statistics");
tb.put("sessionFactory", "all");
ObjectName on = new ObjectName("hibernate", tb); // MBean object name

StatisticsService stats = new StatisticsService(); // MBean implementation
server.registerMBean(stats, on); // Register the MBean on the server

TODO: This doesn't make sense: In the first case, we retrieve and use the MBean directly. In the second one, we must give the JNDI name in which the session factory is held before using it. Use hibernateStatsBean.setSessionFactoryJNDIName("my/JNDI/Name")

You can (de)activate the monitoring for a SessionFactory

    *

      at configuration time, set hibernate.generate_statistics to false 

    *

      at runtime: sf.getStatistics().setStatisticsEnabled(true) or hibernateStatsBean.setStatisticsEnabled(true) 

Statistics can be reset programatically using the clear() method. A summary can be sent to a logger (info level) using the logSummary() method.
19.6.2. Metrics

Hibernate provides a number of metrics, from very basic to the specialized information only relevant in certain scenarios. All available counters are described in the Statistics interface API, in three categories:

    *

      Metrics related to the general Session usage, such as number of open sessions, retrieved JDBC connections, etc.
    *

      Metrics related to he entities, collections, queries, and caches as a whole (aka global metrics),
    *

      Detailed metrics related to a particular entity, collection, query or cache region. 

For exampl,e you can check the cache hit, miss, and put ratio of entities, collections and queries, and the average time a query needs. Beware that the number of milliseconds is subject to approximation in Java. Hibernate is tied to the JVM precision, on some platforms this might even only be accurate to 10 seconds.

Simple getters are used to access the global metrics (i.e. not tied to a particular entity, collection, cache region, etc.). You can access the metrics of a particular entity, collection or cache region through its name, and through its HQL or SQL representation for queries. Please refer to the Statistics, EntityStatistics, CollectionStatistics, SecondLevelCacheStatistics, and QueryStatistics API Javadoc for more information. The following code shows a simple example:

Statistics stats = HibernateUtil.sessionFactory.getStatistics();

double queryCacheHitCount  = stats.getQueryCacheHitCount();
double queryCacheMissCount = stats.getQueryCacheMissCount();
double queryCacheHitRatio =
  queryCacheHitCount / (queryCacheHitCount + queryCacheMissCount);

log.info("Query Hit ratio:" + queryCacheHitRatio);

EntityStatistics entityStats =
  stats.getEntityStatistics( Cat.class.getName() );
long changes =
        entityStats.getInsertCount()
        + entityStats.getUpdateCount()
        + entityStats.getDeleteCount();
log.info(Cat.class.getName() + " changed " + changes + "times"  );

To work on all entities, collections, queries and region caches, you can retrieve the list of names of entities, collections, queries and region caches with the following methods: getQueries(), getEntityNames(), getCollectionRoleNames(), and getSecondLevelCacheRegionNames().
Chapter 20. Toolset Guide

Roundtrip engineering with Hibernate is possible using a set of Eclipse plugins, commandline tools, as well as Ant tasks.

The Hibernate Tools currently include plugins for the Eclipse IDE as well as Ant tasks for reverse engineering of existing databases:

    *

      Mapping Editor: An editor for Hibernate XML mapping files, supporting auto-completion and syntax highlighting. It also supports semantic auto-completion for class names and property/field names, making it much more versatile than a normal XML editor.
    *

      Console: The console is a new view in Eclipse. In addition to a tree overview of your console configurations, you also get an interactive view of your persistent classes and their relationships. The console allows you to execute HQL queries against your database and browse the result directly in Eclipse.
    *

      Development Wizards: Several wizards are provided with the Hibernate Eclipse tools; you can use a wizard to quickly generate Hibernate configuration (cfg.xml) files, or you may even completely reverse engineer an existing database schema into POJO source files and Hibernate mapping files. The reverse engineering wizard supports customizable templates.
    *

      Ant Tasks: 

Please refer to the Hibernate Tools package and it's documentation for more information.

However, the Hibernate main package comes bundled with an integrated tool (it can even be used from "inside" Hibernate on-the-fly): SchemaExport aka hbm2ddl.
20.1. Automatic schema generation

DDL may be generated from your mapping files by a Hibernate utility. The generated schema includes referential integrity constraints (primary and foreign keys) for entity and collection tables. Tables and sequences are also created for mapped identifier generators.

You must specify a SQL Dialect via the hibernate.dialect property when using this tool, as DDL is highly vendor specific.

First, customize your mapping files to improve the generated schema.
20.1.1. Customizing the schema

Many Hibernate mapping elements define optional attributes named length, precision and scale. You may set the length, precision and scale of a column with this attribute.

<property name="zip" length="5"/>

<property name="balance" precision="12" scale="2"/>

Some tags also accept a not-null attribute (for generating a NOT NULL constraint on table columns) and a unique attribute (for generating UNIQUE constraint on table columns).

<many-to-one name="bar" column="barId" not-null="true"/>

<element column="serialNumber" type="long" not-null="true" unique="true"/>

A unique-key attribute may be used to group columns in a single unique key constraint. Currently, the specified value of the unique-key attribute is not used to name the constraint in the generated DDL, only to group the columns in the mapping file.

<many-to-one name="org" column="orgId" unique-key="OrgEmployeeId"/>

<property name="employeeId" unique-key="OrgEmployee"/>

An index attribute specifies the name of an index that will be created using the mapped column or columns. Multiple columns may be grouped into the same index, simply by specifying the same index name.

<property name="lastName" index="CustName"/>

<property name="firstName" index="CustName"/>

A foreign-key attribute may be used to override the name of any generated foreign key constraint.

<many-to-one name="bar" column="barId" foreign-key="FKFooBar"/>

Many mapping elements also accept a child <column> element. This is particularly useful for mapping multi-column types:

<property name="name" type="my.customtypes.Name"/>
    <column name="last" not-null="true" index="bar_idx" length="30"/>
    <column name="first" not-null="true" index="bar_idx" length="20"/>
    <column name="initial"/>
</property>

The default attribute lets you specify a default value for a column (you should assign the same value to the mapped property before saving a new instance of the mapped class).

<property name="credits" type="integer" insert="false">

    <column name="credits" default="10"/>

</property>

<version name="version" type="integer" insert="false">

    <column name="version" default="0"/>

</property>

The sql-type attribute allows the user to override the default mapping of a Hibernate type to SQL datatype.

<property name="balance" type="float">

    <column name="balance" sql-type="decimal(13,3)"/>

</property>

The check attribute allows you to specify a check constraint.

<property name="foo" type="integer">
    <column name="foo" check="foo > 10"/>
</property>

<class name="Foo" table="foos" check="bar < 100.0">
    ...
    <property name="bar" type="float"/>
</class>

Table 20.1. Summary
Attribute	Values	Interpretation
length	number	column length
precision	number	column decimal precision
scale	number	column decimal scale
not-null	true|false	specfies that the column should be non-nullable
unique	true|false	specifies that the column should have a unique constraint
index	index_name	specifies the name of a (multi-column) index
unique-key	unique_key_name	specifies the name of a multi-column unique constraint
foreign-key	foreign_key_name	specifies the name of the foreign key constraint generated for an association, for a <one-to-one>, <many-to-one>, <key>, or <many-to-many> mapping element. Note that inverse="true" sides will not be considered by SchemaExport.
sql-type	SQL column type	overrides the default column type (attribute of <column> element only)
default	SQL expression	specify a default value for the column
check	SQL expression	create an SQL check constraint on either column or table

The <comment> element allows you to specify comments for the generated schema.

<class name="Customer" table="CurCust">
    <comment>Current customers only</comment>
    ...
</class>

<property name="balance">
    <column name="bal">
        <comment>Balance in USD</comment>
    </column>
</property>

This results in a comment on table or comment on column statement in the generated DDL (where supported).
20.1.2. Running the tool

The SchemaExport tool writes a DDL script to standard out and/or executes the DDL statements.

java -cp hibernate_classpaths org.hibernate.tool.hbm2ddl.SchemaExport options mapping_files

Table 20.2. SchemaExport Command Line Options
Option	Description
--quiet	don't output the script to stdout
--drop	only drop the tables
--create	only create the tables
--text	don't export to the database
--output=my_schema.ddl	output the ddl script to a file
--naming=eg.MyNamingStrategy	select a NamingStrategy
--config=hibernate.cfg.xml	read Hibernate configuration from an XML file
--properties=hibernate.properties	read database properties from a file
--format	format the generated SQL nicely in the script
--delimiter=;	set an end of line delimiter for the script

You may even embed SchemaExport in your application:

Configuration cfg = ....;
new SchemaExport(cfg).create(false, true);

20.1.3. Properties

Database properties may be specified

    *

      as system properties with -D<property>
    *

      in hibernate.properties
    *

      in a named properties file with --properties

The needed properties are:

Table 20.3. SchemaExport Connection Properties
Property Name	Description
hibernate.connection.driver_class	jdbc driver class
hibernate.connection.url	jdbc url
hibernate.connection.username	database user
hibernate.connection.password	user password
hibernate.dialect	dialect
20.1.4. Using Ant

You can call SchemaExport from your Ant build script:

<target name="schemaexport">
    <taskdef name="schemaexport"
        classname="org.hibernate.tool.hbm2ddl.SchemaExportTask"
        classpathref="class.path"/>
    
    <schemaexport
        properties="hibernate.properties"
        quiet="no"
        text="no"
        drop="no"
        delimiter=";"
        output="schema-export.sql">
        <fileset dir="src">
            <include name="**/*.hbm.xml"/>
        </fileset>
    </schemaexport>
</target>

20.1.5. Incremental schema updates

The SchemaUpdate tool will update an existing schema with "incremental" changes. Note that SchemaUpdate depends heavily upon the JDBC metadata API, so it will not work with all JDBC drivers.

java -cp hibernate_classpaths org.hibernate.tool.hbm2ddl.SchemaUpdate options mapping_files

Table 20.4. SchemaUpdate Command Line Options
Option	Description
--quiet	don't output the script to stdout
--text	don't export the script to the database
--naming=eg.MyNamingStrategy	select a NamingStrategy
--properties=hibernate.properties	read database properties from a file
--config=hibernate.cfg.xml	specify a .cfg.xml file

You may embed SchemaUpdate in your application:

Configuration cfg = ....;
new SchemaUpdate(cfg).execute(false);

20.1.6. Using Ant for incremental schema updates

You can call SchemaUpdate from the Ant script:

<target name="schemaupdate">
    <taskdef name="schemaupdate"
        classname="org.hibernate.tool.hbm2ddl.SchemaUpdateTask"
        classpathref="class.path"/>
    
    <schemaupdate
        properties="hibernate.properties"
        quiet="no">
        <fileset dir="src">
            <include name="**/*.hbm.xml"/>
        </fileset>
    </schemaupdate>
</target>

20.1.7. Schema validation

The SchemaValidator tool will validate that the existing database schema "matches" your mapping documents. Note that SchemaValidator depends heavily upon the JDBC metadata API, so it will not work with all JDBC drivers. This tool is extremely useful for testing.

java -cp hibernate_classpaths org.hibernate.tool.hbm2ddl.SchemaValidator options mapping_files

Table 20.5. SchemaValidator Command Line Options
Option	Description
--naming=eg.MyNamingStrategy	select a NamingStrategy
--properties=hibernate.properties	read database properties from a file
--config=hibernate.cfg.xml	specify a .cfg.xml file

You may embed SchemaValidator in your application:

Configuration cfg = ....;

new SchemaValidator(cfg).validate();

20.1.8. Using Ant for schema validation

You can call SchemaValidator from the Ant script:

<target name="schemavalidate">

    <taskdef name="schemavalidator"

        classname="org.hibernate.tool.hbm2ddl.SchemaValidatorTask"

        classpathref="class.path"/>

    

    <schemavalidator

        properties="hibernate.properties">

        <fileset dir="src">

            <include name="**/*.hbm.xml"/>

        </fileset>

    </schemaupdate>

</target>

Chapter 21. Example: Parent/Child

One of the very first things that new users try to do with Hibernate is to model a parent / child type relationship. There are two different approaches to this. For various reasons the most convenient approach, especially for new users, is to model both Parent and Child as entity classes with a <one-to-many> association from Parent to Child. (The alternative approach is to declare the Child as a <composite-element>.) Now, it turns out that default semantics of a one to many association (in Hibernate) are much less close to the usual semantics of a parent / child relationship than those of a composite element mapping. We will explain how to use a bidirectional one to many association with cascades to model a parent / child relationship efficiently and elegantly. It's not at all difficult!
21.1. A note about collections

Hibernate collections are considered to be a logical part of their owning entity; never of the contained entities. This is a crucial distinction! It has the following consequences:

    *

      When we remove / add an object from / to a collection, the version number of the collection owner is incremented.
    *

      If an object that was removed from a collection is an instance of a value type (eg, a composite element), that object will cease to be persistent and its state will be completely removed from the database. Likewise, adding a value type instance to the collection will cause its state to be immediately persistent.
    *

      On the other hand, if an entity is removed from a collection (a one-to-many or many-to-many association), it will not be deleted, by default. This behaviour is completely consistent - a change to the internal state of another entity should not cause the associated entity to vanish! Likewise, adding an entity to a collection does not cause that entity to become persistent, by default. 

Instead, the default behaviour is that adding an entity to a collection merely creates a link between the two entities, while removing it removes the link. This is very appropriate for all sorts of cases. Where it is not appropriate at all is the case of a parent / child relationship, where the life of the child is bound to the lifecycle of the parent.
21.2. Bidirectional one-to-many

Suppose we start with a simple <one-to-many> association from Parent to Child.

<set name="children">
    <key column="parent_id"/>
    <one-to-many class="Child"/>
</set>

If we were to execute the following code

Parent p = .....;
Child c = new Child();
p.getChildren().add(c);
session.save(c);
session.flush();

Hibernate would issue two SQL statements:

    *

      an INSERT to create the record for c
    *

      an UPDATE to create the link from p to c 

This is not only inefficient, but also violates any NOT NULL constraint on the parent_id column. We can fix the nullability constraint violation by specifying not-null="true" in the collection mapping:

<set name="children">
    <key column="parent_id" not-null="true"/>
    <one-to-many class="Child"/>
</set>

However, this is not the recommended solution.

The underlying cause of this behaviour is that the link (the foreign key parent_id) from p to c is not considered part of the state of the Child object and is therefore not created in the INSERT. So the solution is to make the link part of the Child mapping.

<many-to-one name="parent" column="parent_id" not-null="true"/>

(We also need to add the parent property to the Child class.)

Now that the Child entity is managing the state of the link, we tell the collection not to update the link. We use the inverse attribute.

<set name="children" inverse="true">
    <key column="parent_id"/>
    <one-to-many class="Child"/>
</set>

The following code would be used to add a new Child

Parent p = (Parent) session.load(Parent.class, pid);
Child c = new Child();
c.setParent(p);
p.getChildren().add(c);
session.save(c);
session.flush();

And now, only one SQL INSERT would be issued!

To tighten things up a bit, we could create an addChild() method of Parent.

public void addChild(Child c) {
    c.setParent(this);
    children.add(c);
}

Now, the code to add a Child looks like

Parent p = (Parent) session.load(Parent.class, pid);
Child c = new Child();
p.addChild(c);
session.save(c);
session.flush();

21.3. Cascading lifecycle

The explicit call to save() is still annoying. We will address this by using cascades.

<set name="children" inverse="true" cascade="all">
    <key column="parent_id"/>
    <one-to-many class="Child"/>
</set>

This simplifies the code above to

Parent p = (Parent) session.load(Parent.class, pid);
Child c = new Child();
p.addChild(c);
session.flush();

Similarly, we don't need to iterate over the children when saving or deleting a Parent. The following removes p and all its children from the database.

Parent p = (Parent) session.load(Parent.class, pid);
session.delete(p);
session.flush();

However, this code

Parent p = (Parent) session.load(Parent.class, pid);
Child c = (Child) p.getChildren().iterator().next();
p.getChildren().remove(c);
c.setParent(null);
session.flush();

will not remove c from the database; it will ony remove the link to p (and cause a NOT NULL constraint violation, in this case). You need to explicitly delete() the Child.

Parent p = (Parent) session.load(Parent.class, pid);
Child c = (Child) p.getChildren().iterator().next();
p.getChildren().remove(c);
session.delete(c);
session.flush();

Now, in our case, a Child can't really exist without its parent. So if we remove a Child from the collection, we really do want it to be deleted. For this, we must use cascade="all-delete-orphan".

<set name="children" inverse="true" cascade="all-delete-orphan">
    <key column="parent_id"/>
    <one-to-many class="Child"/>
</set>

Note: even though the collection mapping specifies inverse="true", cascades are still processed by iterating the collection elements. So if you require that an object be saved, deleted or updated by cascade, you must add it to the collection. It is not enough to simply call setParent().
21.4. Cascades and unsaved-value

Suppose we loaded up a Parent in one Session, made some changes in a UI action and wish to persist these changes in a new session by calling update(). The Parent will contain a collection of childen and, since cascading update is enabled, Hibernate needs to know which children are newly instantiated and which represent existing rows in the database. Lets assume that both Parent and Child have genenerated identifier properties of type Long. Hibernate will use the identifier and version/timestamp property value to determine which of the children are new. (See Section 10.7, ?Automatic state detection?.) In Hibernate3, it is no longer necessary to specify an unsaved-value explicitly.

The following code will update parent and child and insert newChild.

//parent and child were both loaded in a previous session
parent.addChild(child);
Child newChild = new Child();
parent.addChild(newChild);
session.update(parent);
session.flush();

Well, that's all very well for the case of a generated identifier, but what about assigned identifiers and composite identifiers? This is more difficult, since Hibernate can't use the identifier property to distinguish between a newly instantiated object (with an identifier assigned by the user) and an object loaded in a previous session. In this case, Hibernate will either use the timestamp or version property, or will actually query the second-level cache or, worst case, the database, to see if the row exists.
21.5. Conclusion

There is quite a bit to digest here and it might look confusing first time around. However, in practice, it all works out very nicely. Most Hibernate applications use the parent / child pattern in many places.

We mentioned an alternative in the first paragraph. None of the above issues exist in the case of <composite-element> mappings, which have exactly the semantics of a parent / child relationship. Unfortunately, there are two big limitations to composite element classes: composite elements may not own collections, and they should not be the child of any entity other than the unique parent.
Chapter 22. Example: Weblog Application
22.1. Persistent Classes

The persistent classes represent a weblog, and an item posted in a weblog. They are to be modelled as a standard parent/child relationship, but we will use an ordered bag, instead of a set.

package eg;

import java.util.List;

public class Blog {
    private Long _id;
    private String _name;
    private List _items;

    public Long getId() {
        return _id;
    }
    public List getItems() {
        return _items;
    }
    public String getName() {
        return _name;
    }
    public void setId(Long long1) {
        _id = long1;
    }
    public void setItems(List list) {
        _items = list;
    }
    public void setName(String string) {
        _name = string;
    }
}

package eg;

import java.text.DateFormat;
import java.util.Calendar;

public class BlogItem {
    private Long _id;
    private Calendar _datetime;
    private String _text;
    private String _title;
    private Blog _blog;

    public Blog getBlog() {
        return _blog;
    }
    public Calendar getDatetime() {
        return _datetime;
    }
    public Long getId() {
        return _id;
    }
    public String getText() {
        return _text;
    }
    public String getTitle() {
        return _title;
    }
    public void setBlog(Blog blog) {
        _blog = blog;
    }
    public void setDatetime(Calendar calendar) {
        _datetime = calendar;
    }
    public void setId(Long long1) {
        _id = long1;
    }
    public void setText(String string) {
        _text = string;
    }
    public void setTitle(String string) {
        _title = string;
    }
}

22.2. Hibernate Mappings

The XML mappings should now be quite straightforward.

<?xml version="1.0"?>
<!DOCTYPE hibernate-mapping PUBLIC
    "-//Hibernate/Hibernate Mapping DTD 3.0//EN"
    "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd">

<hibernate-mapping package="eg">

    <class
        name="Blog"
        table="BLOGS">

        <id
            name="id"
            column="BLOG_ID">

            <generator class="native"/>

        </id>

        <property
            name="name"
            column="NAME"
            not-null="true"
            unique="true"/>

        <bag
            name="items"
            inverse="true"
            order-by="DATE_TIME"
            cascade="all">

            <key column="BLOG_ID"/>
            <one-to-many class="BlogItem"/>

        </bag>

    </class>

</hibernate-mapping>

<?xml version="1.0"?>
<!DOCTYPE hibernate-mapping PUBLIC
    "-//Hibernate/Hibernate Mapping DTD 3.0//EN"
    "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd">

<hibernate-mapping package="eg">

    <class
        name="BlogItem"
        table="BLOG_ITEMS"
        dynamic-update="true">

        <id
            name="id"
            column="BLOG_ITEM_ID">

            <generator class="native"/>

        </id>

        <property
            name="title"
            column="TITLE"
            not-null="true"/>

        <property
            name="text"
            column="TEXT"
            not-null="true"/>

        <property
            name="datetime"
            column="DATE_TIME"
            not-null="true"/>

        <many-to-one
            name="blog"
            column="BLOG_ID"
            not-null="true"/>

    </class>

</hibernate-mapping>

22.3. Hibernate Code

The following class demonstrates some of the kinds of things we can do with these classes, using Hibernate.

package eg;

import java.util.ArrayList;
import java.util.Calendar;
import java.util.Iterator;
import java.util.List;

import org.hibernate.HibernateException;
import org.hibernate.Query;
import org.hibernate.Session;
import org.hibernate.SessionFactory;
import org.hibernate.Transaction;
import org.hibernate.cfg.Configuration;
import org.hibernate.tool.hbm2ddl.SchemaExport;

public class BlogMain {
    
    private SessionFactory _sessions;
    
    public void configure() throws HibernateException {
        _sessions = new Configuration()
            .addClass(Blog.class)
            .addClass(BlogItem.class)
            .buildSessionFactory();
    }
    
    public void exportTables() throws HibernateException {
        Configuration cfg = new Configuration()
            .addClass(Blog.class)
            .addClass(BlogItem.class);
        new SchemaExport(cfg).create(true, true);
    }
    
    public Blog createBlog(String name) throws HibernateException {
        
        Blog blog = new Blog();
        blog.setName(name);
        blog.setItems( new ArrayList() );
        
        Session session = _sessions.openSession();
        Transaction tx = null;
        try {
            tx = session.beginTransaction();
            session.persist(blog);
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
        return blog;
    }
    
    public BlogItem createBlogItem(Blog blog, String title, String text)
                        throws HibernateException {
        
        BlogItem item = new BlogItem();
        item.setTitle(title);
        item.setText(text);
        item.setBlog(blog);
        item.setDatetime( Calendar.getInstance() );
        blog.getItems().add(item);
        
        Session session = _sessions.openSession();
        Transaction tx = null;
        try {
            tx = session.beginTransaction();
            session.update(blog);
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
        return item;
    }
    
    public BlogItem createBlogItem(Long blogid, String title, String text)
                        throws HibernateException {
        
        BlogItem item = new BlogItem();
        item.setTitle(title);
        item.setText(text);
        item.setDatetime( Calendar.getInstance() );
        
        Session session = _sessions.openSession();
        Transaction tx = null;
        try {
            tx = session.beginTransaction();
            Blog blog = (Blog) session.load(Blog.class, blogid);
            item.setBlog(blog);
            blog.getItems().add(item);
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
        return item;
    }
    
    public void updateBlogItem(BlogItem item, String text)
                    throws HibernateException {
        
        item.setText(text);
        
        Session session = _sessions.openSession();
        Transaction tx = null;
        try {
            tx = session.beginTransaction();
            session.update(item);
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
    }
    
    public void updateBlogItem(Long itemid, String text)
                    throws HibernateException {
    
        Session session = _sessions.openSession();
        Transaction tx = null;
        try {
            tx = session.beginTransaction();
            BlogItem item = (BlogItem) session.load(BlogItem.class, itemid);
            item.setText(text);
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
    }
    
    public List listAllBlogNamesAndItemCounts(int max)
                    throws HibernateException {
        
        Session session = _sessions.openSession();
        Transaction tx = null;
        List result = null;
        try {
            tx = session.beginTransaction();
            Query q = session.createQuery(
                "select blog.id, blog.name, count(blogItem) " +
                "from Blog as blog " +
                "left outer join blog.items as blogItem " +
                "group by blog.name, blog.id " +
                "order by max(blogItem.datetime)"
            );
            q.setMaxResults(max);
            result = q.list();
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
        return result;
    }
    
    public Blog getBlogAndAllItems(Long blogid)
                    throws HibernateException {
        
        Session session = _sessions.openSession();
        Transaction tx = null;
        Blog blog = null;
        try {
            tx = session.beginTransaction();
            Query q = session.createQuery(
                "from Blog as blog " +
                "left outer join fetch blog.items " +
                "where blog.id = :blogid"
            );
            q.setParameter("blogid", blogid);
            blog  = (Blog) q.uniqueResult();
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
        return blog;
    }
    
    public List listBlogsAndRecentItems() throws HibernateException {
        
        Session session = _sessions.openSession();
        Transaction tx = null;
        List result = null;
        try {
            tx = session.beginTransaction();
            Query q = session.createQuery(
                "from Blog as blog " +
                "inner join blog.items as blogItem " +
                "where blogItem.datetime > :minDate"
            );

            Calendar cal = Calendar.getInstance();
            cal.roll(Calendar.MONTH, false);
            q.setCalendar("minDate", cal);
            
            result = q.list();
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
        return result;
    }
}

Chapter 23. Example: Various Mappings

This chapters shows off some more complex association mappings.
23.1. Employer/Employee

The following model of the relationship between Employer and Employee uses an actual entity class (Employment) to represent the association. This is done because there might be more than one period of employment for the same two parties. Components are used to model monetary values and employee names.

Heres a possible mapping document:

<hibernate-mapping>
        
    <class name="Employer" table="employers">
        <id name="id">
            <generator class="sequence">
                <param name="sequence">employer_id_seq</param>
            </generator>
        </id>
        <property name="name"/>
    </class>

    <class name="Employment" table="employment_periods">

        <id name="id">
            <generator class="sequence">
                <param name="sequence">employment_id_seq</param>
            </generator>
        </id>
        <property name="startDate" column="start_date"/>
        <property name="endDate" column="end_date"/>

        <component name="hourlyRate" class="MonetaryAmount">
            <property name="amount">
                <column name="hourly_rate" sql-type="NUMERIC(12, 2)"/>
            </property>
            <property name="currency" length="12"/>
        </component>

        <many-to-one name="employer" column="employer_id" not-null="true"/>
        <many-to-one name="employee" column="employee_id" not-null="true"/>

    </class>

    <class name="Employee" table="employees">
        <id name="id">
            <generator class="sequence">
                <param name="sequence">employee_id_seq</param>
            </generator>
        </id>
        <property name="taxfileNumber"/>
        <component name="name" class="Name">
            <property name="firstName"/>
            <property name="initial"/>
            <property name="lastName"/>
        </component>
    </class>

</hibernate-mapping>

And heres the table schema generated by SchemaExport.

create table employers (
    id BIGINT not null, 
    name VARCHAR(255), 
    primary key (id)
)

create table employment_periods (
    id BIGINT not null,
    hourly_rate NUMERIC(12, 2),
    currency VARCHAR(12), 
    employee_id BIGINT not null, 
    employer_id BIGINT not null, 
    end_date TIMESTAMP, 
    start_date TIMESTAMP, 
    primary key (id)
)

create table employees (
    id BIGINT not null, 
    firstName VARCHAR(255), 
    initial CHAR(1), 
    lastName VARCHAR(255), 
    taxfileNumber VARCHAR(255), 
    primary key (id)
)

alter table employment_periods 
    add constraint employment_periodsFK0 foreign key (employer_id) references employers
alter table employment_periods 
    add constraint employment_periodsFK1 foreign key (employee_id) references employees
create sequence employee_id_seq
create sequence employment_id_seq
create sequence employer_id_seq

23.2. Author/Work

Consider the following model of the relationships between Work, Author and Person. We represent the relationship between Work and Author as a many-to-many association. We choose to represent the relationship between Author and Person as one-to-one association. Another possibility would be to have Author extend Person.

The following mapping document correctly represents these relationships:

<hibernate-mapping>

    <class name="Work" table="works" discriminator-value="W">

        <id name="id" column="id">
            <generator class="native"/>
        </id>
        <discriminator column="type" type="character"/>

        <property name="title"/>
        <set name="authors" table="author_work">
            <key column name="work_id"/>
            <many-to-many class="Author" column name="author_id"/>
        </set>

        <subclass name="Book" discriminator-value="B">
            <property name="text"/>
        </subclass>

        <subclass name="Song" discriminator-value="S">
            <property name="tempo"/>
            <property name="genre"/>
        </subclass>

    </class>

    <class name="Author" table="authors">

        <id name="id" column="id">
            <!-- The Author must have the same identifier as the Person -->
            <generator class="assigned"/> 
        </id>

        <property name="alias"/>
        <one-to-one name="person" constrained="true"/>

        <set name="works" table="author_work" inverse="true">
            <key column="author_id"/>
            <many-to-many class="Work" column="work_id"/>
        </set>

    </class>

    <class name="Person" table="persons">
        <id name="id" column="id">
            <generator class="native"/>
        </id>
        <property name="name"/>
    </class>

</hibernate-mapping>

There are four tables in this mapping. works, authors and persons hold work, author and person data respectively. author_work is an association table linking authors to works. Heres the table schema, as generated by SchemaExport.

create table works (
    id BIGINT not null generated by default as identity, 
    tempo FLOAT, 
    genre VARCHAR(255), 
    text INTEGER, 
    title VARCHAR(255), 
    type CHAR(1) not null, 
    primary key (id)
)

create table author_work (
    author_id BIGINT not null, 
    work_id BIGINT not null, 
    primary key (work_id, author_id)
)

create table authors (
    id BIGINT not null generated by default as identity, 
    alias VARCHAR(255), 
    primary key (id)
)

create table persons (
    id BIGINT not null generated by default as identity, 
    name VARCHAR(255), 
    primary key (id)
)

alter table authors 
    add constraint authorsFK0 foreign key (id) references persons
alter table author_work 
    add constraint author_workFK0 foreign key (author_id) references authors
alter table author_work
    add constraint author_workFK1 foreign key (work_id) references works

23.3. Customer/Order/Product

Now consider a model of the relationships between Customer, Order and LineItem and Product. There is a one-to-many association between Customer and Order, but how should we represent Order / LineItem / Product? I've chosen to map LineItem as an association class representing the many-to-many association between Order and Product. In Hibernate, this is called a composite element.

The mapping document:

<hibernate-mapping>

    <class name="Customer" table="customers">
        <id name="id">
            <generator class="native"/>
        </id>
        <property name="name"/>
        <set name="orders" inverse="true">
            <key column="customer_id"/>
            <one-to-many class="Order"/>
        </set>
    </class>

    <class name="Order" table="orders">
        <id name="id">
            <generator class="native"/>
        </id>
        <property name="date"/>
        <many-to-one name="customer" column="customer_id"/>
        <list name="lineItems" table="line_items">
            <key column="order_id"/>
            <list-index column="line_number"/>
            <composite-element class="LineItem">
                <property name="quantity"/>
                <many-to-one name="product" column="product_id"/>
            </composite-element>
        </list>
    </class>

    <class name="Product" table="products">
        <id name="id">
            <generator class="native"/>
        </id>
        <property name="serialNumber"/>
    </class>

</hibernate-mapping>

customers, orders, line_items and products hold customer, order, order line item and product data respectively. line_items also acts as an association table linking orders with products.

create table customers (
    id BIGINT not null generated by default as identity, 
    name VARCHAR(255), 
    primary key (id)
)

create table orders (
    id BIGINT not null generated by default as identity, 
    customer_id BIGINT, 
    date TIMESTAMP, 
    primary key (id)
)

create table line_items (
    line_number INTEGER not null, 
    order_id BIGINT not null, 
    product_id BIGINT, 
    quantity INTEGER, 
    primary key (order_id, line_number)
)

create table products (
    id BIGINT not null generated by default as identity, 
    serialNumber VARCHAR(255), 
    primary key (id)
)

alter table orders 
    add constraint ordersFK0 foreign key (customer_id) references customers
alter table line_items
    add constraint line_itemsFK0 foreign key (product_id) references products
alter table line_items
    add constraint line_itemsFK1 foreign key (order_id) references orders

23.4. Miscellaneous example mappings

These examples are all taken from the Hibernate test suite. You will find many other useful example mappings there. Look in the test folder of the Hibernate distribution.

TODO: put words around this stuff
23.4.1. "Typed" one-to-one association

<class name="Person">
    <id name="name"/>
    <one-to-one name="address" 
            cascade="all">
        <formula>name</formula>
        <formula>'HOME'</formula>
    </one-to-one>
    <one-to-one name="mailingAddress" 
            cascade="all">
        <formula>name</formula>
        <formula>'MAILING'</formula>
    </one-to-one>
</class>

<class name="Address" batch-size="2" 
        check="addressType in ('MAILING', 'HOME', 'BUSINESS')">
    <composite-id>
        <key-many-to-one name="person" 
                column="personName"/>
        <key-property name="type" 
                column="addressType"/>
    </composite-id>
    <property name="street" type="text"/>
    <property name="state"/>
    <property name="zip"/>
</class>

23.4.2. Composite key example

<class name="Customer">

    <id name="customerId"
        length="10">
        <generator class="assigned"/>
    </id>

    <property name="name" not-null="true" length="100"/>
    <property name="address" not-null="true" length="200"/>

    <list name="orders"
            inverse="true"
            cascade="save-update">
        <key column="customerId"/>
        <index column="orderNumber"/>
        <one-to-many class="Order"/>
    </list>

</class>

<class name="Order" table="CustomerOrder" lazy="true">
    <synchronize table="LineItem"/>
    <synchronize table="Product"/>
    
    <composite-id name="id" 
            class="Order$Id">
        <key-property name="customerId" length="10"/>
        <key-property name="orderNumber"/>
    </composite-id>
    
    <property name="orderDate" 
            type="calendar_date"
            not-null="true"/>
    
    <property name="total">
        <formula>
            ( select sum(li.quantity*p.price) 
            from LineItem li, Product p 
            where li.productId = p.productId 
                and li.customerId = customerId 
                and li.orderNumber = orderNumber )
        </formula>
    </property>
    
    <many-to-one name="customer"
            column="customerId"
            insert="false"
            update="false" 
            not-null="true"/>
        
    <bag name="lineItems"
            fetch="join" 
            inverse="true"
            cascade="save-update">
        <key>
            <column name="customerId"/>
            <column name="orderNumber"/>
        </key>
        <one-to-many class="LineItem"/>
    </bag>
    
</class>
    
<class name="LineItem">
    
    <composite-id name="id" 
            class="LineItem$Id">
        <key-property name="customerId" length="10"/>
        <key-property name="orderNumber"/>
        <key-property name="productId" length="10"/>
    </composite-id>
    
    <property name="quantity"/>
    
    <many-to-one name="order"
            insert="false"
            update="false" 
            not-null="true">
        <column name="customerId"/>
        <column name="orderNumber"/>
    </many-to-one>
    
    <many-to-one name="product"
            insert="false"
            update="false" 
            not-null="true"
            column="productId"/>
        
</class>

<class name="Product">
    <synchronize table="LineItem"/>

    <id name="productId"
        length="10">
        <generator class="assigned"/>
    </id>
    
    <property name="description" 
        not-null="true" 
        length="200"/>
    <property name="price" length="3"/>
    <property name="numberAvailable"/>
    
    <property name="numberOrdered">
        <formula>
            ( select sum(li.quantity) 
            from LineItem li 
            where li.productId = productId )
        </formula>
    </property>
    
</class>

23.4.3. Many-to-many with shared composite key attribute

<class name="User" table="`User`">
    <composite-id>
        <key-property name="name"/>
        <key-property name="org"/>
    </composite-id>
    <set name="groups" table="UserGroup">
        <key>
            <column name="userName"/>
            <column name="org"/>
        </key>
        <many-to-many class="Group">
            <column name="groupName"/>
            <formula>org</formula>
        </many-to-many>
    </set>
</class>
    
<class name="Group" table="`Group`">
    <composite-id>
        <key-property name="name"/>
        <key-property name="org"/>
    </composite-id>
    <property name="description"/>
    <set name="users" table="UserGroup" inverse="true">
        <key>
            <column name="groupName"/>
            <column name="org"/>
        </key>
        <many-to-many class="User">
            <column name="userName"/>
            <formula>org</formula>
        </many-to-many>
    </set>
</class>

23.4.4. Content based discrimination

<class name="Person"
    discriminator-value="P">
    
    <id name="id" 
        column="person_id" 
        unsaved-value="0">
        <generator class="native"/>
    </id>
    
            
    <discriminator 
        type="character">
        <formula>
            case 
                when title is not null then 'E' 
                when salesperson is not null then 'C' 
                else 'P' 
            end
        </formula>
    </discriminator>

    <property name="name" 
        not-null="true"
        length="80"/>
        
    <property name="sex" 
        not-null="true"
        update="false"/>
    
    <component name="address">
        <property name="address"/>
        <property name="zip"/>
        <property name="country"/>
    </component>
    
    <subclass name="Employee" 
        discriminator-value="E">
            <property name="title"
                length="20"/>
            <property name="salary"/>
            <many-to-one name="manager"/>
    </subclass>
    
    <subclass name="Customer" 
        discriminator-value="C">
            <property name="comments"/>
            <many-to-one name="salesperson"/>
    </subclass>
    
</class>

23.4.5. Associations on alternate keys

<class name="Person">
    
    <id name="id">
        <generator class="hilo"/>
    </id>
    
    <property name="name" length="100"/>
    
    <one-to-one name="address" 
        property-ref="person"
        cascade="all"
        fetch="join"/>
    
    <set name="accounts" 
        inverse="true">
        <key column="userId"
            property-ref="userId"/>
        <one-to-many class="Account"/>
    </set>
    
    <property name="userId" length="8"/>

</class>

<class name="Address">

    <id name="id">
        <generator class="hilo"/>
    </id>

    <property name="address" length="300"/>
    <property name="zip" length="5"/>
    <property name="country" length="25"/>
    <many-to-one name="person" unique="true" not-null="true"/>

</class>

<class name="Account">
    <id name="accountId" length="32">
        <generator class="uuid"/>
    </id>
    
    <many-to-one name="user"
        column="userId"
        property-ref="userId"/>
    
    <property name="type" not-null="true"/>
    
</class>

Chapter 24. Best Practices

Write fine-grained classes and map them using <component>.

    Use an Address class to encapsulate street, suburb, state, postcode. This encourages code reuse and simplifies refactoring. 
Declare identifier properties on persistent classes.

    Hibernate makes identifier properties optional. There are all sorts of reasons why you should use them. We recommend that identifiers be 'synthetic' (generated, with no business meaning). 
Identify natural keys.

    Identify natural keys for all entities, and map them using <natural-id>. Implement equals() and hashCode() to compare the properties that make up the natural key. 
Place each class mapping in its own file.

    Don't use a single monolithic mapping document. Map com.eg.Foo in the file com/eg/Foo.hbm.xml. This makes particularly good sense in a team environment. 
Load mappings as resources.

    Deploy the mappings along with the classes they map. 
Consider externalising query strings.

    This is a good practice if your queries call non-ANSI-standard SQL functions. Externalising the query strings to mapping files will make the application more portable. 
Use bind variables.

    As in JDBC, always replace non-constant values by "?". Never use string manipulation to bind a non-constant value in a query! Even better, consider using named parameters in queries. 
Don't manage your own JDBC connections.

    Hibernate lets the application manage JDBC connections. This approach should be considered a last-resort. If you can't use the built-in connections providers, consider providing your own implementation of org.hibernate.connection.ConnectionProvider. 
Consider using a custom type.

    Suppose you have a Java type, say from some library, that needs to be persisted but doesn't provide the accessors needed to map it as a component. You should consider implementing org.hibernate.UserType. This approach frees the application code from implementing transformations to / from a Hibernate type. 
Use hand-coded JDBC in bottlenecks.

    In performance-critical areas of the system, some kinds of operations might benefit from direct JDBC. But please, wait until you know something is a bottleneck. And don't assume that direct JDBC is necessarily faster. If you need to use direct JDBC, it might be worth opening a Hibernate Session and using that JDBC connection. That way you can still use the same transaction strategy and underlying connection provider. 
Understand Session flushing.

    From time to time the Session synchronizes its persistent state with the database. Performance will be affected if this process occurs too often. You may sometimes minimize unnecessary flushing by disabling automatic flushing or even by changing the order of queries and other operations within a particular transaction. 
In a three tiered architecture, consider using detached objects.

    When using a servlet / session bean architecture, you could pass persistent objects loaded in the session bean to and from the servlet / JSP layer. Use a new session to service each request. Use Session.merge() or Session.saveOrUpdate() to synchronize objects with the database. 
In a two tiered architecture, consider using long persistence contexts.

    Database Transactions have to be as short as possible for best scalability. However, it is often neccessary to implement long running application transactions, a single unit-of-work from the point of view of a user. An application transaction might span several client request/response cycles. It is common to use detached objects to implement application transactions. An alternative, extremely appropriate in two tiered architecture, is to maintain a single open persistence contact (session) for the whole lifecycle of the application transaction and simply disconnect from the JDBC connection at the end of each request and reconnect at the beginning of the subsequent request. Never share a single session across more than one application transaction, or you will be working with stale data. 
Don't treat exceptions as recoverable.

    This is more of a necessary practice than a "best" practice. When an exception occurs, roll back the Transaction and close the Session. If you don't, Hibernate can't guarantee that in-memory state accurately represents persistent state. As a special case of this, do not use Session.load() to determine if an instance with the given identifier exists on the database; use Session.get() or a query instead. 
Prefer lazy fetching for associations.

    Use eager fetching sparingly. Use proxies and lazy collections for most associations to classes that are not likely to be completely held in the second-level cache. For associations to cached classes, where there is an a extremely high probability of a cache hit, explicitly disable eager fetching using lazy="false". When an join fetching is appropriate to a particular use case, use a query with a left join fetch. 
Use the open session in view pattern, or a disciplined assembly phase to avoid problems with unfetched data.

    Hibernate frees the developer from writing tedious Data Transfer Objects (DTO). In a traditional EJB architecture, DTOs serve dual purposes: first, they work around the problem that entity beans are not serializable; second, they implicitly define an assembly phase where all data to be used by the view is fetched and marshalled into the DTOs before returning control to the presentation tier. Hibernate eliminates the first purpose. However, you will still need an assembly phase (think of your business methods as having a strict contract with the presentation tier about what data is available in the detached objects) unless you are prepared to hold the persistence context (the session) open across the view rendering process. This is not a limitation of Hibernate! It is a fundamental requirement of safe transactional data access. 
Consider abstracting your business logic from Hibernate.

    Hide (Hibernate) data-access code behind an interface. Combine the DAO and Thread Local Session patterns. You can even have some classes persisted by handcoded JDBC, associated to Hibernate via a UserType. (This advice is intended for "sufficiently large" applications; it is not appropriate for an application with five tables!) 
Don't use exotic association mappings.

    Good usecases for a real many-to-many associations are rare. Most of the time you need additional information stored in the "link table". In this case, it is much better to use two one-to-many associations to an intermediate link class. In fact, we think that most associations are one-to-many and many-to-one, you should be careful when using any other association style and ask yourself if it is really neccessary. 
Prefer bidirectional associations.

    Unidirectional associations are more difficult to query. In a large application, almost all associations must be navigable in both directions in queries. 
    
    
    
JavaFree logo
bannerName
Home Notícias Empregos Artigos Forum Registre-se Sobre
JavaForum


    * RTP - Transmissão em te...
    * DNS da Brasil Telecom. ...
    * Procura-se programador...
    * Frame em .JSP não é pos...
    * como executar um Servle...
    * Atualização versão Java...
    * System.nanoTime()?...
    * Erro na subtração...
    * Z22 e SuperWaba ...
    * Erro no MySQL...
    * Porque available() não ...
    * Acentos com AJAX...
    * Help...
    * Caucho Resin com IBM JD...
    * Problemas com lookup...
    * Deploy do jar e jad de ...
    * jPanel ajuda !!!...
    * ajuda formato JTable !!...
    * chown em Java...
    * Novidades da versão 5.0...

      Índice do Fórum - Novos Posts

Locations of visitors to this page
JavaPesquisa

?

Google Logo
JavaWallpapers
Walpapers JavaFree
JavaAmigos
JavaHispano
Inversion Of Control - Containers de Inversão de Controle e o padrão Dependency Injection
Enviada em Domingo, 25 de Julho de 2004

Martin Fowler

Na comunidade Java, tem havido uma onda de containers leves (lightweight containers) que ajudam a montar componentes de projetos diferentes em uma aplicação coesa. Por trás destes containers há um padrão comum de como eles fazem a amarração (wiring), conceito ao qual eles se referem sob o nome genérico de Inversão de Controle (Inversion of Control, ou IoC). Neste artigo, eu exploro o funcionamento deste padrão, sob o nome mais específico de Dependency Injection (Injeção de Dependências) e o contrasto com a alternativa Service Locator. A escolha entre eles é menos importante do que o princípio de separar a configuração do uso.

Última atualização significativa: 23 Jan 04

| Inglês (Original) | Chinês | Japonês |

    * Componentes e Serviços
    * Um Exemplo Simples
    * Inversão de Controle
    * Formas de Dependency Injection
          o Constructor Injection com o PicoContainer
          o Setter Injection com o Spring
          o Interface Injection 
    * Usando um Service Locator
          o Usando uma Interface Segregada para o Locator
          o Um Service Locator Dinâmico
          o Utilizando tanto um Locator quanto Injection com o Avalon 
    * Decidindo qual opção usar
          o Service Locator vs Dependency Injection
          o Constructor vs Setter Injection
          o Código ou arquivos de configuração
          o Separando Configuração do Uso 
    * Mais algumas questões
    * Pensamentos Conclusivos
    * Agradecimentos 

Uma das coisas interessantes sobre o mundo do Java corporativo é o grande volume de atividade para o desenvolvimento de alternativas às tecnologias J2EE predominantes, boa parte dessas atividades com código aberto. Isto se deve, em parte, a uma reação à complexidade de boa parte do mundo J2EE, mas também se deve à exploração de alternativas e ao surgimento de idéias criativas. Um problema comum é como amarrar diferentes elementos: como encaixar esta arquitetura de controlador web com a interface de acesso ao banco de dados quando eles foram concebidos por times diferentes, com pouco conhecimento um do outro. Uma variedade de frameworks têm tentado resolver este problema, e muitos deles estão se expandindo para prover capacidade de amarrar componentes de diferentes camadas. Estes são freqüentemente referenciados como containers leves, e têm como exemplo o PicoContainer e o Spring.

Por trás destes containers há vários princípios interessantes de design, coisas que vão além, tanto de containers especificos quanto da plataforma Java. Aqui, eu quero iniciar a exploração de alguns destes princípios. Os exemplos que eu uso serão em Java, mas como a maior parte do que escrevo, os princípios podem ser aplicados igualmente em outros ambientes OO, particularmente o .Net.
Componentes e Serviços

O tópico da amarração dos componentes me traz quase que imediatamente a problemas de terminologia difícil que envolvem os termos serviço e componente. Pode-se achar facilmente artigos longos e contraditórios sobre estas definições. Para meus propósitos, abaixo estão os meus usos atuais destes sobrecarregados termos.

Eu uso 'componente' para referenciar um agregado de software projetado para ser usado, sem modificação, por uma aplicação que está fora do controle dos criadores do componente. Por 'sem modificação', eu quero dizer que a aplicação não altera o código-fonte dos componentes, apesar dela poder alterar o comportamento do componente extendendo-o de alguma maneira permitida pelos criadores do componentes.

Um 'serviço' é similar ao componente, ao ponto que ele é utilizado por aplicações externas. A principal diferença é que eu espero que um componente seja usado localmente (pense em um arquivo JAR, DLL ou uma importação de código). Um serviço será usado remotamente, através de alguma interface remota, que pode ser tanto síncrona quanto assíncrona (web service, sistema de mensagens, RPC ou socket).

Na maioria das vezes, eu uso 'serviço' neste artigo, mas muito da mesma lógica pode também ser aplicada a componentes locais. De fato, freqüentemente você precisa de algum tipo de framework de componentes locais para acessar facilmente um serviço remoto. Mas escrever 'componente ou serviço' é cansativo para ler e escrever, e serviços estão bem mais na moda no momento.
Um Exemplo Simples

Para ajudar a tornar isso tudo mais concreto, eu usarei um exemplo funcional. Como todos os meus exemplos, este é um daqueles exemplos super-simples; pequeno o bastante para ser irreal, mas o suficiente, espero, para que se possa visualizar o que está ocorrendo sem cair na complexidade de um exemplo real.

Neste exemplo, estou criando um componente que fornece uma lista de filmes dirigidos por um determinado diretor. Esta função incrivelmente útil é implementada em um único método.
class MovieLister...
public Movie[] moviesDirectedBy(String arg) {
List allMovies = finder.findAll();
for (Iterator it = allMovies.iterator(); it.hasNext();) {
Movie movie = (Movie) it.next();
if (!movie.getDirector().equals(arg)) it.remove();
}
return (Movie[]) allMovies.toArray(new Movie[allMovies.size()]);
}

A implementação desta função é ingênua ao extremo. Ela pede ao finder (objeto de busca, no qual iremos nos aprofundar mais à frente) que este retorne todos os filmes que conhece. Então, é feita um percorrimento desta lista para retornar aqueles dirigidos por um diretor em particular. Este pedaço específico não será alterado posteriormente, já que ele é apenas uma ponte para o ponto real deste artigo.

O ponto principal deste artigo é o finder, mais particularmente como nós conectamos o lister (objeto de listagem) com um finder específico. Isso é interessante porque quero que o meu maravilhoso método moviesDirectedBy seja completamente independente de como todos os filmes são armazenados. Então, tudo o que o método faz é referenciar um finder e tudo o que o finder faz é saber como responder ao método findAll. Eu posso fazer isto definindo uma interface para o finder.
public interface MovieFinder {
List findAll();
}

Agora, tudo isto é muito bem desacoplado, mas em algum ponto eu tenho que obter uma classe concreta para realmente receber os filmes. Neste caso, eu pus este código no construtor da minha classe de listagem.
class MovieLister...
private MovieFinder finder;
public MovieLister() {
finder = new ColonDelimitedMovieFinder("movies1.txt");
}

O nome da classe de implementação vem do fato de que eu estou obtendo minha lista de um arquivo texto delimitado por caracteres ':' (dois-pontos, colon, em inglês). Eu os pouparei dos detalhes, pois, de qualquer modo, é necessário apenas que haja alguma implementação.

Agora, se apenas eu mesmo estiver usando esta classe, está tudo bem. Mas o que acontece quando meus amigos estão loucos de vontade de ter esta incrível funcionalidade e gostariam de uma cópia do meu programa? Se eles também guardarem suas listagens de filmes em um arquivo texto delimitado por caracteres ':' chamados "movies1.txt", então está tudo uma maravilha. Se eles têm um nome diferente para seus arquivos de filmes fica fácil por o nome do deste arquivo em um outro arquivo de propriedades. Mas e se eles têm uma forma completamente diferente de armazenamento para sua lista de filmes: um banco de dados SQL, um arquivo XML, um web service, ou mesmo um arquivo texto em outro formato? Neste caso, nós precisamos de uma classe diferente para recuperar aqueles dados. Agora, como eu defini uma interface MovieFinder, isto não alterará meu método moviesDirectedBy. Mas eu ainda preciso de algum meio de obter uma instância da implementação do finder correto.

Figura 1: As dependências usando uma simples instanciação na classe de listagem.

A Figura 1 mostra as dependências para esta situação. A classe MovieLister é dependente tanto da interface MovieFinder quanto de sua implementação. Nós preferiríamos que esta fosse dependente apenas da interface, mas como podemos obter uma instância para se trabalhar?

Em meu livro P of EAA, descrevemos esta situação como um Plugin. A classe de implementação para o finder não é ligada ao programa em tempo de compilação, já que eu não sei o que meus amigos irão usar. Ao invés disto, queremos que meu objeto de listagem trabalhe com qualquer implementação, e que tal implementação seja plugada posteriormente, fora de meu controle. O problema é como eu posso fazer a ligação de modo que minha classe MovieLister não conheça a implementação, e mesmo assim consiga uma instância que mantenha o funcionamento.

Expandindo isto a um sistema real, nós podemos ter dúzias de tais serviços e componentes. Em cada caso, podemos abstrair nosso uso destes componentes interagindo com eles através de uma interface (e usando um adaptador, se o componente não foi projetado com uma interface em mente). Mas se nós desejarmos instalarmos o sistema de diferentes formas, precisamos usar plugins para lidar com a interação destes serviços, de modo que possamos usar diferentes implementações em diferentes instalações.

Então, o problema central é como podemos reunir estes plugins em uma aplicação? Este é um dos principais problemas que esta nova geração de containers leves tentam resolver e, de forma universal, todos eles o fazem utilizando Inversão de Controle.
Inversão de Controle

Quando as pessoas falam sobre como estes containers são tão úteis por implementarem "Inversão de Controle", eu me sinto desconcertado. Inversão de controle é uma característica comum dos frameworks, portanto, dizer que estes containers leves são especiais porque usam inversão de controle é como dizer que meu carro é especial porque tem rodas.

A questão é, que aspecto de controle eles estão invertendo? Da primeira vez em que eu me deparei com inversão de controle, ela era o controle principal de uma interface com o usuário (UI). UIs antigas eram controladas por um programa de aplicação. Você tinha uma seqüência de comandos, como "entre com o nome", "entre com o endereço"; seu programa direcionava as perguntas e lia a resposta de cada uma. Com as UIs gráficas, o framework de UI conteria o loop principal, e o seu programa proveria os tratadores de eventos para os vários campos da tela. O controle principal do programa foi invertido, movido para dentro do framework.

Para esta nova leva de containers, a inversão é sobre como eles procuram por uma implementação de um plugin. Em meu exemplo ingênuo, o objeto de listagem obtia a implementação do finder instanciando-a diretamente. Isto impede que o finder seja um plugin. A abordagem que estes containers usam é assegurar que qualquer usuário de um plugin siga alguma convenção que permita um módulo montador separado, responsável por injetar a implementação no objeto de listagem.

Assim, eu acho que nós precisamos de um nome mais específico para este padrão. Inversão de Controle é um termo genérico demais, deixando as pessoas confusas. Como um resultado de muita discussão com vários defensores da IoC, nós estabelecemos o nome Dependency Injection.

Eu começarei falando sobre as várias formas de Dependency Injection, mas friso agora que esta não é a única maneira de remover a dependência da classe aplicação quanto à implementação do plugin. Um outro padrão que pode ser usado é o Service Locator, que será discutido depois da explicação da Dependency Injection.
Formas de Dependency Injection

A idéia básica da Dependency Injection é ter um objeto separado, o montador (assembler), que popula um campo em um objeto lister com uma implementação apropriada para a interface finder, resultando em um diagrama de dependências parecido com a Figura 2.

Figure 2: As dependências para um Injetor de Dependências

Existem três tipos principais de Dependency Injection. Os nomes que usarei são Constructor Injection (Injeção por Construtores), Setter Injection (Injeção por Métodos Set) e Interface Injection (Injeção por Interfaces). Se você ler sobre isto nas atuais discussões sobre Inversão de Controle, os verão sendo referenciados como IoC Tipo 1 (Interface Injection, IoC Tipo 2 (Setter Injection) e IoC Tipo 3 (Constructor Injection). Eu acho nomes numéricos particularmente difíceis de lembrar, por isso tenho usado os nomes definidos aqui.
Constructor Injection com o PicoContainer

Começarei mostrando como esta injeção é feita, usando-se um container leve chamado PicoContainer. Eu estou começando aqui, principalmente, porque muitos dos meus colegas na ThoughtWorks são muito ativos no desenvolvimento do PicoContainer (sim, é um tipo de nepotismo corporativo).

O PicoContainer usa um construtor para decidir como injetar uma implementação do finder na classe de listagem. Para isto funcionar, a classe de listagem de filmes precisa declarar um construtor que inclui tudo o que precisa ser injetado.
class MovieLister...
public MovieLister(MovieFinder finder) {
this.finder = finder;
}

O próprio finder irá, também, ser gerenciado pelo PicoContainer, e assim ter o nome do arquivo texto injetado pelo container.
class ColonMovieFinder...
public ColonMovieFinder(String filename) {
this.filename = filename;
}

O PicoContainer, então, precisa ser informado sobre que classe de implementação associar a cada interface, e que string injetar no finder.
private MutablePicoContainer configureContainer() {
MutablePicoContainer pico = new DefaultPicoContainer();
Parameter[] finderParams = {new ConstantParameter("movies1.txt")};
pico.registerComponentImplementation(MovieFinder.class,
ColonMovieFinder.class, finderParams);
pico.registerComponentImplementation(MovieLister.class);
return pico;
}

Este código de configuração é tipicamente feito em uma classe diferente. Por exemplo, cada amigo que usa meu lister pode escrever o código de configuração apropriado em alguma classe de setup própria. É claro que é comum manter este tipo de informação de configuração em arquivos de configuração separados. Pode-se escrever uma classe para ler um arquivo de configuração e ajustar o container apropriadamente. Embora o PicoContainer não contenha esta funcionalidade, existe um projeto relacionado, chamado NanoContainer, que provê os adaptadores apropriados para permitir que se tenham arquivos de configuração em XML. O NanoContainer interpretará o XML e então configurará o PicoContainer. A filosofia do projeto é separar o formato do arquivo de configuração do mecanismo interno.

Para usar o container, é necessário um código como este:
public void testWithPico() {
MutablePicoContainer pico = configureContainer();
MovieLister lister = (MovieLister) pico.getComponentInstance(MovieLister.class);
Movie[] movies = lister.moviesDirectedBy("Sergio Leone");
assertEquals("Once Upon a Time in the West", movies[0].getTitle());
}

Embora neste exemplo eu tenha usado Constructor Injection, o PicoContainer também suporta Setter Injection, apesar de seus desenvolvedores preferirem o primeiro.
Setter Injection no Spring

O Spring é um framework abrangente voltado para o desenvolvimento Java corporativo. Ele inclui camadas de abstração para transações, frameworks de persistência, desenvolvimento de aplicações web e JDBC. Assim como o PicoContainer, ele suporta tanto Constructor quanto Setter Injection, mas seus desenvolvedores tender a preferir Setter Injection - o que o faz uma escolha apropriada para este exemplo.

Para fazer com que meu MovieLister aceite a injeção, eu defino um método set para este serviço:
class MovieLister...
private MovieFinder finder;
public void setFinder(MovieFinder finder) {
this.finder = finder;
}

De maneira semelhante, eu defino um método set para a string do buscador:
class ColonMovieFinder...
public void setFilename(String filename) {
this.filename = filename;
}

O terceiro passo é ajustar os arquivos de configuração. O Spring suporta tanto configuração por arquivos XML quanto por código, mas a maneira mais comum é usando XML.
<beans>
    <bean id="MovieLister" class="spring.MovieLister">
        <property name="finder">
                <ref local="MovieFinder"/>
        </property>
    </bean>
    <bean id="MovieFinder" class="spring.ColonMovieFinder">
        <property name="filename">
                <value>movies1.txt</value>
        </property>
    </bean>
</beans>

O teste, então, fica assim.:

public void testWithSpring() throws Exception {
ApplicationContext ctx = new FileSystemXmlApplicationContext("spring.xml");
MovieLister lister = (MovieLister) ctx.getBean("MovieLister");
Movie[] movies = lister.moviesDirectedBy("Sergio Leone");
assertEquals("Once Upon a Time in the West", movies[0].getTitle());
}

Interface Injection

A terceira técnica de injeção é definir e usar interfaces para este propósito. O Avalon é um exemplo de framework que usa esta técnica. Falarei mais sobre isto mais tarde, mas neste caso eu irei usá-lo com alguns exemplos de código bem simples.

Com esta técnica, eu começo definindo a interface que eu usarei para executar a injeção. Aqui está a interface para injetar um MovieFinder a um objeto:
public interface InjectFinder {
void injectFinder(MovieFinder finder);
}

Esta interface seria definida por qualquer um que fornecesse a interface MovieFinder. Ela precisa ser implementada por qualquer classe que queira usar um finder, como é o caso do lister:
class MovieLister implements InjectFinder...
public void injectFinder(MovieFinder finder) {
this.finder = finder;
}

Eu uso uma abordagem similar para injetar o nome de arquivo na implementação do finder:

public interface InjectFinderFilename {
void injectFilename (String filename);
}

class ColonMovieFinder implements MovieFinder,
InjectFinderFilename......
public void injectFilename(String filename) {
this.filename = filename;
}

Então, como sempre, eu preciso de algum código de configuração para amarrar as implementações.
Por simplicidade, eu o farei em código:
class Tester...
private Container container;

private void configureContainer() {
container = new Container();
registerComponents();
registerInjectors();
container.start();
}

Esta configuração tem dois estágios. O registro dos componentes com chaves identificadoras
é bem parecido com os outros exemplos:
class Tester...
private void registerComponents() {
container.registerComponent("MovieLister", MovieLister.class);
container.registerComponent("MovieFinder", ColonMovieFinder.class);
}

Um novo passo é registrar os injetores que irão injetar os componentes dependentes.
Cada interface de injeção precisa de algum código para injetar o objeto dependente.
Aqui, isto é feito registrando-se os objetos injetores no container.
Cada objeto injetor implementa a interface de injeção:
class Tester...
private void registerInjectors() {
container.registerInjector(InjectFinder.class,
container.lookup("MovieFinder"));
container.registerInjector(InjectFinderFilename.class,
new FinderFilenameInjector());
}


public interface Injector {
public void inject(Object target);
}

Quando o dependente é uma classe escrita para este container, faz sendito para o componente que ele mesmo implemente uma interface de injeção, como faço aqui com o MovieFinder. Para classes genéricas, como uma string, eu uso uma inner class dentro do código de configuração:
class ColonMovieFinder implements Injector......
public void inject(Object target) {
((InjectFinder) target).injectFinder(this);
}


class Tester...
public static class FinderFilenameInjector implements Injector {
public void inject(Object target) {
((InjectFinderFilename)target).injectFilename("movies1.txt");
}
}

Os testes, então, utilizam o container:
class FinderFilenameInjector...
public void testIface() {
configureContainer();
MovieLister lister = (MovieLister)container.lookup("MovieLister");
Movie[] movies = lister.moviesDirectedBy("Sergio Leone");
assertEquals("Once Upon a Time in the West", movies[0].getTitle());
}

O container utiliza as interfaces de injeção declaradas para descobrir as dependências, e os injetores para injetar os dependentes corretos. (A implementação específica do container que eu fiz aqui não é importante para a técnica, e eu não a mostrarei, porque apenas causaria risos.)
Usando um Service Locator

O principal benefício da Dependency Injection é que ela remove a dependência que a classe MovieLister tem com a implementação concreta da MovieFinder. Isto me permite compartilhar as classes lister com amigos, e que eles possam plugar implementações apropriadas para seus ambientes. Dependency Injection não é a única maneira de quebrar esta dependência, outra que pode ser usada é um Service Locator.

A idéia básica por trás do Service Locator é ter um objeto que sabe como obter todos os serviços que uma aplicação pode ter. Então, um Service Locator para esta aplicação teria um método que retorna um MovieFinder quando este é necessário. Claro que isto apenas move esta carga um pouco, nós ainda temos que por o Locator dentro do lister, resultando nas dependências da Figura 3:

Figura 3: As dependências para um Service Locator

Neste caso, usarei um ServiceLocator como um singleton como um Registry. O lister pode então usá-lo para obter o finder quando é instanciado.
class MovieLister...
MovieFinder finder = ServiceLocator.movieFinder();


class ServiceLocator...
public static MovieFinder movieFinder() {
return soleInstance.movieFinder;
}
private static ServiceLocator soleInstance;
private MovieFinder movieFinder;

Como na abordagem da Dependency Injection, nós temos que configurar o Service Locator.
Aqui, eu o farei em código, mas não é difícil usar um mecanismo que leria os dados apropriados de um arquivo de configuração:
class Tester...
private void configure() {
ServiceLocator.load(new ServiceLocator(
new ColonMovieFinder("movies1.txt"))
);
}


class ServiceLocator...
public static void load(ServiceLocator arg) {
soleInstance = arg;
}

public ServiceLocator(MovieFinder movieFinder) {
this.movieFinder = movieFinder;
}

Aqui está o código de teste:
class Tester...
public void testSimple() {
configure();
MovieLister lister = new MovieLister();
Movie[] movies = lister.moviesDirectedBy("Sergio Leone");
assertEquals("Once Upon a Time in the West", movies[0].getTitle());
}

Freqüentemente eu tenho ouvido a reclamação de que estes tipos de service locators são uma coisa ruim,
porque eles não são testáveis por não ser possível substituir suas implementações.
Certamente, se mal projetados eles podem levar a este tipo de problema, mas este não é necessariamente o caso.
A instância do service locator é apenas um simples guardador de dados. Podemos facilmente criar um locator com implementações de teste de nossos serviços.

Para um locator mais sofisticado, eu posso criar uma subclasse do servicelocator
e passá-la à variável de classe do registro. Eu posso alterar os métodos estáticos para chamar métodos na instância,
ao invés de de acessar diretamente as variáveis de instância. Posso prover locators específicos para uma thread,
usando um local de armazenamento específico para a thread. Tudo isto pode ser feito,
sem alterar os clientes do service locator.

Um modo de se pensar nisto é que o service locator é um registro, e não um singleton.
Um singleton provê uma maneira simples de implementar um registro, mas esta decisão
de implementação pode ser facilmente mudada.
Usando uma Interface Segregada para o Locator

Um dos problemas da abordagem simples acima é que o MovieLister é dependente da classe service locator completa,
mesmo que use apenas um serviço. Nós podemos reduzir isto usando uma interface segregada (separada).
Desta maneira, ao invés de usar a interface completa do service locator, o lister pode declarar apenas
a parte da interface de que precisa.

Assim, o fornecedor do MovieLister forneceria também uma interface do locator de que ele precisa para obter o finder:
public interface MovieFinderLocator {
public MovieFinder movieFinder();

O locator então precisa implementar esta interface para prover o aceso ao finder:
MovieFinderLocator locator = ServiceLocator.locator();
MovieFinder finder = locator.movieFinder();


public static ServiceLocator locator() {
return soleInstance;
}
public MovieFinder movieFinder() {
return movieFinder;
}
private static ServiceLocator soleInstance;
private MovieFinder movieFinder;

Note que, já que usamos uma interface, não temos mais acesso aos serviços por métodos estáticos.
Teremos que usar a classe para obter uma instância do locator, e então usá-la para obter o que precisarmos.
Um Service Locator Dinâmico

O exemplo acima era estático, quanto à classe do service locator ter métodos para cada um dos serviços.
Esta não é a única maneira de fazer isto, você pode também fazer um service locator dinâmico,
que permita que você agrupe nele qualquer serviço que você precise, e faça suas escolhas
em tempo de execução.

Neste caso, o service locator utiliza um mapa ao invés de campos para cada um dos serviços,
provendo métodos genéricos para obter e carregar serviços.
class ServiceLocator...
private static ServiceLocator soleInstance;
public static void load(ServiceLocator arg) {
soleInstance = arg;
}
private Map services = new HashMap();
public static Object getService(String key){
return soleInstance.services.get(key);
}
public void loadService (String key, Object service) {
services.put(key, service);
}

A configuração envolve a carga do serviço com uma chave apropriada.
class Tester...
private void configure() {
ServiceLocator locator = new ServiceLocator();
locator.loadService("MovieFinder", new ColonMovieFinder("movies1.txt"));
ServiceLocator.load(locator);
}

Eu uso o serviço utilizando a mesma chave.
class MovieLister...
MovieFinder finder = (MovieFinder) ServiceLocator.getService("MovieFinder");

Em geral, eu não gosto desta abordagem. Apesar de que ela é realmente flexível, ela não é muito explícita.
A única maneira de se descobrir um serviço é através de chaves textuais. Eu prefiro métodos explícitos,
porque é mais fácil encontrar onde eles estão, olhando as definições da interface.
Utilizando tanto um locator quanto injeção com o Avalon

Dependency Injection e Service Locator não são necessariamente conceitos mutuamente excludentes.
Um bom exemplo é o uso dos dois juntos no framework Avalon. O Avalon utiliza um service locator,
mas usa injeção para informar os componentes onde encontrar o locator.

Berin Loritsch me enviou esta versão simples do meu exemplo usando Avalon.
public class MyMovieLister implements MovieLister, Serviceable {
private MovieFinder finder;

public void service( ServiceManager manager ) throws ServiceException {
finder = (MovieFinder)manager.lookup("finder");
}

O método de service() é um exemplo de Interface Injection, permitindo que o container injete
um ServiceManager no MyMovieLister. O ServiceManager é um exemplo de service locator.
Neste exemplo, o lister não armazena o manager em um atributo. Ao invés disso,
ele imediatamente o utiliza para obter o finder, que é o que realmente é guardado.
Decidindo qual opção usar

Até agora, tenho me concentrado em explicar como eu vejo estes padrões e suas variações.
Agora, posso começar a falar sobre seus prós e contras para ajudar na decisão de quando utilizar cada um.
Service Locator vs Dependency Injection

A escolha fundamental é entre o Service Locator e a Dependency Injection. O primeito ponto é que ambas implementações provêem o desacoplamento que está faltando no exemplo simples - em ambos os casos o código da aplicação é independente da implementação concreta da interface de serviços. A diferença importante entre os dois padrões é sobre como esta implementação é disponibilizada à classe de aplicação. Com o service locator, a classe de aplicação pede por ela explicitamente por meio de uma mensagem ao locator. Com injeção, não existe pedido explícito, o serviço simplesmente 'aparece' na classe de aplicação - daí vem a inversão de controle.

Inversão de controle é uma característica comum dos frameworks, mas é algo que vem com um preço. Ela tende a ser difícil de entender e leva a problemas quando tentamos fazer o debug. Assim, em geral, eu tento evitá-la, a não ser que seja necessária. Isto não é dizer que ela é uma coisa ruim, apenas que eu acho que ela deve ter uma justificativa para ser usada no lugar de uma alternativa mais direta.

A diferença principal é que, com um Service Locator, cada usuário do serviço tem uma dependência com o locator. O locator pode esconder dependências de outras implementações, mas você precisa ver o locator. Então, a decisão entre o service locator e a Dependency Injection depende de que dependência é um problema.

O uso de Dependency Injection pode ajudar a facilitar a visualização de quais são as dependências do componente. Você pode simplesmente analisar o mecanismo de injeção, como o construtor, e ver as dependências. Com o Service Locator, você tem que vasculhar código fonte por chamadas ao locator. IDEs modernas com funções de procura por referências facilitam o processo, mas ainda não é tão fácil como olhar o construtor ou os métodos set.

Muito disto depende da natureza do usuário do serviço. Se você está construindo uma aplicação com várias classe que usam um serviço, então a dependência das classes de aplicação com o locator não é um grande problema. Em meu exemplo de distribuir o MovieLister aos meus amigos, usar um ServiceLocator funciona bem. Tudo que eles precisam fazer é configurarem o locator para usar as implementações corretas dos serviços, por código ou arquivo de configuração. Neste tipo de cenário, eu não vejo nenhuma vantagem na inversão do injetor.

A diferença aparece se o lister é um componente que eu estou fornecendo a uma aplicação que outras pessoas estão criando. Neste caso, eu não sei muito sobre as APIs dos service locators que meus clientes irão usar. Cada cliente pode ter seus service locators próprios e incompatívels. Eu posso contornar o problema usando uma interface segregada. Cada cliente pode escrever um adaptador que implementa minha interface em seu locator, mas em qualquer caso, eu ainda preciso ver o primeiro locator para obter minhas interfaces específicas. E, uma vez que o adaptador aparece, começamos a perder a simplicidade da conexão direta a um locator.

Como na Dependency Injection não temos a dependência de um componente com o injetor, o componente não pode obter mais serviços dele, depois que já tiver sido configurado.

Uma razão comum que as pessoas dão para preferirem a Dependency Injection é que ela facilita a realização de testes. O ponto aqui é que, para efetuar testes, você precisa facilmente substituir implementações de serviços reais por stubs ou objetos falsos. Entretanto, não existe nenhuma diferença nisto entre Dependency Injection e Service Locator: ambos são configuráveis. Eu suspeito que esta observação vem de pessoas que não se deram ao trabalho de assegurar que seus service locators podessem ser facilmente substituídos. Aqui é onde teste contínuo pode ajudar, se você não pode facilmente substituir serviços para testes, então isto implica em um sério problema em seu design.

É claro que o problema de testabilidade é exacerbado por ambientes de componentes que são muito intrusivos, como o framework EJB do Java. Minha opinião é de que estes tipos de framework deveriam minimizar seus impactos sobre código de aplicação e, particularmente, não deveriam fazer coisas que atrasassem o ciclo de edição-execução. O uso de plugins substituindo componentes 'heavyweight' ajuda bastante neste processo, o que é vital para práticas como o Desenvolvimento Dirigido por Testes (Test Driven Development).

Então, o caso primário é para pessoas que estão escrevendo código que espera-se que seja usado em aplicações que estejam fora do controle delas. Nestes casos, mesmo suposições mínimas sobre o Service Locator é um problema.
Constructor vs Setter Injection

Para combinação de serviços, você tem sempre que ter alguma convenção, para fazer a amarração das coisas. A vantagem da injeção é principalmente que ela requer convenções muito simples - pelo menos a Construction e a Setter Injection. Você não tem que fazer nada estranho no seu componente e é simples, para o injetor, fazer toda a configuração.

A Interface injection é mais invasiva, já que você tem que escrever muitas interfaces para ajustar as coisas. Para um pequeno número de interfaces exigidas pelo container, como na abordagem do Avalon, isto não é tão ruim. Mas ainda representa bastante trabalho para montar componentes e dependências, o que é o porquê da atual safra de containers leves trilharem o caminho das Setter e Constructor Injection.

A escolha entre Setter e Constructor Injection é interessante, pois ela representa um assunto mais geral da programação orientada a objetos - se deve-se preencher os atributos em um construtor ou com métodos setter.

Desde muito tempo atrás, minha regra com objetos é, tanto quanto possível, criar objetos válidos em tempo de construção. Este conselho vem de Kent Beck, em Smalltalk Best Practice Patterns. Construtores com parâmetros nos dão um enunciado claro do que significa criar um objeto válido em um lugar óbvio. Se existem mais de uma maneira de fazê-lo, crie múltiplos construtores que mostram as diferentes combinações.

Outra vantagem com a inicialização pelo construtor é que ela permite que claramente se esconda quaisquer atributos que forem imutáveis, simplesmente não fornecendo um método setter. Eu acho isto importante - se algo não se altera, então a falta de um setter comunica isto muito bem. Se você usa setters para inicialização, isto pode se tornar um problema. (Realmente, nestas situações, eu prefiro evitar a converção usual de nomeclatura, usando um método como initFoo, para enfatizar que isto é algo que deveria ser feito apenas na criação.

Mas, como em qualquer situação, existem exceções. Se temos muitos parâmetros no construtor, as coisas podem parecer bagunçadas, particularmente em linguagens sem palavras-chave para parâmetros. É verdade que um construtor longo freqüentemente é sinal de um objeto com responsabilidades demais que deveria ser dividido, mas há casos em que realmente precisamos disto.

Se temos múltiplas maneiras de construir um objeto válido, pode ser difícil mostrar isto através de construtores, já que eles podem variar apenas no número e tipo dos parâmetros. Este é o caso onde entram os métodos-fábrica (Factory Methods), que podem combinar construtores privados com setters para fazer seu trabalho. O problema com os métodos-fábrica clássicos para montagem de componentes é que eles são, normalmente, métodos estáticos, e não se pode tê-los em interfaces. Você pode fazer uma classe-fábrica, mas daí ela se torna apenas mais uma instância de serviço. Um serviço-fábrica é, muitas vezes, uma boa tática, mas ainda temos que instanciar a fábrica usando uma das técnicas discutidas.

Construtores também sofrem do problema de parâmetros simples, como strings. Com Setter Injection, pode-se dar um nome que indica o que a string supostamente faz. Com construtores, podemos contar apenas com a posição, o que é mais difícil de seguir.

Se há múltiplos construtores e herança, então a coisa fica particularmente complicada. Para fazer toda a inicialização, temos que fornecer construtores para espelhar cada construtor da superclasse, enquanto adicionamos nossos próprios argumentos. Isto pode levar a uma explosão ainda maior no número de construtores.

Apesar das disvantagens, minha preferência é começar com Constructor Injection, mas estar pronto para mudar para Setter Injection assim que os problemas descritos começarem a se manifestar.

Este assunto tem levado a muitos debates entre os vários times que fornecem injetores de dependência com seus frameworks. Entretanto, parece que a maioria das pessoas que constroem estes frameworks têm percebido que é importante suportar ambos os mecanismos, mesmo que haja uma preferência maior por um deles.
Código ou arquivos de configuração

Um assunto separado, mas freqüentemente adicionado, é quando usar arquivos de configuração ou código sobre uma API para amarrar os serviços. Para a maioria das aplicações que tem de ser instaladas em vários lugares, um arquivo de configuração separado normalmente faz mais sentido. Quase sempre será um arquivo XML, e isto faz sentido. Entretanto, há casos onde é mais fácil usar código de programação para fazer a montagem. Um caso é onde se tem uma aplicação simples, que não tem muitas variações de instalação. Neste caso, um pouco de código pode ser mais claro que um arquivo XML separado.

Um caso constrastante é onde a montagem é muito complexa, envolvendo passos condicionais. Uma vez que se chega mais próximo de uma linguagem de programação, o XML começa a entrar em colapso, e é melhor usar uma linguagem real que tem toda a sintaxe para se escrever um programa claro. É feita então uma classe construtora que faz a montagem. Se há diferentes cenários de montagem, pode-se prover várias classes construtoras e usar um arquivo de configuração simples que faz a seleção entre eles.

Muitas vezes penso que as pessoas estão ansiosas demais por definir arquivos de configuração. Muitas vezes, uma linguagem de programação serve como um mecanismo de configuração direto e poderoso. Linguagens modernas podem facilmente compilar pequenos montadores que podem ser usados para juntar plugins em sistemas maiores. Se a compilação é trabalhosa demais, existem também linguagens script que podem funcionar muito bem.

É freqüentemente falado que arquivos de configuração não deveriam usar uma linguagem de programação, porque eles precisam ser editados por não-programadores. Mas quão freqüente este é o caso? As pessoas realmente esperam que não-programadores alterem os níveis de isolamento de transações de aplicações servidoras complexas? Arquivos de configuração que não usam uma linguagem de programação funcionam bem apenas enquanto simples. Se eles se tornaram complexos, então é hora de pensar sobre usar uma linguagem de programação apropriada.

Uma coisa que vemos no mundo Java no momento é uma dissonância de arquivos de configuração, onde cada componente tem seus próprios arquivos de configuração, que são diferentes de quaisquer outros. Se uma dúzia destes componentes forem usados, pode-se facilmente acabar com uma dúzia de arquivos de configuração que devem ser atualizados.

Meu conselho aqui é sempre prover uma maneira de fazer toda a configuração facilmente com uma interface programática, e então tratar o arquivo de configuração separado como uma característica opcional. Pode-se facilmente construir a manipulação de um arquivo de configuração usando uma interface programática. Quando se cria um componente, deve-se deixar a cargo do usuário quando utilizar a interface programática, o formato padrão do arquivo de configuração, ou criar seu próprio formato de arquivo, amarrando-o à interface programática.
Separando Configuração do Uso

A coisa mais importante nisto tudo é assegurar-se de que a configuração dos serviços seja separada de seu uso. Isto é um princípio fundamental do design próximo à separação entre interfaces e implementação. É algo que vemos dentro de um programa orientado-a-objetos quando lógica condicional decide que classe instanciar, e então, futuras avaliações desta condição é feita por polimorfismo ao invés de ter código condicional duplicado.

Se esta separação é útil dentro de uma única base de código, é especialmente vital quando se usa elementos externos, como componentes e serviços. A primeira questão é se é desejável deferir a escolha da classe de implementação para instalações particulares. Se sim, é necessário o uso de alguma implementação de plugin. Uma vez que plugins estejam sendo utilizados, é essencial que a montagem dos plugins seja feita separadamente do resto da aplicação, para que seja possível substituir diferentes configurações facilmente para diferentes instalações. Como se consegue isto é secundário. Este mecanismo de configuração pode tanto configurar um service locator quanto usar injeção para configurar os objetos diretamente.
Mais algumas questões

Neste artigo, me concentrei nas questões básicas da configuração de serviços utilizando Dependency Injection e Service Locator. Existem mais tópicos que entram neste assunto que também merecem atenção, mas eu ainda não tive tempo de me aprofundar neles. Em particular, há a questão do comportamento do ciclo de vida. Alguns componentes têm eventos de ciclo de vida distintos: parar e iniciar, por exemplo. Outra questão é o crescente interesse em usar idéias da orientação a aspectos com estes containers. Apesar de eu não ter considerado este material no artigo neste momento, eu realmente espero escrever mais sobre isto, ou extendendo este artigo, ou em um outro.

Você pode encontrar muito mais sobre estas idéias procurando nos web sites dedicados a containers leves. Navegar nos sites do PicoContainer e do Spring irá levá-lo a muitas outras discussões sobre estas questões e a uma introdução às questões adicionais.
Pensamentos Conclusivos

Na atual corrida dos containers leves, todos têm um padrão fundamental de como eles fazem a amarração dos serviços - o padrão Dependency Injection. Dependency Injection é uma alternativa útil ao Service Locator. Ao construir classes de aplicação, os dois são, a grosso modo, equivalentes, mas eu acho que o Service Locator tem uma leve vantagem devido ao seu comportamento mais direto. Entretanto, se você está criando classes para serem usadas em múltiplas aplicações, então a Dependency Injection é uma escolha melhor.

Se você usar Dependency Injection, há vários estilos para se escolher. Eu o sugeriria a seguir a Constructor Injection, a menos que você se depare com um dos problemas específicos desta abordagem. Neste caso, mude para a Setter Injection. Se você está fazendo a escolha para construir ou obter um container, procure um que suporte tanto Constructor quanto Setter Injection.

A escolha entre Service Locator e Dependency Injection é menos importante que o princípio de separar a configuração de serviços do uso dos serviços dentro de uma aplicação.
Agradecimentos

Meus sinceros agradecimentos às muitas pessoas que me ajudaram com este artigo. Rod Johnson, Paul Hammant, Joe Walnes, Aslak Hellesøy, Jon Tirsén e Bill Caputo me ajudaram definir estes conceitos e fizeram comentários nas versões preliminares deste artigo. Berin Loritsch e Hamilton Verissimo de Oliveira forneceram algumas dicas muito úteis sobre como o Avalon se encaixa. Dave W Smith foi persistente em me perguntar sobre meu código de configuração por Interface Injection inicial, fazendo com que me confrontasse com o fato de que ele estava horrível.
Revisões Significantes

23 Jan 04: Refeito o código de configuração do exemplo de interface injection.

16 Jan 04: Adicionado um exemplo curto do locator e da injeção com o Avalon.

14 Jan 04: Primeira publicação.
© Copyright Martin Fowler. Todos os direitos reservados
Tradução para o português por: Ronald Tetsuo Miura - JavaFree.com.br



Voltar

    <h1>Inversion of Control Containers and the Dependency Injection
	pattern</h1>

<div class="author">

<p><a href="http://martinfowler.com">Martin Fowler</a></p>
</div>

<p class="abstract"><i>In the Java community there's been a rush of lightweight
containers that help to assemble components from different projects
into a cohesive application. Underlying these containers is a common
pattern to how they perform the wiring, a concept they refer under the
very generic name of "Inversion of Control". In this article I dig
into how this pattern works, under the more specific name of
"Dependency Injection", and contrast it with the Service Locator
alternative. The choice between them is less important than the
principle of separating configuration from use.</i></p>

<p class="lastUpdate">Last significant update: <a href="#SignificantRevisions">23 Jan 04</a></p>

<p class="translations"> | <a href="http://gigix.blogdriver.com/diary/gigix/inc/DependencyInjection.pdf">Chinese</a> | <a href="http://www.javafree.com.br/home/modules.php?name=Content&amp;pa=showpage&amp;pid=4">Portuguese</a> | <a href="http://www.dotnetguru.org/article.php?sid=493&amp;mode=thread&amp;order=0&amp;thold=0">French</a> | </p>

<div class="contents">
<p>Contents</p>

<ul>
<li><a href="#ComponentsAndServices">Components and Services</a></li>

<li><a href="#ANaiveExample">A Naive Example</a></li>

<li><a href="#InversionOfControl">Inversion of Control</a></li>

<li><a href="#FormsOfDependencyInjection">Forms of Dependency Injection</a>

<ul>
<li><a href="#ConstructorInjectionWithPicocontainer">Constructor Injection with PicoContainer</a></li>

<li><a href="#SetterInjectionWithSpring">Setter Injection with Spring</a></li>

<li><a href="#InterfaceInjection">Interface Injection</a></li>
</ul>
</li>

<li><a href="#UsingAServiceLocator">Using a Service Locator</a>
<ul>
<li><a href="#UsingASegregatedInterfaceForTheLocator">Using a Segregated Interface for the Locator</a></li>

<li><a href="#ADynamicServiceLocator">A Dynamic Service Locator</a></li>

<li><a href="#UsingBothALocatorAndInjectionWithAvalon">Using both a locator and injection with Avalon</a></li>
</ul>
</li>

<li><a href="#DecidingWhichOptionToUse">Deciding which option to use</a>
<ul>
<li><a href="#ServiceLocatorVsDependencyInjection">Service Locator vs Dependency Injection</a></li>

<li><a href="#ConstructorVersusSetterInjection">Constructor versus Setter Injection</a></li>

<li><a href="#CodeOrConfigurationFiles">Code or configuration files</a></li>

<li><a href="#SeparatingConfigurationFromUse">Separating Configuration from Use</a></li>
</ul>
</li>

<li><a href="#SomeFurtherIssues">Some further issues</a></li>

<li><a href="#ConcludingThoughts">Concluding Thoughts</a></li>
</ul>
</div>

<div class="paperBody"><hr class="bodySep"><p>One of the entertaining things about the enterprise Java world is
the huge amount of activity in building alternatives to the mainstream
J2EE technologies, much of it happening in open source. A lot of this
is a reaction to the heavyweight complexity in the mainstream
J2EE world, but much of it is also exploring alternatives and coming
up with creative ideas. A common issue to deal with is how to wire
together different elements: how do you fit together this web
controller architecture with that database interface backing when they
were built by different teams with little knowledge of each other.A
number of frameworks have taken a stab at this problem, and several
are branching out to provide a general capability to assemble
components from different layers. These are often referred to as
lightweight containers, examples include <a href="http://www.picocontainer.org/">PicoContainer</a>, and <a href="http://www.springframework.org/">Spring</a>.</p><p>Underlying these containers are a number of interesting design
principles, things that go beyond both these specific containers and
indeed the Java platform. Here I want to start exploring some of these
principles. The examples I use are in Java, but like most of my
writing the principles are equally applicable to other OO
environments, particularly .NET.</p><hr class="topSection">
<a name="ComponentsAndServices"></a>

<h2>Components and Services</h2>
<p>The topic of wiring elements together drags me almost
immediately into the knotty terminology problems that surround the
terms service and component. You find long and contradictory articles
on the definition of these things with ease. For my purposes here are
my current uses of these overloaded terms.</p><p>I use component to mean a glob of software that's intended to
be used, without change,  by application that is out of the control of
the writers of the component. By 'without change' I mean that the
using application doesn't change the source code of the components,
although they may alter the component's behavior by extending it in
ways allowed by the component writers. </p><p>A service is similar to a component in that it's used by
foreign applications. The main difference is that I expect a component
to be used locally (think jar file, assembly, dll, or a source
import). A service will be used remotely through some remote
interface, either synchronous or asynchronous (eg web service,
messaging system, RPC, or socket.)</p><p>I mostly use service in this article, but much of the same
logic can be applied to local components too. Indeed often you need
some kind of local component framework to easily access a remote
service. But writing "component or service" is tiring to read and
write, and services are much more fashionable at the moment.</p><hr class="topSection">
<a name="ANaiveExample"></a>

<h2>A Naive Example</h2>
<p>To help make all of this more concrete I'll use a running
example to talk about all of this. Like all of my examples it's one of
those super-simple examples; small enough to be unreal, but hopefully
enough for you to visualize what's going on without falling into the
bog of a real example.</p><p>In this example I'm writing a component that provides a list of
movies directed by a particular director. This stunningly useful
function is implemented by a single method.</p><pre>class MovieLister...
    public Movie[] moviesDirectedBy(String arg) {
        List allMovies = finder.findAll();
        for (Iterator it = allMovies.iterator(); it.hasNext();) {
            Movie movie = (Movie) it.next();
            if (!movie.getDirector().equals(arg)) it.remove();
        }
        return (Movie[]) allMovies.toArray(new Movie[allMovies.size()]);
    }
</pre><p>The implementation of this function is naive in the extreme, it
asks a finder object (which we'll get to in a moment) to return every
film it knows about. Then it just hunts through this list to return
those directed by a particular director. This particular piece of
naivety I'm not going to fix, since it's just the scaffolding for the
real point of this article.</p><p>The real point of this article is this finder object, or
particularly how we connect the lister object with a particular finder
object. The reason why this is interesting is that I want my wonderful
<code>moviesDirectedBy</code> method to be completely independent of
how all the movies are being stored. So all the method does is refer
to a finder, and all that finder does is know how to respond to the
<code>findAll</code> method. I can bring this out by defining an
interface for the finder.</p><pre>public interface MovieFinder {
    List findAll();
}
</pre><p>Now all of this is very well decoupled, but at some point I
have to come up with a concrete class to actually come up with the
movies. In this case I put the code for this in the constructor of my
lister class.</p><pre>class MovieLister...
  private MovieFinder finder;
  public MovieLister() {
    finder = new ColonDelimitedMovieFinder("movies1.txt");
  }

</pre><p>The name of the implementation class comes from the fact that
I'm getting my list from a colon delimited text file. I'll spare you
the details, after all the point is just that there's some
implementation.</p><p>Now if I'm using this class for just myself, this is all fine
and dandy. But what happens when my friends are overwhelmed by a
desire for this wonderful functionality and would like a copy of my
program? If they also store their movie listings in a colon delimited
text file called "movies1.txt" then everything is wonderful. If they
have a different name for their movies file, then it's easy to put the
name of the file in a properties file. But what if they have a
completely different form of storing their movie listing: a SQL
database, an XML file, a web service, or just another format of text
file? In this case we need a different class to grab that data. Now
because I've defined a <code>MovieFinder</code> interface, this won't
alter my <code>moviesDirectedBy</code> method. But I still need to
have some way to get an instance of the right finder implementation
into place.</p>
<div class="figure">
<p class="figureImage"><a name="naive.gif"></a><img src="naive.gif" alt="Figure 3"></p>

<p class="figureCaption">Figure 3: The dependencies using a simple creation
in the lister class</p>
</div>
<p> Figure <a href="#naive.gif">3</a> shows the dependencies for this
situation. The <code>MovieLister</code> class is dependent on both the

<code>MovieFinder</code> interface and upon the implementation. We
would prefer it if it were only dependent on the interface, but then
how do we make an instance to work with?</p><p>In my book <a href="http://www.martinfowler.com/books.html#eaa">P of EAA</a>, we
described this situation as a <a href="http://martinfowler.com/eaaCatalog/plugin.html">Plugin</a>. The
implementation class for the finder isn't linked into the program at
compile time, since I don't know what my friends are going to use.
Instead we want my lister to work with any implementation, and for
that implementation to be plugged in at some later point, out of my
hands. The problem is how can I make that link so that my lister class
is ignorant of the implementation class, but can still talk to an
instance to do its work.</p><p>Expanding this into a real system, we might have dozens of such
services and components. In each case we can abstract our use of these
components by talking to them through an interface (and using an
adapter if the component isn't designed with an interface in mind).
But if we wish to deploy this system in different ways, we need to use
plugins to handle the interaction with these services so we can use
different implementations in different deployments.</p><p>So the core problem is how do we assemble these plugins into an
application? This is one of the main problems that this new breed of
lightweight containers face, and universally they all do it using
Inversion of Control.</p><hr class="topSection">
<a name="InversionOfControl"></a>

<h2>Inversion of Control</h2>
<p>When these containers talk about how they are so useful because
they implement "Inversion of Control" I end up very puzzled. <a href="http://martinfowler.com/bliki/InversionOfControl.html">Inversion
of control</a> is a common characteristic of frameworks, so saying that
these lightweight containers are special because they use inversion of
control is like saying my car is special because it has wheels.</p><p>The question, is what aspect of control are they inverting?
When I first ran into inversion of control, it was in the main control
of a user interface. Early user interfaces were controlled by the
application program. You would have a sequence of commands like "Enter
name", "enter address"; your program would drive the prompts and pick
up a response to each one. With graphical (or even screen based) UIs
the UI framework would contain this main loop and your program instead
provided event handlers for the various fields on the screen. The main
control of the program was inverted, moved away from you to the
framework.</p><p>For this new breed of containers the inversion is about how
they lookup a plugin implementation. In my naive example the lister
looked up the finder implementation by directly instantiating it. This
stops the finder from being a plugin. The approach that these
containers use is to ensure that any user of a plugin follows some
convention that allows a separate assembler module to inject the
implementation into the lister.</p><p>As a result I think we need a more specific name for this
pattern. Inversion of Control is too generic a term, and thus people
find it confusing. As a result with a lot of discussion with various
IoC advocates we settled on the name  <i>Dependency Injection</i>.</p><p>I'm going to start by talking about the various forms of
dependency injection, but I'll point out now that that's not the only way
of removing the dependency from the application class to the plugin
implementation. The other pattern you can use to do this is Service
Locator, and I'll discuss that after I'm done with explaining Dependency
Injection.</p><hr class="topSection">

<a name="FormsOfDependencyInjection"></a>

<h2>Forms of Dependency Injection</h2>
<p>The basic idea of the Dependency Injection is to have a separate
object, an assembler, that populates a field in the lister class with
an appropriate implementation for the finder interface, resulting in a
dependency diagram along the lines of  Figure <a href="#injector.gif">1</a></p>
<div class="figure">
<p class="figureImage"><a name="injector.gif"></a><img src="injector.gif" alt="Figure 1"></p>

<p class="figureCaption">Figure 1: The dependencies for a Dependency
Injector</p>
</div>
<p>There are three main styles of dependency injection. The names I'm
using for them are Constructor Injection, Setter Injection, and
Interface Injection. If you read about this stuff in the current
discussions about Inversion of Control you'll hear these referred to
as type 1 IoC (interface injection), type 2 IoC (setter injection) and
type 3 IoC (constructor injection). I find numeric names rather hard
to remember, which is why I've used the names I have here.</p>
<a name="ConstructorInjectionWithPicocontainer"></a>

<h3>Constructor Injection with PicoContainer</h3>
<p>I'll start with showing how this injection is done using a
lightweight container called <a href="http://www.picocontainer.org/">PicoContainer</a>. I'm starting here primarily
because several of my colleagues at ThoughtWorks are very active in the
development of PicoContainer (yes, it's a sort of corporate
nepotism.)</p><p>PicoContainer uses a constructor to decide how to inject a
finder implementation into the lister class. For this to work, the
movie lister class needs to declare a constructor that includes
everything it needs injected.</p><pre>class MovieLister...
    public MovieLister(MovieFinder finder) {
        this.finder = finder;       
    }
</pre><p>The finder itself will also be managed by the pico container,
and as such will have the filename of the text file injected into it
by the container.</p><pre>class ColonMovieFinder...
    public ColonMovieFinder(String filename) {
        this.filename = filename;
    }
</pre><p>The pico container then needs to be told which implementation
class to associate with each interface, and which string to inject
into the finder.</p><pre>    private MutablePicoContainer configureContainer() {
        MutablePicoContainer pico = new DefaultPicoContainer();
        Parameter[] finderParams =  {new ConstantParameter("movies1.txt")};
        pico.registerComponentImplementation(MovieFinder.class, ColonMovieFinder.class, finderParams);
        pico.registerComponentImplementation(MovieLister.class);
        return pico;
    }
</pre><p>This configuration code is typically set up in a different
class. For our example, each friend who uses my lister might write the
appropriate configuration code in some setup class of their own. Of
course it's common to hold this kind of configuration information in
separate config files. You can write a class to read a config file and
set up the container appropriately. Although PicoContainer doesn't
contain this functionality itself, there is a closely related project
called NanoContainer that provides the appropriate wrappers to allow
you to have XML configuration files. Such a  nano container will parse
the XML and then configure an underlying pico container. The
philosophy of the project is to separate the config file format from
the underlying mechanism.</p><p>To use the container you write code something like this.</p><pre>    public void testWithPico() {
        MutablePicoContainer pico = configureContainer();
        MovieLister lister = (MovieLister) pico.getComponentInstance(MovieLister.class);
        Movie[] movies = lister.moviesDirectedBy("Sergio Leone");
        assertEquals("Once Upon a Time in the West", movies[0].getTitle());
    }
</pre><p>Although in this example I've used constructor injection,
			PicoContainer also supports setter injection, although it's
			developers do prefer constructor injection.</p>

<a name="SetterInjectionWithSpring"></a>

<h3>Setter Injection with Spring</h3>
<p>The <a href="http://www.springframework.org/">Spring framework</a> is
a wide ranging framework for enterprise Java development. It includes
abstraction layers for transactions, persistence frameworks, web
application development and JDBC. Like PicoContainer it supports both
constructor and setter injection, but its developers tend to prefer
setter injection - which makes it an appropriate choice for this example.
</p><p>To get my movie lister to accept the injection I define a
setting method for that service</p><pre>class MovieLister...
    private MovieFinder finder;
  public void setFinder(MovieFinder finder) {
    this.finder = finder;
  }
</pre><p>Similarly I define a setter for the string the finder.</p><pre>class ColonMovieFinder...
    public void setFilename(String filename) {
        this.filename = filename;
    }
</pre><p>The third step is to set up the configuration for the files.
Spring supports configuration through XML files and also through code,
but XML is the expected way to do it.</p><pre>    &lt;beans&gt;
        &lt;bean id="MovieLister" class="spring.MovieLister"&gt;

            &lt;property name="finder"&gt;
                &lt;ref local="MovieFinder"/&gt;
            &lt;/property&gt;
        &lt;/bean&gt;
        &lt;bean id="MovieFinder" class="spring.ColonMovieFinder"&gt;
            &lt;property name="filename"&gt;

                &lt;value&gt;movies1.txt&lt;/value&gt;
            &lt;/property&gt;
        &lt;/bean&gt;
    &lt;/beans&gt;
</pre><p>The test then looks like this.</p><pre>    public void testWithSpring() throws Exception {
        ApplicationContext ctx = new FileSystemXmlApplicationContext("spring.xml");
        MovieLister lister = (MovieLister) ctx.getBean("MovieLister");
        Movie[] movies = lister.moviesDirectedBy("Sergio Leone");
        assertEquals("Once Upon a Time in the West", movies[0].getTitle());
    }

</pre>
<a name="InterfaceInjection"></a>

<h3>Interface Injection</h3>
<p>The third injection technique is to define and use interfaces
for the injection. <a href="http://avalon.apache.org/">Avalon</a> is
an example of a framework that uses this
technique in places. I'll talk a bit more about that later, but
in this case I'm going to use it with some simple sample code.</p><p>With this technique I begin by defining an interface that
I'll use to perform the injection through. Here's the interface for
injecting a movie finder into an object.</p><pre>public interface InjectFinder {
    void injectFinder(MovieFinder finder);
}
</pre><p>This interface would be defined by whoever provides the
MovieFinder interface. It needs to be implemented by any class that
wants to use a finder, such as the lister.</p><pre>class MovieLister implements InjectFinder...
    public void injectFinder(MovieFinder finder) {
        this.finder = finder;
    }
</pre><p>I use a similar approach to inject the filename into the
finder implementation.</p><pre>public interface InjectFinderFilename {
    void injectFilename (String filename);
}
</pre><pre>class ColonMovieFinder implements MovieFinder, InjectFinderFilename......
    public void injectFilename(String filename) {
        this.filename = filename;
    }
</pre><p>Then, as usual, I  need some configuration code to wire up the
implementations. For simplicity's sake I'll do it in code.</p><pre>class Tester...
    private Container container;

     private void configureContainer() {
       container = new Container();
       registerComponents();
       registerInjectors();
       container.start();
    }

</pre><p>This configuration has two stages, registering components
			through lookup keys is pretty similar to the other examples.</p><pre>class Tester...
  private void registerComponents() {
    container.registerComponent("MovieLister", MovieLister.class);
    container.registerComponent("MovieFinder", ColonMovieFinder.class);
  }
</pre><p>A new step is to register the injectors that will inject the
			dependent components. Each injection interface needs some code
			to inject the dependent object. Here I do this by registering
			injector objects with the container. Each injector object
			implements the injector interface. </p><pre>class Tester...
  private void registerInjectors() {
    container.registerInjector(InjectFinder.class, container.lookup("MovieFinder"));
    container.registerInjector(InjectFinderFilename.class, new FinderFilenameInjector());
  }
</pre><pre>public interface Injector {
  public void inject(Object target);

}
</pre><p>When the
			dependent is a class written for this container, it makes sense for the
			component to implement the injector interface itself, as I do here with the
			movie finder. For generic classes, such as the string, I use an
			inner class within the configuration code. </p><pre>class ColonMovieFinder implements Injector......
  public void inject(Object target) {
    ((InjectFinder) target).injectFinder(this);        
  }
</pre><pre>class Tester...
  public static class FinderFilenameInjector implements Injector {
    public void inject(Object target) {
      ((InjectFinderFilename)target).injectFilename("movies1.txt");      
    }
    }
</pre><p>The tests then use the container.</p><pre>class IfaceTester...
    public void testIface() {
      configureContainer();
      MovieLister lister = (MovieLister)container.lookup("MovieLister");
      Movie[] movies = lister.moviesDirectedBy("Sergio Leone");
      assertEquals("Once Upon a Time in the West", movies[0].getTitle());
    }
</pre><p>The container uses the
			declared injection interfaces to figure out the dependendencies
			and the injectors to inject the correct dependents. (The
			specific container implementation I did here isn't important to
			the technique, and I won't show it because you'd only laugh.)</p><hr class="topSection">
<a name="UsingAServiceLocator"></a>

<h2>Using a Service Locator</h2>
<p>The key benefit of a Dependency Injector is that it removes the
dependency that the <code>MovieLister</code> class has on the concrete

<code>MovieFinder</code> implementation. This allows me to give
listers to friends and for them to plug in a suitable implementation
for their own environment. Injection isn't the only way to break this
dependency, another is to use a <a href="http://java.sun.com/blueprints/corej2eepatterns/Patterns/ServiceLocator.html">service locator</a>.</p><p>The basic idea behind a service locator is to have an object
that knows how to get hold of all of the services that an application
might need. So a service locator for this application would have a
method that returns a movie finder when one is needed. Of course this
just shifts the burden a tad, we still have to get the locator into
the lister, resulting in the dependencies of  Figure <a href="#locator.gif">2</a></p>
<div class="figure">
<p class="figureImage"><a name="locator.gif"></a><img src="locator.gif" alt="Figure 2"></p>

<p class="figureCaption">Figure 2: The dependencies for a Service
Locator</p>
</div>
<p>In this case I'll use the ServiceLocator as a singleton <a href="http://martinfowler.com/eaaCatalog/registry.html">Registry</a>.
The lister can then use that to get the finder when it's
instantiated.</p><pre>class MovieLister...
    MovieFinder finder = ServiceLocator.movieFinder();

</pre><pre>class ServiceLocator...
    public static MovieFinder movieFinder() {
        return soleInstance.movieFinder;
    }
    private static ServiceLocator soleInstance;
    private MovieFinder movieFinder;
</pre><p>As with the injection approach, we have to configure the
service locator. Here I'm doing it in code, but it's not hard to use a
mechanism that would read the appropriate data from a configuration
file.</p><pre>class Tester...
    private void configure() {
        ServiceLocator.load(new ServiceLocator(new ColonMovieFinder("movies1.txt")));
    }
</pre><pre>class ServiceLocator...
    public static void load(ServiceLocator arg) {
        soleInstance = arg;
    }

    public ServiceLocator(MovieFinder movieFinder) {
        this.movieFinder = movieFinder;
    }
</pre><p>Here's the test code.</p><pre>class Tester...
    public void testSimple() {
        configure();
        MovieLister lister = new MovieLister();
        Movie[] movies = lister.moviesDirectedBy("Sergio Leone");
        assertEquals("Once Upon a Time in the West", movies[0].getTitle());
    }
</pre><p>I've often heard the complaint that these kinds of service
locators are a bad thing because they aren't testable because you
can't substitute implementations for them. Certainly you can design
them badly to get into this kind of trouble, but you don't have to. In
this case the service locator instance is just a simple data holder.
I can easily create the locator with test implementations of my
services.</p><p>For a more sophisticated locator I can subclass service locator
and pass that subclass into the registry's class variable. I can
change the static methods to call a method on the instance rather
accessing instance variables directly. I can provide thread specific
locators by using thread specific storage. All of this can be done
without changing clients of service locator.</p><p>A way to think of this is that service locator is a registry
not a singleton. A singleton provides a simple way of implementing a
registry, but that implementation decision is easily changed. </p>
<a name="UsingASegregatedInterfaceForTheLocator"></a>

<h3>Using a Segregated Interface for the Locator</h3>
<p>One of the issues with the simple approach above, is that the
MovieLister is dependent on the full service locator class, even
though it only uses one service. We can reduce this by using a
<a href="http://www.objectmentor.com/resources/articles/isp.pdf">segregated interface</a>. That way, instead of using the full service
locator interface, the lister can declare just the bit of interface it
needs.</p><p>In this situation the provider of the lister would also
provide a locator interface which it needs to get hold of the
finder.</p><pre>public interface MovieFinderLocator {
    public MovieFinder movieFinder();

</pre><p>The locator then needs to implement this interface to provide
access to a finder.</p><pre>    MovieFinderLocator locator = ServiceLocator.locator();
    MovieFinder finder = locator.movieFinder();
</pre><pre>   public static ServiceLocator locator() {
        return soleInstance;
    }
    public MovieFinder movieFinder() {
        return movieFinder;
    }
    private static ServiceLocator soleInstance;
    private MovieFinder movieFinder;
</pre><p>You'll notice that since we want to use an interface, we
can't just access the services through static methods any more. We
have to use the class to get a locator instance and then use that to
get what we need. </p>
<a name="ADynamicServiceLocator"></a>

<h3>A Dynamic Service Locator</h3>
<p>The above example was static, in that the service locator
class has methods for each of the services that you need. This isn't
the only way of doing it, you can also make a dynamic service locator
that allows you to stash any service you need into it and make your
choices at runtime.</p><p>In this case, the service locator uses a map instead of
fields for each of the services, and provides generic methods to get
and load services.</p><pre>class ServiceLocator...
    private static ServiceLocator soleInstance;
    public static void load(ServiceLocator arg) {
        soleInstance = arg;
    }
    private Map services = new HashMap();
    public static Object getService(String key){
        return soleInstance.services.get(key);
    }
    public void loadService (String key, Object service) {
        services.put(key, service);
    }
</pre><p>Configuring involves loading a service with an appropriate
key.</p><pre>class Tester...
    private void configure() {
        ServiceLocator locator = new ServiceLocator();
        locator.loadService("MovieFinder", new ColonMovieFinder("movies1.txt"));
        ServiceLocator.load(locator);
    }
</pre><p>I use the service by using the same key string.</p><pre>class MovieLister...
    MovieFinder finder = (MovieFinder) ServiceLocator.getService("MovieFinder");

</pre><p>On the whole I dislike this approach. Although it's certainly
flexible, it's not very explicit. The only way I can find out how to
reach a service is through textual keys. I prefer explicit methods
because it's easier to find where they are by looking at the interface
definitions.</p>
<a name="UsingBothALocatorAndInjectionWithAvalon"></a>

<h3>Using both a locator and injection with Avalon</h3>
<p>Dependency injection and a service locator aren't necessarily
			mutually exclusive concepts. A good example of using both
			together is the Avalon framework. Avalon uses a service locator,
			but uses injection to tell components where to find the locator.</p><p>Berin Loritsch sent me this simple version of my
			running example using Avalon.</p><pre>
public class MyMovieLister implements MovieLister, Serviceable {
    private MovieFinder finder;

    public void service( ServiceManager manager ) throws ServiceException {
        finder = (MovieFinder)manager.lookup("finder");
    } 
      </pre><p>The service method is an example of interface injection,
			allowing the container to inject a service manager into
			MyMovieLister. The service manager is an example of a service
			locator. In this example the lister doesn't store the manager in
			a field, instead it immediately uses it to lookup the finder,
			which it does store.</p><hr class="topSection">
<a name="DecidingWhichOptionToUse"></a>

<h2>Deciding which option to use</h2>
<p>So far I've concentrated on explaining how I see these patterns
and their variations. Now I can start talking about their pros and
cons to help figure out which ones to use and when.</p>

<a name="ServiceLocatorVsDependencyInjection"></a>

<h3>Service Locator vs Dependency Injection</h3>
<p>The fundamental choice is between Service Locator and Dependency
Injection. The first point is that both implementations provide the
fundamental decoupling that's missing in the naive example - in both
cases application code is independent of the concrete implementation
of the service interface. The important difference between the two
patterns is about how that implementation is provided to the
application class. With service locator the application class asks for
it explicitly by a message to the locator. With injection there is no
explicit request, the service appears in the application class - hence
the inversion of control.</p><p>Inversion of control is a common feature of frameworks, but
it's something that comes at a price. It tends to be hard to
understand and leads to problems when you are trying to debug. So on
the whole I prefer to avoid it unless I need it. This isn't to say
it's a bad thing, just that I think it needs to justify itself over
the more straightforward alternative.</p><p>The key difference is that with a Service Locator every user
of a service has a dependency to the locator. The locator can hide
dependencies to other implementations, but you do need to see the
locator. So the decision between locator and injector depends on
whether that dependency is a problem.</p><p>Using dependency injection can help make it easier to see what the
component dependencies are. With dependency injector you can just look at
the injection mechanism, such as the constructor, and see the
dependencies. With the service locator you have to search the source
code for calls to the locator. Modern IDEs with a find references
feature make this easier, but it's still not as easy as looking at the
constructor or setting methods.</p><p>A lot of this depends on the nature of the user of the
service. If you are building an application with various classes that
use a service, then a dependency from the application classes to the
locator isn't a big deal. In my example of giving a Movie Lister to my
friends, then using a service locator works quite well. All they need
to do is to configure the locator to hook in the right service
implementations, either through some configuration code or through a
configuration file. In this kind of scenario I don't see the
injector's inversion as providing anything compelling.</p><p>The difference comes if the lister is a component that I'm
providing to an application that other people are writing. In this
case I don't know much about the APIs of the service locators that my customers
are going to use. Each customer might have their own incompatible
service locators. I can get around around some of this by using the
segregated interface. Each customer can write an adapter that matches
my interface to their locator, but in any case I still need to see the
first locator to lookup my specific interface. And once the adapter
appears then the simplicity of the direct connection to a locator is
beginning to slip.</p><p>Since with an injector you don't have a dependency from a
component to the injector, the component cannot obtain further
services from the injector once it's been configured. </p><p>A common reason people give for preferring dependency injection
is that it makes testing easier. The point here is that to do testing,
you need to easily replace real service implementations with stubs or
mocks. However there is really no difference here between dependency
injection and service locator: both are very amenable to stubbing. I
suspect this observation comes from projects where people don't make
the effort to ensure that their service locator can be easily
substituted. This is where continual testing helps, if you can't
easily stub services for testing, then this implies a serious problem
with your design.</p><p>Of course the testing problem is exacerbated by component
environments that are very intrusive, such as Java's EJB framework. My
view is that these kinds of frameworks should minimize their impact
upon application code, and particularly should not do things that slow
down the edit-execute cycle. Using plugins to substitute heavyweight
components does a lot help this process, which is vital for practices
such as Test Driven Development.</p><p>So the primary issue is for people who are writing code that
expects to be used in applications outside of the control of the
writer. In these cases even a minimal assumption about a Service
Locator is a problem.</p>
<a name="ConstructorVersusSetterInjection"></a>

<h3>Constructor versus Setter Injection</h3>
<p>For service combination, you always have to have some
convention in order to wire things together. The advantage of
injection is primarily that it requires very simple conventions - at
least for the constructor and setter injections. You don't
have to do anything odd in your component and it's fairly
straightforward for an injector to get everything configured.</p><p>Interface injection
is more invasive since you have to write a lot of interfaces to get
things all sorted out. For a small set of interfaces required by the
container, such as in Avalon's approach, this isn't too bad. But it's
a lot of work for assembling components and dependencies, which is why
the current crop of lightweight containers go with setter and
constructor injection.</p><p>The choice between setter and constructor injection is
interesting as it mirrors a more general issue with object-oriented
programming - should you fill fields in a constructor or with
setters.</p><p>My long running default with objects is as much as possible,
to create valid objects at construction time. This advice goes back to
Kent Beck's <a href="http://www.amazon.com/exec/obidos/ASIN/013476904X">Smalltalk Best Practice Patterns</a>: Constructor Method and
Constructor Parameter Method. Constructors with parameters give you a
clear statement of what it means to create a valid object in an
obvious place. If there's more than one way to do it, create multiple
constructors that show the different combinations.</p><p>Another advantage with constructor initialization is that it
allows you to clearly hide any fields that are immutable by simply not
providing a setter. I think this is important - if something shouldn't
change then the lack of a setter communicates this very well. If you
use setters for initialization, then this can become a pain. (Indeed
in these situations I prefer to avoid the usual setting convention,
I'd prefer a method like <code>initFoo</code>, to stress that it's
something you should only do at birth.)</p><p>But with any situation there are exceptions. If you have a
lot of constructor parameters things can look messy, particularly in
languages without keyword parameters. It's true that a long
constructor is often a sign of an over-busy object that should be
split, but there are cases when that's what you need.</p><p>If you have multiple ways to construct a valid object, it can
be hard to show this through constructors, since constructors can only
vary on the number and type of parameters. This is when Factory
Methods come into play, these can use a combination of private
constructors and setters to implement their work. The problem with
classic Factory Methods for components assembly is that they are
usually seen as static methods, and you can't have those on
interfaces. You can make a factory class, but then that just becomes
another service instance. A factory service is often a good tactic,
but you still have to instantiate the factory using one of the
techniques here.</p><p>Constructors also suffer if you have simple parameters such
as strings. With setter injection you can give each setter a name to
indicate what the string is supposed to do. With constructors you are
just relying on the position, which is harder to follow.</p><p>If you have multiple constructors and inheritance, then
things can get particularly awkward. In order to initialize everything
you have to provide constructors to forward to each superclass
constructor, while also adding you own arguments. This can lead to an
even bigger explosion of constructors.</p><p>Despite the disadvantages my preference is to start with
constructor injection, but be ready to switch to setter injection as
soon as the problems I've outlined above start to become a problem.
</p><p>This issue has led to a lot of debate between the various
teams who provide dependency injectors as part of their
frameworks. However it seems that most people who build these
frameworks have realized that it's important to support both
mechanisms, even if there's a preference for one of them.</p>

<a name="CodeOrConfigurationFiles"></a>

<h3>Code or configuration files</h3>
<p>A separate but often conflated issue is whether to use
configuration files or code on an API to wire up services. For most
applications that are likely to be deployed in many places, a separate
configuration file usually makes most sense. Almost all the time this
will be an XML file, and this makes sense. However there are cases
where it's easier to use program code to do the assembly. One case is
where you have a simple application that's not got a lot of deployment
variation. In this case a bit of code can be clearer than separate XML
file. </p><p>A contrasting case is where the assembly is quite complex,
involving conditional steps. Once you start getting close to
programming language then XML starts breaking down and it's better to
use a real language that has all the syntax to write a clear program.
You then write a builder class that does the assembly. If you have
distinct builder scenarios you can provide several builder classes and
use a simple configuration file to select between them. 
</p><p>I often think that people are over-eager to define
configuration files. Often a programming language makes a
straightforward and powerful configuration mechanism. Modern languages
can easily compile small assemblers that can be used to assemble
plugins for larger systems. If compilation is a pain, then there are
scripting languages that can work well also. </p><p>It's often said that configuration files shouldn't use a
programing language because they need to be edited by non-programmers.
But how often is this the case? Do people really expect
non-programmers to alter the transaction isolation levels of complex
server-side application? Non-language configuration files work well
only to the extent they are simple. If they become complex then it's
time to think about using a proper programming language.</p><p>One thing we're seeing in the Java world at the moment is a
cacophony of configuration files, where every component has its own
configuration files which are different to everyone else's. If you use
a dozen of these components, you can easily end up with a dozen
configuration files to keep in sync.</p><p>My advice here is to always provide a way to do all
configuration easily with a programmatic interface, and then treat a
separate configuration file as an optional feature. You can easily
build configuration file handling to use the programmatic interface.
If you are writing a component you then leave it up to your user
whether to use the programmatic interface, your configuration file
format, or to write their own custom configuration file format and tie
it into the programmatic interface</p>
<a name="SeparatingConfigurationFromUse"></a>

<h3>Separating Configuration from Use</h3>
<p>The important issue in all of this is to ensure that the
configuration of services is separated from their use. Indeed this is
a fundamental design principle that sits with the separation of
interfaces from implementation. It's something we see within an
object-oriented program when conditional logic decides which class to
instantiate, and then future evaluations of that conditional are done
through polymorphism rather than through duplicated conditional
code.</p><p>If this separation is useful within a single code base, it's
especially vital when you're using foreign elements such as components
and services. The first question is whether you wish to defer the
choice of implementation class to particular deployments. If so you
need to use some implementation of plugin. Once you are using plugins
then it's essential that the assembly of the plugins is done
separately from the rest of the application so that you can substitute
different configurations easily for different deployments. How you
achieve this is secondary. This configuration mechanism can either
configure a service locator, or use injection to configure objects
directly.</p><hr class="topSection">

<a name="SomeFurtherIssues"></a>

<h2>Some further issues</h2>
<p>In this article, I've concentrated on the basic issues of
service configuration using Dependency Injection and Service Locator.
There are some more topics that play into this which also deserve
attention, but I haven't had time yet to dig into. In particular there
is the issue of life-cycle behavior. Some components have distinct
life-cycle events: stop and starts for instance. Another issue is the
growing interest in using aspect oriented ideas with these containers.
Although I haven't considered this material in the article at the
moment, I do hope to write more about this either by extending this
article or by writing another.</p><p>You can find out a lot more about these ideas by looking at the
web sites devoted to the lightweight containers. Surfing from the
<a href="http://www.picocontainer.org/">picocontainer</a> and <a href="http://www.springframework.org/">spring</a> web sites will lead to you into
much more discussion of these issues and a start on some of the
further issues.</p><hr class="topSection">
<a name="ConcludingThoughts"></a>

<h2>Concluding Thoughts</h2>

<p>The current rush of lightweight containers all have a common
underlying pattern to how they do service assembly - the dependency
injector pattern. Dependency Injection is a useful alternative
to Service Locator. When building application classes the two are
roughly equivalent, but I think Service Locator has a slight edge due
to its more straightforward behavior. However if you are building
classes to used in multiple applications then Dependency Injection is a
better choice.</p><p>If you use Dependency Injection there are a number of styles to
choose between. I would suggest you follow constructor injection
unless you run into into one of the specific problems with that
approach, in which case switch to setter injection. If you are
choosing to build or obtain a container, look for one that supports
both constructor and setter injection.</p><p>The choice between Service Locator and Dependency Injection is less
important than the principle of separating service configuration from
the use of services within an application. </p><hr class="bodySep"></div>

<div class="appendix"><hr class="topSection">
<a name="Acknowledgements"></a>

<h2>Acknowledgements</h2>
<p>My sincere thanks to the many people who've helped me with this
		article. Rod Johnson, Paul Hammant, Joe Walnes,
		Aslak Helles?y, Jon Tirs?n and Bill Caputo helped me get to grips
		with these concepts and commented on the early drafts of this article. Berin
		Loritsch and Hamilton Verissimo de Oliveira provided some very helpful
		advice on how Avalon fits in. Dave W Smith
		persisted in asking questions about my initial interface injection
		configuration code and thus made me confront the fact that it was stupid.</p></div>

<div class="appendix">
<h2>
<a name="SignificantRevisions"></a>
Significant Revisions</h2>

<p><i>23 Jan 04: </i>Redid the configuration code of the interface
	injection example.</p>

<p><i>16 Jan 04: </i>Added a short example of both locator and
	injection with Avalon.</p>

<p><i>14 Jan 04: </i>First Publication</p>

HIBERNATE - Persistance relationnelle en Java standard
Documentation de référence d'Hibernate

3.1final

Table des matières

Préface
1. Introduction à Hibernate

    1.1. Préface
    1.2. Partie 1 - Première application Hibernate

        1.2.1. La première classe
        1.2.2. Le fichier de mapping
        1.2.3. Configuration d'Hibernate
        1.2.4. Construction avec Ant
        1.2.5. Démarrage et aides
        1.2.6. Charger et stocker des objets

    1.3. Partie 2 - Mapper des associations

        1.3.1. Mapper la classe Person
        1.3.2. Une association unidirectionnelle basée sur Set
        1.3.3. Travailler avec l'association
        1.3.4. Collection de valeurs
        1.3.5. Associations bidirectionnelles
        1.3.6. Travailler avec des liens bidirectionnels

    1.4. Part 3 - L'application web EventManager

        1.4.1. Ecrire la servlet de base
        1.4.2. Procéder et rendre
        1.4.3. Déployer et tester

    1.5. Résumé

2. Architecture

    2.1. Généralités
    2.2. Etats des instances
    2.3. Intégration JMX
    2.4. Support JCA
    2.5. Sessions Contextuelles

3. Configuration

    3.1. Configuration par programmation
    3.2. Obtenir une SessionFactory
    3.3. Connexions JDBC
    3.4. Propriétés de configuration optionnelles

        3.4.1. Dialectes SQL
        3.4.2. Chargement par Jointure Ouverte
        3.4.3. Flux binaires
        3.4.4. Cache de second niveau et cache de requêtes
        3.4.5. Substitution dans le langage de requêtage
        3.4.6. Statistiques Hibernate

    3.5. Tracer
    3.6. Implémenter une NamingStrategy
    3.7. Fichier de configuration XML
    3.8. Intégration à un serveur d'application J2EE

        3.8.1. Configuration de la stratégie transactionnelle
        3.8.2. SessionFactory associée au JNDI
        3.8.3. Association automatique de la Session à JTA
        3.8.4. Déploiement JMX

4. Classes persistantes

    4.1. Un exemple simple de POJO

        4.1.1. Implémenter un constructeur sans argument
        4.1.2. Fournir une propriété d'indentifiant (optionnel)
        4.1.3. Favoriser les classes non finales (optionnel)
        4.1.4. Déclarer les accesseurs et mutateurs des attributs persistants (optionnel)

    4.2. Implémenter l'héritage
    4.3. Implémenter equals() et hashCode()
    4.4. Modèles dynamiques
    4.5. Tuplizers

5. Mapping O/R basique

    5.1. Déclaration de Mapping

        5.1.1. Doctype
        5.1.2. hibernate-mapping
        5.1.3. class
        5.1.4. id

            5.1.4.1. Generator
            5.1.4.2. algorithme Hi/lo
            5.1.4.3. UUID algorithm
            5.1.4.4. Colonnes identifiantes et séquences
            5.1.4.5. Identifiants assignés
            5.1.4.6. Clefs primaires assignées par trigger

        5.1.5. composite-id
        5.1.6. discriminator
        5.1.7. version (optionnel)
        5.1.8. timestamp (optionnel)
        5.1.9. property
        5.1.10. many-to-one
        5.1.11. one-to-one
        5.1.12. natural-id
        5.1.13. component, dynamic-component
        5.1.14. properties
        5.1.15. subclass
        5.1.16. joined-subclass
        5.1.17. union-subclass
        5.1.18. join
        5.1.19. key
        5.1.20. éléments column et formula
        5.1.21. import
        5.1.22. any

    5.2. Hibernate Types

        5.2.1. Entités et valeurs
        5.2.2. Basic value types
        5.2.3. Types de valeur définis par l'utilisateur

    5.3. Mapper une classe plus d'une fois
    5.4. SQL quoted identifiers
    5.5. alternatives Metadata

        5.5.1. utilisation de XDoclet
        5.5.2. Utilisation des annotations JDK 5.0

    5.6. Propriétés générées
    5.7. Objets auxiliaires de la base de données

6. Mapping des collections

    6.1. Collections persistantes
    6.2. Mapper une collection

        6.2.1. Les clefs étrangères d'une collection
        6.2.2. Les éléments d'une collection
        6.2.3. Collections indexées
        6.2.4. Collections de valeurs et associations plusieurs-vers-plusieurs
        6.2.5. Association un-vers-plusieurs

    6.3. Mappings de collection avancés

        6.3.1. Collections triées
        6.3.2. Associations bidirectionnelles
        6.3.3. Associations bidirectionnelles avec des collections indexées
        6.3.4. Associations ternaires
        6.3.5. Utiliser un <idbag>

    6.4. Exemples de collections

7. Mapper les associations

    7.1. Introduction
    7.2. Association unidirectionnelle

        7.2.1. plusieurs à un
        7.2.2. un à un
        7.2.3. un à plusieurs

    7.3. Associations unidirectionnelles avec tables de jointure

        7.3.1. un à plusieurs
        7.3.2. plusieurs à un
        7.3.3. un à un
        7.3.4. plusieurs à plusieurs

    7.4. Associations bidirectionnelles

        7.4.1. un à plusieurs / plusieurs à un
        7.4.2. Un à un

    7.5. Associations bidirectionnelles avec table de jointure

        7.5.1. un à plusieurs / plusieurs à un
        7.5.2. Un à un
        7.5.3. plusieurs à plusieurs

    7.6. Des mappings plus complexes

8. Mapping de composants

    8.1. Objects dépendants
    8.2. Collection d'objets dépendants
    8.3. Utiliser les composants comme index de map
    8.4. Utiliser un composant comme identifiant
    8.5. Composant Dynamique

9. Mapping d'héritage de classe

    9.1. Les trois stratégies

        9.1.1. Une table par hiérarchie de classe
        9.1.2. Une table par classe fille
        9.1.3. Une table par classe fille, en utilisant un discriminant
        9.1.4. Mélange d'une table par hiérarchie de classe avec une table par classe fille
        9.1.5. Une table par classe concrète
        9.1.6. Une table par classe concrète, en utilisant le polymorphisme implicite
        9.1.7. Mélange du polymorphisme implicite avec d'autres mappings d'héritage

    9.2. Limitations

10. Travailler avec des objets

    10.1. États des objets Hibernate
    10.2. Rendre des objets persistants
    10.3. Chargement d'un objet
    10.4. Requêtage

        10.4.1. Exécution de requêtes

            10.4.1.1. Itération de résultats
            10.4.1.2. Requêtes qui retournent des tuples
            10.4.1.3. Résultats scalaires
            10.4.1.4. Lier des paramètres
            10.4.1.5. Pagination
            10.4.1.6. Itération "scrollable"
            10.4.1.7. Externaliser des requêtes nommées

        10.4.2. Filtrer des collections
        10.4.3. Requêtes Criteria
        10.4.4. Requêtes en SQL natif

    10.5. Modifier des objets persistants
    10.6. Modifier des objets détachés
    10.7. Détection automatique d'un état
    10.8. Suppression d'objets persistants
    10.9. Réplication d'objets entre deux entrepôts de données
    10.10. Flush de la session
    10.11. Persistance transitive
    10.12. Utilisation des méta-données

11. Transactions et accès concurrents

    11.1. Gestion de session et délimitation de transactions

        11.1.1. Unité de travail
        11.1.2. Longue conversation
        11.1.3. L'identité des objets
        11.1.4. Problèmes communs

    11.2. Démarcation des transactions

        11.2.1. Environnement non managé
        11.2.2. Utilisation de JTA
        11.2.3. Gestion des exceptions
        11.2.4. Timeout de transaction

    11.3. Contrôle de consurrence optimiste

        11.3.1. Gestion du versionnage au niveau applicatif
        11.3.2. Les sessions longues et le versionnage automatique.
        11.3.3. Les objets détachés et le versionnage automatique
        11.3.4. Personnaliser le versionnage automatique

    11.4. Verouillage pessimiste
    11.5. Mode de libération de Connection

12. Les intercepteurs et les événements

    12.1. Intercepteurs
    12.2. Système d'événements
    12.3. Sécurité déclarative d'Hibernate

13. Traitement par paquet

    13.1. Insertions en paquet
    13.2. Paquet de mises à jour
    13.3. L'interface StatelessSession
    13.4. Opérations de style DML

14. HQL: Langage de requêtage d'Hibernate

    14.1. Sensibilité à la casse
    14.2. La clause from
    14.3. Associations et jointures
    14.4. Formes de syntaxes pour les jointures
    14.5. La clause select
    14.6. Fonctions d'aggrégation
    14.7. Requêtes polymorphiques
    14.8. La clause where
    14.9. Expressions
    14.10. La clause order by
    14.11. La clause group by
    14.12. Sous-requêtes
    14.13. Exemples HQL
    14.14. Mise à jour et suppression
    14.15. Trucs & Astuces

15. Requêtes par critères

    15.1. Créer une instance de Criteria
    15.2. Restriction du résultat
    15.3. Trier les résultats
    15.4. Associations
    15.5. Peuplement d'associations de manière dynamique
    15.6. Requêtes par l'exemple
    15.7. Projections, agrégation et regroupement
    15.8. Requêtes et sous-requêtes détachées
    15.9. Requêtes par identifiant naturel

16. SQL natif

    16.1. Utiliser une SQLQuery
    16.2. Alias et références de propriété
    16.3. Requêtes SQL nommées

        16.3.1. Utilisation de return-property pour spécifier explicitement les noms des colonnes/alias
        16.3.2. Utilisation de procédures stockées pour les requêtes

            16.3.2.1. Règles/limitations lors de l'utilisation des procédures stockées

    16.4. SQL personnalisé pour créer, mettre à jour et effacer
    16.5. SQL personnalisé pour le chargement

17. Filtrer les données

    17.1. Filtres Hibernate

18. Mapping XML

    18.1. Travailler avec des données XML

        18.1.1. Spécifier le mapping XML et le mapping d'une classe ensemble
        18.1.2. Spécifier seulement un mapping XML

    18.2. Métadonnées du mapping XML
    18.3. Manipuler des données XML

19. Améliorer les performances

    19.1. Stratégies de chargement

        19.1.1. Travailler avec des associations chargées tardivement
        19.1.2. Personnalisation des stratégies de chargement
        19.1.3. Proxys pour des associations vers un seul objet
        19.1.4. Initialisation des collections et des proxys
        19.1.5. Utiliser le chargement par lot
        19.1.6. Utilisation du chargement par sous select
        19.1.7. Utiliser le chargement tardif des propriétés

    19.2. Le cache de second niveau

        19.2.1. Mapping de Cache
        19.2.2. Strategie : lecture seule
        19.2.3. Stratégie : lecture/écriture
        19.2.4. Stratégie : lecture/écriture non stricte
        19.2.5. Stratégie : transactionelle

    19.3. Gérer les caches
    19.4. Le cache de requêtes
    19.5. Comprendre les performances des Collections

        19.5.1. Classification
        19.5.2. Les lists, les maps, les idbags et les sets sont les collections les plus efficaces pour la mise à jour
        19.5.3. Les Bags et les lists sont les plus efficaces pour les collections inverse
        19.5.4. Suppression en un coup

    19.6. Moniteur de performance

        19.6.1. Suivi d'une SessionFactory
        19.6.2. Métriques

20. Guide des outils

    20.1. Génération automatique du schéma

        20.1.1. Personnaliser le schéma
        20.1.2. Exécuter l'outil
        20.1.3. Propriétés
        20.1.4. Utiliser Ant
        20.1.5. Mises à jour incrémentales du schéma
        20.1.6. Utiliser Ant pour des mises à jour de schéma par incrément
        20.1.7. Utiliser Ant pour la validation du Schéma

21. Exemple : Père/Fils

    21.1. Une note à propos des collections
    21.2. un-vers-plusieurs bidirectionnel
    21.3. Cycle de vie en cascade
    21.4. Cascades et unsaved-value
    21.5. Conclusion

22. Exemple : application Weblog

    22.1. Classes persistantes
    22.2. Mappings Hibernate
    22.3. Code Hibernate

23. Exemple : quelques mappings

    23.1. Employeur/Employé (Employer/Employee)
    23.2. Auteur/Travail (Author/Work)
    23.3. Client/Commande/Produit (Customer/Order/Product)
    23.4. Divers mappings d'exemple

        23.4.1. "Typed" one-to-one association
        23.4.2. Exemple de clef composée
        23.4.3. Many-to-many avec une clef composée partagée
        23.4.4. Contenu basé sur une discrimination
        23.4.5. Associations sur des clefs alternées

24. Meilleures pratiques

Préface

Traducteur(s): Vincent Ricard, Sebastien Cesbron, Michael Courcy, Vincent Giguère, Baptiste Mathus, Emmanuel Bernard, Anthony Patricio

Travailler dans les deux univers que sont l'orienté objet et la base de données relationnelle peut être lourd et consommateur en temps dans le monde de l'entreprise d'aujourd'hui. Hibernate est un outil de mapping objet/relationnel pour le monde Java. Le terme mapping objet/relationnel (ORM) décrit la technique consistant à faire le lien entre la représentation objet des données et sa représentation relationnelle basée sur un schéma SQL.

Non seulement, Hibernate s'occupe du transfert des classes Java dans les tables de la base de données (et des types de données Java dans les types de données SQL), mais il permet de requêter les données et propose des moyens de les récupérer. Il peut donc réduire de manière significative le temps de développement qui aurait été autrement perdu dans une manipulation manuelle des données via SQL et JDBC.

Le but d'Hibernate est de libérer le développeur de 95 pourcent des tâches de programmation liées à la persistence des données communes. Hibernate n'est probablement pas la meilleure solution pour les applications centrées sur les données qui n'utilisent que les procédures stockées pour implémenter la logique métier dans la base de données, il est le plus utile dans les modèles métier orientés objets dont la logique métier est implémentée dans la couche Java dite intermédiaire. Cependant, Hibernate vous aidera à supprimer ou à encapsuler le code SQL spécifique à votre base de données et vous aidera sur la tâche commune qu'est la transformation des données d'une représentation tabulaire à une représentation sous forme de graphe d'objets.

Si vous êtes nouveau dans Hibernate et le mapping Objet/Relationnel voire même en Java, suivez ces quelques étapes :

   1.

      Lisez Chapitre 1, Introduction à Hibernate pour un didacticiel plus long avec plus d'instructions étape par étape.
   2.

      Lisez Chapitre 2, Architecture pour comprendre les environnements dans lesquels Hibernate peut être utilisé.
   3.

      Regardez le répertoire eg de la distribution Hibernate, il contient une application simple et autonome. Copiez votre pilote JDBC dans le répertoire lib/ et éditez src/hibernate.properties, en positionnant correctement les valeurs pour votre base de données. A partir d'une invite de commande dans le répertoire de la distribution, tapez ant eg (cela utilise Ant), ou sous Windows tapez build eg.
   4.

      Faîtes de cette documentation de référence votre principale source d'information. Pensez à lire Hibernate in Action (http://www.manning.com/bauer) si vous avez besoin de plus d'aide avec le design d'applications ou si vous préférez un tutoriel pas à pas. Visitez aussi http://caveatemptor.hibernate.org et téléchargez l'application exemple pour Hibernate in Action.
   5.

      Les questions les plus fréquemment posées (FAQs) trouvent leur réponse sur le site web Hibernate.
   6.

      Des démos, exemples et tutoriaux de tierces personnes sont référencés sur le site web Hibernate.
   7.

      La zone communautaire (Community Area) du site web Hibernate est une bonne source d'information sur les design patterns et sur différentes solutions d'intégration d'Hibernate (Tomcat, JBoss, Spring Framework, Struts, EJB, etc). 

Si vous avez des questions, utilisez le forum utilisateurs du site web Hibernate. Nous utilisons également l'outil de gestion des incidents JIRA pour tout ce qui est rapports de bogue et demandes d'évolution. Si vous êtes intéressé par le développement d'Hibernate, joignez-vous à la liste de diffusion de développement.

Le développement commercial, le support de production et les formations à Hibernate sont proposés par JBoss Inc (voir http://www.hibernate.org/SupportTraining/). Hibernate est un projet Open Source professionnel et un composant critique de la suite de produits JBoss Enterprise Middleware System (JEMS).
Chapitre 1. Introduction à Hibernate
1.1. Préface

Ce chapitre est un didacticiel introductif destiné aux nouveaux utilisateurs d'Hibernate. Nous commençons avec une simple application en ligne de commande utilisant une base de données en mémoire, et la développons en étapes faciles à comprendre.

Ce didacticiel est destiné aux nouveaux utilisateurs d'Hibernate mais requiert des connaissances Java et SQL. Il est basé sur un didacticiel de Michael Gloegl, les bibliothèques tierces que nous nommons sont pour les JDK 1.4 et 5.0. Vous pourriez avoir besoin d'autres bibliothèques pour le JDK 1.3.

Le code source de ce tutoriel est inclus dans la distribution dans le répertoire doc/reference/tutorial/.
1.2. Partie 1 - Première application Hibernate

D'abord, nous créerons une simple application Hibernate en console. Nous utilisons une base de données en mémoire (HSQL DB), donc nous n'avons pas à installer de serveur de base de données.

Supposons que nous ayons besoin d'une petite application de base de données qui puisse stocker des événements que nous voulons suivre, et des informations à propos des hôtes de ces événements.

La première chose que nous faisons est de configurer notre répertoire de développement et de mettre toutes les bibliothèques dont nous avons besoin dedans. Téléchargez la distribution Hibernate à partir du site web d'Hibernate. Extrayez le paquet et placez toutes les bibliothèques requises trouvées dans /lib dans le répertoire /lib de votre nouveau répertoire de travail. Il devrait ressembler à ça :

.
+lib
  antlr.jar
  cglib-full.jar
  asm.jar
  asm-attrs.jars
  commons-collections.jar
  commons-logging.jar
  ehcache.jar
  hibernate3.jar
  jta.jar
  dom4j.jar
  log4j.jar 

Ceci est l'ensemble minimum de bibliothèques requises (notez que nous avons aussi copié hibernate3.jar, l'archive principale) pour Hibernate. Lisez le fichier README.txt dans le répertoire lib/ de la distribution Hibernate pour plus d'informations à propos des biliothèques tierces requises et optionnelles. (En fait, log4j n'est pas requis mais préféré par beaucoup de développeurs.)

Ensuite, nous créons une classe qui réprésente l'événement que nous voulons stocker dans notre base de données.
1.2.1. La première classe

Notre première classe persistante est une simple classe JavaBean avec quelques propriétés :

package events;

import java.util.Date;

public class Event {
    private Long id;

    private String title;
    private Date date;

    public Event() {}

    public Long getId() {
        return id;
    }

    private void setId(Long id) {
        this.id = id;
    }

    public Date getDate() {
        return date;
    }

    public void setDate(Date date) {
        this.date = date;
    }

    public String getTitle() {
        return title;
    }

    public void setTitle(String title) {
        this.title = title;
    }
}

Vous pouvez voir que cette classe utilise les conventions de nommage standard JavaBean pour les méthodes getter/setter des propriétés, ainsi qu'une visibilité privée pour les champs. Ceci est la conception recommandée - mais pas obligatoire. Hibernate peut aussi accéder aux champs directement, le bénéfice des méthodes d'accès est la robustesse pour la refonte de code. Le constructeur sans argument est requis pour instancier un objet de cette classe via reflexion.

La propriété id contient la valeur d'un identifiant unique pour un événement particulier. Toutes les classes d'entités persistantes (ainsi que les classes dépendantes de moindre importance) auront besoin d'une telle propriété identifiante si nous voulons utiliser l'ensemble complet des fonctionnalités d'Hibernate. En fait, la plupart des applications (surtout les applications web) ont besoin de distinguer des objets par des identifiants, donc vous devriez considérer ça comme une fonctionnalité plutôt que comme une limitation. Cependant, nous ne manipulons généralement pas l'identité d'un objet, dorénavant la méthode setter devrait être privée. Seul Hibernate assignera les identifiants lorsqu'un objet est sauvegardé. Vous pouvez voir qu'Hibernate peut accéder aux méthodes publiques, privées et protégées, ainsi qu'aux champs (publics, privés, protégés) directement. Le choix vous est laissé, et vous pouvez l'ajuster à la conception de votre application.

Le constructeur sans argument est requis pour toutes les classes persistantes ; Hibernate doit créer des objets pour vous en utilisant la réflexion Java. Le constructeur peut être privé, cependant, la visibilité du paquet est requise pour la génération de proxy à l'exécution et une récupération des données efficaces sans instrumentation du bytecode.

Placez ce fichier source Java dans un répertoire appelé src dans le dossier de développement. Ce répertoire devrait maintenant ressembler à ça :

.
+lib
  <Hibernate et bibliothèques tierces>
+src
  +events
    Event.java

Dans la prochaine étape, nous informons Hibernate de cette classe persistante.
1.2.2. Le fichier de mapping

Hibernate a besoin de savoir comment charger et stocker des objets d'une classe persistante. C'est là qu'intervient le fichier de mapping Hibernate. Le fichier de mapping indique à Hibernate à quelle table dans la base de données il doit accéder, et quelles colonnes de cette table il devra utiliser.

La structure basique de ce fichier de mapping ressemble à ça :

<?xml version="1.0"?>
<!DOCTYPE hibernate-mapping PUBLIC
        "-//Hibernate/Hibernate Mapping DTD 3.0//EN"
        "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd">

<hibernate-mapping>
[...]
</hibernate-mapping>

Notez que la DTD Hibernate est très sophistiquée. Vous pouvez l'utiliser pour l'auto-complétement des éléments et des attributs de mapping XML dans votre éditeur ou votre IDE. Vous devriez aussi ouvrir le fichier DTD dans votre éditeur de texte - c'est le moyen le plus facile d'obtenir une vue d'ensemble de tous les éléments et attributs, et de voir les valeurs par défaut, ainsi que quelques commentaires. Notez qu'Hibernate ne chargera pas le fichier DTD à partir du web, mais regardera d'abord dans le classpath de l'application. Le fichier DTD est inclus dans hibernate3.jar ainsi que dans le répertoire src de la distribution Hibernate.

Nous omettrons la déclaration de la DTD dans les exemples futurs pour raccourcir le code. Bien sûr il n'est pas optionnel.

Entre les deux balises hibernate-mapping, incluez un élément class. Toutes les classes d'entités persistantes (encore une fois, il pourrait y avoir des classes dépendantes plus tard, qui ne sont pas des entités mère) ont besoin d'un mapping vers une table de la base de données SQL :

<hibernate-mapping>

    <class name="Event" table="EVENTS">

    </class>

</hibernate-mapping>

Plus loin, nous disons à Hibernate comment persister et charger un objet de la classe Event dans la table EVENTS, chaque instance est représentée par une ligne dans cette table. Maintenant nous continuons avec le mapping de la propriété de l'identifiant unique vers la clef primaire de la table. De plus, comme nous ne voulons pas nous occuper de la gestion de cet identifiant, nous utilisons une stratégie de génération d'identifiant d'Hibernate pour la colonne de la clef primaire subrogée :

<hibernate-mapping>

    <class name="Event" table="EVENTS">
        <id name="id" column="EVENT_ID">
            <generator class="increment"/>
        </id>
    </class>

</hibernate-mapping>

L'élément id est la déclaration de la propriété de l'identifiant, name="id" déclare le nom de la propriété Java - Hibernate utilisera les méthodes getter et setter pour accéder à la propriété. L'attribut column indique à Hibernate quelle colonne de la table EVENTS nous utilisons pour cette clef primaire. L'élément generator imbriqué spécifie la stratégie de génération de l'identifiant, dans ce cas nous avons utilisé increment, laquelle est une méthode très simple utile surtout pour les tests (et didacticiels). Hibernate supporte aussi les identifiants générés par les bases de données, globalement uniques, ainsi que les identifiants assignés par l'application (ou n'importe quelle stratégie que vous avez écrit en extension).

Finalement nous incluons des déclarations pour les propriétés persistantes de la classe dans le fichier de mapping. Par défaut, aucune propriété de la classe n'est considérée comme persistante :

<hibernate-mapping>

    <class name="Event" table="EVENTS">
        <id name="id" column="EVENT_ID">
            <generator class="increment"/>
        </id>
        <property name="date" type="timestamp" column="EVENT_DATE"/>
        <property name="title"/>
    </class>

</hibernate-mapping>

Comme avec l'élément id, l'attribut name de l'élément property indique à Hibernate quels getters/setters utiliser.

Pourquoi le mapping de la propriété date inclut l'attribut column, mais pas title ? Sans l'attribut column Hibernate utilise par défaut le nom de la propriété comme nom de colonne. Ca fonctionne bien pour title. Cependant, date est un mot clef réservé dans la plupart des bases de données, donc nous utilisons un nom différent pour le mapping.

La prochaine chose intéressante est que le mapping de title manque aussi d'un attribut type. Les types que nous déclarons et utilisons dans les fichiers de mapping ne sont pas, comme vous pourriez vous y attendre, des types de données Java. Ce ne sont pas, non plus, des types de base de données SQL. Ces types sont donc appelés des types de mapping Hibernate, des convertisseurs qui peuvent traduire des types Java en types SQL et vice versa. De plus, Hibernate tentera de déterminer la bonne conversion et le type de mapping lui-même si l'attribut type n'est pas présent dans le mapping. Dans certains cas, cette détection automatique (utilisant la réflexion sur la classe Java) pourrait ne pas donner la valeur attendue ou dont vous avez besoin. C'est le cas avec la propriété date. Hibernate ne peut pas savoir si la propriété "mappera" une colonne SQL de type date, timestamp ou time. Nous déclarons que nous voulons conserver des informations avec une date complète et l'heure en mappant la propriété avec un timestamp.

Ce fichier de mapping devrait être sauvegardé en tant que Event.hbm.xml, juste dans le répertoire à côté du fichier source de la classe Java Event. Le nommage des fichiers de mapping peut être arbitraire, cependant le suffixe hbm.xml est devenu une convention dans la communauté des développeurs Hibernate. La structure du répertoire devrait ressembler à ça :

.
+lib
  <Hibernate et bibliothèques tierces>
+src
  Event.java
  Event.hbm.xml

Nous poursuivons avec la configuration principale d'Hibernate.
1.2.3. Configuration d'Hibernate

Nous avons maintenant une classe persistante et son fichier de mapping. Il est temps de configurer Hibernate. Avant ça, nous avons besoin d'une base de données. HSQL DB, un SGBD SQL basé sur Java et travaillant en mémoire, peut être téléchargé à partir du site web de HSQL. En fait, vous avez seulement besoin de hsqldb.jar. Placez ce fichier dans le répertoire lib/ du dossier de développement.

Créez un répertoire appelé data à la racine du répertoire de développement - c'est là que HSQL DB stockera ses fichiers de données. Démarrez maintenant votre base de données en exécutant java -classpath lib/hsqldb.jar org.hsqldb.Server dans votre répertoire de travail. Vous observez qu'elle démarre et ouvre une socket TCP/IP, c'est là que notre application se connectera plus tard. Si vous souhaitez démarrez à partir d'une nouvelle base de données pour ce tutoriel (faites CTRL + C dans la fenêtre the window), effacez le répertoire data/ et redémarrez HSQL DB à nouveau.

Hibernate est la couche de votre application qui se connecte à cette base de données, donc il a besoin des informations de connexion. Les connexions sont établies à travers un pool de connexions JDBC, que nous devons aussi configurer. La distribution Hibernate contient différents outils de gestion de pools de connexions JDBC open source, mais pour ce didacticiel nous utiliserons le pool de connexions intégré à Hibernate. Notez que vous devez copier les bibliothèques requises dans votre classpath et utiliser une configuration de pool de connexions différente si vous voulez utiliser un logiciel de gestion de pools JDBC tiers avec une qualité de production.

Pour la configuration d'Hibernate, nous pouvons utiliser un simple fichier hibernate.properties, un fichier hibernate.cfg.xml légèrement plus sophistiqué, ou même une configuration complète par programmation. La plupart des utilisateurs préfèrent le fichier de configuration XML :

<?xml version='1.0' encoding='utf-8'?>
<!DOCTYPE hibernate-configuration PUBLIC
        "-//Hibernate/Hibernate Configuration DTD 3.0//EN"
        "http://hibernate.sourceforge.net/hibernate-configuration-3.0.dtd">

<hibernate-configuration>

    <session-factory>

        <!-- Database connection settings -->
        <property name="connection.driver_class">org.hsqldb.jdbcDriver</property>
        <property name="connection.url">jdbc:hsqldb:hsql://localhost</property>
        <property name="connection.username">sa</property>
        <property name="connection.password"></property>

        <!-- JDBC connection pool (use the built-in) -->
        <property name="connection.pool_size">1</property>

        <!-- SQL dialect -->
        <property name="dialect">org.hibernate.dialect.HSQLDialect</property>

        <!-- Enable Hibernate's automatic session context management -->
        <property name="current_session_context_class">thread</property>

        <!-- Disable the second-level cache  -->
        <property name="cache.provider_class">org.hibernate.cache.NoCacheProvider</property>

        <!-- Echo all executed SQL to stdout -->
        <property name="show_sql">true</property>

        <!-- Drop and re-create the database schema on startup -->
        <property name="hbm2ddl.auto">create</property>

        <mapping resource="events/Event.hbm.xml"/>

    </session-factory>

</hibernate-configuration>

Notez que cette configuration XML utilise une DTD différente. Nous configurons une SessionFactory d'Hibernate - une fabrique globale responsable d'une base de données particulière. Si vous avez plusieurs base de données, utilisez plusieurs configurations <session-factory>, généralement dans des fichiers de configuration différents (pour un démarrage plus facile).

Les quatre premiers éléments property contiennent la configuration nécessaire pour la connexion JDBC. L'élément property du dialecte spécifie quelle variante du SQL Hibernate va générer. La gestion automatique des sessions d'Hibernate pour les contextes de persistance sera détaillée très vite. L'option hbm2ddl.auto active la génération automatique des schémas de base de données - directement dans la base de données. Cela peut bien sûr aussi être désactivé (en supprimant l'option de configuration) ou redirigé vers un fichier avec l'aide de la tâche Ant SchemaExport. Finalement, nous ajoutons le(s) fichier(s) de mapping pour les classes persistantes.

Copiez ce fichier dans le répertoire source, il terminera dans la racine du classpath. Hibernate cherchera automatiquement, au démarrage, un fichier appelé hibernate.cfg.xml dans la racine du classpath.
1.2.4. Construction avec Ant

Nous allons maintenant construire le didacticiel avec Ant. Vous aurez besoin d'avoir Ant d'installé - récupérez-le à partir de la page de téléchargement de Ant. Comment installer Ant ne sera pas couvert ici. Référez-vous au manuel d'Ant. Après que vous aurez installé Ant, nous pourrons commencer à créer le fichier de construction. Il s'appellera build.xml et sera placé directement dans le répertoire de développement.

Un fichier de construction basique ressemble à ça :

<project name="hibernate-tutorial" default="compile">

    <property name="sourcedir" value="${basedir}/src"/>
    <property name="targetdir" value="${basedir}/bin"/>
    <property name="librarydir" value="${basedir}/lib"/>

    <path id="libraries">
        <fileset dir="${librarydir}">
            <include name="*.jar"/>
        </fileset>
    </path>

    <target name="clean">
        <delete dir="${targetdir}"/>
        <mkdir dir="${targetdir}"/>
    </target>

    <target name="compile" depends="clean, copy-resources">
      <javac srcdir="${sourcedir}"
             destdir="${targetdir}"
             classpathref="libraries"/>
    </target>

    <target name="copy-resources">
        <copy todir="${targetdir}">
            <fileset dir="${sourcedir}">
                <exclude name="**/*.java"/>
            </fileset>
        </copy>
    </target>

</project>

Cela dira à Ant d'ajouter tous les fichiers du répertoire lib finissant par .jar dans le classpath utilisé pour la compilation. Cela copiera aussi tous les fichiers source non Java dans le répertoire cible, par exemple les fichiers de configuration et de mapping d'Hibernate. Si vous lancez Ant maintenant, vous devriez obtenir cette sortie :

C:\hibernateTutorial\>ant
Buildfile: build.xml

copy-resources:
     [copy] Copying 2 files to C:\hibernateTutorial\bin

compile:
    [javac] Compiling 1 source file to C:\hibernateTutorial\bin

BUILD SUCCESSFUL
Total time: 1 second 

1.2.5. Démarrage et aides

Il est temps de charger et de stocker quelques objets Event, mais d'abord nous devons compléter la configuration avec du code d'infrastructure. Nous devons démarrer Hibernate. Ce démarrage inclut la construction d'un objet SessionFactory global et le stocker quelque part facile d'accès dans le code de l'application. Une SessionFactory peut ouvrir des nouvelles Sessions. Une Session représente une unité de travail simplement "threadée", la SessionFactory est un objet global "thread-safe", instancié une seule fois.

Nous créerons une classe d'aide HibernateUtil qui s'occupe du démarrage et rend la gestion des Sessions plus facile. Regardons l'implémentation :

package util;

import org.hibernate.*;
import org.hibernate.cfg.*;

public class HibernateUtil {
    public static final SessionFactory sessionFactory;

    static {
        try {
            // Création de la SessionFactory à partir de hibernate.cfg.xml
            sessionFactory = new Configuration().configure().buildSessionFactory();
        } catch (Throwable ex) {
            // Make sure you log the exception, as it might be swallowed
            System.err.println("Initial SessionFactory creation failed." + ex);
            throw new ExceptionInInitializerError(ex);
        }
    }

    public static final ThreadLocal session = new ThreadLocal();

    public static SessionFactory getSessionFactory() {
        return sessionFactory;
    }
}

Cette classe ne produit pas seulement la SessionFactory globale dans un initialiseur statique (appelé une seule fois par la JVM lorsque la classe est chargée), elle masque le fait qu'elle exploite un singleton. Elle pourrait aussi obtenir la SessionFactory depuis JNDI dans un serveur d'applications.

Si vous nommez la SessionFactory dans votre fichier de configuration, Hibernate tentera la récupération depuis JNDI. Pour éviter ce code, vous pouvez aussi utiliser un déploiement JMX et laisser le conteneur (compatible JMX) instancier et lier un HibernateService à JNDI. Ces options avancées sont détaillées dans la documentation de référence Hibernate.

Placez HibernateUtil.java dans le répertoire source de développement, et ensuite Event.java :

.
+lib
  <Hibernate and third-party libraries>
+src
  +events
    Event.java
    Event.hbm.xml
  +util
    HibernateUtil.java
  hibernate.cfg.xml
+data
build.xml

Cela devrait encore compiler sans problème. Nous avons finalement besoin de configurer le système de "logs" - Hibernate utilise commons-logging et vous laisse le choix entre log4j et le système de logs du JDK 1.4. La plupart des développeurs préfèrent log4j : copiez log4j.properties de la distribution d'Hibernate (il est dans le répertoire etc/) dans votre répertoire src, puis faites de même avec hibernate.cfg.xml. Regardez la configuration d'exemple et changez les paramètres si vous voulez une sortie plus verbeuse. Par défaut, seul le message de démarrage d'Hibernate est affiché sur la sortie standard.

L'infrastructure de ce didacticiel est complète - et nous sommes prêts à effectuer un travail réel avec Hibernate.
1.2.6. Charger et stocker des objets

Finalement nous pouvons utiliser Hibernate pour charger et stocker des objets. Nous écrivons une classe EventManager avec une méthode main() :

package events;
import org.hibernate.Session;

import java.util.Date;

import util.HibernateUtil;

public class EventManager {

    public static void main(String[] args) {
        EventManager mgr = new EventManager();

        if (args[0].equals("store")) {
            mgr.createAndStoreEvent("My Event", new Date());
        }

        HibernateUtil.getSessionFactory().close();
    }

    private void createAndStoreEvent(String title, Date theDate) {

        Session session = HibernateUtil.getSessionFactory().getCurrentSession();

        session.beginTransaction();

        Event theEvent = new Event();
        theEvent.setTitle(title);
        theEvent.setDate(theDate);

        session.save(theEvent);

        session.getTransaction().commit();
    }

Nous créons un nouvel objet Event, et le remettons à Hibernate. Hibernate s'occupe maintenant du SQL et exécute les INSERTs dans la base de données. Regardons le code de gestion de la Session et de la Transaction avant de lancer ça.

Une Session est une unité de travail. Pour le moment, nous allons faire les choses simplement et assumer une granularité un-un entre une Session hibernate et une transaction à la base de données. Pour isoler notre code du système de transaction sous-jacent (dans notre cas, du pure JDBC, mais cela pourrait être JTA), nous utilisons l'API Transaction qui est disponible depuis la Session Hibernate.

Que fait sessionFactory.getCurrentSession() ? Premièrement, vous pouvez l'invoquer autant de fois que vous le voulez et n'importe où du moment que vous avez votre SessionFactory (facile grâce à HibernateUtil). La méthode getCurrentSession() renvoie toujours l'unité de travail courante. Souvenez vous que nous avons basculé notre option de configuration au mécanisme basé sur le "thread" dans hibernate.cfg.xml. Par conséquent, le scope de l'unité de travail courante est le thread java courant d'exécution. Ceci n'est pas totalement vrai. Une Session commence lorsqu'elle est vraiment utilisée la première fois, Lorsque nous appelons pour la première fois getCurrentSession(). Ensuite, elle est liée, par Hibernate, au thread courant. Lorsque la transaction s'achève (commit ou rollback), Hibernate délie la Session du thread et la ferme pour vous. Si vous invoquez getCurrentSession() une autre fois, vous obtenez une nouvelle Session et pouvez entamer une nouvelle unité de travail. Ce modèle de programmation "thread-bound" est le moyen le plus populaire d'utiliser Hibernate.

Lisez Chapitre 11, Transactions et accès concurrents pour plus d'informations sur la gestion des transactions et leur démarcations. Nous n'avons pas géré les erreurs et rollback sur l'exemple précédent.

Pour lancer cette première routine, nous devons ajouter une cible appelable dans le fichier de construction de Ant :

<target name="run" depends="compile">
    <java fork="true" classname="events.EventManager" classpathref="libraries">
        <classpath path="${targetdir}"/>
        <arg value="${action}"/>
    </java>
</target>

La valeur de l'argument action correspond à la ligne de commande qui appelle la cible :

C:\hibernateTutorial\>ant run -Daction=store

Vous devriez voir, après la compilation, Hibernate démarrer et, en fonction de votre configuration, beaucoup de traces sur la sortie. À la fin vous trouverez la ligne suivante :

[java] Hibernate: insert into EVENTS (EVENT_DATE, title, EVENT_ID) values (?, ?, ?)

C'est l'INSERT exécuté par Hibernate, les points d'interrogation représentent les paramètres JDBC liés. Pour voir les valeurs liées aux arguments, ou pour réduire la verbosité des traces, vérifier votre log4j.properties.

Maintenant nous aimerions aussi lister les événements stockés, donc nous ajoutons une option à la méthode principale :

if (args[0].equals("store")) {
    mgr.createAndStoreEvent("My Event", new Date());
}
else if (args[0].equals("list")) {
    List events = mgr.listEvents();
    for (int i = 0; i < events.size(); i++) {
        Event theEvent = (Event) events.get(i);
        System.out.println("Event: " + theEvent.getTitle() +
                           " Time: " + theEvent.getDate());
    }
}

Nous ajoutons aussi une nouvelle méthode listEvents() :

private List listEvents() {

    Session session = HibernateUtil.getSessionFactory().getCurrentSession();

    session.beginTransaction();

    List result = session.createQuery("from Event").list();

    session.getTransaction().commit();

    return result;
}

Ce que nous faisons ici c'est utiliser une requête HQL (Hibernate Query Language) pour charger tous les objets Event existants de la base de données. Hibernate générera le SQL approprié, l'enverra à la base de données et peuplera des objets Event avec les données. Vous pouvez créer des requêtes plus complexes avec HQL, bien sûr.

Maintenant, pour exécuter et tester tout ça, suivez ces étapes :

    *

      Exécutez ant run -Daction=store pour stocker quelque chose dans la base de données et, bien sûr, pour générer, avant, le schéma de la base de données grâce à hbm2ddl.
    *

      Maintenant désactivez hbm2ddl en commentant la propriété dans votre fichier hibernate.cfg.xml. Généralement vous la laissez seulement activée dans des tests unitaires en continu, mais une autre exécution de hbm2ddl effacerait tout ce que vous avez stocké - le paramètre de configuration create se traduit en fait par "supprimer toutes les tables du schéma, puis re-créer toutes les tables, lorsque la SessionFactory est construite". 

Si maintenant vous appelez Ant avec -Daction=list, vous devriez voir les événements que vous avez stockés jusque là. Vous pouvez bien sûr aussi appeler l'action store plusieurs fois.
1.3. Partie 2 - Mapper des associations

Nous avons mappé une classe d'une entité persistante vers une table. Partons de là et ajoutons quelques associations de classe. D'abord nous ajouterons des gens à notre application, et stockerons une liste d'événements auxquels ils participent.
1.3.1. Mapper la classe Person

La première version de la classe Person est simple :

package events;

public class Person {

    private Long id;
    private int age;
    private String firstname;
    private String lastname;

    public Person() {}

    // Accessor methods for all properties, private setter for 'id'

}

Créez un nouveau fichier de mapping appelé Person.hbm.xml (n'oubliez pas la référence à la DTD)

<hibernate-mapping>

    <class name="events.Person" table="PERSON">
        <id name="id" column="PERSON_ID">
            <generator class="native"/>
        </id>
        <property name="age"/>
        <property name="firstname"/>
        <property name="lastname"/>
    </class>

</hibernate-mapping>

Finalement, ajoutez la nouveau mapping à la configuration d'Hibernate :

<mapping resource="events/Event.hbm.xml"/>
<mapping resource="events/Person.hbm.xml"/>

Nous allons maintenant créer une association entre ces deux entités. Évidemment, des personnes peuvent participer aux événements, et des événements ont des participants. Les questions de conception que nous devons traiter sont : direction, cardinalité et comportement de la collection.
1.3.2. Une association unidirectionnelle basée sur Set

Nous allons ajouter une collection d'événements à la classe Person. De cette manière nous pouvons facilement naviguer dans les événements d'une personne particulière, sans exécuter une requête explicite - en appelant aPerson.getEvents(). Nous utilisons une collection Java, un Set, parce que la collection ne contiendra pas d'éléments dupliqués et l'ordre ne nous importe pas.

Nous avons besoin d'une association unidirectionnelle, pluri-valuée, implémentée avec un Set. Écrivons le code pour ça dans les classes Java et mappons les :

public class Person {

    private Set events = new HashSet();

    public Set getEvents() {
        return events;
    }

    public void setEvents(Set events) {
        this.events = events;
    }
}

D'abord nous mappons cette association, mais pensez à l'autre côté. Clairement, nous pouvons la laisser unidirectionnelle. Ou alors, nous pourrions créer une autre collection sur Event, si nous voulons être capable de la parcourir de manière bidirectionnelle, c'est-à-dire avoir anEvent.getParticipants(). Ce n'est pas nécessaire d'un point de vue fonctionnel. Vous pourrez toujours exécuter une requête explicite pour récupérer les participants d'un "event" particulier. Ce choix de conception vous est laissé, mais ce qui reste certains est la cardinalité de l'association: "plusieurs" des deux côtés, nous appelons cela une association many-to-many. Par conséquent nous utilisons un mapping Hibernate many-to-many:

<class name="events.Person" table="PERSON">
    <id name="id" column="PERSON_ID">
        <generator class="native"/>
    </id>
    <property name="age"/>
    <property name="firstname"/>
    <property name="lastname"/>

    <set name="events" table="PERSON_EVENT">
        <key column="PERSON_ID"/>
        <many-to-many column="EVENT_ID" class="Event"/>
    </set>

</class>

Hibernate supporte toutes sortes de mapping de collection, un <set> étant le plus commun. Pour une association many-to-many (ou une relation d'entité n:m), une table d'association est requise. Chaque ligne dans cette table représente un lien entre une personne et un événement. Le nom de la table est configuré avec l'attribut table de l'élément set. Le nom de la colonne identifiant dans l'association, du côté de la personne, est défini avec l'élément <key>, et le nom de la colonne pour l'événement dans l'attribut column de <many-to-many>. Vous devez aussi donner à Hibernate la classe des objets de votre collection (c'est-à-dire : la classe de l'autre côté de la collection).

Le schéma de base de données pour ce mapping est donc :

    _____________        __________________
   |             |      |                  |       _____________
   |   EVENTS    |      |   PERSON_EVENT   |      |             |
   |_____________|      |__________________|      |    PERSON   |
   |             |      |                  |      |_____________|
   | *EVENT_ID   | <--> | *EVENT_ID        |      |             |
   |  EVENT_DATE |      | *PERSON_ID       | <--> | *PERSON_ID  |
   |  TITLE      |      |__________________|      |  AGE        |
   |_____________|                                |  FIRSTNAME  |
                                                  |  LASTNAME   |
                                                  |_____________|
 

1.3.3. Travailler avec l'association

Réunissons quelques personnes et quelques événements dans une nouvelle méthode dans EventManager :

private void addPersonToEvent(Long personId, Long eventId) {

    Session session = HibernateUtil.getSessionFactory().getCurrentSession();
    session.beginTransaction();

    Person aPerson = (Person) session.load(Person.class, personId);
    Event anEvent = (Event) session.load(Event.class, eventId);

    aPerson.getEvents().add(anEvent);

    session.getTransaction().commit();
}

Après le chargement d'une Person et d'un Event, modifiez simplement la collection en utilisant les méthodes normales de la collection. Comme vous pouvez le voir, il n'y a pas d'appel explicite à update() ou save(), Hibernate détecte automatiquement que la collection a été modifiée et a besoin d'être mise à jour. Ceci est appelé la vérification sale automatique (NdT : "automatic dirty checking"), et vous pouvez aussi l'essayer en modifiant le nom ou la propriété date de n'importe lequel de vos objets. Tant qu'ils sont dans un état persistant, c'est-à-dire, liés à une Session Hibernate particulière (c-à-d qu'ils ont juste été chargés ou sauvegardés dans une unité de travail), Hibernate surveille les changements et exécute le SQL correspondant. Le processus de synchronisation de l'état de la mémoire avec la base de données, généralement seulement à la fin d'une unité de travail, est appelé flushing. Dans notre code, l'unité de travail s'achève par un commit (ou rollback) de la transaction avec la base de données - comme défini par notre option thread de configuration pour la classe CurrentSessionContext.

Vous pourriez bien sûr charger une personne et un événement dans différentes unités de travail. Ou vous modifiez un objet à l'extérieur d'une Session, s'il n'est pas dans un état persistant (s'il était persistant avant, nous appelons cet état détaché). Vous pouvez même modifier une collection lorsqu'elle est détachée:

private void addPersonToEvent(Long personId, Long eventId) {

    Session session = HibernateUtil.getSessionFactory().getCurrentSession();
    session.beginTransaction();

    Person aPerson = (Person) session
            .createQuery("select p from Person p left join fetch p.events where p.id = :pid")
            .setParameter("pid", personId)
            .uniqueResult(); // Eager fetch the collection so we can use it detached

    Event anEvent = (Event) session.load(Event.class, eventId);

    session.getTransaction().commit();

    // End of first unit of work

    aPerson.getEvents().add(anEvent); // aPerson (and its collection) is detached

    // Begin second unit of work

    Session session2 = HibernateUtil.getSessionFactory().getCurrentSession();
    session2.beginTransaction();

    session2.update(aPerson); // Reattachment of aPerson

    session2.getTransaction().commit();
}

L'appel à update rend un objet détaché à nouveau persistant, vous pourriez dire qu'il le lie à une unité de travail, ainsi toutes les modifications (ajout, suppression) que vous avez faites pendant qu'il était détaché peuvent être sauvegardées dans la base de données (il se peut que vous ayez besoin de modifier quelques unes des méthodes précédentes pour retourner cet identifiant).

else if (args[0].equals("addpersontoevent")) {
    Long eventId = mgr.createAndStoreEvent("My Event", new Date());
    Long personId = mgr.createAndStorePerson("Foo", "Bar");
    mgr.addPersonToEvent(personId, eventId);
    System.out.println("Added person " + personId + " to event " + eventId);

Ce n'est pas très utile dans notre situation actuelle, mais c'est un concept important que vous pouvez mettre dans votre propre application. Pour le moment, complétez cet exercice en ajoutant une nouvelle action à la méthode principale des EventManagers et appelez la à partir de la ligne de commande. Si vous avez besoin des identifiants d'une personne et d'un événement - la méthode save() les retourne.

C'était un exemple d'une association entre deux classes de même importance, deux entités. Comme mentionné plus tôt, il y a d'autres classes et d'autres types dans un modèle typique, généralement "moins importants". Vous en avez déjà vu certains, comme un int ou une String. Nous appelons ces classes des types de valeur, et leurs instances dépendent d'une entité particulière. Des instances de ces types n'ont pas leur propre identité, elles ne sont pas non plus partagées entre des entités (deux personnes ne référencent pas le même objet firstname, même si elles ont le même prénom). Bien sûr, des types de valeur ne peuvent pas seulement être trouvés dans le JDK (en fait, dans une application Hibernate toutes les classes du JDK sont considérées comme des types de valeur), vous pouvez aussi écrire vous-même des classes dépendantes, Address ou MonetaryAmount, par exemple.

Vous pouvez aussi concevoir une collection de types de valeur. C'est conceptuellement très différent d'une collection de références vers d'autres entités, mais très ressemblant en Java.
1.3.4. Collection de valeurs

Nous ajoutons une collection d'objets de type de valeur à l'entité Person. Nous voulons stocker des adresses email, donc le type que nous utilisons est String, et la collection est encore un Set :

private Set emailAddresses = new HashSet();

public Set getEmailAddresses() {
    return emailAddresses;
}

public void setEmailAddresses(Set emailAddresses) {
    this.emailAddresses = emailAddresses;
}

Le mapping de ce Set :

<set name="emailAddresses" table="PERSON_EMAIL_ADDR">
    <key column="PERSON_ID"/>
    <element type="string" column="EMAIL_ADDR"/>
</set>

La différence comparée au mapping vu plus tôt est la partie element, laquelle dit à Hibernate que la collection ne contient pas de références vers une autre entité, mais une collection d'éléments de type String (le nom en minuscule vous indique que c'est un type/convertisseur du mapping Hibernate). Une fois encore, l'attribut table de l'élément set détermine le nom de la table pour la collection. L'élément key définit le nom de la colonne de la clef étrangère dans la table de la collection. L'attribut column dans l'élément element définit le nom de la colonne où les valeurs de String seront réellement stockées.

Regardons le schéma mis à jour :

  _____________        __________________
 |             |      |                  |       _____________
 |   EVENTS    |      |   PERSON_EVENT   |      |             |       ___________________
 |_____________|      |__________________|      |    PERSON   |      |                   |
 |             |      |                  |      |_____________|      | PERSON_EMAIL_ADDR |
 | *EVENT_ID   | <--> | *EVENT_ID        |      |             |      |___________________|
 |  EVENT_DATE |      | *PERSON_ID       | <--> | *PERSON_ID  | <--> |  *PERSON_ID       |
 |  TITLE      |      |__________________|      |  AGE        |      |  *EMAIL_ADDR      |
 |_____________|                                |  FIRSTNAME  |      |___________________|
                                                |  LASTNAME   |
                                                |_____________|
 

Vous pouvez voir que la clef primaire de la table de la collection est en fait une clef composée, utilisant deux colonnes. Ceci implique aussi qu'il ne peut pas y avoir d'adresses email dupliquées par personne, ce qui est exactement la sémantique dont nous avons besoin pour un ensemble en Java.

Vous pouvez maintenant tester et ajouter des éléments à cette collection, juste comme nous l'avons fait avant en liant des personnes et des événements. C'est le même code en Java.

private void addEmailToPerson(Long personId, String emailAddress) {

    Session session = HibernateUtil.getSessionFactory().getCurrentSession();
    session.beginTransaction();

    Person aPerson = (Person) session.load(Person.class, personId);

    // The getEmailAddresses() might trigger a lazy load of the collection
    aPerson.getEmailAddresses().add(emailAddress);

    session.getTransaction().commit();
}

Cette fois ci, nous n'avons pas utilisé une requête de chargement agressif (fetch) pour initialiser la collection. Par conséquent, l'invocation du getter déclenchera un select supplémentaire pour l'initialiser. Traquez les logs SQL et tentez d'optimiser ce cas avec un chargement aggressif.
1.3.5. Associations bidirectionnelles

Ensuite nous allons mapper une association bidirectionnelle - faire fonctionner l'association entre une personne et un événement à partir des deux côtés en Java. Bien sûr, le schéma de la base de données ne change pas, nous avons toujours une pluralité many-to-many. Une base de données relationnelle est plus flexible qu'un langage de programmation réseau, donc elle n'a pas besoin de direction de navigation - les données peuvent être vues et récupérées de toutes les manières possibles.

D'abord, ajouter une collection de participants à la classe Event :

private Set participants = new HashSet();

public Set getParticipants() {
    return participants;
}

public void setParticipants(Set participants) {
    this.participants = participants;
}

Maintenant mapper ce côté de l'association aussi, dans Event.hbm.xml.

<set name="participants" table="PERSON_EVENT" inverse="true">
    <key column="EVENT_ID"/>
    <many-to-many column="PERSON_ID" class="events.Person"/>
</set>

Comme vous le voyez, ce sont des mappings de sets normaux dans les deux documents de mapping. Notez que les noms de colonne dans key et many-to-many sont inversés dans les 2 documents de mapping. L'ajout le plus important ici est l'attribut inverse="true" dans l'élément set du mapping de la collection des Events.

Ce que signifie qu'Hibernate devrait prendre l'autre côté - la classe Person - s'il a besoin de renseigner des informations à propos du lien entre les deux. Ce sera beaucoup plus facile à comprendre une fois que vous verrez comment le lien bidirectionnel entre les deux entités est créé.
1.3.6. Travailler avec des liens bidirectionnels

Premièrement, gardez à l'esprit qu'Hibernate n'affecte pas la sémantique normale de Java. Comment avons-nous créé un lien entre une Person et un Event dans l'exemple unidirectionnel ? Nous avons ajouté une instance de Event à la collection des références d'événement d'une instance de Person. Donc, évidemment, si vous voulons rendre ce lien bidirectionnel, nous devons faire la même chose de l'autre côté - ajouter une référence de Person à la collection d'un Event. Cette "configuration du lien des deux côtés" est absolument nécessaire et vous ne devriez jamais oublier de le faire.

Beaucoup de développeurs programment de manière défensive et créent des méthodes de gestion de lien pour affecter correctement les deux côtés, par exemple dans Person :

protected Set getEvents() {
    return events;
}

protected void setEvents(Set events) {
    this.events = events;
}

public void addToEvent(Event event) {
    this.getEvents().add(event);
    event.getParticipants().add(this);
}

public void removeFromEvent(Event event) {
    this.getEvents().remove(event);
    event.getParticipants().remove(this);
}

Notez que les méthodes get et set pour la collection sont maintenant protégées - ceci permet à des classes du même paquet et aux sous-classes d'accéder encore aux méthodes, mais empêche n'importe qui d'autre de mettre le désordre directement dans les collections (enfin, presque). Vous devriez probablement faire de même avec la collection de l'autre côté.

Et à propos de l'attribut de mapping inverse ? Pour vous, et pour Java, un lien bidirectionnel est simplement une manière de configurer correctement les références des deux côtés. Hibernate n'a cependant pas assez d'informations pour ordonner correctement les expressions SQL INSERT et UPDATE (pour éviter les violations de contrainte), et a besoin d'aide pour gérer proprement les associations bidirectionnelles. Rendre inverse un côté d'une assocation dit à Hibernate de l'ignorer essentiellement, pour le considérer comme un miroir de l'autre côté. C'est tout ce qui est nécessaire à Hibernate pour découvrir tout des problèmes de transformation d'un modèle de navigation directionnelle vers un schéma SQL de base de données. Les règles dont vous devez vous souvenir sont : toutes les associations bidirectionnelles ont besoin d'un côté marqué inverse. Dans une association un-vers-plusieurs vous pouvez choisir n'importe quel côté, il n'y a pas de différence.
1.4. Part 3 - L'application web EventManager

Une application web Hibernate utilise la Session et Transaction comme une application standalone. Cependant, quelques patterns sont utiles. Nous allons coder une EventManagerServlet. Cette servlet peut lister tous les évènements stockés dans la base de données, et fournir une formulaire HTML pour saisir d'autres évènements.
1.4.1. Ecrire la servlet de base

Créons une nouvelle classe dans notre répertoire source, dans le package events:

package events;

// Imports

public class EventManagerServlet extends HttpServlet {

    private final SimpleDateFormat dateFormatter =
                            new SimpleDateFormat("dd.MM.yyyy");

    // Servlet code
}

Le dateFormatter est un outil que nous utiliserons plus tard pour convertir les objets Date depuis et vers des chaines de caractères. Il est propice de n'avoir qu'un formatter comme membre de la servlet.

La servlet n'accepte que les requêtes HTTP GET, la méthode à implémenter est donc doGet():

protected void doGet(HttpServletRequest request,
                     HttpServletResponse response)
        throws ServletException, IOException {

    try {
        // Begin unit of work
        HibernateUtil.getSessionFactory()
                .getCurrentSession().beginTransaction();

        // Process request and render page...

        // End unit of work
        HibernateUtil.getSessionFactory()
                .getCurrentSession().getTransaction().commit();

    } catch (Exception ex) {
        HibernateUtil.getSessionFactory()
                .getCurrentSession().getTransaction().rollback();
        throw new ServletException(ex);
    }

}

La pattern que nous utilisons ici est appelé session-per-request. Lorsqu'une requête touche la servlet, une nouvelle Session hibernate est ouverte à l'invocationde getCurrentSession() sur la SessionFactory. Ensuite, une transaction avec la base de données est démarrée? tous les accès à la base de données interviennent au sein de la transactiton, peu importe que les données soient lues ou écrites (nous n'utilisons pas le mode auto-commit dans les applications).

Ensuite, les actions possibles de la requêtes sont exécutées et la réponse HTML est rendue. Nous en parlerons plus tard.

Enfin, l'unité de travail s'achève lorsque l'exécution et le rendu sont achevés. Si un problème survient lors de ces deux phases, une exception est soulevée et la transaction avec la base de données subit un rollback. Voila pour le pattern session-per-request. Au lieu d'un code de démarcation de transaction au sein de chaque servlet, vous pouvez écrire un filtre de servlet. Voir le site Hibernate et le Wiki pour plus d'information sur ce pattern, appelé Open Session in View? vous en aurez besoin dès que vous utiliserez des JSPs et non plus des servlets pour le rendu de vos vues.
1.4.2. Procéder et rendre

Implémentons l'exécution de la requête et le rendu de la page.

// Write HTML header
PrintWriter out = response.getWriter();
out.println("<html><head><title>Event Manager</title></head><body>");

// Handle actions
if ( "store".equals(request.getParameter("action")) ) {

    String eventTitle = request.getParameter("eventTitle");
    String eventDate = request.getParameter("eventDate");

    if ( "".equals(eventTitle) || "".equals(eventDate) ) {
        out.println("<b><i>Please enter event title and date.</i></b>");
    } else {
        createAndStoreEvent(eventTitle, dateFormatter.parse(eventDate));
        out.println("<b><i>Added event.</i></b>");
    }
}

// Print page
printEventForm(out);
listEvents(out);

// Write HTML footer
out.println("</body></html>");
out.flush();
out.close();

Ce style de code avec un mix de Java et d'HTML ne serait pas scalable dans une application plus complexe?gardez à l'esprit que nous ne faisons qu'illustrer les concepts basiques d'Hibernate dans ce tutoriel. Ce code affiche une en tête et un pied de page HTML. Dans cette page, sont affichés un formulaire pour la saisie d'évènements ainsi qu'une liste de tous les évènements de la base de données. La première méthode est triviale est ne fait que sortir de l'HTML:

private void printEventForm(PrintWriter out) {
    out.println("<h2>Add new event:</h2>");
    out.println("<form>");
    out.println("Title: <input name='eventTitle' length='50'/><br/>");
    out.println("Date (e.g. 24.12.2009): <input name='eventDate' length='10'/><br/>");
    out.println("<input type='submit' name='action' value='store'/>");
    out.println("</form>");
}

La méthode listEvents() utilise la Session Hibernate liée au thread courant pour exécuter la requête:

private void listEvents(PrintWriter out) {
    List result = HibernateUtil.getSessionFactory()
                    .getCurrentSession().createCriteria(Event.class).list();
    if (result.size() > 0) {
        out.println("<h2>Events in database:</h2>");
        out.println("<table border='1'>");
        out.println("<tr>");
        out.println("<th>Event title</th>");
        out.println("<th>Event date</th>");
        out.println("</tr>");
        for (Iterator it = result.iterator(); it.hasNext();) {
            Event event = (Event) it.next();
            out.println("<tr>");
            out.println("<td>" + event.getTitle() + "</td>");
            out.println("<td>" + dateFormatter.format(event.getDate()) + "</td>");
            out.println("</tr>");
        }
        out.println("</table>");
    }
}

FEnfin, l'action store renvoie à la méthode createAndStoreEvent(), qui utilise aussi la Session du thread courant:

protected void createAndStoreEvent(String title, Date theDate) {
    Event theEvent = new Event();
    theEvent.setTitle(title);
    theEvent.setDate(theDate);

    HibernateUtil.getSessionFactory()
                    .getCurrentSession().save(theEvent);
}

La servlet est faite. Une requête à la servlet sera exécutée par une seule Session et Transaction. Comme pour une application standalone, Hibernate peut automatiquement lier ces objets au thread courant d'exécution. Cela vous laisse la liberté de séparer votre code en couches et d'accéder à la SessionFactory par le moyen que vous voulez. Généralement, vous utiliserez des conceptions plus sophistiquées et déplacerez le code d'accès aux données dans une couche DAO. Voir le wiki Hibernate pour plus d'exemples.
1.4.3. Déployer et tester

Pour déployer cette application, vous devez créer une archive Web, un War. Ajoutez la cible Ant suivante dans votre build.xml:

<target name="war" depends="compile">
    <war destfile="hibernate-tutorial.war" webxml="web.xml">
        <lib dir="${librarydir}">
          <exclude name="jsdk*.jar"/>
        </lib>

        <classes dir="${targetdir}"/>
    </war>
</target>

Cette cible créé un fichier nommé hibernate-tutorial.war dans le répertoire de votre projet. Elle package les bibliothèques et le descripteur web.xml qui est attendu dans le répertoire racine de votre projet:

<?xml version="1.0" encoding="UTF-8"?>
<web-app version="2.4"
    xmlns="http://java.sun.com/xml/ns/j2ee"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd">

    <servlet>
        <servlet-name>Event Manager</servlet-name>
        <servlet-class>events.EventManagerServlet</servlet-class>
    </servlet>

    <servlet-mapping>
        <servlet-name>Event Manager</servlet-name>
        <url-pattern>/eventmanager</url-pattern>
    </servlet-mapping>
</web-app>

Avant de compiler et déployer l'application web, notez qu'une bibliothèque supplémentaire est requise: jsdk.jar. C'est le kit de développement de Servlet Java, si vous ne disposez pas de cette bibliothèque, prenez la sur le site de Sun et copiez la dans votre répertoire des bibliothèques. Cependant, elle ne sera utilisée uniquement pour la compilation et sera exclue du paackage WAR.

Pour construire et déployer, appelez ant war dans votre projet et copier le fichier hibernate-tutorial.war dans le répertoire webapp de tomcat Si vous n'avez pas installé Tomcat, téléchargez le et suivez la notice d'installation. Vous n'avez pas à modifier la configuration Tomcat pour déployer cette application.

Une fois l'application déployée et Tomcat lancé, accédez à l'application via http://localhost:8080/hibernate-tutorial/eventmanager. Assurez vous de consulter les traces tomcat pour observer l'initialisation d'Hibernate à la première requête touchant votre servlet (l'initialisation statique dans HibernateUtil est invoquée) et pour vérifier qu'aucune exception ne survienne.
1.5. Résumé

Ce didacticiel a couvert les bases de l'écriture d'une simple application Hibernate ainsi qu'une petite application web.

Si vous êtes déjà confiants avec Hibernate, continuez à parcourir les sujets que vous trouvez intéressants à travers la table des matières de la documentation de référence - les plus demandés sont le traitement transactionnel (Chapitre 11, Transactions et accès concurrents), la performance des récupérations d'information (Chapitre 19, Améliorer les performances), ou l'utilisation de l'API (Chapitre 10, Travailler avec des objets) et les fonctionnalités des requêtes (Section 10.4, « Requêtage »).

N'oubliez pas de vérifier le site web d'Hibernate pour d'autres didacticiels (plus spécialisés).
Chapitre 2. Architecture
2.1. Généralités

Voici une vue (très) haut niveau de l'architecture d'Hibernate :

Ce diagramme montre Hibernate utilisant une base de données et des données de configuration pour fournir un service de persistance (et des objets persistants) à l'application.

Nous aimerions décrire une vue plus détaillée de l'architecture. Malheureusement, Hibernate est flexible et supporte différentes approches. Nous allons en montrer les deux extrêmes. L'architecture légère laisse l'application fournir ses propres connexions JDBC et gérer ses propres transactions. Cette approche utilise le minimum des APIs Hibernate :

L'architecture la plus complète abstrait l'application des APIs JDBC/JTA sous-jacentes et laisse Hibernate s'occuper des détails.

Voici quelques définitions des objets des diagrammes :

SessionFactory (org.hibernate.SessionFactory)

    Un cache threadsafe (immuable) des mappings vers une (et une seule) base de données. Une factory (fabrique) de Session et un client de ConnectionProvider. Peut contenir un cache optionnel de données (de second niveau) qui est réutilisable entre les différentes transactions que cela soit au sein du même processus (JVLM) ou par plusieurs n½uds d'un cluster. 
Session (org.hibernate.Session)

    Un objet mono-threadé, à durée de vie courte, qui représente une conversation entre l'application et l'entrepôt de persistance. Encapsule une connexion JDBC. Factory (fabrique) des objets Transaction. Contient un cache (de premier niveau) des objets persistants, ce cache est obligatoire. Il est utilisé lors de la navigation dans le graphe d'objets ou lors de la récupération d'objets par leur identifiant. 
Objets et Collections persistants

    Objets mono-threadés à vie courte contenant l'état de persistance et la fonction métier. Ceux-ci sont en général les objets de type JavaBean (ou POJOs) ; la seule particularité est qu'ils sont associés avec une (et une seule) Session. Dès que la Session est fermée, ils seront détachés et libres d'être utilisés par n'importe laquelle des couches de l'application (ie. de et vers la présentation en tant que Data Transfer Objects - DTO : objet de transfert de données). 
Objets et collections transients

    Instances de classes persistantes qui ne sont actuellement pas associées à une Session. Elles ont pu être instanciées par l'application et ne pas avoir (encore) été persistées ou elle ont pu être instanciées par une Session fermée. 
Transaction (org.hibernate.Transaction)

    (Optionnel) Un objet mono-threadé à vie courte utilisé par l'application pour définir une unité de travail atomique. Abstrait l'application des transactions sous-jacentes qu'elles soient JDBC, JTA ou CORBA. Une Session peut fournir plusieurs Transactions dans certains cas. Toutefois, la délimitation des transactions, via l'API d'Hibernate ou par la Transaction sous-jacente, n'est jamais optionnelle! 
ConnectionProvider (org.hibernate.connection.ConnectionProvider)

    (Optionnel) Une fabrique de (pool de) connexions JDBC. Abstrait l'application de la Datasource ou du DriverManager sous-jacent. Non exposé à l'application, mais peut être étendu/implémenté par le développeur. 
TransactionFactory (org.hibernate.TransactionFactory)

    (Optionnel) Une fabrique d'instances de Transaction. Non exposé à l'application, mais peut être étendu/implémenté par le développeur. 
Interfaces d'extension

    Hibernate fournit de nombreuses interfaces d'extensions optionnelles que vous pouvez implémenter pour personnaliser le comportement de votre couche de persistance. Reportez vous à la documentation de l'API pour plus de détails. 

Dans une architecture légère, l'application n'aura pas à utiliser les APIs Transaction/TransactionFactory et/ou n'utilisera pas les APIs ConnectionProvider pour utiliser JTA ou JDBC.
2.2. Etats des instances

Une instance d'une classe persistante peut être dans l'un des trois états suivants, définis par rapport à un contexte de persistance. L'objet Session d'hibernate correspond à ce concept de contexte de persistance :

passager (transient)

    L'instance n'est pas et n'a jamais été associée à un contexte de persistance. Elle ne possède pas d'identité persistante (valeur de clé primaire) 
persistant

    L'instance est associée au contexte de persistance. Elle possède une identité persistante (valeur de clé primaire) et, peut-être, un enregistrement correspondant dans la base. Pour un contexte de persistance particulier, Hibernate garantit que l'identité persistante est équivalente à l'identité Java (emplacement mémoire de l'objet) 
détaché

    L'instance a été associée au contexte de persistance mais ce contexte a été fermé, ou l'instance a été sérialisée vers un autre processus. Elle possède une identité persistante et peut-être un enregistrement correspondant dans la base. Pour des instances détachées, Hibernate ne donne aucune garantie sur la relation entre l'identité persistante et l'identité Java. 

2.3. Intégration JMX

JMX est le standard J2EE de gestion des composants Java. Hibernate peut être géré via un service JMX standard. Nous fournissons une implémentation d'un MBean dans la distribution : org.hibernate.jmx.HibernateService.

Pour avoir un exemple sur la manière de déployer Hibernate en tant que service JMX dans le serveur d'application JBoss Application Server, référez vous au guide utilisateur JBoss (JBoss User Guide). Si vous déployez Hibernate via JMX sur JBoss AS, vous aurez également les bénéfices suivants :

    *

      Gestion de la session : Le cycle de vie de la Session Hibernate peut être automatiquement limitée à la portée d'une transaction JTA. Cela signifie que vous n'avez plus besoin d'ouvrir et de fermer la Session manuellement, cela devient le travail de l'intercepteur EJB de JBoss. Vous n'avez pas non plus à vous occuper des démarcations des transactions dans votre code (sauf si vous voulez écrire une couche de persistance qui soit portable, dans ce cas vous pouvez utiliser l'API optionnelle Transaction d'Hibernate). Vous appelez l'HibernateContext pour accéder à la Session.
    *

      Déploiement HAR : Habituellement vous déployez le service JMX Hibernate en utilisant le descripteur de déploiement de JBoss (dans un fichier EAR et/ou un SAR), il supporte toutes les options de configuration usuelles d'une SessionFactory Hibernate. Cependant, vous devez toujours nommer tous vos fichiers de mapping dans le descripteur de déploiement. Si vous décidez d'utiliser le déploiement optionnel sous forme de HAR, JBoss détectera automatiquement tous vos fichiers de mapping dans votre fichier HAR. 

Consultez le guide d'utilisation de JBoss AS pour plus d'informations sur ces options.

Les statistiques pendant l'exécution d'Hibernate (au runtime) sont une autre fonctionnalité disponible en tant que service JMX. Voyez pour cela Section 3.4.6, « Statistiques Hibernate ».
2.4. Support JCA

Hibernate peut aussi être configuré en tant que connecteur JCA. Référez-vous au site web pour de plus amples détails. Il est important de noter que le support JCA d'Hibernate est encore considéré comme expérimental.
2.5. Sessions Contextuelles

Certaines applications utilisant Hibernate ont besoin d'une sorte de session "contextuelle", où une session est liée à la portée d'un contexte particulier. Cependant, les applications ne définissent pas toutes la notion de contexte de la même manière, et différents contextes définissent différentes portées à la notion de "courant". Les applications à base d'Hibernate, versions précédentes à la 3.0 utilisaient généralement un principe maison de sessions contextuelles basées sur le ThreadLocal, ainsi que sur des classes utilitaires comme HibernateUtil, ou utilisaient des framework tiers (comme Spring ou Pico) qui fournissaient des sessions contextuelles basées sur l'utilisation de proxy/interception.

A partir de la version 3.0.1, Hibernate a ajouté la méthode SessionFactory.getCurrentSession(). Initialement, cela demandait l'usage de transactions JTA, où la transaction JTA définissait la portée et le contexte de la session courante. L'équipe Hibernate pense que, étant donnée la maturité des implémentations de JTA TransactionManager , la plupart (sinon toutes) des applications devraient utiliser la gestion des transactions par JTA qu'elles soient ou non déployées dans un conteneur J2EE. Par conséquent, vous devriez toujours contextualiser vos sessions, si vous en avez besoin, via la méthode basée sur JTA.

Cependant, depuis la version 3.1, la logique derrière SessionFactory.getCurrentSession() est désormais branchable. A cette fin, une nouvelle interface d'extension (org.hibernate.context.CurrentSessionContext) et un nouveau paramètre de configuration (hibernate.current_session_context_class) ont été ajoutés pour permettre de configurer d'autres moyens de définir la portée et le contexte des sessions courantes.

Allez voir les Javadocs de l'interface org.hibernate.context.CurrentSessionContext pour une description détaillée de son contrat. Elle définit une seule méthode, currentSession(), depuis laquelle l'implémentation est responsable de traquer la session courante du contexte. Hibernate fournit deux implémentation de cette interface.

    *

      org.hibernate.context.JTASessionContext - les sessions courantes sont associées à une transaction JTA. La logique est la même que l'ancienne approche basée sur JTA. Voir les javadocs pour les détails.
    *

      org.hibernate.context.ThreadLocalSessionContext - les sessions courantes sont associées au thread d'exécution. Voir les javadocs pour les détails. 

Les deux implémentations fournissent un modèle de programmation de type "une session - une transaction à la base de données", aussi connu sous le nom de session-per-request. Le début et la fin d'une session Hibernate sont définis par la durée d'une transaction de base de données. Si vous utilisez une démarcation programmatique de la transaction (par exemple sous J2SE ou JTA/UserTransaction/BMT), nous vous conseillons d'utiliser l'API Hibernate Transaction pour masquer le système de transaction utilisé. Si vous exécutez sous un conteneur EJB qui supporte CMT, vous n'avez besoin d'aucune opérations de démarcations de session ou transaction dans votre code puisque tout est géré de manière déclarative. Référez vous à Chapitre 11, Transactions et accès concurrents pour plus d'informations et des exemples de code.

Le paramètre de configuration hibernate.current_session_context_class définit quelle implémentation de org.hibernate.context.CurrentSessionContext doit être utilisée. Notez que pour assurer la compatibilité avec les versions précédentes, si ce paramètre n'est pas défini mais qu'un org.hibernate.transaction.TransactionManagerLookup est configuré, Hibernate utilisera le org.hibernate.context.JTASessionContext. La valeur de ce paramètre devrait juste nommer la classe d'implémentation à utiliser, pour les deux implémentations fournies, il y a cependant deux alias correspondant: "jta" et "thread".
Chapitre 3. Configuration

Parce qu'Hibernate est conçu pour fonctionner dans différents environnements, il existe beaucoup de paramètres de configuration. Heureusement, la plupart ont des valeurs par défaut appropriées et la distribution d'Hibernate contient un exemple de fichier hibernate.properties dans le répertoire etc/ qui montre les différentes options. Vous n'avez qu'à placer ce fichier dans votre classpath et à l'adapter.
3.1. Configuration par programmation

Une instance de org.hibernate.cfg.Configuration représente un ensemble de mappings des classes Java d'une application vers la base de données SQL. La Configuration est utilisée pour construire un objet (immuable) SessionFactory. Les mappings sont constitués d'un ensemble de fichiers de mapping XML.

Vous pouvez obtenir une instance de Configuration en l'instanciant directement et en spécifiant la liste des documents XML de mapping. Si les fichiers de mapping sont dans le classpath, vous pouvez le faire à l'aide de la méthode addResource() :

Configuration cfg = new Configuration()
    .addResource("Item.hbm.xml")
    .addResource("Bid.hbm.xml");

Une alternative (parfois meilleure) est de spécifier les classes mappées et de laisser Hibernate trouver les documents de mapping pour vous :

Configuration cfg = new Configuration()
    .addClass(org.hibernate.auction.Item.class)
    .addClass(org.hibernate.auction.Bid.class);

Hibernate va rechercher les fichiers de mappings /org/hibernate/auction/Item.hbm.xml et /org/hibernate/auction/Bid.hbm.xml dans le classpath. Cette approche élimine les noms de fichiers en dur.

Une Configuration vous permet également de préciser des propriétés de configuration :

Configuration cfg = new Configuration()
    .addClass(org.hibernate.auction.Item.class)
    .addClass(org.hibernate.auction.Bid.class)
    .setProperty("hibernate.dialect", "org.hibernate.dialect.MySQLInnoDBDialect")
    .setProperty("hibernate.connection.datasource", "java:comp/env/jdbc/test")
    .setProperty("hibernate.order_updates", "true");

Ce n'est pas le seul moyen de passer des propriétés de configuration à Hibernate. Les différentes options sont :

   1.

      Passer une instance de java.util.Properties à Configuration.setProperties().
   2.

      Placer hibernate.properties dans un répertoire racine du classpath
   3.

      Positionner les propriétés System en utilisant java -Dproperty=value.
   4.

      Inclure des éléments <property> dans le fichier hibernate.cfg.xml (voir plus loin). 

L'utilisation d'hibernate.properties est l'approche la plus simple si vous voulez démarrer rapidement

La Configuration est un objet de démarrage qui sera supprimé une fois qu'une SessionFactory aura été créée.
3.2. Obtenir une SessionFactory

Une fois que tous les mappings ont été parsés par la Configuration, l'application doit obtenir une fabrique d'instances de Session. Cette fabrique sera partagée entre tous les threads de l'application :

SessionFactory sessions = cfg.buildSessionFactory();

Hibernate permet à votre application d'instancier plus d'une SessionFactory. Cela est pratique lorsque vous utilisez plus d'une base de données.
3.3. Connexions JDBC

Habituellement, vous voulez que la SessionFactory crée les connexions JDBC et les mette dans un pool pour vous. Si vous suivez cette approche, ouvrir une Session est aussi simple que :

Session session = sessions.openSession(); // open a new Session

Dès que vous ferez quelquechose qui requiert un accès à la base de données, une connexion JDBC sera récupérée dans le pool.

Pour faire cela, il faut passer les propriétés de la connexion JDBC à Hibernate. Tous les noms des propriétés Hibernate et leur signification sont définies dans la classe org.hibernate.cfg.Environment. Nous allons maintenant décrire les paramètres de configuration des connexions JDBC les plus importants.

Hibernate obtiendra des connexions (et les mettra dans un pool) en utilisant java.sql.DriverManager si vous positionnez les paramètres de la manière suivante :

Tableau 3.1. Propriétés JDBC d'Hibernate
Nom de la propriété	Fonction
hibernate.connection.driver_class	Classe du driver jdbc
hibernate.connection.url	URL jdbc
hibernate.connection.username	utilisateur de la base de données
hibernate.connection.password	mot de passe de la base de données
hibernate.connection.pool_size	nombre maximum de connexions dans le pool

L'algorithme natif de pool de connexions d'Hibernate est plutôt rudimentaire. Il a été fait dans le but de vous aider à démarrer et n'est pas prévu pour un système en production ou même pour un test de peformance. Utilisez plutôt un pool tiers pour de meilleures performances et une meilleure stabilité : pour cela, remplacez la propriété hibernate.connection.pool_size avec les propriétés spécifique au pool de connexions que vous avez choisi. Cela désactivera le pool de connexions interne d'Hibernate. Vous pouvez par exemple utiliser C3P0.

C3P0 est un pool de connexions JDBC open source distribué avec Hibernate dans le répertoire lib. Hibernate utilisera son provider C3P0ConnectionProvider pour le pool de connexions si vous positionnez les propriétés hibernate.c3p0.*. Si vous voulez utiliser Proxool, référez vous au groupe de propriétés d'hibernate.properties correspondant et regardez sur le site web d'Hibernate pour plus d'informations.

Voici un exemple de fichier hibernate.properties pour C3P0:

hibernate.connection.driver_class = org.postgresql.Driver
hibernate.connection.url = jdbc:postgresql://localhost/mydatabase
hibernate.connection.username = myuser
hibernate.connection.password = secret
hibernate.c3p0.min_size=5
hibernate.c3p0.max_size=20
hibernate.c3p0.timeout=1800
hibernate.c3p0.max_statement=50
hibernate.dialect = org.hibernate.dialect.PostgreSQLDialect

Dans le cadre de l'utilisation au sein d'un serveur d'applications, vous devriez quasiment toujours configurer Hibernate pour qu'il obtienne ses connexions de la DataSource du serveur d'application enregistrée dans le JNDI. Pour cela vous devrez définir au moins une des propriétés suivantes :

Tableau 3.2. Propriété d'une Datasource Hibernate
Nom d'une propriété	fonction
hibernate.connection.datasource	Nom JNDI de la datasource
hibernate.jndi.url	URL du fournisseur JNDI (optionnelle)
hibernate.jndi.class	Classe de l'InitialContextFactory du JNDI (optionnelle)
hibernate.connection.username	utilisateur de la base de données (optionnelle)
hibernate.connection.password	mot de passe de la base de données (optionnelle)

Voici un exemple de fichier hibernate.properties pour l'utilisation d'une datasource JNDI fournie par un serveur d'applications :

hibernate.connection.datasource = java:/comp/env/jdbc/test
hibernate.transaction.factory_class = \
    org.hibernate.transaction.JTATransactionFactory
hibernate.transaction.manager_lookup_class = \
    org.hibernate.transaction.JBossTransactionManagerLookup
hibernate.dialect = org.hibernate.dialect.PostgreSQLDialect

Les connexions JDBC obtenues à partir d'une datasource JNDI participeront automatiquement aux transactions gérées par le conteneur du serveur d'applications.

Des propriétés supplémentaires de connexion peuvent être passées en préfixant le nom de la propriété par "hibernate.connnection". Par exemple, vous pouvez spécifier un jeu de caractères en utilisant hibernate.connection.charSet.

Vous pouvez fournir votre propre stratégie d'obtention des connexions JDBC en implémentant l'interface org.hibernate.connection.ConnectionProvider. Vous pouvez sélectionner une implémentation spécifique en positionnant hibernate.connection.provider_class.
3.4. Propriétés de configuration optionnelles

Il y a un certain nombre d'autres propriétés qui contrôlent le fonctionnement d'Hibernate à l'exécution. Toutes sont optionnelles et ont comme valeurs par défaut des valeurs "raisonnables" pour un fonctionnement nominal.

Attention : Certaines de ces propriétés sont uniquement de niveau System. Les propriétés de niveau System ne peuvent être positionnées que via la ligne de commande (java -Dproperty=value) ou être définies dans hibernate.properties. Elle ne peuvent pas l'être via une des autres techniques décrites ci-dessus.

Tableau 3.3. Propriétés de configuration d'Hibernate
Nom de la propriété	Fonction
hibernate.dialect	Le nom de la classe du Dialect Hibernate. qui permet à Hibernate de générer du SQL optimisé pour une base de données relationnelle particulière.

ex. nom.complet.de.ma.classe.de.Dialect
hibernate.show_sql	Ecrit toutes les requêtes SQL sur la console. Il s'agit d'une alternative au positionnement de la catégorie de log org.hibernate.SQL au niveau debug.

ex. true | false
hibernate.format_sql	Formate et indente le sql dans la console et dans le log

ex. true | false
hibernate.default_schema	Positionne dans le SQL généré un schéma/tablespace par défaut pour les noms de table ne l'ayant pas surchargé.

ex. MON_SCHEMA
hibernate.default_catalog	Qualifie les noms de tables non qualifiées avec ce catalogue dans le SQL généré.

ex. CATALOG_NAME
hibernate.session_factory_name	La SessionFactory sera automatiquement liée à ce nom dans le JNDI après sa création.

ex. jndi/nom/hierarchique
hibernate.max_fetch_depth	Définit la profondeur maximale d'un arbre de chargement par jointures ouvertes pour les associations à cardinalité unitaire (un-à-un, plusieurs-à-un). Un 0 désactive le chargement par jointure ouverte.

ex. valeurs recommandées entre 0 et 3
hibernate.default_batch_fetch_size	Définit une taille par défaut pour le chargement par lot des associations

ex. Valeurs recommandées : 4, 8, 16
hibernate.default_entity_mode	Définit un mode de représentation par défaut des entités pour toutes les sessions ouvertes depuis cette SessionFactory

dynamic-map, dom4j, pojo
hibernate.order_updates	Force Hibernate à trier les updates SQL par la valeur de la clé primaire des éléments qui sont mis à jour. Cela permet de limiter les deadlocks de transaction dans les systèmes hautement concurents.

ex. true | false
hibernate.generate_statistics	Si activé, Hibernate va collecter des statistiques utiles pour le réglage des performances.

ex. true | false
hibernate.use_identifer_rollback	Si activé, les propriétés correspondant à l'identifiant des objets vont être remises aux valeurs par défaut lorsque les objets seront supprimés.

ex. true | false
hibernate.use_sql_comments	Si activé, Hibernate va générer des commentaires à l'intérieur des requêtes SQL pour faciliter le debogage., par défaut à false.

ex. true | false

Tableau 3.4. Propriétés Hibernate liées à JDBC et aux connexions
Nom de la propriété	Fonction
hibernate.jdbc.fetch_size	Une valeur non nulle détermine la taille de chargement des statements JDBC (appelle Statement.setFetchSize()).
hibernate.jdbc.batch_size	Une valeur non nulle active l'utilisation par Hibernate des mises à jour par batch de JDBC2.

ex. les valeurs recommandées entre 5 et 30
hibernate.jdbc.batch_versioned_data	Paramétrez cette propriété à true si votre pilote JDBC retourne des row counts corrects depuis executeBatch() (il est souvent approprié d'activer cette option). Hibernate utilisera alors le "batched DML" pour versionner automatiquement les données. Par défaut = false.

eg. true | false
hibernate.jdbc.factory_class	Sélectionne un Batcher personnalisé. La plupart des applications n'auront pas besoin de cette propriété de configuration

ex. classname.of.Batcher
hibernate.jdbc.use_scrollable_resultset	Active l'utilisation par Hibernate des resultsets scrollables de JDBC2. Cette propriété est seulement nécessaire lorsque l'on utilise une connexion JDBC fournie par l'utilisateur. Autrement, Hibernate utilise les métadonnées de la connexion.

ex. true | false
hibernate.jdbc.use_streams_for_binary	Utilise des flux lorsque l'on écrit/lit des types binary ou serializable vers et à partir de JDBC (propriété de niveau système).

ex. true | false
hibernate.jdbc.use_get_generated_keys	Active l'utilisation de PreparedStatement.getGeneratedKeys() de JDBC3 pour récupérer nativement les clés générées après insertion. Nécessite un pilote JDBC3+, le mettre à false si votre pilote a des problèmes avec les générateurs d'identifiant Hibernate. Par défaut, essaie de déterminer les possibilités du pilote en utilisant les meta données de connexion.

eg. true|false
hibernate.connection.provider_class	Le nom de la classe d'un ConnectionProvider personnalisé qui fournit des connexions JDBC à Hibernate

ex. classname.of.ConnectionProvider
hibernate.connection.isolation	Définit le niveau d'isolation des transactions JDBC. Regardez java.sql.Connection pour connaître le sens des différentes valeurs mais notez également que la plupart des bases de données ne supportent pas tous les niveaux d'isolation.

ex. 1, 2, 4, 8
hibernate.connection.autocommit	Active le mode de commit automatique (autocommit) pour les connexions JDBC du pool (non recommandé).

ex. true | false
hibernate.connection.release_mode	Spécifie à quel moment Hibernate doit relacher les connexion JDBC. Par défaut une connexion JDBC est conservée jusqu'à ce que la session soit explicitement fermée ou déconnectée. Pour une source de données JTA d'un serveur d'application, vous devriez utiliser after_statement pour libérer les connexions de manière plus agressive après chaque appel JDBC. Pour une connexion non JTA, il est souvent préférable de libérer la connexion à la fin de chaque transaction en utilisant after_transaction. auto choisira after_statement pour des transactions JTA et CMT et after_transaction pour des transactions JDBC.

ex. on_close (default) | after_transaction | after_statement | auto
hibernate.connection.<propertyName>	Passe la propriété JDBCpropertyName à DriverManager.getConnection().
hibernate.jndi.<propertyName>	Passe la propriété propertyName à l'InitialContextFactory de JNDI.

Tableau 3.5. Propriétés du Cache d'Hibernate
Nom de la propriété	Fonction
hibernate.cache.provider_class	Le nom de classe d'un CacheProvider spécifique.

ex. nom.de.classe.du.CacheProvider
hibernate.cache.use_minimal_puts	Optimise le cache de second niveau en minimisant les écritures, au prix de plus de lectures. Ce paramètre est surtout utile pour les caches en cluster et est activé par défaut dans hibernate3 pour les implémentations de cache en cluster.

ex. true|false
hibernate.cache.use_query_cache	Activer le cache de requête, les requêtes individuelles doivent tout de même être déclarées comme pouvant être mise en cache.

ex. true|false
hibernate.cache.use_second_level_cache	Peut être utilisé pour désactiver complètement le cache de second niveau qui est activé par défaut pour les classes qui spécifient un élément <cache> dans leur mapping.

ex. true|false
hibernate.cache.query_cache_factory	Le nom de classe d'une interface QueryCacheFactory , par défaut = built-in StandardQueryCacheFactory.

ex. nom.de.la.classe.de.QueryCacheFactory
hibernate.cache.region_prefix	Un préfixe à utiliser pour le nom des régions du cache de second niveau.

ex. prefix
hibernate.cache.use_structured_entries	Force Hibernate à stocker les données dans le cache de second niveau dans un format plus adapté à la visualisation par un humain.

ex. true|false

Tableau 3.6. Propriétés des transactions Hibernate
Nom de la propriété	Fonction
hibernate.transaction.factory_class	Le nom de classe d'une TransactionFactory qui sera utilisée par l'API Transaction d'Hibernate (la valeur par défaut est JDBCTransactionFactory).

ex. nom.de.classe.d.une.TransactionFactory
jta.UserTransaction	Le nom JNDI utilisé par la JTATransactionFactory pour obtenir la UserTransaction JTA du serveur d'applications.

eg. jndi/nom/compose
hibernate.transaction.manager_lookup_class	Le nom de la classe du TransactionManagerLookup - requis lorsque le cache de niveau JVM est activé ou lorsque l'on utilise un générateur hilo dans un environnement JTA.

ex. nom.de.classe.du.TransactionManagerLookup
hibernate.transaction.flush_before_completion	Si activé, la session sera automatiquement vidée durant la phase qui précède la fin de la transaction (before completion). La gestion automatique de contexte fourni par Hibernate est recommandée, voir Section 2.5, « Sessions Contextuelles ».

ex. true | false
hibernate.transaction.auto_close_session	Si activé, la session sera automatiquement fermé pendant la phase qui suit la fin de la transaction (after completion). La gestion automatique de contexte fourni par Hibernate est recommandée, voir

ex. true | false

Tableau 3.7. Propriétés diverses
Nom de la propriété	Fonction
hibernate.current_session_context_class	Fournit une stratégie particulière pour contextualiser la Session courante. Voir Section 2.5, « Sessions Contextuelles » pour plus d'informations sur les stratégies fournies.

eg. jta | thread | custom.Class
hibernate.query.factory_class	Choisi l'implémentation du parseur de requête

ex. org.hibernate.hql.ast.ASTQueryTranslatorFactory ou org.hibernate.hql.classic.ClassicQueryTranslatorFactory
hibernate.query.substitutions	Lien entre les tokens de requêtes Hibernate et les tokens SQL (les tokens peuvent être des fonctions ou des noms littéraux par exemple).

ex. hqlLiteral=SQL_LITERAL, hqlFunction=SQLFUNC
hibernate.hbm2ddl.auto	Valide ou exporte automatiquement le schéma DDL vers la base de données lorsque la SessionFactory est créée. La valeur create-drop permet de supprimer le schéma de base de données lorsque la SessionFactory est fermée explicitement.

ex. validate | update | create | create-drop
hibernate.cglib.use_reflection_optimizer	Active l'utilisation de CGLIB à la place de la réflexion à l'exécution (Propriété de niveau système). La réflexion peut parfois être utile pour résoudre des problèmes. Notez qu'Hibernate a tout de même toujours besoin de CGLIB même si l'optimiseur est désactivé. Cette optimisation ne peut être définie que dans le fichier hibernate.cfg.xml.

ex. true | false
3.4.1. Dialectes SQL

Vous devriez toujours positionner la propriété hibernate.dialect à la sous-classe de org.hibernate.dialect.Dialect appropriée à votre base de données. Si vous spécifiez un dialecte, Hibernate utilisera des valeurs adaptées pour certaines autres propriétés listées ci-dessus, vous évitant l'effort de le faire à la main.

Tableau 3.8. Dialectes SQL d'Hibernate (hibernate.dialect)
SGBD	Dialecte
DB2	org.hibernate.dialect.DB2Dialect
DB2 AS/400	org.hibernate.dialect.DB2400Dialect
DB2 OS390	org.hibernate.dialect.DB2390Dialect
PostgreSQL	org.hibernate.dialect.PostgreSQLDialect
MySQL	org.hibernate.dialect.MySQLDialect
MySQL with InnoDB	org.hibernate.dialect.MySQLInnoDBDialect
MySQL with MyISAM	org.hibernate.dialect.MySQLMyISAMDialect
Oracle (any version)	org.hibernate.dialect.OracleDialect
Oracle 9i/10g	org.hibernate.dialect.Oracle9Dialect
Sybase	org.hibernate.dialect.SybaseDialect
Sybase Anywhere	org.hibernate.dialect.SybaseAnywhereDialect
Microsoft SQL Server	org.hibernate.dialect.SQLServerDialect
SAP DB	org.hibernate.dialect.SAPDBDialect
Informix	org.hibernate.dialect.InformixDialect
HypersonicSQL	org.hibernate.dialect.HSQLDialect
Ingres	org.hibernate.dialect.IngresDialect
Progress	org.hibernate.dialect.ProgressDialect
Mckoi SQL	org.hibernate.dialect.MckoiDialect
Interbase	org.hibernate.dialect.InterbaseDialect
Pointbase	org.hibernate.dialect.PointbaseDialect
FrontBase	org.hibernate.dialect.FrontbaseDialect
Firebird	org.hibernate.dialect.FirebirdDialect
3.4.2. Chargement par Jointure Ouverte

Si votre base de données supporte les outer joins de type ANSI, Oracle ou Sybase, le chargement par jointure ouverte devrait améliorer les performances en limitant le nombre d'aller-retour avec la base de données (la base de données effectuant donc potentiellement plus de travail). Le chargement par jointure ouverte permet à un graphe entier d'objets connectés par une relation plusieurs-à-un, un-à-plusieurs ou un-à-un d'être chargé en un seul SELECT SQL.

Le chargement par jointure ouverte peut être désactiver globalement en mettant la propriété hibernate.max_fetch_depth à 0. Une valeur de 1 ou plus active le chargement par jointure ouverte pour les associatiosn un-à-un et plusieurs-à-un qui ont été mappée avec fetch="join".

Reportez vous à Section 19.1, « Stratégies de chargement » pour plus d'information.
3.4.3. Flux binaires

Oracle limite la taille d'un tableau de byte qui peuvent être passées à et vers son pilote JDBC. Si vous souhaitez utiliser des instances larges de type binary ou serializable, vous devez activer la propriété hibernate.jdbc.use_streams_for_binary. C'est une fonctionalité de niveau système uniquement.
3.4.4. Cache de second niveau et cache de requêtes

Les propriétés préfixées par hibernate.cache vous permettent d'utiliser un système de cache de second niveau. Ce cache peut avoir une portée dans le processus ou même être utilisable dans un système distribué. Référez vous au chapitre Section 19.2, « Le cache de second niveau » pour plus de détails.
3.4.5. Substitution dans le langage de requêtage

Vous pouvez définir de nouveaux tokens dans les requêtes Hibernate en utilisant la propriété hibernate.query.substitutions. Par exemple :

hibernate.query.substitutions vrai=1, faux=0

remplacerait les tokens vrai et faux par des entiers dans le SQL généré.

hibernate.query.substitutions toLowercase=LOWER

permettrait de renommer la fonction SQL LOWER en toLowercase
3.4.6. Statistiques Hibernate

Si vous activez hibernate.generate_statistics, Hibernate va fournir un certains nombre de métriques utiles pour régler les performances d'une application qui tourne via SessionFactory.getStatistics(). Hibernate peut aussi être configuré pour exposer ces statistiques via JMX. Lisez les Javadoc des interfaces dans le package org.hibernate.stats pour plus d'informations.
3.5. Tracer

Hibernate trace divers évènements en utilisant Apache commons-logging.

Le service commons-logging délèguera directement à Apache Log4j (si vous incluez log4j.jar dans votre classpath) ou le système de trace du JDK 1.4 (si vous tournez sous le JDK 1.4 et supérieur). Vous pouvez télécharger Log4j à partir de http://jakarta.apache.org. Pour utiliser Log4j, vous devrez placer dans votre classpath un fichier log4j.properties. Un exemple de fichier est distribué avec Hibernate dans le répertoire src/.

Nous vous recommandons fortement de vous familiariser avec les messages des traces d'Hibernate. Beaucoup de soins a été apporté pour donner le plus de détails possible sans les rendre illisibles. C'est un outil essentiel en cas de soucis. Les catégories de trace les plus intéressantes sont les suivantes :

Tableau 3.9. Catégories de trace d'Hibernate
Catégorie	Fonction
org.hibernate.SQL	Trace toutes les requêts SQL de type DML (gestion des données) qui sont exécutées
org.hibernate.type	Trace tous les paramètres JDBC
org.hibernate.tool.hbm2ddl	Trace toutes les requêts SQL de type DDL (gestion de la structure de la base) qui sont exécutées
org.hibernate.pretty	Trace l'état de toutes les entités (20 entités maximum) qui sont associées avec la session hibernate au moment du flush
org.hibernate.cache	Trace toute l'activité du cache de second niveau
org.hibernate.transaction	Trace toute l'activité relative aux transactions
org.hibernate.jdbc	Trace toute acquisition de ressource JDBC
org.hibernate.hql.ast.AST	Trace l'arbre syntaxique des requêtes HQL et SQL durant l'analyse syntaxique des requêtes
org.hibernate.secure	Trace toutes les demandes d'autorisation JAAS
org.hibernate	Trace tout (beaucoupe d'informations, mais très utile pour résoudre les problèmes).

Lorsque vous développez des applications avec Hibernate, vous devriez quasiment toujours travailler avec le niveau debug activé pour la catégorie org.hibernate.SQL, ou sinon avec la propriété hibernate.show_sql activée.
3.6. Implémenter une NamingStrategy

L'interface org.hibernate.cfg.NamingStrategy vous permet de spécifier une "stratégie de nommage" des objets et éléments de la base de données.

Vous pouvez fournir des règles pour automatiquement générer les identifiants de base de données à partir des identifiants Java, ou transformer une colonne ou table "logique" donnée dans le fichier de mapping en une colonne ou table "physique". Cette fonctionnalité aide à réduire la verbosité de documents de mapping, en éliminant le bruit répétitif (les préfixes TBL_ par exemple). La stratégie par défaut utilisée par Hibernate est minimale.

Vous pouvez définir une stratégie différente en appelant Configuration.setNamingStrategy() avant d'ajouter des mappings :

SessionFactory sf = new Configuration()
    .setNamingStrategy(ImprovedNamingStrategy.INSTANCE)
    .addFile("Item.hbm.xml")
    .addFile("Bid.hbm.xml")
    .buildSessionFactory();

net.sf.hibernate.cfg.ImprovedNamingStrategy est une stratégie fournie qui peut être utile comme point de départ de quelques applications.
3.7. Fichier de configuration XML

Une approche alternative est de spécifier toute la configuration dans un fichier nommé hibernate.cfg.xml. Ce fichier peut être utilisé à la place du fichier hibernate.properties, voire même peut servir à surcharger les propriétés si les deux fichiers sont présents.

Le fichier de configuration XML doit par défaut se placer à la racine du CLASSPATH. En voici un exemple :

<?xml version='1.0' encoding='utf-8'?>
<!DOCTYPE hibernate-configuration PUBLIC
    "-//Hibernate/Hibernate Configuration DTD//EN"
    "http://hibernate.sourceforge.net/hibernate-configuration-3.0.dtd">

<hibernate-configuration>

    <!-- a SessionFactory instance listed as /jndi/name -->
    <session-factory
        name="java:hibernate/SessionFactory">

        <!-- properties -->
        <property name="connection.datasource">java:/comp/env/jdbc/MyDB</property>
        <property name="dialect">org.hibernate.dialect.MySQLDialect</property>
        <property name="show_sql">false</property>
        <property name="transaction.factory_class">
            org.hibernate.transaction.JTATransactionFactory
        </property>
        <property name="jta.UserTransaction">java:comp/UserTransaction</property>

        <!-- mapping files -->
        <mapping resource="org/hibernate/auction/Item.hbm.xml"/>
        <mapping resource="org/hibernate/auction/Bid.hbm.xml"/>

        <!-- cache settings -->
        <class-cache class="org.hibernate.auction.Item" usage="read-write"/>
        <class-cache class="org.hibernate.auction.Bid" usage="read-only"/>
        <collection-cache collection="org.hibernate.auction.Item.bids" usage="read-write"/>

    </session-factory>

</hibernate-configuration>

Commme vous pouvez le voir, l'avantage de cette approche est l'externalisation des noms des fichiers de mapping de la configuration. Le fichier hibernate.cfg.xml est également plus pratique quand on commence à régler le cache d'Hibernate. Notez que vous pouvez choisir entre utiliser hibernate.properties ou hibernate.cfg.xml, les deux sont équivalents, sauf en ce qui concerne les bénéfices de l'utilisation de la syntaxe XML mentionnés ci-dessus.

Avec la configuration XML, démarrer Hibernate devient donc aussi simple que ceci :

SessionFactory sf = new Configuration().configure().buildSessionFactory();

3.8. Intégration à un serveur d'application J2EE

Hibernate possède les points suivants d'intégration à l'infrastructure J2EE :

    *

      Source de données gérée par le conteneur : Hibernate peut utiliser des connexions JDBC gérées par le conteneur et fournie par l'intermédiaire de JNDI. Souvent, un TransactionManager compatible JTA et un ResourceManager s'occupent de la gestion des transactions (CMT). Ils sont particulièrement prévus pour pouvoir gérer des transactions distribuées sur plusieurs sources de données. Vous pouvez bien sûr également définir vos limites de transaction dans votre programme (BMT) ou vous pouvez sinon aussi utiliser l'API optionnelle Transaction d'Hibernate qui vous garantira la portabilité de votre code entre plusieurs serveurs d'application. 

    *

      Association JNDI automatique: Hibernate peut associer sa SessionFactory à JNDI après le démarrage. 

    *

      Association de la Session à JTA: La Session Hibernate peut être associée automatiquement à une transaction JTA si vous utilisez les EJBs. Vous avez juste à récupérer la SessionFactory depuis JNDI et à récupérer la Session courante. Hibernate s'occupe de vider et fermer la Session lorsque le transaction JTA se termine. La démarcation des transactions se fait de manière déclarative dans les descripteurs de déploiement. 

    *

      Déploiement JMX :Si vous avez un serveur d'application compatible JMX (JBoss AS par exemple), vous pouvez choisir de déployer Hibernate en temps que MBean géré par le serveur. Cela vous évite de coder la ligne de démarrage qui permet de construire la SessionFactory depuis la Configuration. Le conteneur va démarrer votre HibernateService, et va idéalement s'occuper des dépendances entre les services (la source de données doit être disponible avant qu'Hibernate ne démarre, etc). 

En fonction de votre environnement, vous devrez peut être mettre l'option de configuration hibernate.connection.aggressive_release à vrai si le serveur d'application affiche des exceptions de type "connection containment".
3.8.1. Configuration de la stratégie transactionnelle

L'API de la Session Hibernate est indépendante de tout système de démarcation des transactions qui peut être présent dans votre architecture. Si vous laissez Hibernate utiliser l'API JDBC directement via un pool de connexion, vous devrez commencer et terminer vos transactions en utilisant l'API JDBC. Si votre application tourne à l'intérieur d'un serveur d'application J2EE, vous voudrez peut être utiliser les transactions gérées par les beans (BMT) et appeller l'API JTA et UserTransaction lorsque cela est nécessaire.

Pour conserver votre code portable entre ces deux environnements (et d'autres éventuels) nous vous recommandons d'utiliser l'API optionnelle Transaction d'Hibernate, qui va encapsuler et masquer le système de transaction sous-jacent. Pour cela, vous devez préciser une classe de fabrique d'instances de Transaction en positionnant la propriété hibernate.transaction.factory_class.

Il existe trois choix standards (fournis) :

net.sf.hibernate.transaction.JDBCTransactionFactory

    délègue aux transactions de la base de données (JDBC). Valeur par défaut.
org.hibernate.transaction.JTATransactionFactory

    délègue à CMT si une transaction existante est sous ce contexte (ex: méthode d'un EJB session), sinon une nouvelle transaction est entamée et une transaction gérée par le bean est utilisée. 
org.hibernate.transaction.CMTTransactionFactory

    délègue à aux transactions JTA gérées par le conteneur

Vous pouvez également définir votre propre stratégie transactionnelle (pour un service de transaction CORBA par exemple).

Certaines fonctionnalités d'Hibernate (i.e. le cache de second niveau, l'association automatique des Session à JTA, etc.) nécessitent l'accès au TransactionManager JTA dans un environnement "managé". Dans un serveur d'application, vous devez indiquer comment Hibernate peut obtenir une référence vers le TransactionManager, car J2EE ne fournit pas un seul mécanisme standard.

Tableau 3.10. TransactionManagers JTA
Fabrique de Transaction	Serveur d'application
org.hibernate.transaction.JBossTransactionManagerLookup	JBoss
org.hibernate.transaction.WeblogicTransactionManagerLookup	Weblogic
org.hibernate.transaction.WebSphereTransactionManagerLookup	WebSphere
org.hibernate.transaction.WebSphereExtendedJTATransactionLookup	WebSphere 6
org.hibernate.transaction.OrionTransactionManagerLookup	Orion
org.hibernate.transaction.ResinTransactionManagerLookup	Resin
org.hibernate.transaction.JOTMTransactionManagerLookup	JOTM
org.hibernate.transaction.JOnASTransactionManagerLookup	JOnAS
org.hibernate.transaction.JRun4TransactionManagerLookup	JRun4
org.hibernate.transaction.BESTransactionManagerLookup	Borland ES
3.8.2. SessionFactory associée au JNDI

Une SessionFactory Hibernate associée au JNDI peut simplifier l'accès à la fabrique et donc la création de nouvelles Sessions. Notez que cela n'est pas lié avec les Datasource associées au JNDI, elles utilisent juste le même registre.

Si vous désirez associer la SessionFactory à un nom JNDI, spécifiez un nom (ex. java:hibernate/SessionFactory) en utilisant la propriété hibernate.session_factory_name. Si cette propriété est omise, la SessionFactory ne sera pas associée au JNDI (c'est particulièrement pratique dans les environnements ayant une implémentation de JNDI en lecture seule, comme c'est le cas pour Tomcat).

Lorsqu'il associe la SessionFactory au JNDI, Hibernate utilisera les valeurs de hibernate.jndi.url, hibernate.jndi.class pour instancier un contexte d'initialisation. S'ils ne sont pas spécifiés, l'InitialContext par défaut sera utilisé.

Hibernate va automatiquement placer la SessionFactory dans JNDI après avoir appelé cfg.buildSessionFactory(). Cela signifie que vous devez avoir cet appel dans un code de démarrage (ou dans une classe utilitaire) dans votre application sauf si vous utilisez le déploiement JMX avec le service HibernateService présenté plus tard dans ce document.

Si vous utilisez SessionFactory JNDI, un EJB ou n'importe quelle autre classe peut obtenir la SessionFactory en utilisant un lookup JNDI.

Nous recommandons que vous liiez la SessionFactory à JNDI dans les environnements managés et que vous utilisiez un singleton static si ce n'est pas le cas. Pour isoler votre application de ces détails, nous vous recommandons aussi de masquer le code de lookup actuel pour une SessionFactory dans une classe helper, comme HibernateUtil.getSessionFactory(). Notez qu'une telle classe est aussi un moyen efficace de démarrer Hibernate?voir chapitre 1.
3.8.3. Association automatique de la Session à JTA

Le moyen le plus simple de gérer les Sessions et transactions est la gestion automatique de session "courante" offerte par Hibernate. Voir détail à Section 2.5, « Sessions Contextuelles ». En utilisant le contexte de session "jta" session context, s'il n'y a pas de Session associée à la transaction JTA courante, une session sera démarrée et associée à la transaction JTA courante la première fois que vous appelez sessionFactory.getCurrentSession(). Les Sessions obtenue via getCurrentSession() dans une contexte "jta" seront automatiquement flushées avant la validation de la transaction, fermées une fois la transaction complétée, et libéreront les connexions JDBC de manière aggressive après chaque statement. Ceci permet aux Sessions d'être gérées par le cycle de vie de la transaction JTA à la quelle est sont associées, laissant le code de l'utilisateur propre de ce type de gestion. Votre code peut soit utiliser JTA de manière programmatique via UserTransaction, ou (ce qui est recommandé pour la portabilité du code) utiliser l'API Transaction API pour marquer les limites. Si vous exécutez sous un conteneur EJB, la démarcation déclarative des transactions avec CMT est recommandée.
3.8.4. Déploiement JMX

La ligne cfg.buildSessionFactory() doit toujours être exécutée quelque part pour avoir une SessionFactory dans JNDI. Vous pouvez faire cela dans un bloc d'initialisation static (comme celui qui se trouve dans la classe HibernateUtil) ou vous pouvez déployer Hibernate en temps que service managé.

Hibernate est distribué avec org.hibernate.jmx.HibernateService pour le déploiement sur un serveur d'application avec le support de JMX comme JBoss AS. Le déploiement et la configuration sont spécifiques à chaque vendeur. Voici un fichier jboss-service.xml d'exemple pour JBoss 4.0.x:

<?xml version="1.0"?>
<server>

<mbean code="org.hibernate.jmx.HibernateService"
    name="jboss.jca:service=HibernateFactory,name=HibernateFactory">

    <!-- Required services -->
    <depends>jboss.jca:service=RARDeployer</depends>
    <depends>jboss.jca:service=LocalTxCM,name=HsqlDS</depends>

    <!-- Bind the Hibernate service to JNDI -->
    <attribute name="JndiName">java:/hibernate/SessionFactory</attribute>

    <!-- Datasource settings -->
    <attribute name="Datasource">java:HsqlDS</attribute>
    <attribute name="Dialect">org.hibernate.dialect.HSQLDialect</attribute>

    <!-- Transaction integration -->
    <attribute name="TransactionStrategy">
        org.hibernate.transaction.JTATransactionFactory</attribute>
    <attribute name="TransactionManagerLookupStrategy">
        org.hibernate.transaction.JBossTransactionManagerLookup</attribute>
    <attribute name="FlushBeforeCompletionEnabled">true</attribute>
    <attribute name="AutoCloseSessionEnabled">true</attribute>

    <!-- Fetching options -->
    <attribute name="MaximumFetchDepth">5</attribute>

    <!-- Second-level caching -->
    <attribute name="SecondLevelCacheEnabled">true</attribute>
    <attribute name="CacheProviderClass">org.hibernate.cache.EhCacheProvider</attribute>
    <attribute name="QueryCacheEnabled">true</attribute>

    <!-- Logging -->
    <attribute name="ShowSqlEnabled">true</attribute>

    <!-- Mapping files -->
    <attribute name="MapResources">auction/Item.hbm.xml,auction/Category.hbm.xml</attribute>

</mbean>

</server>

Ce fichier est déployé dans un répertoire META-INF et est packagé dans un fichier JAR avec l'extension .sar (service archive). Vous devez également packager Hibernate, les librairies tierces requises, vos classes persistantes compilées et vos fichiers de mapping dans la même archive. Vos beans entreprise (souvent des EJBs session) peuvent rester dans leur propre fichier JAR mais vous pouvez inclure ce fichier JAR dans le jar principal du service pour avoir une seule unité déployable à chaud. Vous pouvez consulter la documentation de JBoss AS pour plus d'information sur les services JMX et le déploiement des EJBs.
Chapitre 4. Classes persistantes

Les classes persistantes sont les classes d'une application qui implémentent les entités d'un problème métier (ex. Client et Commande dans une application de commerce électronique). Toutes les instances d'une classe persistante ne sont pas forcément dans l'état persistant - au lieu de cela, une instance peut être éphémère (NdT : transient) ou détachée.

Hibernate fonctionne de manière optimale lorsque ces classes suivent quelques règles simples, aussi connues comme le modèle de programmation Plain Old Java Object (POJO). Cependant, aucune de ces règles ne sont des besoins absolus. En effet, Hibernate3 suppose très peu de choses à propos de la nature de vos objets persistants. Vous pouvez exprimer un modèle de domaine par d'autres moyens : utiliser des arbres d'instances de Map, par exemple.
4.1. Un exemple simple de POJO

Toute bonne application Java nécessite une classe persistante représentant les félins.

package eg;
import java.util.Set;
import java.util.Date;

public class Cat {
    private Long id; // identifier

    private Date birthdate;
    private Color color;
    private char sex;
    private float weight;
    private int litterId;

    private Cat mother;
    private Set kittens = new HashSet();

    private void setId(Long id) {
        this.id=id;
    }
    public Long getId() {
        return id;
    }

    void setBirthdate(Date date) {
        birthdate = date;
    }
    public Date getBirthdate() {
        return birthdate;
    }

    void setWeight(float weight) {
        this.weight = weight;
    }
    public float getWeight() {
        return weight;
    }

    public Color getColor() {
        return color;
    }
    void setColor(Color color) {
        this.color = color;
    }

    void setSex(char sex) {
        this.sex=sex;
    }
    public char getSex() {
        return sex;
    }

    void setLitterId(int id) {
        this.litterId = id;
    }
    public int getLitterId() {
        return litterId;
    }

    void setMother(Cat mother) {
        this.mother = mother;
    }
    public Cat getMother() {
        return mother;
    }
    void setKittens(Set kittens) {
        this.kittens = kittens;
    }
    public Set getKittens() {
        return kittens;
    }

    // addKitten not needed by Hibernate
    public void addKitten(Cat kitten) {
        kitten.setMother(this);
    kitten.setLitterId( kittens.size() );
        kittens.add(kitten);
    }
}

Il y a quatre règles à suivre ici :
4.1.1. Implémenter un constructeur sans argument

Cat a un constructeur sans argument. Toutes les classes persistantes doivent avoir un constructeur par défaut (lequel peut ne pas être public) pour qu'Hibernate puissent les instancier en utilisant Constructor.newInstance(). Nous recommandons fortement d'avoir un constructeur par défaut avec au moins une visibilité paquet pour la génération du proxy à l'exécution dans Hibernate.
4.1.2. Fournir une propriété d'indentifiant (optionnel)

Cat possède une propriété appelée id. Cette propriété mappe la valeur de la colonne de clé primaire de la table d'une base de données.La propriété aurait pu s'appeler complètement autrement, et son type aurait pu être n'importe quel type primitif, n'importe quel "encapsuleur" de type primitif, java.lang.String ou java.util.Date. (Si votre base de données héritée possède des clés composites, elles peuvent être mappées en utilisant une classe définie par l'utilisateur et possédant les propriétés associées aux types de la clé composite - voir la section concernant les identifiants composites plus tard).

La propriété d'identifiant est strictement optionnelle. Vous pouver l'oublier et laisser Hibernate s'occuper des identifiants de l'objet en interne. Toutefois, nous ne le recommandons pas.

En fait, quelques fonctionnalités ne sont disponibles que pour les classes déclarant un identifiant de propriété :

    *

      Les réattachements transitifs pour les objets détachés (mise à jour en cascade ou fusion en cascade) - voir Section 10.11, « Persistance transitive »
    *

      Session.saveOrUpdate()
    *

      Session.merge() 

Nous recommandons que vous déclariez les propriétés d'identifiant de manière uniforme. Nous recommandons également que vous utilisiez un type nullable (ie. non primitif).
4.1.3. Favoriser les classes non finales (optionnel)

Une fonctionnalité clef d'Hibernate, les proxies, nécessitent que la classe persistente soit non finale ou qu'elle soit l'implémentation d'une interface qui déclare toutes les méthodes publiques.

Vous pouvez persister, grâce à Hibernate, les classes final qui n'implémentent pas d'interface, mais vous ne pourrez pas utiliser les proxies pour les chargements d'associations paresseuses - ce qui limitera vos possibilités d'ajustement des performances.

Vous devriez aussi éviter de déclarer des méthodes public final sur des classes non-finales. Si vous voulez utiliser une classe avec une méthode public final, vous devez explicitement désactiver les proxies en paramétrant lazy="false".
4.1.4. Déclarer les accesseurs et mutateurs des attributs persistants (optionnel)

Cat déclare des mutateurs pour toutes ses champs persistants. Beaucoup d'autres solutions de mapping Objet/relationnel persistent directement les variables d'instance. Nous pensons qu'il est bien mieux de fournir une indirection entre le schéma relationnel et les structures de données internes de la classe. Par défaut, Hibernate persiste les propriétés suivant le style JavaBean, et reconnaît les noms de méthodes de la forme getFoo, isFoo et setFoo. Nous pouvons changer pour un accès direct aux champs pour des propriétés particulières, si besoin est.

Les propriétés n'ont pas à être déclarées publiques - Hibernate peut persister une propriété avec un paire de getter/setter de visibilité par défault, protected ou private.
4.2. Implémenter l'héritage

Une sous-classe doit également suivre la première et la seconde règle. Elle hérite sa propriété d'identifiant de Cat.

package eg;

public class DomesticCat extends Cat {
        private String name;

        public String getName() {
                return name;
        }
        protected void setName(String name) {
                this.name=name;
        }
}

4.3. Implémenter equals() et hashCode()

Vous devez surcharger les méthodes equals() et hashCode() si vous

    *

      avez l'intention de mettre des instances de classes persistantes dans un Set (la manière recommandée pour représenter des associations pluri-valuées) et
    *

      avez l'intention d'utiliser le réattachement d'instances détachées 

Hibernate garantit l'équivalence de l'identité persistante (ligne de base de données) et l'identité Java seulement à l'intérieur de la portée d'une session particulière. Donc dès que nous mélangeons des instances venant de différentes sessions, nous devons implémenter equals() et hashCode() si nous souhaitons avoir une sémantique correcte pour les Sets.

La manière la plus évidente est d'implémenter equals()/hashCode() en comparant la valeur de l'identifiant des deux objets. Si cette valeur est identique, les deux doivent représenter la même ligne de base de données, ils sont donc égaux (si les deux sont ajoutés à un Set, nous n'aurons qu'un seul élément dans le Set). Malheureusement, nous ne pouvons pas utiliser cette approche avec des identifiants générés ! Hibernate n'assignera de valeur d'identifiant qu'aux objets qui sont persistants, une instance nouvellement créée n'aura donc pas de valeur d'identifiant ! De plus, si une instance est non sauvegardée et actuellement dans un Set, le sauvegarder assignera une valeur d'identifiant à l'objet. Si equals() et hashCode() sont basées sur la valeur de l'identifiant, le code de hachage devrait changer, rompant le contrat du Set. Regardez sur le site web d'Hibernate pour une discussion complète de ce problème. Notez que ceci n'est pas un problème d'Hibernate, mais la sémantique normale de Java pour l'identité d'un objet et l'égalité.

Nous recommandons donc d'implémenter equals() et hashCode() en utilisant l'égalité par clé métier.L'égalité par clé métier signifie que la méthode equals() compare uniquement les propriétés qui forment une clé métier, une clé qui identifierait notre instance dans le monde réel (une clé candidate naturelle) :

public class Cat {

    ...
    public boolean equals(Object other) {
        if (this == other) return true;
        if ( !(other instanceof Cat) ) return false;

        final Cat cat = (Cat) other;

        if ( !cat.getLitterId().equals( getLitterId() ) ) return false;
        if ( !cat.getMother().equals( getMother() ) ) return false;

        return true;
    }

    public int hashCode() {
        int result;
        result = getMother().hashCode();
        result = 29 * result + getLitterId();
        return result;
    }

}

Notez qu'une clef métier ne doit pas être solide comme une clef primaire de base de données (voir Section 11.1.3, « L'identité des objets »). Les propriétés immuables ou uniques sont généralement de bonnes candidates pour une clef métier.
4.4. Modèles dynamiques

Notez que la fonctionnalités suivantes sont actuellement considérées comme expérimentales et peuvent changer dans un futur proche.

Les entités persistantes ne doivent pas nécessairement être représentées comme des classes POJO ou des objets JavaBean à l'exécution. Hibernate supporte aussi les modèles dynamiques (en utilisant des Maps de Maps à l'exécution) et la représentation des entités comme des arbres DOM4J. Avec cette approche, vous n'écrivez pas de classes persistantes, seulement des fichiers de mapping.

Par défaut, Hibernate fonctionne en mode POJO normal. Vous pouvez paramétrer un mode de représentation d'entité par défaut pour une SessionFactory particulière en utilisant l'option de configuration default_entity_mode (voir Tableau 3.3, « Propriétés de configuration d'Hibernate »).

Les exemples suivants démontrent la représentation utilisant des Maps. D'abord, dans le fichier de mapping, un entity-name doit être déclaré au lieu (ou en plus) d'un nom de classe :

<hibernate-mapping>

    <class entity-name="Customer">

        <id name="id"
            type="long"
            column="ID">
            <generator class="sequence"/>
        </id>

        <property name="name"
            column="NAME"
            type="string"/>

        <property name="address"
            column="ADDRESS"
            type="string"/>

        <many-to-one name="organization"
            column="ORGANIZATION_ID"
            class="Organization"/>

        <bag name="orders"
            inverse="true"
            lazy="false"
            cascade="all">
            <key column="CUSTOMER_ID"/>
            <one-to-many class="Order"/>
        </bag>

    </class>

</hibernate-mapping>

Notez que même si des associations sont déclarées en utilisant des noms de classe cible, le type de cible d'une association peut aussi être une entité dynamique au lieu d'un POJO.

Après avoir configuré le mode d'entité par défaut à dynamic-map pour la SessionFactory, nous pouvons lors de l'exécution fonctionner avec des Maps de Maps :

Session s = openSession();
Transaction tx = s.beginTransaction();
Session s = openSession();

// Create a customer
Map david = new HashMap();
david.put("name", "David");

// Create an organization
Map foobar = new HashMap();
foobar.put("name", "Foobar Inc.");

// Link both
david.put("organization", foobar);

// Save both
s.save("Customer", david);
s.save("Organization", foobar);

tx.commit();
s.close();

Les avantages d'un mapping dynamique sont un gain de temps pour le prototypage sans la nécessité d'implémenter les classes d'entité. Pourtant, vous perdez la vérification du typage au moment de la compilation et aurez plus d'exceptions à gérer lors de l'exécution. Grâce au mapping d'Hibernate, le schéma de la base de données peut facilement être normalisé et solidifié, permettant de rajouter une implémentation propre du modèle de domaine plus tard.

Les modes de représentation d'une entité peut aussi être configuré par Session :

Session dynamicSession = pojoSession.getSession(EntityMode.MAP);

// Create a customer
Map david = new HashMap();
david.put("name", "David");
dynamicSession.save("Customer", david);
...
dynamicSession.flush();
dynamicSession.close()
...
// Continue on pojoSession

Veuillez noter que l'appel à getSession() en utilisant un EntityMode se fait sur l'API Session, pas SessionFactory. De cette manière, la nouvelle Session partage les connexions JDBC, transactions et autres informations de contexte sous-jacentes. Cela signifie que vous n'avez pas à appeler flush() et close() sur la Session secondaire, et laissez aussi la gestion de la transaction et de la connexion à l'unité de travail primaire.

Plus d'informations à propos de la représentation XML peuvent être trouvées dans Chapitre 18, Mapping XML.
4.5. Tuplizers

org.hibernate.tuple.Tuplizer, et ses sous-interfaces, sont responsables de la gestion d'une représentation particulière d'un morceau de données, en fonction du org.hibernate.EntityMode de réprésentation. Si un morceau donné de données est pensé comme une structure de données, alors un tuplizer est la chose qui sait comment créer une telle structure de données, comment extraire des valeurs et injecter des valeurs dans une telle structure de données. Par exemple, pour le mode d'entité POJO, le tuplizer correspondant sait comment créer le POJO à travers son constructeur et comment accéder aux propriétés du POJO utilisant les accesseurs de la propriété définie. Il y a deux types de Tuplizers haut niveau, représenté par les interfaces org.hibernate.tuple.EntityTuplizer et org.hibernate.tuple.ComponentTuplizer. Les EntityTuplizers sont responsables de la gestion des contrats mentionnés ci-dessus pour les entités, alors que les ComponentTuplizers s'occupent des composants.

Les utilisateurs peuvent aussi brancher leurs propres tuplizers. Peut-être vous est-il nécessaire qu'une implémentation de java.util.Map autre que java.util.HashMap soit utilisée dans le mode d'entité dynamic-map ; ou peut-être avez-vous besoin de définir une statégie de génération de proxy différente de celle utilisée par défaut. Les deux devraient être effectuées en définissant une implémentation de tuplizer utilisateur. Les définitions de tuplizers sont attachées au mapping de l'entité ou du composant qu'ils sont censés gérer. Retour à l'exemple de notre entité utilisateur :

<hibernate-mapping>
    <class entity-name="Customer">
        <!--
            Override the dynamic-map entity-mode
            tuplizer for the customer entity
        -->
        <tuplizer entity-mode="dynamic-map"
                class="CustomMapTuplizerImpl"/>

        <id name="id" type="long" column="ID">
            <generator class="sequence"/>
        </id>

        <!-- other properties -->
        ...
    </class>
</hibernate-mapping>


public class CustomMapTuplizerImpl
        extends org.hibernate.tuple.DynamicMapEntityTuplizer {
    // override the buildInstantiator() method to plug in our custom map...
    protected final Instantiator buildInstantiator(
            org.hibernate.mapping.PersistentClass mappingInfo) {
        return new CustomMapInstantiator( mappingInfo );
    }

    private static final class CustomMapInstantiator
            extends org.hibernate.tuple.DynamicMapInstantitor {
        // override the generateMap() method to return our custom map...
        protected final Map generateMap() {
            return new CustomMap();
        }
    }
}

TODO: Document user-extension framework in the property and proxy packages
Chapitre 5. Mapping O/R basique
5.1. Déclaration de Mapping

Les mappings Objet/relationnel sont généralement définis dans un document XML. Le document de mapping est conçu pour être lisible et éditable à la main. Le langage de mapping est Java-centrique, c'est à dire que les mappings sont construits à partir des déclarations des classes persistantes et non des déclarations des tables.

Remarquez que même si beaucoup d'utilisateurs de Hibernate préfèrent écrire les fichiers de mappings à la main, plusieurs outils existent pour générer ce document, notamment XDoclet, Middlegen et AndroMDA.

Démarrons avec un exemple de mapping :

<?xml version="1.0"?>
<!DOCTYPE hibernate-mapping PUBLIC
      "-//Hibernate/Hibernate Mapping DTD 3.0//EN"
          "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd">

<hibernate-mapping package="eg">

        <class name="Cat" 
            table="cats"
            discriminator-value="C">
                
                <id name="id">
                        <generator class="native"/>
                </id>

                <discriminator column="subclass" 
                     type="character"/>

                <property name="weight"/>

                <property name="birthdate"
                    type="date" 
                    not-null="true" 
                    update="false"/>

                <property name="color"
                    type="eg.types.ColorUserType"
                    not-null="true"
                    update="false"/>

                <property name="sex"
                    not-null="true" 
                    update="false"/>

                <property name="litterId"
                    column="litterId"
                    update="false"/>

                <many-to-one name="mother"
                    column="mother_id"
                    update="false"/>

                <set name="kittens"
                    inverse="true"
                    order-by="litter_id">
                        <key column="mother_id"/>
                        <one-to-many class="Cat"/>
                </set>

                <subclass name="DomesticCat"
                    discriminator-value="D">

                        <property name="name" 
                            type="string"/>

                </subclass>

        </class>

        <class name="Dog">
                <!-- mapping for Dog could go here -->
        </class>

</hibernate-mapping>

Etudions le contenu du document de mapping. Nous décrirons uniquement les éléments et attributs du document utilisés par Hibernate à l'exécution. Le document de mapping contient aussi des attributs et éléments optionnels qui agissent sur le schéma de base de données exporté par l'outil de génération de schéma. (Par exemple l'attribut not-null.)
5.1.1. Doctype

Tous les mappings XML devraient utiliser le doctype indiqué. Ce fichier est présent à l'URL ci-dessus, dans le répertoire hibernate-x.x.x/src/org/hibernate ou dans hibernate3.jar. Hibernate va toujours chercher la DTD dans son classpath en premier lieu. Si vous constatez des recherches de la DTD sur Internet, vérifiez votre déclaration de DTD par rapport au contenu de votre classpath.
5.1.2. hibernate-mapping

Cet élément a plusieurs attributs optionnels. Les attributs schema et catalog indiquent que les tables référencées par ce mapping appartiennent au schéma nommé et/ou au catalogue. S'ils sont spécifiés, les noms de tables seront qualifiés par les noms de schéma et catalogue. L'attribut default-cascade indique quel type de cascade sera utlisé par défaut pour les propriétés et collections qui ne précisent pas l'attribut cascade. L'attribut auto-import nous permet d'utiliser par défaut des noms de classes non qualifiés dans le langage de requête.

<hibernate-mapping
         schema="schemaName"                          (1)
         catalog="catalogName"                        (2)
         default-cascade="cascade_style"              (3)
         default-access="field|property|ClassName"    (4)
         default-lazy="true|false"                    (5)
         auto-import="true|false"                     (6)
         package="package.name"                       (7)
 />

(1)	

schema (optionnel) : Le nom d'un schéma de base de données.
(2)	

catalog (optionnel) : Le nom d'un catalogue de base de données.
(3)	

default-cascade (optionnel - par défaut vaut : none) : Un type de cascade par défaut.
(4)	

default-access (optionnel - par défaut vaut : property) : Comment hibernate accèdera aux propriétés. On peut aussi redéfinir sa propre implémentation de PropertyAccessor.
(5)	

default-lazy (optionnel - par défaut vaut : true) : Valeur par défaut pour un attribut lazy non spécifié : celui des mappings de classes et de collection.
(6)	

auto-import (optionnel - par défaut vaut : true) : Spécifie si l'on peut utiliser des noms de classes non qualifiés (des classes de ce mapping) dans le langage de requête.
(7)	

package (optionnel) : Préfixe de package par défaut pour les noms de classe non qualifiés du document de mapping.

Si deux classes possèdent le même nom de classe (non qualifié), vous devez indiquer auto-import="false". Hibernate lancera une exception si vous essayez d'assigner à deux classes le même nom importé.

Notez que l'élément hibernate-mapping vous permet d'imbriquer plusieurs mappings de <class> persistantes, comme dans l'exemple ci-dessus. Cependant la bonne pratique (ce qui est attendu par certains outils) est de mapper une seule classe (ou une seule hiérarchie de classes) par fichier de mapping et de nommer ce fichier d'après le nom de la superclasse, par exemple Cat.hbm.xml, Dog.hbm.xml, ou en cas d'héritage, Animal.hbm.xml.
5.1.3. class

Déclarez une classe persistante avec l'élément class :

<class
        name="ClassName"                              (1)
        table="tableName"                             (2)
        discriminator-value="discriminator_value"     (3)
        mutable="true|false"                          (4)
        schema="owner"                                (5)
        catalog="catalog"                             (6)
        proxy="ProxyInterface"                        (7)
        dynamic-update="true|false"                   (8)
        dynamic-insert="true|false"                   (9)
        select-before-update="true|false"             (10)
        polymorphism="implicit|explicit"              (11)
        where="arbitrary sql where condition"         (12)
        persister="PersisterClass"                    (13)
        batch-size="N"                                (14)
        optimistic-lock="none|version|dirty|all"      (15)
        lazy="true|false"                             (16)
        entity-name="EntityName"                      (17)
        catalog="catalog"                             (18)
        check="arbitrary sql check condition"         (19)
        rowid="rowid"                                 (20)
        subselect="SQL expression"                    (21)
        abstract="true|false"
        entity-name="EntityName"
/>

(1)	

name (optionnel) : Le nom Java complet de la classe (ou interface) persistante. Si cet attribut est absent, il est supposé que ce mapping ne se rapporte pas à une entité POJO.
(2)	

table (optionnel - par défaut le nom (non-qualifié) de la classe) : Le nom de sa table en base de données.
(3)	

discriminator-value (optionnel - par défaut le nom de la classe) : Une valeur permettant de distinguer les sous-classes dans le cas de l'utilisation du polymorphisme. Les valeurs null et not null sont autorisées.
(4)	

mutable (optionnel, vaut true par défaut) : Spécifie que des instances de la classe sont (ou non) immuables.
(5)	

schema (optionnel) : Surcharge le nom de schéma spécifié par l'élément racine <hibernate-mapping>.
(6)	

catalog (optionnel) : Surcharge le nom du catalogue spécifié par l'élément racine <hibernate-mapping>.
(7)	

proxy (optionnel) : Spécifie une interface à utiliser pour l'initialisation différée (lazy loading) des proxies. Vous pouvez indiquer le nom de la classe elle-même.
(8)	

dynamic-update (optionnel, par défaut à false) : Spécifie que les UPDATE SQL doivent être générés à l'exécution et contenir uniquement les colonnes dont les valeurs ont été modifiées.
(9)	

dynamic-insert (optionnel, par défaut à false): Spécifie que les INSERT SQL doivent être générés à l'exécution et ne contenir que les colonnes dont les valeurs sont non nulles.
(10)	

select-before-update (optionnel, par défaut à false): Spécifie que Hibernate ne doit jamais exécuter un UPDATE SQL sans être certain qu'un objet a été réellement modifié. Dans certains cas, (en réalité, seulement quand un objet transient a été associé à une nouvelle session par update()), cela signifie que Hibernate exécutera un SELECT SQL pour s'assurer qu'un UPDATE SQL est véritablement nécessaire.
(11)	

polymorphism (optionnel, vaut implicit par défaut) : Détermine si, pour cette classe, une requête polymorphique implicite ou explicite est utilisée.
(12)	

where (optionnel) spécifie une clause SQL WHERE à utiliser lorsque l'on récupère des objets de cette classe.
(13)	

persister (optionnel) : Spécifie un ClassPersister particulier.
(14)	

batch-size (optionnel, par défaut = 1) : spécifie une taille de batch pour remplir les instances de cette classe par identifiant en une seule requête.
(15)	

optimistic-lock (optionnel, par défaut = version) : Détermine la stratégie de verrou optimiste.
(16)	

lazy (optionnel) : Déclarer lazy="true" est un raccourci pour spécifier le nom de la classe comme étant l'interface proxy.
(17)	

entity-name (optionnel) : Hibernate3 permet à une classe d'être mappée plusieurs fois (potentiellement à plusieurs tables), et permet aux mappings d'entité d'être représentés par des Maps ou du XML au niveau Java. Dans ces cas, vous devez indiquer un nom explicite arbitraire pour les entités. Voir Section 4.4, « Modèles dynamiques » et Chapitre 18, Mapping XML pour plus d'informations.
(18)	

catalog (optionnel) : The name of a database catalog used for this class and its table.
(19)	

check (optionnel) : expression SQL utilisée pour générer une contrainte de vérification multi-lignes pour la génération automatique de schéma.
(20)	

rowid (optionnel) : Hibernate peut utiliser des ROWID sur les bases de données qui utilisent ce mécanisme. Par exemple avec Oracle, Hibernate peut utiliser la colonne additionnelle rowid pour des mises à jour rapides si cette option vaut rowid. Un ROWID représente la localisation physique d'un tuple enregistré.
(21)	

subselect (optionnel) : Permet de mapper une entité immuable en lecture-seule sur un sous-select de base de données. Utile pour avoir une vue au lieu d'une table en base, mais à éviter. Voir plus bas pour plus d'information.
???	

abstract (optionnel) : Utilisé pour marquer des superclasses abstraites dans des hiérarchies de <union-subclass>.

Il est tout à fait possible d'utiliser une interface comme nom de classe persistante. Vous devez alors déclarer les classes implémentant cette interface en utilisant l'élément <subclass>. Vous pouvez faire persister toute classe interne static. Vous devez alors spécifier le nom de la classe par la notation habituelle des classes internes c'est à dire eg.Foo$Bar.

Les classes immuables, mutable="false", ne peuvent pas être modifiées ou supprimées par l'application. Cela permet à Hibernate de faire quelques optimisations mineures sur les performances.

L'attribut optionnnel proxy permet les intialisations différées des instances persistantes de la classe. Hibernate retournera initialement des proxies CGLIB qui implémentent l'interface nommée. Le véritable objet persistant ne sera chargé que lorsque une méthode du proxy sera appelée. Voir plus bas le paragraphe abordant les proxies et le chargement différé (lazy initialization).

Le polymorphisme implicite signifie que les instances de la classe seront retournées par une requête qui utilise les noms de la classe ou de chacune de ses superclasses ou encore des interfaces implémentées par cette classe ou ses superclasses. Les instances des classes filles seront retournées par une requête qui utilise le nom de la classe elle même. Le polymorphisme explicite signifie que les instances de la classe ne seront retournées que par une requête qui utilise explicitement son nom et que seules les instances des classes filles déclarées dans les éléments <subclass> ou <joined-subclass> seront retournées. Dans la majorités des cas la valeur par défaut, polymorphism="implicit", est appropriée. Le polymorphisme explicite est utile lorsque deux classes différentes sont mappées à la même table (ceci permet d'écrire une classe "légère" qui ne contient qu'une partie des colonnes de la table - voir la partie design pattern du site communautaire).

L'attribut persister vous permet de customiser la stratégie utilisée pour la classe. Vous pouvez, par exemple, spécifier votre propre sous-classe de org.hibernate.persister.EntityPersister ou vous pourriez aussi créer une nouvelle implémentation de l'interface org.hibernate.persister.ClassPersister qui proposerait une persistance via, par exemple, des appels de procédures stockées, de la sérialisation vers des fichiers plats ou un annuaire LDAP. Voir org.hibernate.test.CustomPersister pour un exemple simple (d'une "persistance" vers une Hashtable).

Notez que les paramètres dynamic-update et dynamic-insert ne sont pas hérités par les sous-classes et peuvent donc être spécifiés pour les éléments <subclass> ou <joined-subclass> Ces paramètres peuvent améliorer les performances dans certains cas, mais peuvent aussi les amoindrir. A utiliser en connaissance de causes.

L'utilisation de select-before-update va généralement faire baisser les performances. Ce paramètre est pratique pour prévenir l'appel inutile d'un trigger sur modification quand on réattache un graphe d'instances à une Session.

Si vous utilisez le dynamic-update, les différentes stratégies de verrouillage optimiste (optimistic locking) sont les suivantes:

    *

      version vérifie les colonnes version/timestamp
    *

      all vérifie toutes les colonnes
    *

      dirty vérifie les colonnes modifiées, permettant des updates concurrents
    *

      none pas de verrouillage optimiste 

Nous encourageons très fortement l'utilisation de colonnes de version/timestamp pour le verrouillage optimiste avec Hibernate. C'est la meilleure stratégie en regard des performances et la seule qui gère correctement les modifications sur les objets détachés (c'est à dire lorsqu'on utilise Session.merge()).

Il n'y a pas de différence entre table et vue pour le mapping Hibernate, tant que c'est transparent au niveau base de données (remarquez que certaines BDD ne supportent pas les vues correctement, notamment pour les updates). Vous rencontrerez peut-être des cas où vous souhaitez utiliser une vue mais ne pouvez pas en créer sur votre BDD (par exemple à cause de schémas anciens et figés). Dans ces cas, vous pouvez mapper une entité immuable en lecture seule sur un sous-select SQL donné:

<class name="Summary">
    <subselect>
        select item.name, max(bid.amount), count(*)
        from item
        join bid on bid.item_id = item.id
        group by item.name
    </subselect>
    <synchronize table="item"/>
    <synchronize table="bid"/>
    <id name="name"/>
    ...
</class>

Déclarez les tables à synchroniser avec cette entité pour assurer que le flush automatique se produise correctement, et pour que les requêtes sur l'entité dérivée ne renvoient pas des données périmées. Le litéral <subselect> est disponible comme attribut ou comme élément de mapping.
5.1.4. id

Les classes mappées doivent déclarer la clef primaire de la table en base de données. La plupart des classes auront aussi une propriété de type javabean présentant l'identifiant unique d'une instance. L'élément <id> sert à définir le mapping entre cette propriété et la clef primaire en base.

<id
        name="propertyName"                                     (1)
        type="typename"                                         (2)
        column="column_name"                                    (3)
        unsaved-value="null|any|none|undefined|id_value"        (4)
        access="field|property|ClassName">                      (5)

        <generator class="generatorClass"/>
</id>

(1)	

name (optionnel) : Nom de la propriété qui sert d'identifiant.
(2)	

type (optionnel) : Nom indiquant le type Hibernate.
(3)	

column (optionnel - le nom de la propriété est pris par défaut) : Nom de la clef primaire.
(4)	

unsaved-value (optionnel - par défaut une valeur "bien choisie") : Une valeur de la propriété d'identifiant qui indique que l'instance est nouvellement instanciée (non sauvegardée), et qui la distingue des instances transients qui ont été sauvegardées ou chargées dans une session précédente.
(5)	

access (optionnel - par défaut property) : La stratégie que doit utiliser Hibernate pour accéder aux valeurs des propriétés.

Si l'attribut name est absent, Hibernate considère que la classe ne possède pas de propriété identifiant.

L'attribut unsaved-value est important ! Si l'identifiant de votre classe n'a pas une valeur par défaut compatible avec le comportement standard de Java (zéro ou null), vous devez alors préciser la valeur par défaut.

La déclaration alternative <composite-id> permet l'acccès aux données d'anciens systèmes qui utilisent des clefs composées. Son utilisation est fortement déconseillée pour d'autres cas.
5.1.4.1. Generator

L'élément fils <generator> nomme une classe Java utilisée pour générer les identifiants uniques pour les instances des classes persistantes. Si des paramètres sont requis pour configurer ou initialiser l'instance du générateur, ils sont passés en utilisant l'élément <param>.

<id name="id" type="long" column="cat_id">
        <generator class="org.hibernate.id.TableHiLoGenerator">
                <param name="table">uid_table</param>
                <param name="column">next_hi_value_column</param>
        </generator>
</id>

Tous les générateurs doivent implémenter l'interface org.hibernate.id.IdentifierGenerator. C'est une interface très simple ; certaines applications peuvent proposer leur propre implémentations spécialisées. Cependant, Hibernate propose une série d'implémentations intégrées. Il existe des noms raccourcis pour les générateurs intégrés :

increment

    Génère des identifiants de type long, short ou int qui ne sont uniques que si aucun autre processus n'insère de données dans la même table. Ne pas utiliser en environnement clusterisé. 
identity

    Utilisation de la colonne identity de DB2, MySQL, MS SQL Server, Sybase et HypersonicSQL. L'identifiant renvoyé est de type long, short ou int. 
sequence

    Utilisation des séquences dans DB2, PostgreSQL, Oracle, SAP DB, McKoi ou d'un générateur dans Interbase. L'identifiant renvoyé est de type long, short ou int 
hilo

    Utilise un algorithme hi/lo pour générer de façon efficace des identifiants de type long, short ou int, en prenant comme source de valeur "hi" une table et une colonne (par défaut hibernate_unique_key et next_hi respectivement). L'algorithme hi/lo génère des identifiants uniques pour une base de données particulière seulement. 
seqhilo

    Utilise un algorithme hi/lo pour générer efficacement des identifiants de type long, short ou int, étant donné un nom de séquence en base. 
uuid

    Utilise un algorithme de type UUID 128 bits pour générer des identifiants de type string, unique au sein d'un réseau (l'adresse IP est utilisée). Le UUID en codé en une chaîne de nombre héxadécimaux de longueur 32. 
guid

    Utilise une chaîne GUID générée par la base pour MS SQL Server et MySQL. 
native

    Choisit identity, sequence ou hilo selon les possibilités offertes par la base de données sous-jacente. 
assigned

    Laisse l'application affecter un identifiant à l'objet avant que la métode save() soit appelée. Il s'agit de la stratégie par défaut si aucun <generator> n'est spécifié. 
select

    Récupère une clef primaire assignée par un trigger en sélectionnant la ligne par une clef unique quelconque. 
foreign

    Utilise l'identifiant d'un objet associé. Habituellement utilisé en conjonction avec une association <one-to-one> sur la clef primaire. 

5.1.4.2. algorithme Hi/lo

Les générateurs hilo et seqhilo proposent deux implémentations alternatives de l'algorithme hi/lo, une approche largement utilisée pour générer des identifiants. La première implémentation nécessite une table "spéciale" en base pour héberger la prochaine valeur "hi" disponible. La seconde utilise une séquence de type Oracle (quand la base sous-jacente le propose).

<id name="id" type="long" column="cat_id">
        <generator class="hilo">
                <param name="table">hi_value</param>
                <param name="column">next_value</param>
                <param name="max_lo">100</param>
        </generator>
</id>

<id name="id" type="long" column="cat_id">
        <generator class="seqhilo">
                <param name="sequence">hi_value</param>
                <param name="max_lo">100</param>
        </generator>
</id>

Malheureusement, vous ne pouvez pas utilisez hilo quand vous apportez votre propre Connection à Hibernate. Quand Hibernate utilise une datasource du serveur d'application pour obtenir des connexions inscrites avec JTA, vous devez correctement configurer hibernate.transaction.manager_lookup_class.
5.1.4.3. UUID algorithm

Le contenu du UUID est : adresse IP, date de démarrage de la JVM (précis au quart de seconde), l'heure système et un compteur (unique au sein de la JVM). Il n'est pas possible d'obtenir l'adresse MAC ou une adresse mémoire à partir de Java, c'est donc le mieux que l'on puisse faire sans utiliser JNI.
5.1.4.4. Colonnes identifiantes et séquences

Pour les bases qui implémentent les colonnes "identité" (DB2, MySQL, Sybase, MS SQL), vous pouvez utiliser la génération de clef par identity. Pour les bases qui implémentent les séquences (DB2, Oracle, PostgreSQL, Interbase, McKoi, SAP DB) vous pouvez utiliser la génération de clef par sequence. Ces deux méthodes nécessitent deux requêtes SQL pour insérer un objet.

<id name="id" type="long" column="person_id">
        <generator class="sequence">
                <param name="sequence">person_id_sequence</param>
        </generator>
</id>

<id name="id" type="long" column="person_id" unsaved-value="0">
        <generator class="identity"/>
</id>

Pour le développement multi-plateformes, la stratégie native choisira entre les méthodes identity, sequence et hilo, selon les possibilités offertes par la base sous-jacente.
5.1.4.5. Identifiants assignés

Si vous souhaitez que l'application assigne des identifiants (par opposition à la génération par Hibernate), vous pouvez utiliser le générateur assigned. Ce générateur spécial utilisera une valeur d'identifiant déjà utilisé par la propriété identifiant l'objet. Ce générateur est utilisé quand la clef primaire est une clef naturelle plutôt qu'une clef secondaire. C'est le comportement par défaut si vous ne précisez pas d'élément <generator>.

Choisir le générateur assigned fait utiliser unsaved-value="undefined" par Hibernate, le forçant à interroger la base pour déterminer si l'instance est transiente ou détachée, à moins d'utiliser une propriété version ou timestamp, ou alors de définir Interceptor.isUnsaved().
5.1.4.6. Clefs primaires assignées par trigger

Pour les schémas de base hérités d'anciens systèmes uniquement (Hibernate ne génère pas de DDL avec des triggers)

<id name="id" type="long" column="person_id">
        <generator class="select">
                <param name="key">socialSecurityNumber</param>
        </generator>
</id>

Dans l'exemple ci-dessus, socialSecurityNumber a une valeur unique définie par la classe en tant que clef naturelle et person_id est une clef secondaire dont la valeur est générée par trigger.
5.1.5. composite-id

<composite-id
        name="propertyName"
        class="ClassName"
        mapped="true|false"
        access="field|property|ClassName">
        node="element-name|."

        <key-property name="propertyName" type="typename" column="column_name"/>
        <key-many-to-one name="propertyName class="ClassName" column="column_name"/>
        ......
</composite-id>

Pour une table avec clef composée, vous pouvez mapper plusieurs attributs de la classe comme propriétés identifiantes. L'élement <composite-id> accepte les mappings de propriétés <key-property> et les mappings <key-many-to-one> comme fils.

<composite-id>
        <key-property name="medicareNumber"/>
        <key-property name="dependent"/>
</composite-id>

Vos classes persistantes doivent surcharger les méthodes equals() et hashCode() pour implémenter l'égalité d'identifiant composé. Elles doivent aussi implenter l'interface Serializable.

Malheureusement cette approche sur les identifiants composés signifie qu'un objet persistant est son propre identifiant. Il n'y a pas d'autre moyen pratique de manipuler l'objet que par l'objet lui-même. Vous devez instancier une instance de la classe persistante elle-même et peupler ses attributs identifiants avant de pouvoir appeler la méthode load() pour charger son état persistant associé à une clef composée. Nous appelons cette approche "identifiant composé embarqué" et ne la recommandons pas pour des applications complexes.

Une seconde approche, appelée identifiant composé mappé, consiste à encapsuler les propriétés identifiantes (celles contenues dans <composite-id>) dans une classe particulière.

<composite-id class="MedicareId" mapped="true">
        <key-property name="medicareNumber"/>
        <key-property name="dependent"/>
</composite-id>

Dans cet exemple, la classe d'identifiant composée,MedicareId et la classe mappée elle-même, possèdent les propriétés medicareNumber et dependent. La classe identifiante doit redéfinir equals() et hashCode() et implémenter Serializable. Le désavantage de cette approche est la duplication du code.

Les attributs suivants servent à configurer un identifiant composé mappé :

    *

      mapped (optionnel, défaut à false) : indique qu'un identifiant composé mappé est utilisé, et que les propriétés contenues font référence aux deux classes (celle mappée et la classe identifiante).
    *

      class (optionnel, mais requis pour un identifiant composé mappé) : La classe composant utilisée comme identifiant composé. 

Nous décrirons une troisième approche beaucoup plus efficace ou l'identifiant composé est implémenté comme une classe composant dans Section 8.4, « Utiliser un composant comme identifiant ». Les attributs décrits ci dessous, ne s'appliquent que pour cette dernière approche :

    *

      name (optionnel, requis pour cette approche) : une propriété de type composant qui contient l'identifiant composé (voir chapitre 9).
    *

      access (optionnel - défaut à property) : La stratégie qu'Hibernate utilisera pour accéder à la valeur de la propriété.
    *

      class (optionnel - défaut au type de la propriété déterminé par réflexion) : La classe composant utilisée comme identifiant (voir prochaine section). 

Cette dernière approche est celle que nous recommandons pour toutes vos applications.
5.1.6. discriminator

L'élément <discriminator> est nécessaire pour la persistance polymorphique qui utilise la stratégie de mapping de table par hiérarchie de classe. La colonne discriminante contient une valeur marqueur qui permet à la couche de persistance de savoir quelle sous-classe instancier pour une ligne particulière de table en base. Un nombre restreint de types peuvent être utilisés : string, character, integer, byte, short, boolean, yes_no, true_false.

<discriminator
        column="discriminator_column"                      (1)
        type="discriminator_type"                          (2)
        force="true|false"                                 (3)
        insert="true|false"                                (4)
        formula="arbitrary sql expression"                 (5)
/>

(1)	

column (optionnel - par défaut à class) le nom de la colonne discriminante.
(2)	

type (optionnel - par défaut à string) un nom indiquant le type Hibernate.
(3)	

force (optionnel - par défaut à false) "oblige" Hibernate à spécifier une valeur discriminante autorisée même quand on récupère toutes les instances de la classe de base.
(4)	

insert (optionnel - par défaut à true) à passer à false si la colonne discriminante fait aussi partie d'un identifiant composé mappé (Indique à Hibernate de ne pas inclure la colonne dans les INSERT SQL).
(5)	

formula (optionnel) une expression SQL arbitraire qui est exécutée quand un type doit être évalué. Permet la discrimination basée sur le contenu.

Les véritables valeurs de la colonne discriminante sont spécifiées par l'attribut discriminator-value des éléments <class> et <subclass>.

L'attribut force n'est utile que si la table contient des lignes avec des valeurs "extra" discriminantes qui ne sont pas mappées à une classe persistante. Ce ne sera généralement pas le cas.

En utilisant l'attribut formula vous pouvez déclarer une expression SQL arbitraire qui sera utilisée pour évaluer le type d'une ligne :

<discriminator
    formula="case when CLASS_TYPE in ('a', 'b', 'c') then 0 else 1 end"
    type="integer"/>

5.1.7. version (optionnel)

L'élément <version> est optionnel et indique que la table contient des données versionnées. C'est particulièrement utile si vous avez l'intention d'utiliser des transactions longues (voir plus-bas).

<version
        column="version_column"                            (1)
        name="propertyName"                                (2)
        type="typename"                                    (3)
        access="field|property|ClassName"                  (4)
        unsaved-value="null|negative|undefined"            (5)
        generated="never|always"                                     (6)
        insert="true|false"                                          (7)
        node="element-name|@attribute-name|element/@attribute|."
/>

(1)	

column (optionnel - par défaut égal au nom de la propriété) : Le nom de la colonne contenant le numéro de version.
(2)	

name : Le nom d'un attribut de la classe persistante.
(3)	

type (optionnel - par défaut à integer) : Le type du numéro de version.
(4)	

access (optionnel - par défaut à property) : La stratégie à utiliser par Hibernate pour accéder à la valeur de la propriété.
(5)	

unsaved-value (optionnel - par défaut à undefined) : Une valeur de la propriété d'identifiant qui indique que l'instance est nouvellement instanciée (non sauvegardée), et qui la distingue des instances détachées qui ont été sauvegardées ou chargées dans une session précédente (undefined indique que la valeur de l'atribut identifiant devrait être utilisé).
(6)	

generated (optional - défaut à never) : Indique que la valeur de la propriété version est générée par la base de données cf. Section 5.6, « Propriétés générées ».
(7)	

insert (optionnel - défaut à true) : Indique si la colonne de version doit être incluse dans les ordres insert. Peut être à false si et seulement si la colonne de la base de données est définie avec une valeur par défaut à 0.

Les numéros de version doivent avoir les types Hibernate long, integer, short, timestamp ou calendar.

Une propriété de version ou un timestamp ne doit jamais être null pour une instance détachée, ainsi Hibernate pourra détecter toute instance ayant une version ou un timestamp null comme transient, quelles que soient les stratégies unsaved-value spécifiées. Déclarer un numéro de version ou un timestamp "nullable" est un moyen pratique d'éviter tout problème avec les réattachements transitifs dans Hibernate, particulièrement utile pour ceux qui utilisent des identifiants assignés ou des clefs composées !
5.1.8. timestamp (optionnel)

L'élément optionnel <timestamp> indique que la table contient des données horodatées (timestamp). Cela sert d'alternative à l'utilisation de numéros de version. Les timestamps (ou horodatage) sont par nature une implémentation moins fiable pour l'optimistic locking. Cependant, l'application peut parfois utiliser l'horodatage à d'autres fins.

<timestamp
        column="timestamp_column"           (1)
        name="propertyName"                 (2)
        access="field|property|ClassName"   (3)
        unsaved-value="null|undefined"      (4)
        source="vm|db"                                               (5)
        generated="never|always"                                     (6)
        node="element-name|@attribute-name|element/@attribute|."
/>

(1)	

column (optionnel - par défaut à le nom de la propriété) : Le nom d'une colonne contenant le timestamp.
(2)	

name : Le nom d'une propriété au sens JavaBean de type Date ou Timestamp de la classe persistante.
(3)	

access (optionnel - par défaut à property) : La stratégie à utiliser par Hibernate pour accéder à la valeur de la propriété.
(4)	

unsaved-value (optionnel - par défaut à null) : Propriété dont la valeur est un numéro de version qui indique que l'instance est nouvellement instanciée (non sauvegardée), et qui la distingue des instances détachées qui ont été sauvegardées ou chargées dans une session précédente (undefined indique que la valeur de l'attribut identifiant devrait être utilisée).
(5)	

source (optionnel - par défaut à vm) : D'où Hibernate doit-il récupérer la valeur du timestamp? Depuis la base de données ou depuis la JVM d'exécution? Les valeurs de timestamp de la base de données provoquent une surcharge puisque Hibernate doit interroger la base pour déterminer la prochaine valeur mais cela est plus sûr lorsque vous fonctionnez dans un cluster. Remarquez aussi que certains des dialectes ne supportent pas cette fonction, et que d'autres l'implémentent mal, provoquant des erreurs de précision (Oracle 8 par exemple).
(6)	

generated (optional - défaut à never) : Indique que la valeur de ce timestamp est générée par la base de données cf. Section 5.6, « Propriétés générées ».

Notez que <timestamp> est équivalent à <version type="timestamp">.
5.1.9. property

L'élément <property> déclare une propriété de la classe au sens JavaBean.

<property
        name="propertyName"                 (1)
        column="column_name"                (2)
        type="typename"                     (3)
        update="true|false"                 (4)
        insert="true|false"                 (4)
        formula="arbitrary SQL expression"  (5)
        access="field|property|ClassName"   (6)
        lazy="true|false"                   (7)
        unique="true|false"                 (8)
        not-null="true|false"               (9)
        optimistic-lock="true|false"        (10)
        generated="never|insert|always"                              (11)
        node="element-name|@attribute-name|element/@attribute|."
        index="index_name"
        unique_key="unique_key_id"
        length="L"
        precision="P"
        scale="S"
/>

(1)	

name : nom de la propriété, avec une lettre initiale en minuscule.
(2)	

column (optionnel - par défaut au nom de la propriété) : le nom de la colonne mappée. Cela peut aussi être indiqué dans le(s) sous-élément(s) <column>.
(3)	

type (optionnel) : nom indiquant le type Hibernate.
(4)	

update, insert (optionnel - par défaut à true) : indique que les colonnes mappées devraient être incluses dans des UPDATE SQL et/ou des INSERT. Mettre les deux à false empêche la propagation en base de données (utile si vous savez qu'un trigger affectera la valeur à la colonne).
(5)	

formula (optionnel) : une expression SQL qui définit la valeur pour une propriété calculée. Les propriétés calculées ne possède pas leur propre mapping.
(6)	

access (optionnel - par défaut à property): Stratégie que Hibernate doit utiliser pour accéder à cette valeur.
(7)	

lazy (optionnel - par défaut à false): Indique que cette propriété devrait être chargée en différé (lazy loading) quand on accède à la variable d'instance pour la première fois.
(8)	

unique (optionnel): Génère le DDL d'une contrainte d'unicité pour les colonnes. Permet aussi d'en faire la cible d'un property-ref.
(9)	

not-null (optionnel): Génère le DDL d'une contrainte de non nullité pour les colonnes.
(10)	

optimistic-lock (optionnel - par défaut à true): Indique que les mises à jour de cette propriété peuvent ou non nécessiter l'acquisition d'un verrou optimiste. En d'autres termes, cela détermine s'il est nécessaire d'incrémenter un numéro de version quand cette propriété est marquée obsolète (dirty).
(11)	

generated (optional - défaut ànever): Indique que la valeur de ce timestamp est générée par la base de données cf. Section 5.6, « Propriétés générées ».

typename peut être:

   1.

      Nom d'un type basique Hibernate (ex: integer, string, character, date, timestamp, float, binary, serializable, object, blob).
   2.

      Nom d'une classe Java avec un type basique par défaut (ex: int, float, char, java.lang.String, java.util.Date, java.lang.Integer, java.sql.Clob).
   3.

      Nom d'une classe Java sérialisable.
   4.

      Nom d'une classe ayant un type spécifique (ex: com.illflow.type.MyCustomType). 

Si vous n'indiquez pas un type, Hibernate utlisera la réflexion sur le nom de la propriété pour tenter de trouver le type Hibernate correct. Hibernate essayera d'interprêter le nom de la classe retournée par le getter de la propriété en utilisant les régles 2, 3, 4 dans cet ordre. Cependant, ce n'est pas toujours suffisant. Dans certains cas vous aurez encore besoin de l'attribut type (Par exemple, pour distinguer Hibernate.DATE et Hibernate.TIMESTAMP, ou pour préciser un type spécifique).

L'attribut access permet de contrôler comment Hibernate accèdera à la propriété à l'exécution. Par défaut, Hibernate utilisera les méthodes set/get. Si vous indiquez access="field", Hibernate ignorera les getter/setter et accèdera à la propriété directement en utilisant la réflexion. Vous pouvez spécifier votre propre stratégie d'accès aux propriété en donnant une classe qui implémente l'interface org.hibernate.property.PropertyAccessor.

Une fonctionnalité particulièrement intéressante est les propriétés dérivées. Ces propriétés sont par définition en lecture seule, la valeur de la propriété est calculée au chargement. Le calcul est déclaré comme une expression SQL, qui se traduit par une sous-requête SELECT dans la requête SQL qui charge une instance :

<property name="totalPrice"
    formula="( SELECT SUM (li.quantity*p.price) FROM LineItem li, Product p
                WHERE li.productId = p.productId
                AND li.customerId = customerId
                AND li.orderNumber = orderNumber )"/>

Remarquez que vous pouvez référencer la propre table des entités en ne déclarant pas un alias sur une colonne particulière (customerId dans l'exemple donné). Notez aussi que vous pouvez utiliser le sous-élément de mapping <formula> plutôt que d'utiliser l'attribut si vous le souhaitez.
5.1.10. many-to-one

Une association ordinaire vers une autre classe persistante est déclarée en utilisant un élément many-to-one. Le modèle relationnel est une association de type many-to-one : une clef étrangère dans une table référence la ou les clef(s) primaire(s) dans la table cible.

<many-to-one
        name="propertyName"                                (1)
        column="column_name"                               (2)
        class="ClassName"                                  (3)
        cascade="cascade_style"                            (4)
        fetch="join|select"                                (5)
        update="true|false"                                (6)
        insert="true|false"                                (6)
        property-ref="propertyNameFromAssociatedClass"     (7)
        access="field|property|ClassName"                  (8)
        unique="true|false"                                (9)
        not-null="true|false"                              (10)
        optimistic-lock="true|false"                       (11)
        lazy="proxy|no-proxy|false"                        (12)
        not-found="ignore|exception"                       (13)          (14)
        entity-name="EntityName"                                     (15)
        formula="arbitrary SQL expression"                           (16)
        node="element-name|@attribute-name|element/@attribute|."
        embed-xml="true|false"
        index="index_name"
        unique_key="unique_key_id"
        foreign-key="foreign_key_name"
/>

(1)	

name : Nom de la propriété.
(2)	

column (optionnel) : Le nom de la clef étrangère. Cela peut être aussi indiqué avec le sous-élément <column>.
(3)	

class (optionnel - par défaut le type de la propriété déterminé par réflexion) : Le nom de la classe associée.
(4)	

cascade (optionnel) : Indique quelles opérations doivent être propagées de l'objet père vers les objets associés.
(5)	

fetch (optionnel - par défaut à select) : Choisit entre le chargement de type outer-join ou le chargement par select successifs.
(6)	

update, insert (optionnel - par défaut à true) : indique que les colonnes mappées devraient être incluses dans des UPDATE SQL et/ou des INSERT. Mettre les deux à false empêche la propagation en base de données (utile si vous savez qu'un trigger affectera la valeur à la colonne).
(7)	

property-ref : (optionnel) Le nom d'une propriété de la classe associée qui est liée à cette clef étrangère. Si ce n'est pas spécifié, la clef primaire de la classe associée est utilisée.
(8)	

access (optionnel - par défaut à property) : La stratégie à utiliser par Hibernate pour accéder à la valeur de cette propriété.
(9)	

unique (optionnel) : Génère le DDL d'une contrainte d'unicité pour la clef étrangère. Permet aussi d'en faire la cible d'un property-ref. Cela permet de créer une véritable association one-to-one.
(10)	

not-null (optionnel) : Génère le DDL pour une contrainte de non nullité pour la clef étrangère.
(11)	

optimistic-lock (optionnel - par défaut à true) : Indique que les mises à jour de cette propriété requièrent ou non l'acquisition d'un verrou optimiste. En d'autres termes, détermine si un incrément de version doit avoir lieu quand la propriété est marquée obsolète (dirty).
(12)	

lazy (optionnel - par défaut à false) : Indique que cette propriété doit être chargée en différé (lazy loading) au premier accès à la variable d'instance (nécessite une instrumentation du bytecode lors de la phase de construction). Remarquez que cela n'influence pas le comportement du proxy Hibernate - comme l'attribut lazy sur des classes ou des mappings de collections, mais utilise l'interception pour le chargement différé. lazy="false" indique que l'association sera toujours chargée.
(13)	

not-found (optionnel - par défaut à exception) : Indique comment les clefs étrangères qui référencent des lignes manquantes doivent être manipulées : ignore traitera une ligne manquante comme une association nulle.
(15)	

entity-name (optionnel) : Le nom de l'entité de la classe associée.
(16)	

formula (optionnel) : une expression SQL qui définit la valeur pour une clé étrangère calculée.

Donner une valeur significative à l'attribut cascade autre que none propagera certaines opérations à l'objet associé. Les valeurs significatives sont les noms des opérations Hibernate basiques, persist, merge, delete, save-update, evict, replicate, lock, refresh, ainsi que les valeurs spéciales delete-orphan et all et des combinaisons de noms d'opérations séparées par des virgules, comme par exemple cascade="persist,merge,evict" ou cascade="all,delete-orphan". Voir Section 10.11, « Persistance transitive » pour une explication complète. Notez que les assocations many-to-one et one-to-one ne supportent pas orphan delete.

Une déclaration many-to-one typique est aussi simple que :

<many-to-one name="product" class="Product" column="PRODUCT_ID"/>

L'attribut property-ref devrait être utilisé pour mapper seulement des données provenant d'un ancien système où les clefs étrangères font référence à une clef unique de la table associée et qui n'est pas la clef primaire. C'est un cas de mauvaise conception relationnelle. Par exemple, supposez que la classe Product a un numéro de série unique qui n'est pas la clef primaire. (L'attribut unique contrôle la génération DDL par Hibernate avec l'outil SchemaExport.)

<property name="serialNumber" unique="true" type="string" column="SERIAL_NUMBER"/>

Ainsi le mapping pour OrderItem peut utiliser :

<many-to-one name="product" property-ref="serialNumber" column="PRODUCT_SERIAL_NUMBER"/>

bien que ce ne soit certainement pas encouragé.

Si la clef unique référencée comprend des propriétés multiples de l'entité associée, vous devez mapper ces propriétés à l'intérieur d'un élément <properties>.
5.1.11. one-to-one

Une association one-to-one vers une autre classe persistante est déclarée avec l'élément one-to-one.

<one-to-one
        name="propertyName"                                (1)
        class="ClassName"                                  (2)
        cascade="cascade_style"                            (3)
        constrained="true|false"                           (4)
        fetch="join|select"                                (5)
        property-ref="propertyNameFromAssociatedClass"     (6)
        access="field|property|ClassName"                  (7)
        formula="any SQL expression"                       (8)
        entity-name="EntityName"                                     (9)
/>

(1)	

name : Le nom de la propriété.
(2)	

class (optionnel - par défaut du type de la propriété déterminé par réflexion) : Le nom de la classe associée.
(3)	

cascade (optionnel) : Indique quelles opérations doivent être cascadées de l'objet père vers l'objet associé.
(4)	

constrained (optionnel) : Indique qu'une contrainte de clef étrangère sur la clef primaire de la table mappée référence la table de la classe associée. Cette option affecte l'ordre dans lequel chaque save() et chaque delete() sont cascadés et détermine si l'association peut utiliser un proxy (aussi utilisé par l'outil d'export de schéma).
(5)	

fetch (optionnel - par défaut à select) : Choisit entre récupération par jointure externe ou select séquentiel.
(6)	

property-ref (optionnel) : Le nom de la propriété de la classe associée qui est jointe à la clef primaire de cette classe. Si ce n'est pas spécifié, la clef primaire de la classe associée est utilisée.
(7)	

access (optionnel - par défaut à property) : La stratégie à utiliser par Hibernate pour accéder à la valeur de la propriété.
(8)	

formula (optionnel) : Presque toutes les associations one-to-one pointent sur la clef primaire de l'entité propriétaire. Dans les rares cas différents, vous devez donner une ou plusieurs autres colonnes ou expression à joindre par une formule SQL (voir org.hibernate.test.onetooneformula pour un exemple).
(9)	

lazy (optionnel - par défaut proxy) : Par défaut, les associations simples sont soumise à proxy. lazy="no-proxy" spécifie que la propriété doit être chargée à la demande au premier accès à l'instance. (nécessite l'intrumentation du bytecode à la construction). lazy="false" indique que l'association sera toujours chargée agressivement. Notez que si constrained="false", l'utilisation de proxy est impossible et Hibernate chargera automatiquement l'association !
(10)	

entity-name (optional) : The entity name of the associated class.

Il existe deux types d'associations one-to-one :

    *

      associations par clef primaire
    *

      association par clef étrangère unique 

Les associations par clef primaire ne nécessitent pas une colonne supplémentaire en table ; si deux lignes sont liés par l'association alors les deux lignes de la table partagent la même valeur de clef primaire. Donc si vous voulez que deux objets soient liés par une association par clef primaire, vous devez faire en sorte qu'on leur assigne la même valeur d'identifiant !

Pour une association par clef primaire, ajoutez les mappings suivants à Employee et Person, respectivement.

<one-to-one name="person" class="Person"/>

<one-to-one name="employee" class="Employee" constrained="true"/>

Maintenant, vous devez faire en sorte que les clefs primaires des lignes liées dans les tables PERSON et EMPLOYEE sont égales. On utilise une stratégie Hibernate spéciale de génération d'identifiants appelée foreign :

<class name="person" table="PERSON">
    <id name="id" column="PERSON_ID">
        <generator class="foreign">
            <param name="property">employee</param>
        </generator>
    </id>
    ...
    <one-to-one name="employee"
        class="Employee"
        constrained="true"/>
</class>

Une instance fraîchement enregistrée de Person se voit alors assignée la même valeur de clef primaire que l'instance de Employee référencée par la propriété employee de cette Person.

Alternativement, une clef étrangère avec contrainte d'unicité de Employee vers Person peut être indiquée ainsi :

<many-to-one name="person" class="Person" column="PERSON_ID" unique="true"/>

Et cette association peut être rendue bidirectionnelle en ajoutant ceci au mapping de Person :

<one-to-one name"employee" class="Employee" property-ref="person"/>

5.1.12. natural-id

<natural-id mutable="true|false"/>
        <property ... />
        <many-to-one ... />
        ......
</natural-id>

Bien que nous recommandions l'utilisation de clé primaire générée, vous devriez toujours essayer d'identifier des clé métier (naturelles) pour toutes vos entités. Une clé naturelle est une propriété ou une combinaison de propriétés uniques et non nulles. Si elle est aussi immuable, c'est encore mieux. Mappez les propriétés de la clé naturelle dans l'élément <natural-id>. Hibernate générera la clé unique nécessaire et les contraintes de non-nullité, et votre mapping s'auto-documentera.

Nous vous recommandons fortement d'implémenter equals() et hashCode() pour comparer les clés naturelles de l'entité.

Ce mapping n'est pas destiné à être utilisé avec des entités qui ont des clés naturelles.

    *

      mutable (optionel, par défaut à false) : Par défaut, les identifiants naturels sont supposés être immuable (constants). 

5.1.13. component, dynamic-component

L'élément <component> mappe les propriétés d'un objet fils aux colonnes d'une classe parente. Les composants peuvent en retour déclarer leurs propres propriétés, composants ou collections. Voir "Components" plus bas.

<component 
        name="propertyName"                 (1)
        class="className"                   (2)
        insert="true|false"                 (3)
        update="true|false"                 (4)
        access="field|property|ClassName"   (5)
        lazy="true|false"                   (6)
        optimistic-lock="true|false"        (7)
        unique="true|false"                 (8)
>
        
        <property ...../>
        <many-to-one .... />
        ........
</component>

(1)	

name : Nom de la propriété
(2)	

class (optionnel - par défaut au type de la propriété déterminé par réflexion) : le nom de la classe (fille) du composant.
(3)	

insert : Est ce que les colonnes mappées apparaissent dans les INSERTs ?
(4)	

update: Est ce que les colonnes mappées apparaissent dans les UPDATEs ?
(5)	

access (optionnel - par défaut à property) : La stratégie que Hibernate doit utiliser pour accéder à la valeur de cette propriété.
(6)	

lazy (optionnel - par défaut à false) : Indique que ce composant doit être chargé au premier accès à la variable d'instance (nécessite une instrumentation du bytecode au moment du build).
(7)	

optimistic-lock (optionnel - par défaut à true) : Indique que les mises à jour sur ce composant nécessitent ou non l'acquisition d'un verrou optimiste. En d'autres termes, cela détermine si une incrémentation de version doit avoir lieu quand la propriété est marquée obsolète (dirty).
(8)	

unique (optionnel - par défaut à false) : Indique qu'une contrainte d'unicité existe sur toutes les colonnes mappées de ce composant.

Les tags fils <property> mappent les propriétés de la classe fille sur les colonnes de la table.

L'élément <component> permet de déclarer sous-élément <parent> qui associe une propriété de la classe composant comme une référence arrière vers l'entité contenante.

L'élément <dynamic-component> permet à une Map d'être mappée comme un composant, quand les noms de la propriété font référence aux clefs de cette Map, voir Section 8.5, « Composant Dynamique ».
5.1.14. properties

L'élément <properties> permet la définition d'un groupement logique nommé des propriétés d'une classe. L'utilisation la plus importante de cette construction est la possibilité pour une combinaison de propriétés d'être la cible d'un property-ref. C'est aussi un moyen pratique de définir une contrainte d'unicité multi-colonnes.

<properties 
        name="logicalName"                  (1)
        insert="true|false"                 (2)
        update="true|false"                 (3)
        optimistic-lock="true|false"        (4)
        unique="true|false"                 (5)
>
        
        <property ...../>
        <many-to-one .... />
        ........
</properties>

(1)	

name : Le nom logique d'un regroupement et non le véritable nom d'une propriété.
(2)	

insert : Est-ce que les colonnes mappées apparaissent dans les INSERTs ?
(3)	

update : Est-ce que les colonnes mappées apparaissent dans les UPDATEs ?
(4)	

optimistic-lock (optionnel - par défaut à true) : Indique que les mises à jour sur ce composant nécessitent ou non l'acquisition d'un verrou optimiste. En d'autres termes, cela détermine si une incrémentation de version doit avoir lieu quand la propriété est marquée obsolète (dirty).
(5)	

unique (optionnel - par défaut à false) : Indique qu'une contrainte d'unicité existe sur toutes les colonnes mappées de ce composant.

Par exemple, si nous avons le mapping de <properties> suivant :

<class name="Person">
    <id name="personNumber"/>
    ...
    <properties name="name" 
            unique="true" update="false">
        <property name="firstName"/>
        <property name="initial"/>
        <property name="lastName"/>
    </properties>
</class>

Alors nous pourrions avoir une association sur des données d'un ancien système (legacy) qui font référence à cette clef unique de la table Person au lieu de la clef primaire :

<many-to-one name="person" 
         class="Person" property-ref="name">
    <column name="firstName"/>
    <column name="initial"/>
    <column name="lastName"/>
</many-to-one>

Nous ne recommandons pas l'utilisation de ce genre de chose en dehors du contexte de mapping de données héritées d'anciens systèmes.
5.1.15. subclass

Pour finir, la persistance polymorphique nécessite la déclaration de chaque sous-classe de la classe persistante de base. pour la stratégie de mapping de type table-per-class-hierarchy, on utilise la déclaration <subclass>.

<subclass
        name="ClassName"                              (1)
        discriminator-value="discriminator_value"     (2)
        proxy="ProxyInterface"                        (3)
        lazy="true|false"                             (4)
        dynamic-update="true|false"
        dynamic-insert="true|false"
        entity-name="EntityName"
        node="element-name"
        extends="SuperclassName">

        <property .... />
        .....
</subclass>

(1)	

name : Le nom complet de la sous-classe.
(2)	

discriminator-value (optionnel - par défaut le nom de la classe) : une valeur qui distingue les différentes sous-classes.
(3)	

proxy (optionnel) : Indique une classe ou interface à utiliser pour les chargements à la demande des proxies (lazy).
(4)	

lazy (optionnel, par défaut à true) : Spécifier lazy="false" désactive l'utilisation du chargement à la demande (lazy).

Chaque sous-classe devrait déclarer ses propres propriétés persistantes et sous-classes. Les propriétés <version> et <id> sont implicitement hérités de la classe de base. Chaque sous-classe dans une hiérarchie doit définir une unique discriminator-value. Si aucune n'est spécifiée, le nom complet de la classe Java est utilisé.

Pour plus d'infos sur le mapping d'héritage, voir Chapitre 9, Mapping d'héritage de classe.

<hibernate-mapping>
    <subclass name="DomesticCat" extends="Cat" discriminator-value="D">
         <property name="name" type="string"/>
    </subclass>
</hibernate-mapping>

Pour des informations sur les mappings d'héritage, voir Chapitre 9, Mapping d'héritage de classe.
5.1.16. joined-subclass

Une autre façon possible de faire est la suivante, chaque sous-classe peut être mappée vers sa propre table (stratégie de mapping de type table-per-subclass). L'état hérité est récupéré en joignant la table de la super-classe. L'élément <joined-subclass> est utilisé.

<joined-subclass
        name="ClassName"                    (1)
        table="tablename"                   (2)
        proxy="ProxyInterface"              (3)
        lazy="true|false"                   (4)
        dynamic-update="true|false"
        dynamic-insert="true|false"
        schema="schema"
        catalog="catalog"
        extends="SuperclassName"
        persister="ClassName"
        subselect="SQL expression"
        entity-name="EntityName">

        <key .... >

        <property .... />
        .....
</joined-subclass>

(1)	

name : Le nom Java complet de la sous-classe.
(2)	

table : Le nom de la table de la sous-classe.
(3)	

proxy (optionnel) : Indique une classe ou interface pour le chargement différé des proxies.
(4)	

lazy (optionnel, par défaut à true) : Indiquer lazy="false" désactive l'utilisation du chargement à la demande.

Aucune colonne discriminante n'est nécessaire pour cette stratégie de mapping. Cependant, chaque sous-classe doit déclarer une colonne de table contenant l'objet identifiant qui utilise l'élément <key>. Le mapping au début de ce chapitre serait ré-écrit ainsi :

<?xml version="1.0"?>
<!DOCTYPE hibernate-mapping PUBLIC
        "-//Hibernate/Hibernate Mapping DTD//EN"
        "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd">

<hibernate-mapping package="eg">

        <class name="Cat" table="CATS">
                <id name="id" column="uid" type="long">
                        <generator class="hilo"/>
                </id>
                <property name="birthdate" type="date"/>
                <property name="color" not-null="true"/>
                <property name="sex" not-null="true"/>
                <property name="weight"/>
                <many-to-one name="mate"/>
                <set name="kittens">
                        <key column="MOTHER"/>
                        <one-to-many class="Cat"/>
                </set>
                <joined-subclass name="DomesticCat" table="DOMESTIC_CATS">
                    <key column="CAT"/>
                    <property name="name" type="string"/>
                </joined-subclass>
        </class>

        <class name="eg.Dog">
                <!-- mapping for Dog could go here -->
        </class>

</hibernate-mapping>

Pour des informations sur les mappings d'héritage, voir Chapitre 9, Mapping d'héritage de classe.
5.1.17. union-subclass

Une troisième option est de seulement mapper vers des tables les classes concrètes d'une hiérarchie d'héritage, (stratégie de type table-per-concrete-class) où chaque table définit tous les états persistants de la classe, y compris les états hérités. Dans Hibernate il n'est absolument pas nécessaire de mapper explicitement de telles hiérarchies d'héritage. Vous pouvez simplement mapper chaque classe avec une déclaration <class> différente. Cependant, si vous souhaitez utiliser des associations polymorphiques (càd une association vers la superclasse de la hiérarchie), vous devez utiliser le mapping <union-subclass>.

<union-subclass
        name="ClassName"                    (1)
        table="tablename"                   (2)
        proxy="ProxyInterface"              (3)
        lazy="true|false"                   (4)
        dynamic-update="true|false"
        dynamic-insert="true|false"
        schema="schema"
        catalog="catalog"
        extends="SuperclassName"
        abstract="true|false"
        persister="ClassName"
        subselect="SQL expression"
        entity-name="EntityName">

        <property .... />
        .....
</union-subclass>

(1)	

name : Le nom Java complet de la sous-classe.
(2)	

table : nom de la table de la sous-classe.
(3)	

proxy (optionnel) : Indique une classe ou interface pour le chargement différé des proxies.
(4)	

lazy (optionnel, par défaut à true) : Indiquer lazy="false" désactive l'utilisation du chargement à la demande.

Aucune colonne discriminante ou colonne clef n'est requise pour cette stratégie de mapping.

Pour des informations sur les mappings d'héritage, voir Chapitre 9, Mapping d'héritage de classe.
5.1.18. join

En utilisant l'élément <join>, il est possible de mapper des propriétés d'une classe sur plusieurs tables.

<join
        table="tablename"                        (1)
        schema="owner"                           (2)
        catalog="catalog"                        (3)
        fetch="join|select"                      (4)
        inverse="true|false"                     (5)
        optionnel="true|false">                  (6)
        
        <key ... />
        
        <property ... />
        ...
</join>

(1)	

table : Le nom de la table jointe.
(2)	

schema (optionnel) : court-circuite le nom de schéma spécifié par l'élément de base <hibernate-mapping>.
(3)	

catalog (optionnel) : court-circuite le nom de catalogue spécifié par l'élément de base <hibernate-mapping>.
(4)	

fetch (optionnel - par défaut à join) : Si positionné à join, Hibernate utilisera une jointure interne pour charger une jointure définie par une classe ou ses super-classes et une jointure externe pour une <jointure> définie par une sous-classe. Si positionné à select alors Hibernate utilisera un select séquentiel pour une <jointure> définie sur une sous-classe, qui ne sera délivrée que si une ligne se représente une instance de la sous-classe. Les jointures internes seront quand même utilisées pour charger une <jointure> définie par une classe et ses super-classes.
(5)	

inverse (optionnel - par défaut à false) : Si positionné à true, Hibernate n'essaiera pas d'insérer ou de mettre à jour les propriétés définies par cette jointure.
(6)	

optionnel (optionnel - par défaut à false) : Si positionné à true, Hibernate insèrera une ligne seulement si les propriétés définies par cette jointure sont non-nulles et utilisera toujours une jointure externe pour charger les propriétés.

Par exemple, les informations d'adresse pour une personne peuvent être mappées vers une table séparée (tout en préservant des sémantiques de type valeur pour toutes ses propriétés) :

<class name="Person"
    table="PERSON">

    <id name="id" column="PERSON_ID">...</id>

    <join table="ADDRESS">
        <key column="ADDRESS_ID"/>
        <property name="address"/>
        <property name="zip"/>
        <property name="country"/>
    </join>
    ...

Cette fonctionnalité est souvent seulement utile pour les modèles de données hérités d'anciens systèmes (legacy), nous recommandons d'utiliser moins de tables que de classes et un modèle de domaine à granularité fine. Cependant, c'est utile pour passer d'une stratégie de mapping d'héritage à une autre dans une hiérarchie simple ainsi qu'il est expliqué plus tard.
5.1.19. key

Nous avons rencontré l'élément <key> à plusieurs reprises maintenant. Il apparaît partout que l'élément de mapping parent définit une jointure sur une nouvele table, et définit la clef étrangère dans la table jointe, ce qui référence la clef primaire de la table d'origine.

<key
        column="columnname"                      (1)
        on-delete="noaction|cascade"             (2)
        property-ref="propertyName"              (3)
        not-null="true|false"                    (4)
        update="true|false"                      (5)
        unique="true|false"                      (6)
/>

(1)	

column (optionnel) : Le nom de la colonne de la clef étrangère Cela peut aussi être spécifié par l'élément(s) intégré(s) <column>.
(2)	

on-delete (optionnel, par défaut à noaction) : Indique si la contrainte de clef étrangère possède la possibilité au niveau base de données de suppression en cascade.
(3)	

property-ref (optionnel) : Indique que la clef étrangère fait référence à des colonnes qui ne sont pas la clef primaire de la table d'origine (Pour les données de systèmes legacy).
(4)	

not-null (optionnel) : Indique que les colonnes des clefs étrangères ne peuvent pas être nulles (c'est implicite si la clef étrangère fait partie de la clef primaire).
(5)	

update (optionnel) : Indique que la clef étrangère ne devrait jamais être mise à jour (implicite si celle-ci fait partie de la clef primaire).
(6)	

unique (optionnel) : Indique que la clef étrangère doit posséder une contrainte d'unicité (implicite si la clef étrangère est aussi la clef primaire).

Nous recommandons pour les systèmes où les suppressions doivent être performantes de définir toutes les clefs on-delete="cascade", ainsi Hibernate utilisera une contrainte ON CASCADE DELETE au niveau base de données, plutôt que de nombreux DELETE individuels. Attention, cette fonctionnalité court-circuite la stratégie habituelle de verrou optimiste pour les données versionnées.

Les attributs not-null et update sont utiles pour mapper une association one-to-many unidirectionnelle. Si vous mappez un one-to-many unidirectionnel vers une clef étrangère non nulle, vous devez déclarer la colonne de la clef en utilisant <key not-null="true">.
5.1.20. éléments column et formula

Tout élément de mapping qui accepte un attribut column acceptera alternativement un sous-élément <column>. De façon identique, <formula> est une alternative à l'attribut formula.

<column
        name="column_name"
        length="N"
        precision="N"
        scale="N"
        not-null="true|false"
        unique="true|false"
        unique-key="multicolumn_unique_key_name"
        index="index_name"
        sql-type="sql_type_name"
        check="SQL expression"/>

<formula>SQL expression</formula>

Les attributs column et formula peuvent même être combinés au sein d'une même propriété ou mapping d'association pour exprimer, par exemple, des conditions de jointure exotiques.

<many-to-one name="homeAddress" class="Address"
        insert="false" update="false">
    <column name="person_id" not-null="true" length="10"/>
    <formula>'MAILING'</formula>
</many-to-one>

5.1.21. import

Supposez que votre application possède deux classes persistantes du même nom, et vous ne voulez pas préciser le nom Java complet (packages inclus) dans les queries Hibernate. Les classes peuvent alors être "importées" explicitement plutôt que de compter sur auto-import="true".Vous pouvez même importer des classes et interfaces qui ne sont pas mappées explicitement.

<import class="java.lang.Object" rename="Universe"/>

<import
        class="ClassName"              (1)
        rename="ShortName"             (2)
/>

(1)	

class : Nom Java complet de la classe.
(2)	

rename (optionnel - par défaut vaut le nom de la classe Java (sans package)) : Nom pouvant être utilisé dans le langage de requête.
5.1.22. any

Il existe encore un type de mapping de propriété. L'élément de mapping <any> définit une association polymorphique vers des classes de tables multiples. Ce type de mapping requiert toujours plus d'une colonne. La première colonne contient le type de l'entité associée. Les colonnes restantes contiennent l'identifiant. il est impossible de spécifier une contrainte de clef étrangère pour ce type d'association, donc ce n'est certainement pas considéré comme le moyen habituel de mapper des associations (polymorphiques). Vous devriez utiliser cela uniquement dans des cas particuliers (par exemple des logs d'audit, des données de session utilisateur, etc...).

L'attribut meta-type permet à l'application de spécifier un type personnalisé qui mappe des valeurs de colonnes de le base de données sur des classes persistantes qui ont un attribut identifiant du type spécifié par id-type. Vous devez spécifier le mapping à partir de valeurs du méta-type sur les noms des classes.

<any name="being" id-type="long" meta-type="string">
    <meta-value value="TBL_ANIMAL" class="Animal"/>
    <meta-value value="TBL_HUMAN" class="Human"/>
    <meta-value value="TBL_ALIEN" class="Alien"/>
    <column name="table_name"/>
    <column name="id"/>
</any>

<any
        name="propertyName"                      (1)
        id-type="idtypename"                     (2)
        meta-type="metatypename"                 (3)
        cascade="cascade_style"                  (4)
        access="field|property|ClassName"        (5)
        optimistic-lock="true|false"             (6)
>
        <meta-value ... />
        <meta-value ... />
        .....
        <column .... />
        <column .... />
        .....
</any>

(1)	

name : le nom de la propriété.
(2)	

id-type : le type identifiant.
(3)	

meta-type (optionnel - par défaut à string) : Tout type permis pour un mapping par discriminateur.
(4)	

cascade (optionnel - par défaut à none) : le style de cascade.
(5)	

access (optionnel - par défaut à property) : La stratégie à utiliser par Hibernate pour accéder à cette propriété.
(6)	

optimistic-lock (optionnel - par défaut à true) : Indique que les mises à jour sur cette propriété nécessitent ou non l'acquisition d'un verrou optimiste. En d'autres termes, définit si un incrément de version doit avoir lieu quand cette propriété est marquée dirty.
5.2. Hibernate Types
5.2.1. Entités et valeurs

Pour comprendre le comportement des différents objets Java par rapport au service de persistance, nous avons besoin de les classer en deux groupes :

Une entité existe indépendamment de tout autre objet possédant une référence vers l'entité. Comparez cela avec le modèle Java habituel où un objet est supprimé par le garbage collector dès qu'il n'est plus référencé. Les entités doivent être explicitement enregistrées et supprimées (sauf dans les cas où sauvegardes et suppressions sont cascadées d'une entité mère vers ses enfants). C'est différent du modèle ODMG de persistance par atteignabilité - et correspond mieux à la façon dont les objets sont habituellement utilisés dans des grands systèmes. Les entités permettent les références circulaires et partagées. Elles peuvent aussi être versionnées.

L'état persistant d'une entité consiste en des références vers d'autres entités et instances de types valeurs. Ces valeurs sont des types primitifs, des collections (et non le contenu d'une collection), des composants de certains objets immuables. Contrairement aux entités, les valeurs (et en particulier les collections et composants) sont persistés par atteignabiliité. Comme les valeurs (et types primitifs) sont persistés et supprimés avec l'entité qui les contient, ils ne peuvent pas posséder leurs propres versions. Les valeurs n'ont pas d'identité indépendantes, ainsi elles ne peuvent pas être partagées par deux entités ou collections.

Jusqu'à présent nous avons utilisé le terme "classe persistante" pour parler d'entités. Nous allons continuer à faire ainsi. Cependant, au sens strict, toutes les classes définies par un utilisateur possédant un état persistant ne sont pas des entités. Un composant est une classe définie par un utilisateur avec les caractéristiques d'une valeur. Une propriété Java de type java.lang.String a aussi les caractéristiques d'une valeur. Given this definition, we can say that all types (classes) provided by the JDK have value type semantics in Java, while user-defined types may be mapped with entity or value type semantics. This decision is up to the application developer. A good hint for an entity class in a domain model are shared references to a single instance of that class, while composition or aggregation usually translates to a value type.

Nous nous pencherons sur ces deux concepts tout au long de la documentation.

Le défi est de mapper les type Javas (et la définition des développeurs des entités et valeurs types) sur les types du SQL ou des bases de données. Le pont entre les deux systèmes est proposé par Hibernate : pour les entités nous utilisons <class>, <subclass> et ainsi de suite. Pour les types valeurs nous utilisons <property>, <component>, etc., habituellement avec un attribut type. La valeur de cet attribut est le nom d'un type de mapping Hibernate. Hibernate propose de base de nombreux mappings (pour les types de valeurs standards du JDK). Vous pouvez écrire vos propres types de mappings et implémenter aussi vos propres stratégies de conversion, nous le verrons plus tard.

Tous les types proposés de base par Hibernate à part les collections autorisent la valeur null.
5.2.2. Basic value types

Les types basiques de mapping proposés de base peuvent grossièrement être rangés dans les catégories suivantes :

integer, long, short, float, double, character, byte, boolean, yes_no, true_false

    Les mappings de type des primitives Java ou leurs classes wrappers (ex: Integer pour int) vers les types SQL (propriétaires) appropriés. boolean, yes_noet true_false sont tous des alternatives pour les types Java boolean ou java.lang.Boolean. 
string

    Mapping de type de java.lang.String vers VARCHAR (ou le VARCHAR2 Oracle). 
date, time, timestamp

    Mappings de type pour java.util.Date et ses sous-classes vers les types SQL DATE, TIME et TIMESTAMP (ou équivalent). 
calendar, calendar_date

    Mappings de type pour java.util.Calendar vers les types SQL TIMESTAMP et DATE (ou équivalent). 
big_decimal, big_integer

    Mappings de type pour java.math.BigDecimal et java.math.BigInteger vers NUMERIC (ou le NUMBER Oracle). 
locale, timezone, currency

    Mappings de type pour java.util.Locale, java.util.TimeZone et java.util.Currency vers VARCHAR (ou le VARCHAR2 Oracle). Les instances de Locale et Currency sont mappées sur leurs codes ISO. Les instances de TimeZone sont mappées sur leur ID. 
class

    Un type de mapping pour java.lang.Class vers VARCHAR (ou le VARCHAR2 Oracle). Un objet Class est mappé sur son nom Java complet. 
binary

    Mappe les tableaux de bytes vers le type binaire SQL approprié. 
text

    Mappe les longues chaînes de caractères Java vers les types SQL CLOB ou TEXT. 
serializable

    Mappe les types Java sérialisables vers le type SQL binaire approprié. Vous pouvez aussi indiquer le type Hibernate serializable avec le nom d'une classe Java sérialisable ou une interface qui ne soit pas par défaut un type de base. 
clob, blob

    Mappings de type pour les classes JDBC java.sql.Clob and java.sql.Blob. Ces types peuvent ne pas convenir pour certaines applications car un objet blob ou clob peut ne pas être réutilisable en dehors d'une transaction (de plus l'implémentation par les pilotes est moyennement bonne). 
imm_date, imm_time, imm_timestamp, imm_calendar, imm_calendar_date, imm_serializable, imm_binary

    Mappings de type pour ceux qui sont habituellement modifiable, pour lesquels Hibernate effectue certains optimisations convenant seulement aux types Java immuables, et l'application les traite comme immuable. Par exemple, vous ne devriez pas appeler Date.setTime() sur une instance mappée sur un imm_timestamp. Pour changer la valeur de la propriété, et faire que cette modification soit persistée, l'application doit assigner un nouvel (non identique) objet à la propriété. 

Les identifiants uniques des entités et collections peuvent être de n'importe quel type de base excepté binary, blob et clob (les identifiants composites sont aussi permis, voir plus bas).

Les types de base des valeurs ont des Type constants correspondants définis dans org.hibernate.Hibernate. Par exemple, Hibernate.STRING représenté le type string.
5.2.3. Types de valeur définis par l'utilisateur

Il est assez facile pour les développeurs de créer leurs propres types de valeurs. Par exemple, vous pourriez vouloir persister des propriétés du type java.lang.BigInteger dans des colonnnes VARCHAR. Hibernate ne procure pas par défaut un type pour cela. Mais les types que vous pouvez créer ne se limitent pas à mapper des propriétés (ou élément collection) à une simple colonne d'une table. Donc, par exemple, vous pourriez avoir une propriété Java getName()/setName() de type java.lang.String persistée dans les colonnes FIRST_NAME, INITIAL, SURNAME.

Pour implémenter votre propre type, vous pouvez soit implémenter org.hibernate.UserType soit org.hibernate.CompositeUserType et déclarer des propriétés utilisant des noms de classes complets du type. Regardez org.hibernate.test.DoubleStringType pour voir ce qu'il est possible de faire.

<property name="twoStrings" type="org.hibernate.test.DoubleStringType">
    <column name="first_string"/>
    <column name="second_string"/>
</property>

Remarquez l'utilisation des tags <column> pour mapper une propriété sur des colonnes multiples.

Les interfaces CompositeUserType, EnhancedUserType, UserCollectionType, et UserVersionType permettent des utilisations plus spécialisées.

Vous pouvez même donner des paramètres en indiquant UserType dans le fichier de mapping ; Pour cela, votre UserType doit implémenter l'interface org.hibernate.usertype.ParameterizedType. Pour spécifier des paramètres dans votre type propre, vous pouvez utiliser l'élément <type> dans vos fichiers de mapping.

<property name="priority">
    <type name="com.mycompany.usertypes.DefaultValueIntegerType">
        <param name="default">0</param>
    </type>
</property>

Le UserType permet maintenant de récupérer la valeur pour le paramètre nommé default à partir de l'objet Properties qui lui est passé.

Si vous utilisez fréquemment un UserType, cela peut être utile de lui définir un nom plus court. Vous pouvez faire cela en utilisant l'élément <typedef>. Les typedefs permettent d'assigner un nom à votre type propre et peuvent aussi contenir une liste de valeurs de paramètres par défaut si ce type est paramétré.

<typedef class="com.mycompany.usertypes.DefaultValueIntegerType" name="default_zero">
    <param name="default">0</param>
</typedef>

<property name="priority" type="default_zero"/>

Il est aussi possible de redéfinir les paramètres par défaut du typedef au cas par cas en utilisant des paramètres type sur le mapping de la propriété.

Bien que le fait que Hibernate propose de base une riche variété de types, et qu'il supporte les composants signifie que vous aurez très rarement besoin d'utiliser un nouveau type propre, il est néanmoins de bonne pratique d'utiliser des types propres pour les classes (non entités) qui apparaissent fréquemment dans votre application. Par exemple une classe MonetaryAmount est un bon candidat pour un CompositeUserType même s'il pourrait facilement être mappé comme un composant. Une motivation pour cela est l'abstraction. Avec un type propre vos documents de mapping sont à l'abri des changements futurs dans votre façon de représenter des valeurs monétaires.
5.3. Mapper une classe plus d'une fois

Il est possible de proposer plus d'un mapping par classe persistante. Dans ce cas, vous devez spécifier un nom d'entité pour lever l'ambiguité entre les instances des entités mappées (par défaut, le nom de l'entité est celui de la classe). Hibernate vous permet de spécifier le nom de l'entité lorsque vous utilisez des objets persistants, lorsque vous écrivez des requêtes ou quand vous mappez des associations vers les entités nommées.

<class name="Contract" table="Contracts" 
        entity-name="CurrentContract">
    ...
    <set name="history" inverse="true" 
            order-by="effectiveEndDate desc">
        <key column="currentContractId"/>
        <one-to-many entity-name="HistoricalContract"/>
    </set>
</class>

<class name="Contract" table="ContractHistory" 
        entity-name="HistoricalContract">
    ...
    <many-to-one name="currentContract" 
            column="currentContractId" 
            entity-name="CurrentContract"/>
</class>

Remarquez comment les associations sont désormais spécifiées en utilisant entity-name au lieu de class.
5.4. SQL quoted identifiers

Vous pouvez forcer Hibernate à mettre un identifiant entre quotes dans le SQL généré en mettant le nom de la table ou de la colonne entre backticks dans le document de mapping. Hibernate utilisera les bons styles de quotes pour le Dialect SQL (habituellement des doubles quotes, mais des parenthèses pour SQL server et des backticks pour MySQL).

<class name="LineItem" table="`Line Item`">
    <id name="id" column="`Item Id`"/><generator class="assigned"/></id>
    <property name="itemNumber" column="`Item #`"/>
    ...
</class>

5.5. alternatives Metadata

XML ne convient pas à tout le monde, il y a donc des moyens alternatifs pour définir des metatda de mappings O/R dans Hibernate.
5.5.1. utilisation de XDoclet

De nombreux utilisateurs de Hibernate préfèrent embarquer les informations de mappings directement au sein du code source en utilisant les tags XDoclet @hibernate.tags. Nous ne couvrons pas cette approche dans ce document cependant, puisque c'est considéré comme faisant partie de XDoclet. Cependant, nous présentons l'exemple suivant de la classe Cat avec des mappings XDoclet.

package eg;
import java.util.Set;
import java.util.Date;

/**
 * @hibernate.class
 *  table="CATS"
 */
public class Cat {
    private Long id; // identifier
    private Date birthdate;
    private Cat mother;
    private Set kittens
    private Color color;
    private char sex;
    private float weight;

    /*
     * @hibernate.id
     *  generator-class="native"
     *  column="CAT_ID"
     */
    public Long getId() {
        return id;
    }
    private void setId(Long id) {
        this.id=id;
    }

    /**
     * @hibernate.many-to-one
     *  column="PARENT_ID"
     */
    public Cat getMother() {
        return mother;
    }
    void setMother(Cat mother) {
        this.mother = mother;
    }

    /**
     * @hibernate.property
     *  column="BIRTH_DATE"
     */
    public Date getBirthdate() {
        return birthdate;
    }
    void setBirthdate(Date date) {
        birthdate = date;
    }
    /**
     * @hibernate.property
     *  column="WEIGHT"
     */
    public float getWeight() {
        return weight;
    }
    void setWeight(float weight) {
        this.weight = weight;
    }

    /**
     * @hibernate.property
     *  column="COLOR"
     *  not-null="true"
     */
    public Color getColor() {
        return color;
    }
    void setColor(Color color) {
        this.color = color;
    }
    /**
     * @hibernate.set
     *  inverse="true"
     *  order-by="BIRTH_DATE"
     * @hibernate.collection-key
     *  column="PARENT_ID"
     * @hibernate.collection-one-to-many
     */
    public Set getKittens() {
        return kittens;
    }
    void setKittens(Set kittens) {
        this.kittens = kittens;
    }
    // addKitten not needed by Hibernate
    public void addKitten(Cat kitten) {
        kittens.add(kitten);
    }

    /**
     * @hibernate.property
     *  column="SEX"
     *  not-null="true"
     *  update="false"
     */
    public char getSex() {
        return sex;
    }
    void setSex(char sex) {
        this.sex=sex;
    }
}

Voyez le site web de Hibernate pour plus d'exemples sur XDoclet et Hibernate.
5.5.2. Utilisation des annotations JDK 5.0

Le JDK 5.0 introduit des annotations proches de celles de XDoclet au niveau java, qui sont type-safe et vérifiées à la compilation. Ce mécanisme est plus puissant que XDoclet et mieux supporté par les outils et IDE. IntelliJ IDEA, par exemple, supporte l'auto-complétion et le surlignement syntaxique des annotations JDK 5.0. La nouvelle révision des spécifications des EJB (JSR-220) utilise les annotations JDK 5.0 comme mécanisme primaire pour les meta-données des beans entités. Hibernate3 implémente l'EntityManager de la JSR-220 (API de persistance), le support du mapping de meta-données est disponible via le package Hibernate Annotations, en tant que module séparé à télécharger. EJB3 (JSR-220) et les métadata Hibernate3 sont supportés.

Ceci est un exemple d'une classe POJO annotée comme un EJB entité :

@Entity(access = AccessType.FIELD)
public class Customer implements Serializable {

    @Id;
    Long id;

    String firstName;
    String lastName;
    Date birthday;

    @Transient
    Integer age;

    @Embedded
    private Address homeAddress;

    @OneToMany(cascade=CascadeType.ALL)
    @JoinColumn(name="CUSTOMER_ID")
    Set<Order> orders;

    // Getter/setter and business methods
}

Notez que le support des annotations JDK 5.0 (et de la JSR-220) est encore en cours et n'est pas terminé. Référez vous au module Hibernate Annotation pour plus de détails.
5.6. Propriétés générées

Les propriétés générées sont des propriétés dont les valeurs sont générées par la base de données. Typiquement, les applications Hibernate avaient besoin d'invoquer refresh sur les instances qui contenaient des propriétés pour lesquelles la base de données générait des valeurs. Marquer les propriétés comme générées permet à l'application de déléguer cette responsabilité à Hibernate. Principalement, à chaque fois qu'Hibernate réalise une insertion ou une mise à jour en base de données pour une entité marquée comme telle, cela provoque immédiatement un select pour récupérer les valeurs générées.

Les propriétés marquées comme générées doivent de plus ne pas être insérables et modifiables Seuls Section 5.1.7, « version (optionnel) », Section 5.1.8, « timestamp (optionnel) », et Section 5.1.9, « property » peuvent être marqués comme générées.

never (par défaut) - indique la valeur de la propriété n'est pas générée dans la base de données.

insert - indique que la valeur de la propriété donnée est générée à l'insertion mais pas lors des futures mises à jour de l'enregistrement. Les colonnes de type "date de création" sont le cas d'utilisation typique de cette option. Notez que même les propriétés Section 5.1.7, « version (optionnel) » et Section 5.1.8, « timestamp (optionnel) » peuvent être déclarées comme générées, cette option n'est pas disponible à cet endroit...

always - indique que la valeur de la propriété est générée à l'insert comme aux updates.
5.7. Objets auxiliaires de la base de données

Permettent les ordres CREATE et DROP d'objets arbitraire de la base de donnéées, en conjonction avec les outils Hibernate d'évolutions de schéma, pour permettre de définir complètement un schéma utilisateur au sein des fichiers de mapping Hibernate. Bien que conçu spécifiquement pour créer et supprimer des objets tels que des triggers et des procédures stockées, ou toute commande pouvant être exécutée via une méthode de java.sql.Statement.execute() (ALTERs, INSERTS, etc). Il y a principalement deux modes pour définir les objets auxiliaires de base de données...

Le premier mode est de lister explicitement les commandes CREATE et DROP dans le fichier de mapping:

<hibernate-mapping>
    ...
    <database-object>
        <create>CREATE TRIGGER my_trigger ...</create>
        <drop>DROP TRIGGER my_trigger</drop>
    </database-object>
</hibernate-mapping>

Le second mode est de fournir une classe particulière qui connait comment construire les commandes CREATE et DROP. Cette classe particulière doit implémenter l'interface org.hibernate.mapping.AuxiliaryDatabaseObject.

<hibernate-mapping>
    ...
    <database-object>
        <definition class="MyTriggerDefinition"/>
    </database-object>
</hibernate-mapping>

Additionnellement, ces objets de base de données peuvent être optionnellement traités selon l'utilisation de dialectes particuliers..

<hibernate-mapping>
    ...
    <database-object>
        <definition class="MyTriggerDefinition"/>
        <dialect-scope name="org.hibernate.dialect.Oracle9Dialect"/>
        <dialect-scope name="org.hibernate.dialect.OracleDialect"/>
    </database-object>
</hibernate-mapping>

Chapitre 6. Mapping des collections
6.1. Collections persistantes

Hibernate requiert que les champs contenant des collections persistantes soient déclarés comme des types d'interface, par exemple :

public class Product {
    private String serialNumber;
    private Set parts = new HashSet();

    public Set getParts() { return parts; }
    void setParts(Set parts) { this.parts = parts; }
    public String getSerialNumber() { return serialNumber; }
    void setSerialNumber(String sn) { serialNumber = sn; }
}

L'interface réelle devrait être java.util.Set, java.util.Collection, java.util.List, java.util.Map, java.util.SortedSet, java.util.SortedMap ou ... n'importe quoi d'autre ! (Où "n'importe quoi d'autre" signifie que vous devrez écrire une implémentation de org.hibernate.usertype.UserCollectionType.)

Notez comment nous avons initialisé les variables d'instance avec une instance de HashSet. C'est le meilleur moyen pour initialiser les collections d'instances nouvellement créées (non persistantes). Quand nous fabriquons l'instance persistante - en appelant persist(), par exemple - Hibernate remplacera réellement le HashSet avec une instance d'une implémentation propre à Hibernate de Set. Prenez garde aux erreurs :

Cat cat = new DomesticCat();
Cat kitten = new DomesticCat();
....
Set kittens = new HashSet();
kittens.add(kitten);
cat.setKittens(kittens);
session.persist(cat);
kittens = cat.getKittens(); // Ok, la collection kittens est un Set
(HashSet) cat.getKittens(); // Erreur !

Les collections persistantes injectées par Hibernate se comportent de la même manière que HashMap, HashSet, TreeMap, TreeSet ou ArrayList, selon le type de l'interface.

Les instances des collections ont le comportement habituel des types des valeurs. Elles sont automatiquement persistées quand elles sont référencées par un objet persistant et automatiquement effacées quand elles sont déréférencées. Si une collection est passée d'un objet persistant à un autre, ses éléments pourraient être déplacés d'une table à une autre. Deux entités ne peuvent pas partager une référence vers une même instance d'une collection. Dû au modèle relationnel sous-jacent, les propriétés contenant des collections ne supportent pas la sémantique de la valeur null ; Hibernate ne distingue pas une référence vers une collection nulle d'une collection vide.

Vous ne devriez pas vous préoccuper trop de ça. Utilisez les collections persistantes de la même manière que vous utilisez des collections Java ordinaires. Assurez-vous de comprendre la sémantique des associations bidirectionnelles (traitée plus loin).
6.2. Mapper une collection

L'élément de mapping d'Hibernate utilisé pour mapper une collection dépend du type de l'interface. Par exemple, un élément <set> est utilisé pour mapper des propriétés de type Set.

<class name="Product">
    <id name="serialNumber" column="productSerialNumber"/>
    <set name="parts">
        <key column="productSerialNumber" not-null="true"/>
        <one-to-many class="Part"/>
    </set>
</class>

À part <set>, il y aussi les éléments de mapping <list>, <map>, <bag>, <array> et <primitive-array>. L'élément <map> est représentatif :

<map
    name="nomDePropriete"                                       (1)
    table="nom_de_table"                                        (2)
    schema="nom_du_schema"                                      (3)
    lazy="true|extra|false"                                     (4)
    inverse="true|false"                                        (5)
    cascade="all|none|save-update|delete|all-delete-orphan"     (6)
    sort="unsorted|natural|ClasseDeComparateur"                 (7)
    order-by="nom_de_column asc|desc"                           (8)
    where="condition sql where quelcconque"                     (9)
    fetch="join|select|subselect"                               (10)
    batch-size="N"                                              (11)
    access="field|property|NomDeClasse"                         (12)
    optimistic-lock="true|false"                                (13)
    mutable="true|false"                                        (14)
    node="nom-d-element|."
    embed-xml="true|false"
>

    <key .... />
    <map-key .... />
    <element .... />
</map>

(1)	

name : le nom de la propriété contenant la collection
(2)	

table (optionnel - par défaut = nom de la propriété) : le nom de la table de la collection (non utilisé pour les associations one-to-many)
(3)	

schema (optionnel) : le nom du schéma pour surcharger le schéma déclaré dans l'élément racine
(4)	

lazy (optionnel - par défaut = true) : peut être utilisé pour désactiver l'initialisation tardive et spécifier que l'association est toujours rapportée, ou pour activer la récupération extra-paresseuse (NdT : extra-lazy) où la plupart des opérations n'initialisent pas la collection (approprié pour de très grosses collections)
(5)	

inverse (optionnel - par défaut = false) : définit cette collection comme l'extrêmité "inverse" de l'association bidirectionnelle
(6)	

cascade (optionnel - par défaut = none) : active les opérations de cascade vers les entités filles
(7)	

sort (optionnel) : spécifie une collection triée via un ordre de tri naturel, ou via une classe comparateur donnée (implémentant Comparator)
(8)	

order-by (optionnel, seulement à partir du JDK1.4) : spécifie une colonne de table (ou des colonnes) qui définit l'ordre d'itération de Map, Set ou Bag, avec en option asc ou desc
(9)	

where (optionnel) : spécifie une condition SQL arbitraire WHERE à utiliser au chargement ou à la suppression d'une collection (utile si la collection ne doit contenir qu'un sous ensemble des données disponibles)
(10)	

fetch (optionnel, par défaut = select) : à choisir entre récupération par jointures externes, récupération par selects séquentiels, et récupération par sous-selects séquentiels
(11)	

batch-size (optionnel, par défaut = 1) : une taille de batch (batch size) utilisée pour charger plusieurs instances de cette collection en initialisation tardive
(12)	

access (optionnel - par défaut = property) : La stratégie qu'Hibernate doit utiliser pour accéder à la valeur de la propriété
(13)	

optimistic-lock (optionnel - par défaut = true) : spécifie que changer l'état de la collection entraîne l'incrémentation de la version appartenant à l'entité (Pour une association un vers plusieurs, il est souvent raisonnable de désactiver ce paramètre)
(14)	

mutable (optionnel - par défaut = true) : une valeur à false spécifie que les éléments de la collection ne changent jamais (une optimisation mineure dans certains cas)
6.2.1. Les clefs étrangères d'une collection

Les instances d'une collection sont distinguées dans la base par la clef étrangère de l'entité qui possède la collection. Cette clef étrangère est référencée comme la(es) colonne(s) de la clef de la collection de la table de la collection. La colonne de la clef de la collection est mappée par l'élément <key>.

Il peut y avoir une contrainte de nullité sur la colonne de la clef étrangère. Pour les associations unidirectionnelles un vers plusieurs, la colonne de la clef étrangère peut être nulle par défaut, donc vous pourriez avoir besoin de spécifier not-null="true".

<key column="productSerialNumber" not-null="true"/>

La contraite de la clef étrangère peut utiliser ON DELETE CASCADE.

<key column="productSerialNumber" on-delete="cascade"/>

Voir le chapitre précédent pour une définition complète de l'élément <key>.
6.2.2. Les éléments d'une collection

Les collections peuvent contenir la plupart des autres types Hibernate, dont tous les types basiques, les types utilisateur, les composants, et bien sûr, les références vers d'autres entités. C'est une distinction importante : un objet dans une collection pourrait être géré avec une sémantique de "valeur" (sa durée de vie dépend complètement du propriétaire de la collection) ou il pourrait avoir une référence vers une autre entité, avec sa propre durée de vie. Dans le dernier cas, seul le "lien" entre les 2 objets est considéré être l'état retenu par la collection.

Le type contenu est référencé comme le type de l'élément de la collection. Les éléments de la collections sont mappés par <element> ou <composite-element>, ou dans le cas des références d'entité, avec <one-to-many> ou <many-to-many>. Les deux premiers mappent des éléments avec un sémantique de valeur, les deux suivants sont utilisés pour mapper des associations d'entité.
6.2.3. Collections indexées

Tous les mappings de collection, exceptés ceux avec les sémantiques d'ensemble (NdT : set) et de sac (NdT : bag), ont besoin d'une colonne d'index dans la table de la collection - une colonne qui mappe un index de tableau, ou un index de List, ou une clef de Map. L'index d'une Map peut être n'importe quel type basique, mappé avec <map-key>, ça peut être une référence d'entité mappée avec <map-key-many-to-many>, ou ça peut être un type composé, mappé avec <composite-map-key>. L'index d'un tableau ou d'une liste est toujours de type integer et est mappé en utilisant l'élément <list-index>. Les colonnes mappées contiennent des entiers séquentiels (numérotés à partir de zéro par défaut).

<list-index
        column="nom_de_colonne"             (1)
        base="0|1|..."/>

(1)	

nom_de_colonne (requis) : le nom de la colonne contenant les valeurs de l'index de la collection
(1)	

base (optionnel, par défaut = 0) : la valeur de la colonne de l'index qui correspond au premier élément de la liste ou du tableau

<map-key
        column="nom_de_colonne"             (1)
        formula="n'importe quelle expression(2) SQL"
        type="nom_du_type"                  (3)
        node="@nom-d-attribut"
        length="N"/>

(1)	

column (optionnel) : le nom de la colonne contenant les valeurs de l'index de la collection
(2)	

formula (optionnel) : une formule SQL utilisée pour évaluer la clef de la map
(3)	

type (reguis): le type des clefs de la map

<map-key-many-to-many
        column="nom_de_colonne"             (1)
        formula="n'importe quelle expression(2)(3) SQL"
        class="NomDeClasse"
/>

(1)	

column (optionnel) : le nom de la colonne de la clef étrangère pour les valeurs de l'index de la collection
(2)	

formula (optionnel) : une formulre SQL utilisée pour évaluer la clef étrangère de la clef de la map
(3)	

class (requis): la classe de l'entité utilisée comme clef de la map

Si votre table n'a pas de colonne d'index, et que vous souhaitez tout de même utiliser List comme type de propriété, vous devriez mapper la propriété comme un <bag> Hibernate. Un sac (NdT : bag) ne garde pas son ordre quand il est récupéré de la base de données, mais il peut être optionnellement trié ou ordonné.

Il y a pas mal de variétés de mappings qui peuvent être générés pour les collections, couvrant beaucoup des modèles relationnels communs. Nous vous suggérons d'expérimenter avec l'outil de génération de schéma pour avoir une idée de comment traduire les différentes déclarations de mapping vers des table de la base de données.
6.2.4. Collections de valeurs et associations plusieurs-vers-plusieurs

N'importe quelle collection de valeurs ou association plusieurs-vers-plusieurs requiert une table de collection avec une(des) colonne(s) de clef étrangère, une(des) colonne(s) d'élément de la collection ou des colonnes et possiblement une(des) colonne(s) d'index.

Pour une collection de valeurs, nous utilisons la balise <element>.

<element
        column="nom_de_colonne"                  (1)
        formula="n'importe quelle expression SQL"(2)
        type="nomDeType"                         (3)
        length="L"
        precision="P"
        scale="S"
        not-null="true|false"
        unique="true|false"
        node="nom-d-element"
/>

(1)	

column (optionnel) : le nom de la colonne contenant les valeurs de l'élément de la collection
(2)	

formula (optionnel) : une formule SQL utilisée pour évaluer l'élément
(3)	

type (requis) : le type de l'élément de la collection

Une association plusieurs-vers-plusieurs est spécifiée en utilisant l'élément <many-to-many>.

<many-to-many
        column="nom_de_colonne"                            (1)
        formula="n'importe quelle expression SQL"          (2)
        class="NomDeClasse"                                (3)
        fetch="select|join"                                (4)
        unique="true|false"                                (5)
        not-found="ignore|exception"                       (6)
        entity-name="NomDEntite"                           (7)
        property-ref="nomDeProprieteDeLaClasseAssociee"    (8)
        node="nom-d-element"
        embed-xml="true|false"
    />

(1)	

column (optionnel) : le nom de la colonne de la clef étrangère de l'élément
(2)	

formula (optionnel) : une formule SQL utilisée pour évaluer la valeur de la clef étrangère de l'élément
(3)	

class (requis) : le nom de la classe associée
(4)	

fetch (optionnel - par défaut join) : active les récupérations par jointures externes ou par selects séquentiels pour cette association. C'est un cas spécial ; pour une récupération complète sans attente (dans un seul SELECT) d'une entité et de ses relations plusieurs-vers-plusieurs vers d'autres entités, vous devriez activer la récupération join non seulement sur la collection elle-même, mais aussi avec cet attribut sur l'élément imbriqué <many-to-many>.
(5)	

unique (optionnel) : activer la génération DDL d'une contrainte d'unicité pour la colonne de la clef étrangère. Ça rend la pluralité de l'association effectivement un-vers-plusieurs.
(6)	

not-found (optionnel - par défaut exception) : spécifie comment les clefs étrangères qui référencent la lignes manquantes seront gérées : ignore traitera une ligne manquante comme une association nulle.
(7)	

entity-name (optionnel) : le nom de l'entité de la classe associée, comme une alternative à class
(8)	

property-ref (optionnel) : le nom d'une propriété de la classe associée qui est jointe à cette clef étrangère. Si non spécifiée, la clef primaire de la classe associée est utilisée.

Quelques exemples, d'abord, un ensemble de chaînes de caractères :

<set name="names" table="person_names">
    <key column="person_id"/>
    <element column="person_name" type="string"/>
</set>

Un bag contenant des entiers (avec un ordre d'itération déterminé par l'attribut order-by) :

<bag name="sizes"
        table="item_sizes"
        order-by="size asc">
    <key column="item_id"/>
    <element column="size" type="integer"/>
</bag>

Un tableau d'entités - dans ce cas, une association plusieurs-vers-plusieurs :

<array name="addresses"
        table="PersonAddress"
        cascade="persist">
    <key column="personId"/>
    <list-index column="sortOrder"/>
    <many-to-many column="addressId" class="Address"/>
</array>

Une map de chaînes de caractères vers des dates :

<map name="holidays"
        table="holidays"
        schema="dbo"
        order-by="hol_name asc">
    <key column="id"/>
    <map-key column="hol_name" type="string"/>
    <element column="hol_date" type="date"/>
</map>

Une liste de composants (discute dans le prochain chapitre) :

<list name="carComponents"
        table="CarComponents">
    <key column="carId"/>
    <list-index column="sortOrder"/>
    <composite-element class="CarComponent">
        <property name="price"/>
        <property name="type"/>
        <property name="serialNumber" column="serialNum"/>
    </composite-element>
</list>

6.2.5. Association un-vers-plusieurs

Une association un vers plusieurs lie les tables de deux classes par une clef étrangère, sans l'intervention d'une table de collection. Ce mapping perd certaines sémantiques des collections Java normales :

    *

      Une instance de la classe de l'entité contenue ne peut pas appartenir à plus d'une instance de la collection
    *

      Une instance de la classe de l'entité contenue ne peut pas apparaître plus plus d'une valeur d'index de la collection 

Une association de Product vers Part requiert l'existence d'une clef étrangère et possiblement une colonne d'index pour la table Part. Une balise <one-to-many> indique que c'est une association un vers plusieurs.

<one-to-many
        class="NomDeClasse"                                (1)
        not-found="ignore|exception"                       (2)
        entity-name="NomDEntite"                           (3)
        node="nom-d-element"
        embed-xml="true|false"
    />

(1)	

class (requis) : le nom de la classe associée
(2)	

not-found (optionnel - par défaut exception) : spécifie comment les identifiants cachés qui référencent des lignes manquantes seront gérés : ignore traitera une ligne manquante comme une association nulle
(3)	

entity-name (optionnel) : le nom de l'entité de la classe associée, comme une alternative à class.

Notez que l'élément <one-to-many> n'a pas besoin de déclarer de colonnes. Il n'est pas non plus nécessaire de spécifier le nom de la table nulle part.

Note très importante : si la colonne de la clef d'une association <one-to-many> est déclarée NOT NULL, vous devez déclarer le mapping de <key> avec not-null="true" ou utiliser une association bidirectionnelle avec le mapping de la collection marqué inverse="true". Voir la discussion sur les associations bidirectionnelles plus tard dans ce chapitre.

Cet exemple montre une map d'entités Part par nom (où partName est une propriété persistante de Part). Notez l'utilisation d'un index basé sur une formule.

<map name="parts"
        cascade="all">
    <key column="productId" not-null="true"/>
    <map-key formula="partName"/>
    <one-to-many class="Part"/>
</map>

6.3. Mappings de collection avancés
6.3.1. Collections triées

Hibernate supporte des collections implémentant java.util.SortedMap et java.util.SortedSet. Vous devez spécifier un comparateur dans le fichier de mapping :

<set name="aliases"
            table="person_aliases"
            sort="natural">
    <key column="person"/>
    <element column="name" type="string"/>
</set>

<map name="holidays" sort="my.custom.HolidayComparator">
    <key column="year_id"/>
    <map-key column="hol_name" type="string"/>
    <element column="hol_date" type="date"/>
</map>

Les valeurs permises pour l'attribut sort sont unsorted, natural et le nom d'une classe implémentant java.util.Comparator.

Les collections triées se comportent réellement comme java.util.TreeSet ou java.util.TreeMap.

Si vous voulez que la base de données elle-même ordonne les éléments de la collection, utilisez l'attribut order-by des mappings set, bag ou map. Cette solution est seulement disponible à partir du JDK 1.4 (c'est implémenté en utilisant LinkedHashSet ou LinkedHashMap). Ceci exécute le tri dans la requête SQL, pas en mémoire.

<set name="aliases" table="person_aliases" order-by="lower(name) asc">
    <key column="person"/>
    <element column="name" type="string"/>
</set>

<map name="holidays" order-by="hol_date, hol_name">
    <key column="year_id"/>
    <map-key column="hol_name" type="string"/>
    <element column="hol_date type="date"/>
</map>

Notez que la valeur de l'attribut order-by est un ordre SQL, pas un ordre HQL !

Les associations peuvent même être triées sur des critères arbitraires à l'exécution en utilisant un filter() de collection.

sortedUsers = s.createFilter( group.getUsers(), "order by this.name" ).list();

6.3.2. Associations bidirectionnelles

Une association bidirectionnelle permet une navigation à partir de la "fin" de l'association. Deux sortes d'associations bidirectionnelles sont supportées :

un-vers-plusieurs (NdT : one-to-many)

    ensemble ou sac à une extrémité, une seule valeur à l'autre 
plusieurs-vers-plusieurs (NdT : many-to-many)

    ensemble ou sac aux deux extrémités 

Vous pouvez spécifier une association plusieurs-vers-plusieurs bidirectionnelle simplement en mappant deux associations plusieurs-vers-plusieurs vers la même table de base de données et en déclarant une extrémité comme inverse (celle de votre choix, mais ça ne peut pas être une collection indexée).

Voici un exemple d'association bidirectionnelle plusieurs-vers-plusieurs ; chaque catégorie peut avoir plusieurs objets et chaque objet peut être dans plusieurs catégories :

<class name="Category">
    <id name="id" column="CATEGORY_ID"/>
    ...
    <bag name="items" table="CATEGORY_ITEM">
        <key column="CATEGORY_ID"/>
        <many-to-many class="Item" column="ITEM_ID"/>
    </bag>
</class>

<class name="Item">
    <id name="id" column="CATEGORY_ID"/>
    ...

    <!-- inverse end -->
    <bag name="categories" table="CATEGORY_ITEM" inverse="true">
        <key column="ITEM_ID"/>
        <many-to-many class="Category" column="CATEGORY_ID"/>
    </bag>
</class>

Les changements faits uniquement sur l'extréminté inverse de l'association ne sont pas persistés. Ceci signifie qu'Hibernate a deux représentations en mémoire pour chaque association bidirectionnelles, un lien de A vers B et un autre de B vers A. C'est plus facile à comprendre si vous pensez au modèle objet de Java et comment nous créons une relation plusieurs-vers-plusieurs en Java :

category.getItems().add(item);          // La catégorie est maintenant "au courant" de la relation
item.getCategories().add(category);     // L'objet est maintenant "au courant" de la relation

session.persist(item);                   // La relation ne sera pas sauvegardée !
session.persist(category);               // La relation sera sauvegardée

La partie non-inverse est utilisée pour sauvegarder la représentation en mémoire dans la base de données.

Vous pouvez définir une association un-vers-plusieurs bidirectionnelle en mappant une association un-vers-plusieurs vers la(es) même(s) colonne(s) de table qu'une association plusieurs-vers-un et en déclarant l'extrémité pluri-valuée inverse="true".

<class name="Parent">
    <id name="id" column="parent_id"/>
    ....
    <set name="children" inverse="true">
        <key column="parent_id"/>
        <one-to-many class="Child"/>
    </set>
</class>

<class name="Child">
    <id name="id" column="child_id"/>
    ....
    <many-to-one name="parent"
        class="Parent"
        column="parent_id"
        not-null="true"/>
</class>

Mapper une extrémité d'une association avec inverse="true" n'affecte pas l'opération de cascades, ce sont des concepts orthogonaux !
6.3.3. Associations bidirectionnelles avec des collections indexées

Une association bidirectionnelle où une extrémité est représentée comme une <list> ou une <map> requiert une considération spéciale. Si il y a une propriété de la classe enfant qui mappe la colonne de l'index, pas de problème, nous pouvons continuer à utiliser inverse="true" sur le mapping de la collection :

<class name="Parent">
    <id name="id" column="parent_id"/>
    ....
    <map name="children" inverse="true">
        <key column="parent_id"/>
        <map-key column="name"
            type="string"/>
        <one-to-many class="Child"/>
    </map>
</class>

<class name="Child">
    <id name="id" column="child_id"/>
    ....
    <property name="name"
        not-null="true"/>
    <many-to-one name="parent"
        class="Parent"
        column="parent_id"
        not-null="true"/>
</class>

Mais, si il n'y a pas de telle prorpriété sur la classe enfant, nous ne pouvons pas penser à l'association comme vraiment bidirectionnelle (il y a des informations disponibles à une extrémité de l'association qui ne sont pas disponibles à l'autre extrémité). Dans ce cas, nous ne pouvons pas mapper la collection inverse="true". À la place, nous pourrions utiliser le mapping suivant :

<class name="Parent">
    <id name="id" column="parent_id"/>
    ....
    <map name="children">
        <key column="parent_id"
            not-null="true"/>
        <map-key column="name"
            type="string"/>
        <one-to-many class="Child"/>
    </map>
</class>

<class name="Child">
    <id name="id" column="child_id"/>
    ....
    <many-to-one name="parent"
        class="Parent"
        column="parent_id"
        insert="false"
        update="false"
        not-null="true"/>
</class>

Notez que dans ce mapping, l'extrémité de l'association contenant la collection est responsable des mises à jour de la clef étrangère. À faire : cela entraîne-t-il réellement des expressions updates inutiles ?
6.3.4. Associations ternaires

Il y a trois approches possibles pour mapper une association ternaire. L'une est d'utiliser une Map avec une association en tant qu'index :

<map name="contracts">
    <key column="employer_id" not-null="true"/>
    <map-key-many-to-many column="employee_id" class="Employee"/>
    <one-to-many class="Contract"/>
</map>

<map name="connections">
    <key column="incoming_node_id"/>
    <map-key-many-to-many column="outgoing_node_id" class="Node"/>
    <many-to-many column="connection_id" class="Connection"/>
</map>

Une seconde approche est simplement de remodeler l'association comme une classe d'entité. C'est l'approche la plus commune.

Une alternative finale est d'utiliser des éléments composites, dont nous discuterons plus tard.
6.3.5. Utiliser un <idbag>

Si vous embrassez pleinement notre vue que les clefs composées sont une mauvaise chose et que des entités devraient avoir des identifiants artificiels (des clefs subrogées), alors vous pourriez trouver un peu curieux que les associations plusieurs-vers-plusieurs et les collections de valeurs que nous avons montré jusqu'ici mappent toutes des tables avec des clefs composées ! Maintenant, ce point est assez discutable ; une table d'association pure ne semble pas beaucoup bénéficier d'une clef subrogée (bien qu'une collection de valeur composées le pourrait). Néanmoins, Hibernate fournit une foncionnalité qui vous permet de mapper des associations plusieurs-vers-plusieurs et des collections de valeurs vers une table avec une clef subrogée.

L'élément <idbag> vous laisse mapper une List (ou une Collection) avec une sémantique de sac.

<idbag name="lovers" table="LOVERS">
    <collection-id column="ID" type="long">
        <generator class="sequence"/>
    </collection-id>
    <key column="PERSON1"/>
    <many-to-many column="PERSON2" class="Person" fetch="join"/>
</idbag>

Comme vous pouvez voir, un <idbag> a un généréteur d'id artificiel, comme une classe d'entité ! Une clef subrogée différente est assignée à chaque ligne de la collection. Cependant, Hibernate ne fournit pas de mécanisme pour découvrir la valeur d'une clef subrogée d'une ligne particulière.

Notez que les performances de la mise à jour d'un <idbag> sont bien meilleures qu'un <bag> ordinaire ! Hibernate peut localiser des lignes individuelles efficacement et les mettre à jour ou les effacer individuellement, comme une liste, une map ou un ensemble.

Dans l'implémentation actuelle, la stratégie de la génération de l'identifiant native n'est pas supportée pour les identifiants de collection <idbag>.
6.4. Exemples de collections

Les sections précédentes sont assez confuses. Donc prenons un exemple. Cette classe :

package eg;
import java.util.Set;

public class Parent {
    private long id;
    private Set children;

    public long getId() { return id; }
    private void setId(long id) { this.id=id; }

    private Set getChildren() { return children; }
    private void setChildren(Set children) { this.children=children; }

    ....
    ....
}

a une collection d'instances de Child. Si chaque enfant a au plus un parent, le mapping le plus naturel est une association un-vers-plusieurs :

<hibernate-mapping>

    <class name="Parent">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <set name="children">
            <key column="parent_id"/>
            <one-to-many class="Child"/>
        </set>
    </class>

    <class name="Child">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <property name="name"/>
    </class>

</hibernate-mapping>

Ceci mappe les définitions de tables suivantes :

create table parent ( id bigint not null primary key )
create table child ( id bigint not null primary key, name varchar(255), parent_id bigint )
alter table child add constraint childfk0 (parent_id) references parent

Si le parent est requis, utilisez une association un-vers-plusieurs unidirectionnelle :

<hibernate-mapping>

    <class name="Parent">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <set name="children" inverse="true">
            <key column="parent_id"/>
            <one-to-many class="Child"/>
        </set>
    </class>

    <class name="Child">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <property name="name"/>
        <many-to-one name="parent" class="Parent" column="parent_id" not-null="true"/>
    </class>

</hibernate-mapping>

Notez la contrainte NOT NULL :

create table parent ( id bigint not null primary key )
create table child ( id bigint not null
                     primary key,
                     name varchar(255),
                     parent_id bigint not null )
alter table child add constraint childfk0 (parent_id) references parent

Alternativement, si vous insistez absolument pour que cette association soit unidirectionnelle, vous pouvez déclarer la contrainte NOT NULL sur le mapping <key> :

<hibernate-mapping>

    <class name="Parent">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <set name="children">
            <key column="parent_id" not-null="true"/>
            <one-to-many class="Child"/>
        </set>
    </class>

    <class name="Child">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <property name="name"/>
    </class>

</hibernate-mapping>

D'un autre côté, si un enfant pouvait avoir plusieurs parent, une association plusieurs-vers-plusieurs est plus appropriée :

<hibernate-mapping>

    <class name="Parent">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <set name="children" table="childset">
            <key column="parent_id"/>
            <many-to-many class="Child" column="child_id"/>
        </set>
    </class>

    <class name="Child">
        <id name="id">
            <generator class="sequence"/>
        </id>
        <property name="name"/>
    </class>

</hibernate-mapping>

Définitions des tables :

create table parent ( id bigint not null primary key )
create table child ( id bigint not null primary key, name varchar(255) )
create table childset ( parent_id bigint not null,
                        child_id bigint not null,
                        primary key ( parent_id, child_id ) )
alter table childset add constraint childsetfk0 (parent_id) references parent
alter table childset add constraint childsetfk1 (child_id) references child

Pour plus d'exemples et une revue complète du mapping de la relation parent/enfant, voir see Chapitre 21, Exemple : Père/Fils.

Des mappings d'association plus exotiques sont possibles, nous cataloguerons toutes les possibilités dans le prochain chapitre.
Chapitre 7. Mapper les associations
7.1. Introduction

Correctement mapper les associations est souvent la tâche la plus difficile. Dans cette section nous traiterons les cas classiques les uns après les autres. Nous commencerons d'abbord par les mappings unidirectionnels, puis nous aborderons la question des mappings bidirectionnels. Nous illustrerons tous nos exemples avec les classes Person et Address.

Nous utiliserons deux critères pour classer les associations : le premier sera de savoir si l'association est bâti sur une table supplémentaire d'association et le deuxieme sera basé sur la multiplicité de cette association.

Autoriser une clé étrangère nulle est considéré comme un mauvais choix dans la construction d'un modèle de données. Nous supposerons donc que dans tous les exemples qui vont suivre on aura interdit la valeur nulle pour les clés étrangères. Attention, ceci ne veut pas dire que Hibernate ne supporte pas les clés étrangères pouvant prendre des valeurs nulles, les exemples qui suivent continueront de fonctionner si vous décidiez ne plus imposer la contrainte de non-nullité sur les clés étrangères.
7.2. Association unidirectionnelle
7.2.1. plusieurs à un

Une association plusieurs-à-un (many-to-one) unidirectionnelle est le type que l'on rencontre le plus souvent dans les associations unidirectionnelles.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <many-to-one name="address" 
        column="addressId"
        not-null="true"/>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
</class>

create table Person ( personId bigint not null primary key, addressId bigint not null )
create table Address ( addressId bigint not null primary key )
        

7.2.2. un à un

une association un-à-un (one-to-one) sur une clé étrangère est presque identique. La seule différence est sur la contrainte d'unicité que l'on impose à cette colonne.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <many-to-one name="address" 
        column="addressId" 
        unique="true"
        not-null="true"/>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
</class>

create table Person ( personId bigint not null primary key, addressId bigint not null unique )
create table Address ( addressId bigint not null primary key )
        

Une association un-à-un (one-to-one) unidirectionnelle sur une clé primaire utilise un générateur d'identifiant particulier. (Remarquez que nous avons inversé le sens de cette association dans cet exemple.)

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
</class>

<class name="Address">
    <id name="id" column="personId">
        <generator class="foreign">
            <param name="property">person</param>
        </generator>
    </id>
    <one-to-one name="person" constrained="true"/>
</class>

create table Person ( personId bigint not null primary key )
create table Address ( personId bigint not null primary key )
        

7.2.3. un à plusieurs

Une association un-à-plusieurs (one-to-many) unidirectionnelle sur une clé étrangère est vraiment inhabituelle, et n'est pas vraiment recommandée.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <set name="addresses">
        <key column="personId" 
            not-null="true"/>
        <one-to-many class="Address"/>
    </set>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
</class>

create table Person ( personId bigint not null primary key )
create table Address ( addressId bigint not null primary key, personId bigint not null )
        

Nous pensons qu'il est préférable d'utiliser une table de jointure pour ce type d'association.
7.3. Associations unidirectionnelles avec tables de jointure
7.3.1. un à plusieurs

Une association unidirectionnelle un-à-plusieurs (one-to-many) avec une table de jointure est un bien meilleur choix. Remarquez qu'en spécifiant unique="true", on a changé la multiplicité plusieurs-à-plusieurs (many-to-many) pour un-à-plusieurs (one-to-many).

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <set name="addresses" table="PersonAddress">
        <key column="personId"/>
        <many-to-many column="addressId"
            unique="true"
            class="Address"/>
    </set>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
</class>

create table Person ( personId bigint not null primary key )
create table PersonAddress ( personId not null, addressId bigint not null primary key )
create table Address ( addressId bigint not null primary key )
        

7.3.2. plusieurs à un

Une assiociation plusieurs-à-un (many-to-one) unidirectionnelle sur une table de jointure est très fréquente quand l'association est optionnelle.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <join table="PersonAddress" 
        optional="true">
        <key column="personId" unique="true"/>
        <many-to-one name="address"
            column="addressId" 
            not-null="true"/>
    </join>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
</class>

create table Person ( personId bigint not null primary key )
create table PersonAddress ( personId bigint not null primary key, addressId bigint not null )
create table Address ( addressId bigint not null primary key )
        

7.3.3. un à un

Une association unidirectionnelle un-à-un (one-to-one) sur une table de jointure est extrèmement rare mais envisageable.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <join table="PersonAddress" 
        optional="true">
        <key column="personId" 
            unique="true"/>
        <many-to-one name="address"
            column="addressId" 
            not-null="true"
            unique="true"/>
    </join>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
</class>

create table Person ( personId bigint not null primary key )
create table PersonAddress ( personId bigint not null primary key, addressId bigint not null unique )
create table Address ( addressId bigint not null primary key )
        

7.3.4. plusieurs à plusieurs

Finallement, nous avons l'association unidirectionnelle plusieurs-à-plusieurs (many-to-many).

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <set name="addresses" table="PersonAddress">
        <key column="personId"/>
        <many-to-many column="addressId"
            class="Address"/>
    </set>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
</class>

create table Person ( personId bigint not null primary key )
create table PersonAddress ( personId bigint not null, addressId bigint not null, primary key (personId, addressId) )
create table Address ( addressId bigint not null primary key )
        

7.4. Associations bidirectionnelles
7.4.1. un à plusieurs / plusieurs à un

Une association bidirectionnelle plusieurs à un (many-to-one) est le type d'association que l'on rencontre le plus souvent. (c'est la façon standard de créer des relations parents/enfants.)

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <many-to-one name="address" 
        column="addressId"
        not-null="true"/>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
    <set name="people" inverse="true">
        <key column="addressId"/>
        <one-to-many class="Person"/>
    </set>
</class>

create table Person ( personId bigint not null primary key, addressId bigint not null )
create table Address ( addressId bigint not null primary key )
        

Si vous utilisez une List (ou toute autre collection indexée) vous devez paramétrer la colonne key de la clé étrangère à not null, et laisser Hibernate gérer l'association depuis l'extrémité collection pour maintenir l'index de chaque élément (rendant l'autre extrémité virtuellement inverse en paramétrant update="false" et insert="false"):

<class name="Person">
   <id name="id"/>
   ...
   <many-to-one name="address"
      column="addressId"
      not-null="true"
      insert="false"
      update="false"/>
</class>

<class name="Address">
   <id name="id"/>
   ...
   <list name="people">
      <key column="addressId" not-null="true"/>
      <list-index column="peopleIdx"/>
      <one-to-many class="Person"/>
   </list>
</class>

7.4.2. Un à un

Une association bidirectionnelle un à un (one-to-one) sur une clé étrangère est aussi très fréquente.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <many-to-one name="address" 
        column="addressId" 
        unique="true"
        not-null="true"/>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
   <one-to-one name="person" 
        property-ref="address"/>
</class>

create table Person ( personId bigint not null primary key, addressId bigint not null unique )
create table Address ( addressId bigint not null primary key )
        

Une association bidirectionnelle un-à-un (one-to-one) sur une clé primaire utilise un générateur particulier d'id.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <one-to-one name="address"/>
</class>

<class name="Address">
    <id name="id" column="personId">
        <generator class="foreign">
            <param name="property">person</param>
        </generator>
    </id>
    <one-to-one name="person" 
        constrained="true"/>
</class>

create table Person ( personId bigint not null primary key )
create table Address ( personId bigint not null primary key )
        

7.5. Associations bidirectionnelles avec table de jointure
7.5.1. un à plusieurs / plusieurs à un

Une association bidirectionnelle un-à-plusieurs (one-to-many) sur une table de jointure . Remarquez que inverse="true" peut s'appliquer sur les deux extrémités de l' association, sur la collection, ou sur la jointure.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <set name="addresses" 
        table="PersonAddress">
        <key column="personId"/>
        <many-to-many column="addressId"
            unique="true"
            class="Address"/>
    </set>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
    <join table="PersonAddress" 
        inverse="true" 
        optional="true">
        <key column="addressId"/>
        <many-to-one name="person"
            column="personId"
            not-null="true"/>
    </join>
</class>

create table Person ( personId bigint not null primary key )
create table PersonAddress ( personId bigint not null, addressId bigint not null primary key )
create table Address ( addressId bigint not null primary key )
        

7.5.2. Un à un

Une association bidirectionnelle un-à-un (one-to-one) sur une table de jointure est extrèmement rare mais envisageable.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <join table="PersonAddress" 
        optional="true">
        <key column="personId" 
            unique="true"/>
        <many-to-one name="address"
            column="addressId" 
            not-null="true"
            unique="true"/>
    </join>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
    <join table="PersonAddress" 
        optional="true"
        inverse="true">
        <key column="addressId" 
            unique="true"/>
        <many-to-one name="person"
            column="personId" 
            not-null="true"
            unique="true"/>
    </join>
</class>

create table Person ( personId bigint not null primary key )
create table PersonAddress ( personId bigint not null primary key, addressId bigint not null unique )
create table Address ( addressId bigint not null primary key )
        

7.5.3. plusieurs à plusieurs

Finallement nous avons l'association bidirectionnelle plusieurs à plusieurs.

<class name="Person">
    <id name="id" column="personId">
        <generator class="native"/>
    </id>
    <set name="addresses" table="PersonAddress">
        <key column="personId"/>
        <many-to-many column="addressId"
            class="Address"/>
    </set>
</class>

<class name="Address">
    <id name="id" column="addressId">
        <generator class="native"/>
    </id>
    <set name="people" inverse="true"  table="PersonAddress">
        <key column="addressId"/>
        <many-to-many column="personId"
            class="Person"/>
    </set>
</class>

create table Person ( personId bigint not null primary key )
create table PersonAddress ( personId bigint not null, addressId bigint not null, primary key (personId, addressId) )
create table Address ( addressId bigint not null primary key )
        

7.6. Des mappings plus complexes

Des associations encore plus complexes sont extrêmement rares. Hibernate permet de gérer des situations plus complexes en utilisant des parties SQL dans les fichiers de mapping. Par exemple, si une table avec l'historiques des informations d'un compte définit les colonnes accountNumber, effectiveEndDate et effectiveStartDate, mappées de telle sorte:

<properties name="currentAccountKey">
    <property name="accountNumber" type="string" not-null="true"/>
    <property name="currentAccount" type="boolean">
        <formula>case when effectiveEndDate is null then 1 else 0 end</formula>
    </property>
</properties>
<property name="effectiveEndDate" type="date"/>
<property name="effectiveStateDate" type="date" not-null="true"/>

alors nous pouvons mapper une association à l'instance courante (celle avec une effectiveEndDate) nulle en utilisant:

<many-to-one name="currentAccountInfo" 
        property-ref="currentAccountKey"
        class="AccountInfo">
    <column name="accountNumber"/>
    <formula>'1'</formula>
</many-to-one>

Dans un exemple plus complexe, imaginez qu'une association entre Employee et Organization est gérée dans une table Employment pleines de données historiques. Dans ce cas, une association vers l'employeur le plus récent (celui avec la startDate la plus récente) pourrait être mappée comme cela:

<join>
    <key column="employeeId"/>
    <subselect>
        select employeeId, orgId 
        from Employments 
        group by orgId 
        having startDate = max(startDate)
    </subselect>
    <many-to-one name="mostRecentEmployer" 
            class="Organization" 
            column="orgId"/>
</join>

Vous pouvez être créatif grace à ces possibilités, mais il est généralement plus pratique d'utiliser des requêtes HQL ou criteria dans ce genre de situation.
Chapitre 8. Mapping de composants

La notion de composants est réutilisé dans différents contextes, avec différents objectifs, à travers Hibernate.
8.1. Objects dépendants

Le composant est un objet inclu dans un autre qui est sauvegardé comme une valeur, et non pas comme une entité. Le composant fait référence à la notion (au sens objet) de composition (et non pas de composant au sens d'architecture de composants). Par exemple on pourrait modélisé l'objet personne de cette façon:

public class Person {
    private java.util.Date birthday;
    private Name name;
    private String key;
    public String getKey() {
        return key;
    }
    private void setKey(String key) {
        this.key=key;
    }
    public java.util.Date getBirthday() {
        return birthday;
    }
    public void setBirthday(java.util.Date birthday) {
        this.birthday = birthday;
    }
    public Name getName() {
        return name;
    }
    public void setName(Name name) {
        this.name = name;
    }
    ......
    ......
}

public class Name {
    char initial;
    String first;
    String last;
    public String getFirst() {
        return first;
    }
    void setFirst(String first) {
        this.first = first;
    }
    public String getLast() {
        return last;
    }
    void setLast(String last) {
        this.last = last;
    }
    public char getInitial() {
        return initial;
    }
    void setInitial(char initial) {
        this.initial = initial;
    }
}

Maintenant Name peut-être sauvegardé comme un composant de Person. Remarquer que Name définit des methodes d'accès et de modification pour ses propriétés persistantes, mais il n'a pas besoin des interfaces ou des propriétés d'identification ( par exemple getId() ) qui sont propres aux entités.

Nous serions alors amené à mapper ce composant de cette façon:

<class name="eg.Person" table="person">
    <id name="Key" column="pid" type="string">
        <generator class="uuid"/>
    </id>
    <property name="birthday" type="date"/>
    <component name="Name" class="eg.Name"> <!-- class attribute optional -->
        <property name="initial"/>
        <property name="first"/>
        <property name="last"/>
    </component>
</class>

La table person aurai les colonnes pid, birthday, initial, first and last.

Comme tous les types valeurs, les composants ne supportent pas les références partagés. En d'autres mots, deux instances de person peuvent avoir un même nom, mais ces noms sont indépendants, ils peuvent être identiques si on les compare par valeur mais ils représentent deux objets distincts en mémoire. La notion de nullité pour un composant est ad hoc. Quand il recharge l'objet qui contient le composant, Hibernate supposera que si tous les champs du composants sont nuls alors le composant sera positionné à la valeur null. Ce choix programmatif devrait être satisfaisant dans la plupart des cas.

Les propriétés d'un composant peuvent être de tous les types qu'Hibernate supporte habituellement (collections, many-to-one associations, autres composants, etc). Les composants inclus ne doivent pas être vus comme quelque chose d'exotique. Hibernate a été conçu pour supporter un modèle objet très granulaire.

Le <component> peut inclure dans la liste de ses propriétés une référence au <parent> conteneur.

<class name="eg.Person" table="person">
    <id name="Key" column="pid" type="string">
        <generator class="uuid"/>
    </id>
    <property name="birthday" type="date"/>
    <component name="Name" class="eg.Name" unique="true">
        <parent name="namedPerson"/> <!-- référence arrière à Person -->
        <property name="initial"/>
        <property name="first"/>
        <property name="last"/>
    </component>
</class>

8.2. Collection d'objets dépendants

Les collections d'objets dépendants sont supportés (exemple: un tableau de type Name). Déclarer la collection de composants en remplaçant le tag <element> par le tag <composite-element>.

<set name="someNames" table="some_names" lazy="true">
    <key column="id"/>
    <composite-element class="eg.Name"> <!-- class attribute required -->
        <property name="initial"/>
        <property name="first"/>
        <property name="last"/>
    </composite-element>
</set>

Remarque: Si vous définissez un Set d'élément composite, il est très important d'implémenter la méthode equals() et hashCode() correctement.

Les élements composite peuvent aussi contenir des composants mais pas des collections. Si votre élément composite contient aussi des composants, utilisez l'élément <nested-composite-element> . Une collections de composants qui ccontiennent eux-mêmes des composants est un cas très exotique. A ce stade demandez-vous si une association un-à-plusieurs ne serait pas plus approprié. Essayez de re remodeler votre élément composite comme une entité ( Dans ce cas même si le modèle Java est le même la logique de persitence et de relation sont tout de même différentes)

Remarque, le mapping d'éléments composites ne supporte pas la nullité des propriétés lorsqu'on utilise un <set>. Hibernate lorsqu'il supprime un objet utilise chaque colonne pour identifier un objet (on ne peut pas utiliser des clés primaires distinctes dans une table d'éléments composites), ce qui n'est pas possible avec des valeurs nulles. Vous devez donc choisir d'interdire la nullité des propriétés d'un élément composite ou choisir un autre type de collection comme : <list>, <map>, <bag> ou <idbag>.

Un cas particulier d'élément composite est un élément composite qui inclut un élément <many-to-one>. Un mapping comme celui-ci vous permet d'associer les colonnes d'une table d'association plusieurs à plusieurs (many-to-many) à la classse de l'élément composite. L'exemple suivant est une association plusieurs à plusieurs de Order à Item à purchaseDate, price et quantity sont des propriétés de l'association.

<class name="eg.Order" .... >
    ....
    <set name="purchasedItems" table="purchase_items" lazy="true">
        <key column="order_id">
        <composite-element class="eg.Purchase">
            <property name="purchaseDate"/>
            <property name="price"/>
            <property name="quantity"/>
            <many-to-one name="item" class="eg.Item"/> <!-- class attribute is optional -->
        </composite-element>
    </set>
</class>

Bien sûr, il ne peut pas y avoir de référence à l'achat (purchase) depuis l'article (item), pour pouvoir naviguer de façon bidirectionnelle dans l'association. N'oubliez pas que les composants sont de type valeurs et n'autorise pas les références partagées.

Même les associations ternaires ou quaternaires sont possibles:

<class name="eg.Order" .... >
    ....
    <set name="purchasedItems" table="purchase_items" lazy="true">
        <key column="order_id">
        <composite-element class="eg.OrderLine">
            <many-to-one name="purchaseDetails class="eg.Purchase"/>
            <many-to-one name="item" class="eg.Item"/>
        </composite-element>
    </set>
</class>

Les éléments composites peuvent apparaître dans les requêtes en utilisant la même syntaxe que associations
8.3. Utiliser les composants comme index de map

l'élément <composite-map-key> vous permet d'utiliser une classe de composant comme indice de Map. Assurez-vous d'avoir surdéfini hashCode() et equals() dans la classe du composant.
8.4. Utiliser un composant comme identifiant

Vous pouvez utiliser un composant comme identifiant d'une entité. Mais pour cela la classe du composant doit respecter certaines règles.

    *

      Elle doit implémenter java.io.Serializable.
    *

      Elle doit redéfinir equals() et hashCode(), de façon cohérente avec le fait qu'elle définit une clé composite dans la base de données. 

Remarque: avec hibernate3, la seconde règle n'est plus absolument necessaire mais faîtes le quand même.

Vous ne pouvez pas utiliser de IdentifierGenerator pour générer une clé composite, l'application devra définir elle même ses propres identifiants.

Utiliser l'élément <composite-id> (en incluant l'élément <key-property>) à la place de l'habituel déclaration <id>. Par exemple la classe OrderLine qui dépend de la clé primaire (composite) de Order.

<class name="OrderLine">
    
    <composite-id name="id" class="OrderLineId">
        <key-property name="lineId"/>
        <key-property name="orderId"/>
        <key-property name="customerId"/>
    </composite-id>
    
    <property name="name"/>
    
    <many-to-one name="order" class="Order"
            insert="false" update="false">
        <column name="orderId"/>
        <column name="customerId"/>
    </many-to-one>
    ....
    
</class>

Maintenant toutes clés étrangères référençant la table OrderLine devra aussi être composite. Vous devez en tenir compte lorsque vous écrivez vos mapping d'association pour les autres classes. Une association à OrderLine devrait être mappé de la façon suivante :

<many-to-one name="orderLine" class="OrderLine">
<!-- the "class" attribute is optional, as usual -->
    <column name="lineId"/>
    <column name="orderId"/>
    <column name="customerId"/>
</many-to-one>

(Remarque: l'élément <column> est une alternative à l'attribut column que l'on utilise partout.)

Une association plusieurs-à-plusieurs (many-to-many) à OrderLine utilisera aussi une clé étrangère composite:

<set name="undeliveredOrderLines">
    <key column name="warehouseId"/>
    <many-to-many class="OrderLine">
        <column name="lineId"/>
        <column name="orderId"/>
        <column name="customerId"/>
    </many-to-many>
</set>

La collection des OrderLines dans Order utilisera:

<set name="orderLines" inverse="true">
    <key>
        <column name="orderId"/>
        <column name="customerId"/>
    </key>
    <one-to-many class="OrderLine"/>
</set>

(L'élément <one-to-many>, comme d'habitude, ne déclare pas de colonne.)

Si OrderLine lui-même possède une collection, celle-ci aura aussi une clé composite étrangère.

<class name="OrderLine">
    ....
    ....
    <list name="deliveryAttempts">
        <key>   <!-- a collection inherits the composite key type -->
            <column name="lineId"/>
            <column name="orderId"/>
            <column name="customerId"/>
        </key>
        <list-index column="attemptId" base="1"/>
        <composite-element class="DeliveryAttempt">
            ...
        </composite-element>
    </set>
</class>

8.5. Composant Dynamique

Vous pouvez même mapper une propriété de type Map:

<dynamic-component name="userAttributes">
    <property name="foo" column="FOO"/>
    <property name="bar" column="BAR"/>
    <many-to-one name="baz" class="Baz" column="BAZ_ID"/>
</dynamic-component>

La sémantique de l'association à un <dynamic-component> est identique à celle que l'on utilise pour les composants. L'avantage de ce type de mapping est qu'il pemet de déterminer les véritables propriétés du bean au moment su déploiement en éditant simplement le document de mapping. La manipulation du document de mapping pendant l'execution de l'application est aussi possible en utilisant un parser DOM. Il ya même mieux, vous pouvez accéder (et changer) le metamodel de configuration d'hibernate en utilisant l'objet Configuration
Chapitre 9. Mapping d'héritage de classe
9.1. Les trois stratégies

Hibernate supporte les trois stratégies d'héritage de base :

    *

      une table par hiérarchie de classe (table per class hierarchy)
    *

      une table par classe fille (table per subclass)
    *

      une table par classe concrète (table per concrete class) 

Hibernate supporte en plus une quatrièmestratégie, légèrement différente, qui supporte le polymorphisme :

    *

      le polymorphisme implicite 

Il est possible d'utiliser différentes stratégies de mapping pour différentes branches d'une même hiérarchie d'héritage, et alors d'employer le polymorphisme implicite pour réaliser le polymorphisme à travers toute la hiérarchie. Pourtant, Hibernate ne supporte pas de mélanger des mappings <subclass> et <joined-subclass> et <union-subclass> pour le même élément <class> racine. Il est possible de mélanger ensemble les stratégies d'une table par hiérarchie et d'une table par sous-classe, pour le même élément <class>, en combinant les éléments <subclass> et <join> (voir dessous).

Il est possible de définir des mappings de subclass, union-subclass, et joined-subclass dans des documents de mapping séparés, directement sous hibernate-mapping. Ceci vous permet d'étendre une hiérarchie de classe juste en ajoutant un nouveau fichier de mapping. Vous devez spécifier un attribut extends dans le mapping de la sous-classe, en nommant une super-classe précédemment mappée. Note : précédemment cette foncionnalité rendait l'ordre des documents de mapping important. Depuis Hibernate3, l'ordre des fichier de mapping n'importe plus lors de l'utilisation du mot-clef "extends". L'ordre à l'intérieur d'un simple fichier de mapping impose encore de définir les classes mères avant les classes filles.

 <hibernate-mapping>
     <subclass name="DomesticCat" extends="Cat" discriminator-value="D">
          <property name="name" type="string"/>
     </subclass>
 </hibernate-mapping>

9.1.1. Une table par hiérarchie de classe

Supposons que nous ayons une interface Payment, implémentée par CreditCardPayment, CashPayment, ChequePayment. La stratégie une table par hiérarchie serait :

<class name="Payment" table="PAYMENT">
    <id name="id" type="long" column="PAYMENT_ID">
        <generator class="native"/>
    </id>
    <discriminator column="PAYMENT_TYPE" type="string"/>
    <property name="amount" column="AMOUNT"/>
    ...
    <subclass name="CreditCardPayment" discriminator-value="CREDIT">
        <property name="creditCardType" column="CCTYPE"/>
        ...
    </subclass>
    <subclass name="CashPayment" discriminator-value="CASH">
        ...
    </subclass>
    <subclass name="ChequePayment" discriminator-value="CHEQUE">
        ...
    </subclass>
</class>

Une seule table est requise. Une grande limitation de cette stratégie est que les colonnes déclarées par les classes filles, telles que CCTYPE, ne peuvent avoir de contrainte NOT NULL.
9.1.2. Une table par classe fille

La stratégie une table par classe fille serait :

<class name="Payment" table="PAYMENT">
    <id name="id" type="long" column="PAYMENT_ID">
        <generator class="native"/>
    </id>
    <property name="amount" column="AMOUNT"/>
    ...
    <joined-subclass name="CreditCardPayment" table="CREDIT_PAYMENT">
        <key column="PAYMENT_ID"/>
        <property name="creditCardType" column="CCTYPE"/>
        ...
    </joined-subclass>
    <joined-subclass name="CashPayment" table="CASH_PAYMENT">
        <key column="PAYMENT_ID"/>
        ...
    </joined-subclass>
    <joined-subclass name="ChequePayment" table="CHEQUE_PAYMENT">
        <key column="PAYMENT_ID"/>
        ...
    </joined-subclass>
</class>

Quatre tables sont requises. Les trois tables des classes filles ont une clé primaire associée à la table classe mère (le modèle relationnel est une association un-vers-un).
9.1.3. Une table par classe fille, en utilisant un discriminant

Notez que l'implémentation Hibernate de la stratégie un table par classe fille ne nécessite pas de colonne discriminante dans la table classe mère. D'autres implémentations de mappers Objet/Relationnel utilisent une autre implémentation de la stratégie une table par classe fille qui nécessite une colonne de type discriminant dans la table de la classe mère. L'approche prise par Hibernate est plus difficile à implémenter mais plus correcte d'une point de vue relationnel. Si vous aimeriez utiliser une colonne discriminante avec la stratégie d'une table par classe fille, vous pourriez combiner l'utilisation de <subclass> et <join>, comme suit :

<class name="Payment" table="PAYMENT">
    <id name="id" type="long" column="PAYMENT_ID">
        <generator class="native"/>
    </id>
    <discriminator column="PAYMENT_TYPE" type="string"/>
    <property name="amount" column="AMOUNT"/>
    ...
    <subclass name="CreditCardPayment" discriminator-value="CREDIT">
        <join table="CREDIT_PAYMENT">
            <key column="PAYMENT_ID"/>
            <property name="creditCardType" column="CCTYPE"/>
            ...
        </join>
    </subclass>
    <subclass name="CashPayment" discriminator-value="CASH">
        <join table="CASH_PAYMENT">
            <key column="PAYMENT_ID"/>
            ...
        </join>
    </subclass>
    <subclass name="ChequePayment" discriminator-value="CHEQUE">
        <join table="CHEQUE_PAYMENT" fetch="select">
            <key column="PAYMENT_ID"/>
            ...
        </join>
    </subclass>
</class>

La déclaration optionnelle fetch="select" indique à Hibernate de ne pas récupérer les données de la classe fille ChequePayment par une jointure externe lors des requêtes sur la classe mère.
9.1.4. Mélange d'une table par hiérarchie de classe avec une table par classe fille

Vous pouvez même mélanger les stratégies d'une table par hiérarchie de classe et d'une table par classe fille en utilisant cette approche :

<class name="Payment" table="PAYMENT">
    <id name="id" type="long" column="PAYMENT_ID">
        <generator class="native"/>
    </id>
    <discriminator column="PAYMENT_TYPE" type="string"/>
    <property name="amount" column="AMOUNT"/>
    ...
    <subclass name="CreditCardPayment" discriminator-value="CREDIT">
        <join table="CREDIT_PAYMENT">
            <property name="creditCardType" column="CCTYPE"/>
            ...
        </join>
    </subclass>
    <subclass name="CashPayment" discriminator-value="CASH">
        ...
    </subclass>
    <subclass name="ChequePayment" discriminator-value="CHEQUE">
        ...
    </subclass>
</class>

Pour importe laquelle de ces stratégies, une association polymorphique vers la classe racine Payment est mappée en utilisant <many-to-one>.

<many-to-one name="payment" column="PAYMENT_ID" class="Payment"/>

9.1.5. Une table par classe concrète

Il y a deux manières d'utiliser la stratégie d'une table par classe concrète. La première est d'employer <union-subclass>.

<class name="Payment">
    <id name="id" type="long" column="PAYMENT_ID">
        <generator class="sequence"/>
    </id>
    <property name="amount" column="AMOUNT"/>
    ...
    <union-subclass name="CreditCardPayment" table="CREDIT_PAYMENT">
        <property name="creditCardType" column="CCTYPE"/>
        ...
    </union-subclass>
    <union-subclass name="CashPayment" table="CASH_PAYMENT">
        ...
    </union-subclass>
    <union-subclass name="ChequePayment" table="CHEQUE_PAYMENT">
        ...
    </union-subclass>
</class>

Trois tables sont nécessaires pour les classes filles. Chaque table définit des colonnes pour toutes les propriétés de la classe, incluant les propriétés héritéés.

La limitation de cette approche est que si une propriété est mappée sur la classe mère, le nom de la colonne doit être le même pour toutes les classes filles. (Nous pourrions être plus souple dans une future version d'Hibernate). La stratégie du générateur d'identifiant n'est pas permise dans l'héritage de classes filles par union, en effet la valeur (NdT : seed) de la clef primaire doit être partagée par toutes les classes filles "union" d'une hiérarchie.

Si votre classe mère est abstraite, mappez la avec abstract="true". Bien sûr, si elle n'est pas abstraite, une table supplémentaire (par défaut, PAYMENT dans l'exemple ci-dessus) est requise pour contenir des instances de la classe mère.
9.1.6. Une table par classe concrète, en utilisant le polymorphisme implicite

Une approche alternative est l'emploi du polymorphisme implicite :

<class name="CreditCardPayment" table="CREDIT_PAYMENT">
    <id name="id" type="long" column="CREDIT_PAYMENT_ID">
        <generator class="native"/>
    </id>
    <property name="amount" column="CREDIT_AMOUNT"/>
    ...
</class>

<class name="CashPayment" table="CASH_PAYMENT">
    <id name="id" type="long" column="CASH_PAYMENT_ID">
        <generator class="native"/>
    </id>
    <property name="amount" column="CASH_AMOUNT"/>
    ...
</class>

<class name="ChequePayment" table="CHEQUE_PAYMENT">
    <id name="id" type="long" column="CHEQUE_PAYMENT_ID">
        <generator class="native"/>
    </id>
    <property name="amount" column="CHEQUE_AMOUNT"/>
    ...
</class>

Notez que nulle part nous ne mentionnons l'interface Payment explicitement. Notez aussi que des propriétés de Payment sont mappées dans chaque classe fille. Si vous voulez éviter des duplications, considérez l'utilisation des entités XML (cf. [ <!ENTITY allproperties SYSTEM "allproperties.xml"> ] dans la déclaration du DOCTYPE et &allproperties; dans le mapping).

L'inconvénient de cette approche est qu'Hibernate ne génère pas d'UNIONs SQL lors de l'exécution des requêtes polymorphiques.

Pour cette stratégie de mapping, une association polymorphique pour Payment est habituellement mappée en utilisant <any>.

<any name="payment" meta-type="string" id-type="long">
    <meta-value value="CREDIT" class="CreditCardPayment"/>
    <meta-value value="CASH" class="CashPayment"/>
    <meta-value value="CHEQUE" class="ChequePayment"/>
    <column name="PAYMENT_CLASS"/>
    <column name="PAYMENT_ID"/>
</any>

9.1.7. Mélange du polymorphisme implicite avec d'autres mappings d'héritage

Il y a une chose supplémentaire à noter à propos de ce mapping. Puisque les classes filles sont chacune mappées avec leur propre élément <class> (et puisque Payment est juste une interface), chaque classe fille pourrait facilement faire partie d'une autre hiérarchie d'héritage ! (Et vous pouvez encore faire des requêtes polymorphiques pour l'interface Payment).

<class name="CreditCardPayment" table="CREDIT_PAYMENT">
    <id name="id" type="long" column="CREDIT_PAYMENT_ID">
        <generator class="native"/>
    </id>
    <discriminator column="CREDIT_CARD" type="string"/>
    <property name="amount" column="CREDIT_AMOUNT"/>
    ...
    <subclass name="MasterCardPayment" discriminator-value="MDC"/>
    <subclass name="VisaPayment" discriminator-value="VISA"/>
</class>

<class name="NonelectronicTransaction" table="NONELECTRONIC_TXN">
    <id name="id" type="long" column="TXN_ID">
        <generator class="native"/>
    </id>
    ...
    <joined-subclass name="CashPayment" table="CASH_PAYMENT">
        <key column="PAYMENT_ID"/>
        <property name="amount" column="CASH_AMOUNT"/>
        ...
    </joined-subclass>
    <joined-subclass name="ChequePayment" table="CHEQUE_PAYMENT">
        <key column="PAYMENT_ID"/>
        <property name="amount" column="CHEQUE_AMOUNT"/>
        ...
    </joined-subclass>
</class>

Encore une fois, nous ne mentionnons pas explicitement Payment. Si nous exécutons une requête sur l'interface Payment - par exemple, from Payment - Hibernate retournera automatiquement les instances de CreditCardPayment (et ses classes filles puisqu'elles implémentent aussi Payment), CashPayment et ChequePayment mais pas les instances de NonelectronicTransaction.
9.2. Limitations

Il y a certaines limitations à l'approche du "polymorphisme implicite" pour la stratégie de mapping d'une table par classe concrète. Il y a plutôt moins de limitations restrictives aux mappings <union-subclass>.

La table suivante montre les limitations des mappings d'une table par classe concrète, et du polymorphisme implicite, dans Hibernate.

Tableau 9.1. Caractéristiques du mapping d'héritage
Stratégie d'héritage	many-to-one polymorphique	one-to-one polymorphique	one-to-many polymorphique	many-to-many polymorphique	load()/get() polymorphique	Requêtes polymorphiques	Jointures polymorphiques	Récupération par jointure externe
une table par hiérarchie de classe	<many-to-one>	<one-to-one>	<one-to-many>	<many-to-many>	s.get(Payment.class, id)	from Payment p	from Order o join o.payment p	supportée
une table par classe fille	<many-to-one>	<one-to-one>	<one-to-many>	<many-to-many>	s.get(Payment.class, id)	from Payment p	from Order o join o.payment p	supportée
une table par classe concrète (union-subclass)	<many-to-one>	<one-to-one>	<one-to-many> (pour inverse="true" seulement)	<many-to-many>	s.get(Payment.class, id)	from Payment p	from Order o join o.payment p	supportée
une table par classe concrète (polymorphisme implicite)	<any>	non supporté	non supporté	<many-to-any>	s.createCriteria(Payment.class).add( Restrictions.idEq(id) ).uniqueResult()	from Payment p	non supportées	non supportée
Chapitre 10. Travailler avec des objets

Hibernate est une solution de mapping objet/relationnel complète qui ne masque pas seulement au développpeur les détails du système de gestion de base de données sous-jacent, mais offre aussi la gestion d'état des objets. C'est, contrairement à la gestion de statements SQL dans les couches de persistance habituelles JDBC/SQL, une vue orientée objet très naturelle de la persistance dans les applications Java.

En d'autres mots, les développeurs d'applications Hibernate devrait toujours réfléchir à l'état de leurs objets, et pas nécessairement à l'exécution des expressions SQL. Cette part est prise en charge pas Hibernate et seulement importante pour les développeurs d'applications lors du réglage de la performance de leur système.
10.1. États des objets Hibernate

Hibernate définit et comprend les états suivants :

    *

      Éphémère (NdT : transient) - un objet est éphémère s'il a juste été instancié en utilisant l'opérateur new. Il n'a aucune représentation persistante dans la base de données et aucune valeur d'identifiant n'a été assignée. Les instances éphémères seront détruites par le ramasse-miettes si l'application n'en conserve aucune référence. Utilisez la Session d'Hibernate pour rendre un objet persistant (et laisser Hibernate s'occuper des expressions SQL qui ont besoin d'être exécutées pour cette transistion).
    *

      Persistant - une instance persistante a une représentation dans la base de données et une valeur d'identifiant. Elle pourrait avoir juste été sauvegardée ou chargée, pourtant, elle est par définition dans la portée d'une Session. Hibernate détectera n'importe quels changements effectués sur un objet dans l'état persistant et synchronisera l'état avec la base de données lors de la fin l'unité de travail. Les développeurs n'exécutent pas d'expressions UPDATE ou DELETE manuelles lorsqu'un objet devrait être rendu éphémère.
    *

      Détaché - une instance détachée est un objet qui a été persistant, mais dont sa Session a été fermée. La référence à l'objet est encore valide, bien sûr, et l'instance détachée pourrait même être modifiée dans cet état. Une instance détachée peut être réattachée à une nouvelle Session plus tard dans le temps, la rendant (et toutes les modifications avec) de nouveau persistante. Cette fonctionnalité rend possible un modèle de programmation pour de longues unités de travail qui requièrent un temps de réflexion de l'utilisateur. Nous les appelons des conversations, c'est-à-dire une unité de travail du point de vue de l'utilisateur. 

Nous alons maintenant dicuster des états et des transitions d'état (et des méthodes d'Hibernate qui déclenchent une transition) plus en détails.
10.2. Rendre des objets persistants

Les instances nouvellement instanciées d'une classe persistante sont considérées éphémères par Hibernate. Nous pouvons rendre une instance éphémère persistante en l'associant avec une session :

DomesticCat fritz = new DomesticCat();
fritz.setColor(Color.GINGER);
fritz.setSex('M');
fritz.setName("Fritz");
Long generatedId = (Long) sess.save(fritz);

Si Cat a un identifiant généré, l'identifiant est généré et assigné au cat lorsque save() est appelée. Si Cat a un identifiant assigned, ou une clef composée, l'identifiant devrait être assigné à l'instance de cat avant d'appeler save(). Vous pouvez aussi utiliser persist() à la place desave(), avec la sémantique définie plus tôt dans le brouillon d'EJB3.

Alternativement, vous pouvez assigner l'identifiant en utilisant une version surchargée de save().

DomesticCat pk = new DomesticCat();
pk.setColor(Color.TABBY);
pk.setSex('F');
pk.setName("PK");
pk.setKittens( new HashSet() );
pk.addKitten(fritz);
sess.save( pk, new Long(1234) );

Si l'objet que vous rendez persistant a des objets associés (par exemple, la collection kittens dans l'exemple précédent), ces objets peuvent être rendus persistants dans n'importe quel ordre que vous souhaitez à moins que vous ayez une contrainte NOT NULL sur la colonne de la clef étrangère. Il n'y a jamais de risque de violer une contrainte de clef étrangère. Cependant, vous pourriez violer une contrainte NOT NULL si vous appeliez save() sur les objets dans le mauvais ordre.

Habituellement, vous ne vous préoccupez pas de ce détail, puisque vous utiliserez très probablement la fonctionnalité de persistance transitive d'Hibernate pour sauvegarder les objets associés automatiquement. Alors, même les violations de contrainte NOT NULL n'ont plus lieu - Hibernate prendra soin de tout. La persistance transitive est traitée plus loin dans ce chapitre.
10.3. Chargement d'un objet

Les méthodes load() de Session vous donnent un moyen de récupérer une instance persistante si vous connaissez déjà son identifiant. load() prend un objet de classe et chargera l'état dans une instance nouvellement instanciée de cette classe, dans un état persistant.

Cat fritz = (Cat) sess.load(Cat.class, generatedId);

// vous avez besoin d'envelopper les identiants primitifs
long pkId = 1234;
DomesticCat pk = (DomesticCat) sess.load( Cat.class, new Long(pkId) );

Alternativement, vous pouvez charger un état dans une instance donnée :

Cat cat = new DomesticCat();
// load pk's state into cat
sess.load( cat, new Long(pkId) );
Set kittens = cat.getKittens();

Notez que load() lèvera une exception irrécupérable s'il n'y a pas de ligne correspondante dans la base de données. Si la classe est mappée avec un proxy, load() retourne juste un proxy non initialisé et n'accède en fait pas à la base de données jusqu'à ce que vous invoquiez une méthode du proxy. Ce comportement est très utile si vous souhaitez créer une association vers un objet sans réellement le charger à partir de la base de données. Cela permet aussi à de multiples instances d'être chargées comme un lot si batch-size est défini pour le mapping de la classe.

Si vous n'êtes pas certain qu'une ligne correspondante existe, vous devriez utiliser la méthode get(), laquelle accède à la base de données immédiatement et retourne null s'il n'y a pas de ligne correspondante.

Cat cat = (Cat) sess.get(Cat.class, id);
if (cat==null) {
    cat = new Cat();
    sess.save(cat, id);
}
return cat;

Vous pouvez même charger un objet en employant un SELECT ... FOR UPDATE SQL, en utilisant un LockMode. Voir la documentation de l'API pour plus d'informations.

Cat cat = (Cat) sess.get(Cat.class, id, LockMode.UPGRADE);

Notez que n'importe quelles instances associées ou collections contenues ne sont pas sélectionnées par FOR UPDATE, à moins que vous ne décidiez de spécifier lock ou all en tant que style de cascade pour l'association.

Il est possible de re-charger un objet et toutes ses collections à n'importe quel moment, en utilisant la méthode refresh(). C'est utile lorsque des "triggers" de base de données sont utilisés pour initiliser certains propriétés de l'objet.

sess.save(cat);
sess.flush(); //force the SQL INSERT
sess.refresh(cat); //re-read the state (after the trigger executes)

Une question importante apparaît généralement à ce point : combien (NdT : de données) Hibernate charge-t-il de la base de données et combient de SELECTs utilisera-t-il ? Cela dépent de la stratégie de récupération et cela est expliqué dans Section 19.1, « Stratégies de chargement ».
10.4. Requêtage

Si vous ne connaissez par les identifiants des objets que vous recherchez, vous avez besoin d'une requête. Hibernate supporte un langage de requêtes orientées objet facile à utiliser mais puissant. Pour la création de requêtes par programmation, Hibernate supporte une fonction de requêtage sophistiqué Criteria et Example (QBC et QBE). Vous pouvez aussi exprimez votre requête dans le SQL natif de votre base de données, avec un support optionnel d'Hibernate pour la conversion des ensembles de résultats en objets.
10.4.1. Exécution de requêtes

Les requêtes HQL et SQL natives sont représentées avec une instance de org.hibernate.Query. L'interface offre des méthodes pour la liaison des paramètres, la gestion des ensembles de resultats, et pour l'exécution de la requête réelle. Vous obtenez toujours une Query en utilisant la Session courante :

List cats = session.createQuery(
    "from Cat as cat where cat.birthdate < ?")
    .setDate(0, date)
    .list();

List mothers = session.createQuery(
    "select mother from Cat as cat join cat.mother as mother where cat.name = ?")
    .setString(0, name)
    .list();

List kittens = session.createQuery(
    "from Cat as cat where cat.mother = ?")
    .setEntity(0, pk)
    .list();

Cat mother = (Cat) session.createQuery(
    "select cat.mother from Cat as cat where cat = ?")
    .setEntity(0, izi)
    .uniqueResult();

Une requête est généralement exécutée en invoquant list(), le résultat de la requête sera chargée complètement dans une collection en mémoire. Les intances d'entités recupérées par une requête sont dans un état persistant. La méthode uniqueResult() offre un raccourci si vous savez que votre requête retournera seulement un seul objet.
10.4.1.1. Itération de résultats

Occasionnellement, vous pourriez être capable d'obtenir de meilleures performances en exécutant la requête avec la méthode iterate(). Ce sera généralement seulement le cas si vous espérez que les intances réelles d'entité retournées par la requête soient déjà chargées dans la session ou le cache de second niveau. Si elles ne sont pas cachées, iterate() sera plus lent que list() et pourrait nécessiter plusieurs accès à la base de données pour une simple requête, généralement 1 pour le select initial qui retourne seulement les identifiants, et n selects supplémentaires pour initialiser les instances réelles.

// fetch ids
Iterator iter = sess.createQuery("from eg.Qux q order by q.likeliness").iterate();
while ( iter.hasNext() ) {
    Qux qux = (Qux) iter.next();  // fetch the object
    // something we couldnt express in the query
    if ( qux.calculateComplicatedAlgorithm() ) {
        // delete the current instance
        iter.remove();
        // dont need to process the rest
        break;
    }
}

10.4.1.2. Requêtes qui retournent des tuples

Les requêtes d'Hibernate retournent parfois des tuples d'objets, auquel cas chaque tuple est retourné comme un tableau :

Iterator kittensAndMothers = sess.createQuery(
            "select kitten, mother from Cat kitten join kitten.mother mother")
            .list()
            .iterator();

while ( kittensAndMothers.hasNext() ) {
    Object[] tuple = (Object[]) kittensAndMothers.next();
    Cat kitten  = tuple[0];
    Cat mother  = tuple[1];
    ....
}

10.4.1.3. Résultats scalaires

Des requêtes peuvent spécifier une propriété d'une classe dans la clause select. Elles peuvent même appeler des fonctions d'aggrégat SQL. Les propriétés ou les aggrégats sont considérés comme des résultats "scalaires" (et pas des entités dans un état persistant).

Iterator results = sess.createQuery(
        "select cat.color, min(cat.birthdate), count(cat) from Cat cat " +
        "group by cat.color")
        .list()
        .iterator();

while ( results.hasNext() ) {
    Object[] row = (Object[]) results.next();
    Color type = (Color) row[0];
    Date oldest = (Date) row[1];
    Integer count = (Integer) row[2];
    .....
}

10.4.1.4. Lier des paramètres

Des méthodes de Query sont fournies pour lier des valeurs à des paramètres nommés ou à des paramètres de style JDBC ?. Contrairement à JDBC, les numéros des paramètres d'Hibernate commencent à zéro. Les paramètres nommés sont des identifiants de la forme :nom dans la chaîne de caractères de la requête. Les avantages des paramètres nommés sont :

    *

      les paramètres nommés sont insensibles à l'ordre de leur place dans la chaîne de la requête
    *

      ils peuvent apparaître plusieurs fois dans la même requête
    *

      ils sont auto-documentés 

//paramètre nomme (préféré)
Query q = sess.createQuery("from DomesticCat cat where cat.name = :name");
q.setString("name", "Fritz");
Iterator cats = q.iterate();

//paramètre positionnel
Query q = sess.createQuery("from DomesticCat cat where cat.name = ?");
q.setString(0, "Izi");
Iterator cats = q.iterate();

//liste de paramètres nommés
List names = new ArrayList();
names.add("Izi");
names.add("Fritz");
Query q = sess.createQuery("from DomesticCat cat where cat.name in (:namesList)");
q.setParameterList("namesList", names);
List cats = q.list();

10.4.1.5. Pagination

Si vous avez besoin de spécifier des liens sur votre ensemble de résultats (le nombre maximum de lignes que vous voulez récupérez et/ou la première ligne que vous voulez récupérer) vous devriez utiliser des méthodes de l'interface Query :

Query q = sess.createQuery("from DomesticCat cat");
q.setFirstResult(20);
q.setMaxResults(10);
List cats = q.list();

Hibernate sait comment traduite cette requête de limite en SQL natif pour votre SGBD.
10.4.1.6. Itération "scrollable"

Si votre connecteur JDBC supporte les ResultSets "scrollables", l'interface Query peut être utilisée pour obtenir un objet ScrollableResults, lequel permet une navigation flexible dans les résultats de la requête.

Query q = sess.createQuery("select cat.name, cat from DomesticCat cat " +
                            "order by cat.name");
ScrollableResults cats = q.scroll();
if ( cats.first() ) {

    // trouve le premier nom sur chaque page d'une liste alphabétique de noms de chats
    firstNamesOfPages = new ArrayList();
    do {
        String name = cats.getString(0);
        firstNamesOfPages.add(name);
    }
    while ( cats.scroll(PAGE_SIZE) );

    // Maintenant, obtiens la première page de chats
    pageOfCats = new ArrayList();
    cats.beforeFirst();
    int i=0;
    while( ( PAGE_SIZE > i++ ) && cats.next() ) pageOfCats.add( cats.get(1) );

}
cats.close()

Notez qu'une connexion ouverte (et un curseur) est requise pour cette fonctionnalité, utilisez setMaxResult()/setFirstResult() si vous avez besoin d'une fonctionnalité de pagination hors ligne.
10.4.1.7. Externaliser des requêtes nommées

Vous pouvez aussi définir des requêtes nommées dans le document de mapping. (Souvenez-vous d'utiliser une section CDATA si votre requête contient des caractères qui pourraient être interprétés comme des éléments XML.)

<query name="eg.DomesticCat.by.name.and.minimum.weight"><![CDATA[
    from eg.DomesticCat as cat
        where cat.name = ?
        and cat.weight > ?
] ]></query>

La liaison de paramètres et l'exécution sont fait par programmation :

Query q = sess.getNamedQuery("eg.DomesticCat.by.name.and.minimum.weight");
q.setString(0, name);
q.setInt(1, minWeight);
List cats = q.list();

Notez que le code réel du programme est indépendant du langage de requête qui est utilisé, vous pouvez aussi définir des requêtes SQL nativez dans les méta-données, ou migrer des requêtes existantes vers Hibernate en les plaçant dans les fichiers de mapping.
10.4.2. Filtrer des collections

Un filtre de collection est un type spécial de requête qui peut être appliqué à une collection persistante ou à un tableau. La chaîne de requête peut se référer à this, correspondant à l'élément de la collection courant.

Collection blackKittens = session.createFilter(
    pk.getKittens(),
    "where this.color = ?")
    .setParameter( Color.BLACK, Hibernate.custom(ColorUserType.class) )
    .list()
);

La collection retournée est considérée comme un bag, et c'est une copie de la collection donnée. La collection originale n'est pas modifiée (c'est contraire à l'implication du nom "filtre"; mais cohérent avec le comportement attendu).

Observez que les filtres ne nécessitent pas une clause from (bien qu'ils puissent en avoir une si besoin est). Les filtres ne sont pas limités à retourner des éléments de la collection eux-mêmes.

Collection blackKittenMates = session.createFilter(
    pk.getKittens(),
    "select this.mate where this.color = eg.Color.BLACK.intValue")
    .list();

Même une requête de filtre vide est utile, par exemple pour charger un sous-ensemble d'éléments dans une énorme collection :

Collection tenKittens = session.createFilter(
    mother.getKittens(), "")
    .setFirstResult(0).setMaxResults(10)
    .list();

10.4.3. Requêtes Criteria

HQL est extrêmement puissant mais certains développeurs préfèrent construire des requêtes dynamiquement, en utilisant l'API orientée objet, plutôt que construire des chaînes de requêtes. Hibernate fournit une API intuitive de requête Criteria pour ces cas :

Criteria crit = session.createCriteria(Cat.class);
crit.add( Expression.eq( "color", eg.Color.BLACK ) );
crit.setMaxResults(10);
List cats = crit.list();

Les APIs Criteria et Example associé sont traitées plus en détail dans Chapitre 15, Requêtes par critères.
10.4.4. Requêtes en SQL natif

Vous pouvez exprimer une requête en SQL, en utilisant createSQLQuery() et laisser Hibernate s'occuper du mapping des résultats vers des objets. Notez que vous pouvez n'importe quand appeler session.connection() et utiliser directement la Connection JDBC. Si vous choisissez d'utiliser l'API Hibernate, vous devez mettre les alias SQL entre accolades :

List cats = session.createSQLQuery(
    "SELECT {cat.*} FROM CAT {cat} WHERE ROWNUM<10",
    "cat",
    Cat.class
).list();

List cats = session.createSQLQuery(
    "SELECT {cat}.ID AS {cat.id}, {cat}.SEX AS {cat.sex}, " +
           "{cat}.MATE AS {cat.mate}, {cat}.SUBCLASS AS {cat.class}, ... " +
    "FROM CAT {cat} WHERE ROWNUM<10",
    "cat",
    Cat.class
).list()

Les requêtes SQL peuvent contenir des paramètres nommés et positionnels, comme des requêtes Hibernate. Plus d'informations à propos des requêtes SQL natives dans Hibernate peuvent être trouvées dans Chapitre 16, SQL natif.
10.5. Modifier des objets persistants

Les instances persistantes transactionnelles (c'est-à-dire des objets chargés, sauvegardés, créés ou requêtés par la Session) peuvent être manipulées par l'application et n'importe quel changement vers l'état persistant sera persisté lorsque la Session est "flushée" (traité plus tard dans ce chapitre). Il n'y a pas besoin d'appeler une méthode particulière (comme update(), qui a un but différent) pour rendre vos modifications persistantes. Donc la manière la plus directe de mettre à jour l'état d'un objet est de le charger avec load(), et puis le manipuler directement, tant que la Session est ouverte :

DomesticCat cat = (DomesticCat) sess.load( Cat.class, new Long(69) );
cat.setName("PK");
sess.flush();  // changes to cat are automatically detected and persisted

Parfois ce modèle de programmation est inefficace puisqu'il nécessiterait un SELECT SQL (pour charger l'objet) et un UPDATE SQL (pour persister son état mis à jour) dans la même session. Aussi Hibernate offre une autre approche, en utilisant des instances détachées.

Notez que Hibernate n'offre par sa propre API pour l'exécution directe d'expressions UPDATE ou DELETE. Hibernate est un service de gestion d'état, vous n'avez pas à penser aux expressions pour l'utiliser. JDBC est une API parfaite pour exécuter des expressions SQL, vous pouvez obtenir une Connection JDBC n'importe quand en appelant session.connection(). En outre, la notion d'opérations de masse entre en conflit avec le mapping objet/relationnel pour les applications orientées processus de transactions en ligne. Les futures versions d'Hibernate peuvent cependant fournir des fonctions d'opération de masse. Voir Chapitre 13, Traitement par paquet pour les astuces possibles d'opérations groupées.
10.6. Modifier des objets détachés

Beaucoup d'applications ont besoin de récupérer un objet dans une transaction, l'envoyer à la couche interfacée avec l'utilisateur pour les manipulations, puis sauvegarder les changements dans une nouvelle transaction. Les applications qui utilisent cette approche dans un environnement à haute concurrence utilisent généralement des données versionnées pour assurer l'isolation pour les "longues" unités de travail.

Hibernate supporte ce modèle en permettant pour le réattachement d'instances détachées l'utilisation des méthodes Session.update() ou Session.merge() :

// dans la première session
Cat cat = (Cat) firstSession.load(Cat.class, catId);
Cat potentialMate = new Cat();
firstSession.save(potentialMate);

// dans une couche plus haute de l'application
cat.setMate(potentialMate);

// plus tard, dans une nouvelle session
secondSession.update(cat);  // update cat
secondSession.update(mate); // update mate

Si le Cat avec l'identifiant catId avait déjà été chargé par secondSession lorsque l'application a essayé de le réattacher, une exception aurait été levée.

Utilisez update() si vous êtes sure que la session ne contient pas déjà une instance persistante avec le même identifiant, et merge() si vous voulez fusionner vos modifications n'importe quand sans considérer l'état de la session. En d'autres mots, update() est généralement la première méthode que vous devriez appeler dans une session fraîche, pour s'assurer que le réattachement de vos instances détachées est la première opération qui est exécutée.

L'application devrait individuellement update() (NdT : mettre à jour) les instances détachées accessibles depuis l'instance détachée donnée si et seulement si elle veut que leur état soit aussi mis à jour. Ceci peut être automatisé bien sûr, en utilisant la persistance transitive, voir Section 10.11, « Persistance transitive ».

La méthode lock() permet aussi à une application de réassocier un objet avec une nouvelle session. Pourtant, l'instance détachée doit être non modifiée !

//réassocie :
sess.lock(fritz, LockMode.NONE);
//fait une vérification de version, puis réassocie :
sess.lock(izi, LockMode.READ);
//fait une vérification de version, en utilisant SELECT ... FOR UPDATE, puis réassocie :
sess.lock(pk, LockMode.UPGRADE);

Notez que lock() peut être utilisé avec différents LockModes, voir la documentation de l'API documentation et le chapitre sur la gestion des transactions pour plus d'informations. Le réattachement n'est pas le seul cas d'utilisation pour lock().

D'autres modèles pour de longues unités de travail sont traités dans Section 11.3, « Contrôle de consurrence optimiste ».
10.7. Détection automatique d'un état

Les utilisateurs d'Hibernate ont demandé une méthode dont l'intention générale serait soit de sauvegarder une instance éphémère en générant un nouvel identifiant, soit mettre à jour/réattacher les instances détachées associées à l'identifiant courant. La méthode saveOrUpdate() implémente cette fonctionnalité.

// dans la première session
Cat cat = (Cat) firstSession.load(Cat.class, catID);

// dans une partie plus haute de l'application
Cat mate = new Cat();
cat.setMate(mate);

// plus tard, dans une nouvelle session
secondSession.saveOrUpdate(cat);   // met à jour un état existant (cat a un identifiant non-null)
secondSession.saveOrUpdate(mate);  // sauvegarde les nouvelles instances (mate a un identiant null)

L'usage et la sémantique de saveOrUpdate() semble être confuse pour les nouveaux utilisateurs. Premièrement, aussi longtemps que vous n'essayez pas d'utiliser des instances d'une session dans une autre, vous ne devriez pas avoir besoin d'utiliser update(), saveOrUpdate(), ou merge(). Certaines applications n'utiliseront jamais ces méthodes.

Généralement update() ou saveOrUpdate() sont utilisées dans le scénario suivant :

    *

      l'application charge un objet dans la première session
    *

      l'objet est passé à la couche utilisateur
    *

      certaines modifications sont effectuées sur l'objet
    *

      l'objet est retourné à la couche logique métier
    *

      l'application persiste ces modifications en appelant update() dans une seconde sessin 

saveOrUpdate() s'utilise dans le cas suivant :

    *

      si l'objet est déjà persistant dans cette session, ne rien faire
    *

      si un autre objet associé à la session a le même identifiant, lever une exception
    *

      si l'objet n'a pas de propriété d'identifiant, appeler save()
    *

      si l'identifiant de l'objet a une valeur assignée à un objet nouvellement instancié, appeler save()
    *

      si l'objet est versionné (par <version> ou <timestamp>), et la valeur de la propriété de version est la même valeur que celle assignée à un objet nouvellement instancié, appeler save()
    *

      sinon mettre à jour l'objet avec update() 

et merge() est très différent :

    *

      s'il y a une instance persistante avec le même identifiant couramment associée à la session, copier l'état de l'objet donné dans l'instance persistante
    *

      s'il n'y a pas d'instance persistante associée à cette session, essayer de le charger à partir de la base de données, ou créer une nouvelle instance persistante
    *

      l'instance persistante est retournée
    *

      l'instance donnée ne devient pas associée à la session, elle reste détachée 

10.8. Suppression d'objets persistants

Session.delete() supprimera l'état d'un objet de la base de données. Bien sûr, votre application pourrait encore conserver une référence vers un objet effacé. Il est mieux de penser à delete() comme rendant une instance persistante éphémère.

sess.delete(cat);

Vous pouvez effacer des objets dans l'ordre que vous voulez, sans risque de violations de contrainte de clef étrangère. Il est encore possible de violer une contrainte NOT NULL sur une colonne de clef étrangère en effaçant des objets dans le mauvais ordre, par exemple si vous effacer le parent, mais oubliez d'effacer les enfants.
10.9. Réplication d'objets entre deux entrepôts de données

Il est occasionnellement utile de pouvoir prendre un graphe d'instances persistantes et de les rendre persistantes dans un entrepôt différent, sans regénérer les valeurs des identifiants.

//récupère un cat de la base de données
Session session1 = factory1.openSession();
Transaction tx1 = session1.beginTransaction();
Cat cat = session1.get(Cat.class, catId);
tx1.commit();
session1.close();

// réconcilie la seconde base de données
Session session2 = factory2.openSession();
Transaction tx2 = session2.beginTransaction();
session2.replicate(cat, ReplicationMode.LATEST_VERSION);
tx2.commit();
session2.close();

Le ReplicationMode détermine comment replicate() traitera les conflits avec les lignes existantes dans la base de données.

    *

      ReplicationMode.IGNORE - ignore l'objet s'il y a une ligne existante dans la base de données avec le même identifiant
    *

      ReplicationMode.OVERWRITE - écrase n'importe quelle ligne existante dans la base de données avec le même identifiant
    *

      ReplicationMode.EXCEPTION - lève une exception s'il y une ligne dans la base de données avec le même identifiant
    *

      ReplicationMode.LATEST_VERSION - écrase la ligne si son numéro de version est plus petit que le numéro de version de l'objet, ou ignore l'objet sinon 

Les cas d'utilisation de cette fonctionnalité incluent la réconciliation de données entrées dans différentes base de données, l'extension des informations de configuration du système durant une mise à jour du produit, retour en arrière sur les changements effectués durant des transactions non-ACID, et plus.
10.10. Flush de la session

De temps en temps la Session exécutera les expressions SQL requises pour syncrhoniser l'état de la connexion JDBC avec l'état des objets retenus en mémoire. Ce processus, flush, arrive par défaut aux points suivants :

    *

      lors de certaines exécutions de requête
    *

      lors d'un appel à org.hibernate.Transaction.commit()
    *

      lors d'un appel à Session.flush() 

Les expressions SQL sont effectuées dans l'ordre suivant :

   1.

      insertion des entités, dans le même ordre que celui des objets correspondants sauvegardés par l'appel à Session.save()
   2.

      mise à jours des entités
   3.

      suppression des collections
   4.

      suppression, mise à jour et insertion des éléments des collections
   5.

      insertion des collections
   6.

      suppression des entités, dans le même ordre que celui des objets correspondants qui ont été supprimés par l'appel à Session.delete() 

(Une exception est que des objets utilisant la génération native d'identifiants sont insérés lorsqu'ils sont sauvegardés.)

Excepté lorsque vous appelez flush() explicitement, il n'y absolument aucune garantie à propos de quand la Session exécute les appels JDBC, seulement sur l'ordre dans lequel ils sont exécutés. Cependant, Hibernate garantit que Query.list(..) ne retournera jamais de données périmées, ni des données fausses.

Il est possible de changer le comportement par défaut, donc que le flush se produise moins fréquemment. La classe FlushMode définit trois modes différents : flush seulement lors du commit (et seulement quand l'API Transaction d'Hibernate est utilisée), flush automatiquement en utilisant la procédure expliquée, ou jamais de flush à moins que flush() soit appelée explicitement. Le dernier mode est utile pour l'exécution de longues unités de travail, où une Session est gardée ouverte et déconnectée pour un long moment (voir Section 11.3.2, « Les sessions longues et le versionnage automatique. »).

sess = sf.openSession();
Transaction tx = sess.beginTransaction();
sess.setFlushMode(FlushMode.COMMIT); // permet aux requêtes de retourner un état périmé

Cat izi = (Cat) sess.load(Cat.class, id);
izi.setName(iznizi);

// pourrait retourner des données périmées
sess.find("from Cat as cat left outer join cat.kittens kitten");

// le changement pour izi n'est pas flushé !
...
tx.commit(); // le flush se produit

Durant le flush, une exception peut se produire (par exemple, si une opération de la DML viole une contrainte). Puisque les exceptions de gestion impliquent une certaine compréhension du comportement transactionnel d'Hibernate, nous le traitons dans Chapitre 11, Transactions et accès concurrents.
10.11. Persistance transitive

Il est assez pénible de sauvegarder, supprimer, ou réattacher des objets un par un, surtout si vous traitez un graphe d'objets associés. Un cas habituel est une relation parent/enfant. Considérez l'exemple suivant :

Si les enfants de la relation parent/enfant étaient des types de valeur (par exemple, une collection d'adresses ou de chaînes de caractères), leur cycle de vie dépendraient du parent et aucune action ne serait requise pour "cascader" facilement les changements d'état. Si le parent est sauvegardé, les objets enfants de type de valeur sont sauvegardés également, si le parent est supprimé, les enfants sont supprimés, etc. Ceci fonctionne même pour des opérations telles que la suppression d'un enfant de la collection ; Hibernate détectera cela et, puisque les objets de type de valeur ne peuvent pas avoir des références partagées, supprimera l'enfant de la base de données.

Maintenant considérez le même scénario avec un parent et dont les objets enfants sont des entités, et non des types de valeur (par exemple, des catégories et des objets, ou un parent et des chatons). Les entités ont leur propre cycle de vie, supportent les références partagées (donc supprimer une entité de la collection ne signifie pas qu'elle peut être supprimée), et il n'y a par défaut pas de cascade d'état d'une entité vers n'importe quelle entité associée. Hibernate n'implémente pas la persistance par accessibilité par défaut.

Pour chaque opération basique de la session d'Hibernate - incluant persist(), merge(), saveOrUpdate(), delete(), lock(), refresh(), evict(), replicate() - il y a un style de cascade correspondant. Respectivement, les styles de cascade s'appellent persist, merge, save-update, delete, lock, refresh, evict, replicate. Si vous voulez qu'une opération soit cascadée le long d'une association, vous devez l'indiquer dans le document de mapping. Par exemple :

<one-to-one name="person" cascade="persist"/>

Les styles de cascade peuvent être combinés :

<one-to-one name="person" cascade="persist,delete,lock"/>

Vous pouvez même utiliser cascade="all" pour spécifier que toutes les opérations devraient être cascadées le long de l'association. La valeur par défaut cascade="none" spécifie qu'aucune opération ne sera cascadée.

Une style de cascade spécial, delete-orphan, s'applique seulement aux associations un-vers-plusieurs, et indique que l'opération delete() devrait être appliquée à n'importe quel enfant qui est supprimé de l'association.

Recommandations :

    *

      Cela n'a généralement aucun sens d'activer la cascade sur une association <many-to-one> ou <many-to-many>. Les cascades sont souvent utiles pour des associations <one-to-one> et <one-to-many>.
    *

      Si la durée de vie de l'objet enfant est liée à la durée de vie de l'objet parent, faites en un objet du cycle de vie en spécifiant cascade="all,delete-orphan".
    *

      Sinon, vous pourriez ne pas avoir besoin de cascade du tout. Mais si vous pensez que vous travaillerez souvent avec le parent et les enfants ensemble dans la même transaction, et que vous voulez vous éviter quelques frappes, considérez l'utilisation de cascade="persist,merge,save-update". 

Mapper une association (soit une simple association valuée, soit une collection) avec cascade="all" marque l'association comme une relation de style parent/enfant où la sauvegarde/mise à jour/suppression du parent entraîne la sauvegarde/mise à jour/suppression de l'enfant ou des enfants.

En outre, une simple référence à un enfant d'un parent persistant aura pour conséquence la sauvegarde/mise à jour de l'enfant. Cette métaphore est cependant incomplète. Un enfant qui devient non référencé par son parent n'est pas automatiquement supprimée, excepté dans le cas d'une association <one-to-many> mappée avec cascade="delete-orphan". La sémantique précise des opérations de cascade pour une relation parent/enfant est la suivante :

    *

      Si un parent est passé à persist(), tous les enfant sont passés à persist()
    *

      Si un parent est passé à merge(), tous les enfants sont passés à merge()
    *

      Si un parent est passé à save(), update() ou saveOrUpdate(), tous les enfants sont passés à saveOrUpdate()
    *

      Si un enfant détaché ou éphémère devient référencé par un parent persistant, il est passé à saveOrUpdate()
    *

      Si un parent est supprimé, tous les enfants sont passés à delete()
    *

      Si un enfant est déréférencé par un parent persistant, rien de spécial n'arrive - l'application devrait explicitement supprimer l'enfant si nécessaire - à moins que cascade="delete-orphan" soit paramétré, au quel cas l'enfant "orphelin" est supprimé. 

Enfin, la cascade des opérations peut être effectuée sur un graphe donné lors de l'appel de l'opération or lors du flush suivant. Toutes les opérations, lorsque cascadées, le sont sur toutes les entités associées atteignables lorsque l'opétation est exécutée. Cependant save-upate et delete-orphan sont cascadées à toutes les entités associées atteignables lors du flush de la Session.
10.12. Utilisation des méta-données

Hibernate requiert un modèle de méta-niveau très riche de toutes les entités et types valués. De temps en temps, ce modèle est très utile à l'application elle même. Par exemple, l'application pourrait utiliser les méta-données d'Hibernate pour implémenter un algorithme de copie en profondeur "intelligent" qui comprendrait quels objets devraient copiés (par exemple les types de valeur mutables) et lesquels ne devraient pas l'être (par exemple les types de valeurs immutables et, possiblement, les entités associées).

Hibernate expose les méta-données via les interfaces ClassMetadata et CollectionMetadata et la hiérarchie Type. Les instances des interfaces de méta-données peuvent être obtenues à partir de la SessionFactory.

Cat fritz = ......;
ClassMetadata catMeta = sessionfactory.getClassMetadata(Cat.class);

Object[] propertyValues = catMeta.getPropertyValues(fritz);
String[] propertyNames = catMeta.getPropertyNames();
Type[] propertyTypes = catMeta.getPropertyTypes();

// récupère une Map de toutes les propriétés qui ne sont pas des collections ou des associations
Map namedValues = new HashMap();
for ( int i=0; i<propertyNames.length; i++ ) {
    if ( !propertyTypes[i].isEntityType() && !propertyTypes[i].isCollectionType() ) {
        namedValues.put( propertyNames[i], propertyValues[i] );
    }
}

Chapitre 11. Transactions et accès concurrents

L'un des principaux avantages du mécanisme de contrôle des accès concurrents d'Hibernate est qu'il est très facile à comprendre. Hibernate utilise directement les connexions JDBC ainsi que les ressources JTA sans y ajouter davantage de mécanisme de blocage. Nous vous recommandons de vous familiariser avec les spécifications JDBC, ANSI et d'isolement de transaction de la base de données que vous utilisez.

Hibernate ne vérouille pas vos objets en mémoire. Votre application peut suivre le comportement défini par le niveau d'isolation de vos transactions de base de données. Notez que grâce à la Session, qui est aussi un cache de scope transaction, Hibernate fournit des lectures répétées pour les récupération par identifiants et les requêtes d'entités (pas celle de valeurs scalaires).

En addition au versionning pour le controle automatique de concurrence, Hibernate fournit une API (mineure) pour le verrouillage perssimiste des enregistrements, en générant une syntaxe SELECT FOR UPDATE. Le controle de concurrence optimiste et cette API seront détaillés plus tard dans ce chapitre.

Nous aborderons la gestion des accès concurrents en discutant de la granularité des objets Configuration, SessionFactory, et Session, ainsi que de certains concepts relatifs à la base de données et aux longues transactions applicatives.
11.1. Gestion de session et délimitation de transactions

Il est important de savoir qu'un objet SessionFactory est un objet complexe et optimisé pour fonctionner avec les threads(thread- safe). Il est coûteux à créer et est ainsi prévu pour n'être instancié qu?une seule fois via un objet Configuration au démarrage de l'application, et être partagé par tous les threads d'une application.

Un objet Session est relativement simple et n'est threadsafe. Il est également peu coûteux à créer. Il devrait n'être utilisé qu'une seule fois, pour un processus d'affaire ou une unité de travail ou une conversation et ensuite être relâché. Un objet Session ne tentera pas d'obtenir de connexion ( Connection ) JDBC (ou de Datasource ) si ce n'est pas nécessaire.

Afin de compléter ce tableau, vous devez également penser aux transactions de base de données. Une transaction de base de données se doit d'être la plus courte possible afin de réduire les risques de collision sur des enregistrements verrouillés. De longues transactions à la base de données nuiront à l'extensibilité de vos applications lorsque confrontées à de hauts niveaux de charge. Par conséquent, il n'est jamais bon de maintenir une transaction ouverte pendant la durée de reflexion de l'utilisateur, jusqu'a ce que l'unité de travail soit achevée.

Maintenant, comment délimiter une unité de travail? Est-ce qu'une instance de Session peut avoir une durée de vie dépassant plusieurs transactions à la base de données, ou bien est-ce que celles-ci doivent être liées une à une? Quand faut-il ouvrir et fermer une Session ? Comment définir la démarcation de vos transactions à la base de données?
11.1.1. Unité de travail

Il est important de mentionner que d'utiliser un paradigme session-par-operation est un anti-pattern. Autrement dit: n'ouvrez et ne fermez pas la Session à chacun de vos accès simples à la base de données dans un même thread! Bien sûr, le même raisonnement s'applique sur la gestion des transactions à la base de données. Les appels à la base de données devraient être faits en ordre et selon une séquence définie. Ils devraient également être regroupés en des unités de travail atomiques. (Notez que l?utilisation d?une connexion auto-commit constitue le même anti-pattern. Ce mode de fonctionnement existe pour les applications émettant des commandes SQL à partir d?une console. Hibernate désengage le mode auto-commit et s'attend à ce qu'un serveur d'applications le fasse également.) Les transactions avec la base de données ne sont jamais optionnelles, toute communication avec une base de données doit se dérouler dans une transaction, peu importe si vous lisez ou écrivez des données. Comme évoqué, le comportement auto-commit pour lire les données devrait être évité, puisque plusieurs petites transactions ne seront jamais aussi efficaces qu'une seule plus grosse clairement définie comme unité de travail. Ce dernier choix et en plus beaucoup plus facile a maintenir et à faire évoluer.

Le pattern d'utilisation le plus fréquemment rencontré dans des applications clients serveur multi-usagers est le session-per-request (littéralement : Session par requête). Dans ce modèle, la requête d'un client est envoyée à un serveur (Où la couche de persistance est implémentée via Hibernate), une nouvelle Session est ouverte et toutes les opérations d'accès à la base de données sont exécutées à l'intérieur de celle-ci. Lorsque le travail est terminé (et que les réponses à envoyer au client ont été préparées), la session est flushée et fermée. Une seule transaction à la base de données peut être utilisée pour répondre à la requête du client. La transaction est démarrée et validée au même moment où la Session est ouverte et fermée. La relation entre la Session et la Transaction est donc one-to-one. Ce modèle permet de répondre parfaitement aux attentes de la grande majorité des applications.

Le défi réside dans l'implémentation. Hibernate fournit une fonction de gestion de la "session courante" pour simplifier ce pattern. Tout ce que vous devez faire est démarrer une transaction lorsqu'une requête est traitée par le serveur, et la terminer avant que la réponse ne soit envoyée au client. Vous pouvez le faire de la manière que vous voulez, les solutions communes sont un ServletFilter, l'interception via AOP avec une pointcut sur les méthodes de type "service", ou un conteneur avec interception/proxy. Un conteneur EJB est un moyen standard d'implémenter ce genre d'acpect tranverse comme la démarcation des transactions sur les EJBs session, de manière déclarative avec CMT. Si vous décidez d'utiliser la démarcation programmatique des transactions, préferrez l'API Hibernate Transaction détaillée plus tard dans ce chapitre, afin de facilité l'utilisation et la portabilité du code.

Votre application peut accéder la "session courante" pour exécuter une requête en invoquant simplement sessionFactory.getCurrentSession() n'importe où et autant de fois que souhaité. Vous obtiendrez toujours une Session dont le scope est la transaction courante avec la base de données. Ceci doit être configuré soit dans les ressources local ou dans l'environnement JTA, voir Section 2.5, « Sessions Contextuelles ».

Il est parfois utile d'étendre le scope d'une Session et d'une transaction à la base de données jusqu'à ce que "la vue soit rendue". Ceci est particulièrement utile dans des applications à base de servlet qui utilisent une phase de rendue séparée une fois que la réponse a été préparée. Etendre la transaction avec la base de données jusqu'à la fin du rendering de la vue est aisé si vous implémentez votre propre intercepteur. Cependant, ce n'est pas facile si vous vous appuyez sur les EJBs avec CMT, puisqu'une transaction sera achevée au retour de la méthode EJB, avant le rendu de la vue. Rendez vous sur le site Hibernate et sur le forum pour des astuces et des exemples sur le pattern Open Session in View pattern..
11.1.2. Longue conversation

Le paradigme session-per-request n'est pas le seul élément à utiliser dans le design de vos unités de travail. Plusieurs processus d'affaire requièrent toute une série d'interactions avec l'utilisateur, entrelacées d'accès à la base de donnée. Dans une application Web ou une application d'entreprise, il serait inacceptable que la durée de vie d'une transaction s'étale sur plusieurs interactions avec l'usager. Considérez l'exemple suivant:

    *

      Un écran s'affiche. Les données vues par l'usager ont été chargées dans l'instance d'un objet Session , dans le cadre d'une transaction de base de données. L'usager est libre de modifier ces objets.
    *

      L'usager clique "Sauvegarder" après 5 minutes et souhaite persister les modifications qu'il a apportées. Il s'attend à être la seule personne a avoir modifié ces données et qu'aucune modification conflictuelle ne se soit produite durant ce laps de temps.

Ceci s'appelle une unité de travail. Du point de vue de l'utilisateur: une conversation (ou transaction d'application). Il y a plusieurs façon de mettre ceci en place dans votre application.

Une première implémentation naïve pourrait consister à garder la Session et la transaction à la base de données ouvertes durant le temps de travail de l'usager, à maintenir les enregistrements verrouillés dans la base de données afin d'éviter des modifications concurrentes et de maintenir l'isolation et l'atomicité de la transaction de l'usager. Ceci est un anti-pattern à éviter, puisque le verrouillage des enregistrements dans la base de données ne permettrait pas à l'application de gérer un grand nombre d'usagers concurrents.

Il apparaît donc évident qu'il faille utiliser plusieurs transactions BDD afin d'implémenter la conversation. Dans ce cas, maintenir l'isolation des processus d'affaire devient partiellement la responsabilité de la couche applicative. Ainsi, la durée de vie d'une conversation devrait englober celle d'une ou de plusieurs transactions de base de données. Celle-ci sera atomique seulement si l'écriture des données mises à jour est faite exclusivement par la dernière transaction BDD la composant. Toutes les autres sous transactions BD ne doivent faire que la lecture de données. Ceci est relativement facile à mettre en place, surtout avec l'utilisation de certaines fonctionnalités d'Hibernate:

    *

      Versionnage Automatique - Hibernate peut gérer automatiquement les accès concurrents de manière optimiste et détecter si une modification concurrente s'est produite durant le temps de réflexion d'un usager.
    *

      Objets Détachés - Si vous décidez d'utiliser le paradigme session-par-requête discuté plus haut, toutes les entités chargées en mémoire deviendront des objets détachés durant le temps de réflexion de l'usager. Hibernate vous permet de rattacher ces objets et de persister les modifications y ayant été apportées. Ce pattern est appelé: session-per- request-with-detached-objects (littéralement: session- par-requête-avec-objets-détachés). Le versionnage automatique est utilisé afin d'isoler les modifications concurrentes.
    *

      Session Longues (conversation) - Une Session Hibernate peut être déconnectée de la couche JDBC sous-jacente après que commit() ait été appelé sur une transaction à la base de données et reconnectée lors d'une nouvelle requête-client. Ce pattern s'appelle: session-per-conversation (Littéralement: session-par- conversation) et rend superflu le rattachement des objets. Le versionnage automatique est utilisé afin d'isoler les modifications concurrentes. 

Les deux patterns session-per-request-with- detached- objects (session-par-requête-avec-objets- détachés) et session-per-conversation (session-par-conversation) ont chacun leurs avantages et désavantages qui seront exposés dans ce même chapitre, dans la section au sujet du contrôle optimiste de concurrence.
11.1.3. L'identité des objets

Une application peut accéder à la même entité persistante de manière concurrente dans deux Session s différentes. Toutefois, une instance d'une classe persistante n'est jamais partagée par deux instances distinctes de la classe Session . Il existe donc deux notions de l'identité d'un objet:

Identité BD

    foo.getId().equals( bar.getId() ) 
Identité JVM

    foo==bar 

Ainsi, pour des objets attachés à une Session précise (dans la cadre d'exécution (scope) d'une instance de Session ), ces deux notions d'identité sont équivalentes et garanties par Hibernate. Par contre, si une application peut accéder de manière concurrente à la même entité persistante dans deux sessions différentes, les deux instances seront en fait différentes (en ce qui a trait à l'identité JVM). Les conflits sont résolus automatiquement par approche optimiste grâce au système de versionnage automatique lorsque Session.flush() ou Transaction.commit() est appelé.

Cette approche permet de reléguer à Hibernate et à la base de données sous-jacente le soin de gérer les problèmes d'accès concurrents. Cette manière de faire assure également une meilleure extensibilité de l'application puisque assurer l'identité JVM dans un thread ne nécessite pas de mécanismes de verrouillage coûteux ou d'autres dispositifs de synchronisation. Une application n'aura jamais le besoin de synchroniser des objets d'affaire tant qu'elle peut garantir qu'un seul thread aura accès à une instance de Session . Dans le cadre d'exécution d'un objet Session , l'application peut utiliser en toute sécurité == pour comparer des objets.

Une application qui utiliserait == à l'extérieur du cadre d'exécution d'une Session pourrait obtenir des résultats inattendus et causer certains effets de bords. Par exemple, si vous mettez 2 objets dans le même Set , ceux-ci pourraient avoir la même identité BD (i.e. ils représentent le même enregistrement), mais leur identité JVM pourrait être différente (elle ne peut, par définition, pas être garantie sur deux objets détachés). Le développeur doit donc redéfinir l'implémentation des méthodes equals() et hashcode() dans les classes persistantes et y adjoindre sa propre notion d'identité. Il existe toutefois une restriction: Il ne faut jamais utiliser uniquement l'identifiant de la base de données dans l'implémentation de l'égalité; Il faut utiliser une clé d'affaire, généralement une combinaison de plusieurs attributs uniques, si possible immuables. Les identifiants de base de données vont changer si un objet transitoire (transient) devient persistant. Si une instance transitoire est contenue dans un Set , changer le hashcode brisera le contrat du Set . Les attributs pour les clés d'affaire n'ont pas à être aussi stables que des clés primaires de bases de données. Il suffit simplement qu'elles soient stables tant et aussi longtemps que les objets sont dans le même Set . Veuillez consulter le site web Hibernate pour des discussions plus pointues à ce sujet. Notez que ce concept n'est pas propre à Hibernate mais bien général à l'implémentation de l'identité et de l'égalité en Java.
11.1.4. Problèmes communs

Bien qu'il puisse y avoir quelques rares exceptions à cette règle, il est recommandé de ne jamais utiliser les anti-patterns session-per- user-session et session-per-application . Vous trouverez ici- bas quelques problèmes que vous risquez de rencontrer si vous en faite l?utilisation. (Ces problèmes pourraient quand même survenir avec des patterns recommandés) Assurez-vous de bien comprendre les implications de chacun des patterns avant de prendre votre décision.

    *

      L'objet Session n?est pas conçu pour être utilisé par de multiples threads. En conséquence, les objets potentiellement multi-thread comme les requêtes HTTP, les EJB Session et Swing Worker, risquent de provoquer des conditions de course dans la Session si celle-ci est partagée. Dans un environnement web classique, il serait préférable de synchroniser les accès à la session http afin d?éviter qu?un usager ne recharge une page assez rapidement pour que deux requêtes s?exécutant dans des threads concurrents n?utilisent la même Session .
    *

      Lorsque Hibernate lance une exception, le roll back de la transaction en cours doit être effectué et la Session doit être immédiatement fermée. (Ceci sera exploré plus tard dans le chapitre.) Si la Session est directement associée à une application, il faut arrêter l?application. Le roll back de la transaction ne remettra pas les objets dans leur état du début de la transaction. Ainsi, ceux-ci pourraient être désynchronisés d?avec les enregistrements. (Généralement, cela ne cause pas de réels problèmes puisque la plupart des exceptions sont non traitables et requièrent la reprise du processus d?affaire ayant échoué.)
    *

      La Session met en mémoire cache tous les objets persistants (les objets surveillés et dont l'état est géré par Hibernate.) Si la Session est ouverte indéfiniment ou si une trop grande quantité d'objets y est chargée, l?utilisation de la mémoire peut potentiellement croître jusqu?à atteindre le maximum allouable à l?application (java.lang.OutOfMemoryError.) Une solution à ce problème est d?appeler les méthodes Session.clear() et Session.evict() pour gérer la mémoire cache de la Session . Vous pouvez également utiliser des stored procedures si vous devez lancer des traitements sur de grandes quantités d?informations. Certaines solutions sont décrites ici : Chapitre 13, Traitement par paquet . Garder une Session ouverte pour toute la durée d?une session usager augmente également considérablement le risque de travailler avec de l?information périmée. 

11.2. Démarcation des transactions

La démarcation des transactions est importante dans le design d?une application. Aucune communication avec la base de données ne peut être effectuée à l?extérieur du cadre d?une transaction. (Il semble que ce concept soit mal compris par plusieurs développeurs trop habitués à utiliser le mode auto-commit.) Même si certains niveaux d'isolation et certaines possibilités offertes par les bases de données permettent de l?éviter, il n'est jamais désavantageux de toujours explicitement indiquer les bornes de transaction pour les opérations complexes comme pour les opérations simples de lecture.

Une application utilisant Hibernate peut s'exécuter dans un environnement léger n?offrant pas la gestion automatique des transactions (application autonome, application web simple ou applications Swing) ou dans un environnement J2EE offrant des services de gestion automatique des transactions JTA. Dans un environnement simple, Hibernate a généralement la responsabilité de la gestion de son propre pool de connexions à la base de données. Le développeur de l'application doit manuellement délimiter les transactions. En d'autres mots, il appartient au développeur de gérer les appels à Transaction.begin() , Transaction.commit() et Transaction.rollback() . Un environnement transactionnel J2EE (serveur d'application J2EE) doit offrir la gestion des transactions au niveau du container J2EE. Les bornes de transaction peuvent normalement être définies de manière déclarative dans les descripteurs de déploiement d'EJB Session, par exemple. La gestion programmatique des transactions n'y est donc pas nécessaire. Même les appels à Session.flush() sont faits automatiquement.

Il peut être requis d'avoir une couche de persistance portable. Hibernate offre donc une API appelée Transaction qui sert d'enveloppe pour le système de transaction natif de l'environnement de déploiement. Il n'est pas obligatoire d'utiliser cette API mais il est fortement conseillé de le faire, sauf lors de l'utilisation de CMT Session Bean (EJB avec transactions gérées automatiquement par le container EJB).

Il existe quatre étapes disctinctes lors de la fermeture d'une Session

    *

      flush de la session
    *

      commit de la transaction
    *

      Fermeture de la session (Close)
    *

      Gestion des exceptions

La synchronisation de bdd depuis la session (flush) a déjà été expliqué, nous nous attarderons maintenant à la démarcation des transactions et à la gestion des exceptions dans les environnements légers et les environnements J2EE.
11.2.1. Environnement non managé

Si la couche de persistance Hibernate s'exécute dans un environnement non managé, les connexions à la base de données seront généralement prises en charge par le mécanisme de pool d'Hibernate. La gestion de la session et de la transaction se fera donc de la manière suivante:

// Non-managed environment idiom
Session sess = factory.openSession();
Transaction tx = null;
try {
    tx = sess.beginTransaction();

    // do some work
    ...

    tx.commit();
}
catch (RuntimeException e) {
    if (tx != null) tx.rollback();
    throw e; // or display error message
}
finally {
    sess.close();
}

Vous n'avez pas à invoquer flush() explicitement sur la Session - l'appel de commit() déclenchera automatiquement la synchronisation (selon le Section 10.10, « Flush de la session » de la session. Un appel à close() marque la fin de la session. La conséquence directe est que la connexion à la base de données sera relachée par la session. Ce code est portable est fonctionne dans les environnements non managé ET les environnements JTA.

Une solution plus flexible est la gestion par contexte fourni par Hibernate que nous avons déjà rencontré:

// Non-managed environment idiom with getCurrentSession()
try {
    factory.getCurrentSession().beginTransaction();

    // do some work
    ...

    factory.getCurrentSession().getTransaction().commit();
}
catch (RuntimeException e) {
    factory.getCurrentSession().getTransaction().rollback();
    throw e; // or display error message
}

Vous ne verrez probablement jamais ces exemples de code dans les applications; les exceptions fatales (exceptions du système) ne devraient être traitées que dans la couche la plus "haute". En d'autres termes, le code qui exécute les appels à Hibernate (à la couche de persistance) et le code qui gère les RuntimeException (qui ne peut généralement effectuer qu'un nettoyage et une sortie) sont dans des couches différentes. La gestion du contexte courant par Hibernate peut simplifier notablement ce design, puisque vous devez accéder à la gestion des exceptions de la SessionFactory, ce qui est décrit plus tard dans ce chapitre.

Notez que vous devriez sélectionner org.hibernate.transaction.JDBCTransactionFactory (le défaut), pour le second exemple "thread" comme hibernate.current_session_context_class.
11.2.2. Utilisation de JTA

Si votre couche de persistance s'exécute dans un serveur d'application (par exemple, derrière un EJB Session Bean), toutes les datasource utilisées par Hibernate feront automatiquement partie de transactions JTA globales. Hibernate propose deux stratégies pour réussir cette intégration.

Si vous utilisez des transactions gérées par un EJB (bean managed transactions - BMT), Hibernate informera le serveur d'application du début et de la fin des transactions si vous utilisez l'API Transaction . Ainsi, le code de gestion des transactions sera identique dans les deux types d'environnements.

// BMT idiom
Session sess = factory.openSession();
Transaction tx = null;
try {
    tx = sess.beginTransaction();

    // do some work
    ...

    tx.commit();
}
catch (RuntimeException e) {
    if (tx != null) tx.rollback();
    throw e; // or display error message
}
finally {
    sess.close();
}

Ou encore, avec la gestion automatique de contexte:

// BMT idiom with getCurrentSession()
try {
    factory.getCurrentSession().beginTransaction();

    // do some work
    ...

    factory.getCurrentSession().getTransaction().commit();
}
catch (RuntimeException e) {
    factory.getCurrentSession().getTransaction().rollback();
    throw e; // or display error message
}

Avec CMT, la démarcation des transactions est faite dans les descripteurs de déploiement des Beans Sessions et non de manière programmmatique, ceci réduit le code:

// CMT idiom
 Session sess = factory.getCurrentSession();

 // do some work
 ...

Dans un EJB CMT même le rollback intervient automatiquement, puisqu'une RuntimeException non traitée et soulevée par une méthode d'un bean session indique au conteneur d'annuler la transaction globale. Ceci veut donc dire que vous n'avez pas à utiliser l'API Transaction d'Hibernate dans CMT.

Notez que le fichier de configuration Hibernate devrait contenir les valeurs org.hibernate.transaction.JTATransactionFactory dans un environnement BMT ou org.hibernate.transaction.CMTTransactionFactory dans un environnement CMT là où vous configurez votre transaction factory Hibernate. N'oubliez pas non plus de spécifier le paramètre org.hibernate.transaction.manager_lookup_class . De plus, assurez vous de fixez votre hibernate.current_session_context_class soit à "jta" ou de ne pas le configurer (compatibilité avec les versions précédentes).

La méthode getCurrentSession() a un inconvénient dans les environnement JTA. Il y a une astuce qui est d'utiliser un mode de libération de connexion after_statement , qui est alors utilisé par défaut. Du à une étrange limitation de la spec JTA, il n'est pas possible pour Hibernate de nettoyer et ferme automatiquement un ScrollableResults ouvert ou une instance d'Iterator retournés scroll() ou iterate(). Vous devez libérer le curseur base de données sous jacent ou invoquer Hibernate.close(Iterator) explicitement depuis un bloc finally. (Bien sur, la plupart des applications peuvent éviter d'uiliser scroll() ou iterate() dans un code CMT.)
11.2.3. Gestion des exceptions

Si une Session lance une exception (incluant les exceptions du type SQLException ou d'un sous-type), vous devez immédiatement faire le rollback de la transaction, appeler Session.close() et relâcher les références sur l'objet Session . La Session contient des méthodes pouvant la mettre dans un état inutilisable. Vous devez considérer qu'aucune exception lancée par Hibernate n'est traitable. Assurez-vous de fermer la session en faisant l'appel à close() dans un bloc finally .

L'exception HibernateException , qui englobe la plupart des exceptions pouvant survenir dans la couche de persistance Hibernate, est une exception non vérifiée (Ceci n'était pas le cas dans certaines versions antérieures de Hibernate.) Il est de notre avis que nous ne devrions pas forcer un développeur à gérer une exception qu'il ne peut de toute façon pas traiter dans une couche technique. Dans la plupart des applications, les exceptions non vérifiées et les exceptions fatales sont gérées en amont du processus (dans les couches hautes) et un message d'erreur est alors affiché à l'usager (ou un traitement alternatif est invoqué.) Veuillez noter qu'Hibernate peut également lancer des exceptions non vérifiées d'un autre type que HibernateException . Celles-ci sont également non traitables et vous devez les traiter comme telles.

Hibernate englobe les SQLException s lancées lors des interactions directes avec la base de données dans des exceptions de type: JDBCException . En fait, Hibernate essaiera de convertir l'exception dans un sous-type plus significatif de JDBCException . L'exception SQLException sous-jacente est toujours disponible via la méthode JDBCException.getCause() . Cette conversion est faite par un objet de type SQLExceptionConverter , qui est rattaché à l'objet SessionFactory . Par défaut, le SQLExceptionConverter est associé au dialecte de BD configuré dans Hibernate. Toutefois, il est possible de fournir sa propre implémentation de l'interface. (Veuillez vous référer à la javadoc sur la classe SQLExceptionConverterFactory pour plus de détails. Les sous-types standard de JDBCException sont:

    *

      JDBCConnectionException - Indique une erreur de communication avec la couche JDBC sous-jacente.
    *

      SQLGrammarException - Indique un problème de grammaire ou de syntaxe avec la requête SQL envoyée.
    *

      ConstraintViolationException - Indique une violation de contrainte d'intégrité.
    *

      LockAcquisitionException - Indique une erreur de verrouillage lors de l'éxécution de la requête.
    *

      GenericJDBCException - Indique une erreur générique JDBC d'une autre catégorie. 

11.2.4. Timeout de transaction

L'un des avantages fournis par les environnements transactionnels JTA (tels les containers EJB) est la gestion du timeout de transaction. La gestion des dépassements de temps de transaction vise à s'assurer qu'une transaction agissant incorrectement ne viendra pas bloquer indéfiniment les ressources de l'application. Hibernate ne peut fournir cette fonctionnalité dans un environnement transactionnel non-JTA. Par contre, Hibernate gère les opérations d'accès aux données en allouant un temps maximal aux requêtes pour s'exécuter. Ainsi, une requête créant de l'inter blocage ou retournant de très grandes quantités d'information pourrait être interrompue. Dans un environnement transactionnel JTA, Hibernate peut déléguer au gestionnaire de transaction le soin de gérer les dépassements de temps. Cette fonctionnalité est abstraite par l'objet Transaction .

        Session sess = factory.openSession();
        try {
            //mettre le timeout à 3 secondes.
            sess.getTransaction().setTimeout(3);
            sess.getTransaction().begin();

            // Effectuer le travail ...

            sess.getTransaction().commit()
        }
        catch (RuntimeException e) {
            if ( sess.getTransaction().isActive() ) {
                sess.getTransaction().rollback();
            }
            throw e;
            // ou afficher le message d'erreur.
        }
        finally {
            sess.close();
        }

Notez que setTimeout() ne peut pas être appelé d'un EJB CMT, puisque le timeout des transaction doit être spécifié de manière déclarative.
11.3. Contrôle de consurrence optimiste

La gestion optimiste des accès concurrents avec versionnage est la seule approche pouvant garantir l'extensibilité des applications à haut niveau de charge. Le système de versionnage utilise des numéros de version ou l'horodatage pour détecter les mises à jour causant des conflits avec d'autres actualisations antérieures. Hibernate propose trois approches pour l'écriture de code applicatif utilisant la gestion optimiste d'accès concurrents. Le cas d'utilisation décrit plus bas fait mention de conversation, mais le versionnage peut également améliorer la qualité d'une application en prévenant la perte de mises à jour.
11.3.1. Gestion du versionnage au niveau applicatif

Dans cet exemple d'implémentation utilisant peu les fonctionnalités d'Hibernate, chaque interaction avec la base de données se fait en utilisant une nouvelle Session et le développeur doit recharger les données persistantes à partir de la BD avant de les manipuler. Cette implémentation force l'application à vérifier la version des objets afin de maintenir l'isolation transactionnelle. Cette approche, semblable à celle retrouvée pour les EJB, est la moins efficace de celles présentées dans ce chapitre.

            // foo est une instance chargée antérieurement par une autre
            Session session = factory.openSession();
            Transaction t = session.beginTransaction();

            int oldVersion = foo.getVersion();
            session.load( foo, foo.getKey() ); // Charger l'état courant

            if ( oldVersion!=foo.getVersion )
                throw new StaleObjectStateException();

            foo.setProperty("bar");
            t.commit();
            session.close();

Le mapping de la propriété version est fait via <version> et Hibernate l'incrémentera automatiquement à chaque flush() si l'entité doit être mise à jour.

Bien sûr, si votre application ne fait pas face à beaucoup d'accès concurrents et ne nécessite pas l'utilisation du versionnage, cette approche peut également être utilisée, il n'y a qu'à ignorer le code relié au versionnage. Dans ce cas, la stratégie du last commit wins (littéralement: le dernier commit l'emporte) sera utilisée pour les conversations (longues transactions applicatives). Gardez à l'esprit que cette approche pourrait rendre perplexe les utilisateurs de l'application car ils pourraient perdre des données mises à jour sans qu'aucun message d'erreur ne leur soit présenté et sans avoir la possibilité de fusionner les données.

Il est clair que la gestion manuelle de la vérification du versionnage des objets ne peut être effectuée que dans certains cas triviaux et que cette approche n'est pas valable pour la plupart des applications. De manière générale, les applications ne cherchent pas à actualiser de simples objets sans relations, elles le font généralement pour de larges graphes d'objets. Pour toute application utilisant le paradigme des conversations ou des objets détachés, Hibernate peut gérer automatiquement la vérification des versions d'objets.
11.3.2. Les sessions longues et le versionnage automatique.

Dans ce scénario, une seule instance de Session et des objets persistants est utilisée pour toute l'application. Hibernate vérifie la version des objets persistants avant d'effectuer le flush() et lance une exception si une modification concurrente est détectée. Il appartient alors au développeur de gérer l'exception. Les traitements alternatifs généralement proposés sont alors de permettre à l'usager de faire la fusion des données ou de lui offrir de recommencer son travail à partie des données les plus récentes dans la BD.

Il est à noter que lorsqu'une application est en attente d'une action de la part de l?usager, La Session n'est pas connectée à la couche JDBC sous-jacente. C'est la manière la plus efficace de gérer les accès à la base de données. L'application ne devrait pas se préoccuper du versionnage des objets, de la réassociation des objets détachés, ni du rechargement de tous les objets à chaque transaction.

            // foo est une instance chargée antérieurement par une autre session

            session.reconnect();// Obtention d'une nouvelle connexion JDBC
            Transaction t = session.beginTransaction();
            foo.setProperty("bar");
            t.commit(); //Terminer la transaction, propager les changements et vérifier les versions.
            session.disconnect(); // Retourner la connexion JDBC
            

L'objet foo sait quel objet Session l'a chargé. Session.reconnect() obtient une nouvelle connexion (celle-ci peut être également fournie) et permet à la session de continuer son travail. La méthode Session.disconnect() déconnecte la session de la connexion JDBC et retourne celle-ci au pool de connexion (à moins que vous ne lui ayez fourni vous même la connexion.) Après la reconnexion, afin de forcer la vérification du versionnage de certaines entités que vous ne cherchez pas à actualiser, vous pouvez faire un appel à Session.lock() en mode LockMode.READ pour tout objet ayant pu être modifié par une autre transaction. Il n'est pas nécessaire de verrouiller les données que vous désirez mettre à jour.

Si des appels implicites aux méthodes disconnect() et reconnect() sont trop coûteux, vous pouvez les éviter en utilisant hibernate.connection.release_mode .

Ce pattern peut présenter des problèmes si la Session est trop volumineuse pour être stockée entre les actions de l'usager. Plus spécifiquement, une session HttpSession se doit d'être la plus petite possible. Puisque la Session joue obligatoirement le rôle de mémoire cache de premier niveau et contient à ce titre tous les objets chargés, il est préférable de n'utiliser cette stratégie que pour quelques cycles de requêtes car les objets risquent d'y être rapidement périmés.

Notez que la Session déconnectée devrait être conservée près de la couche de persistance. Autrement dit, utilisez un EJB stateful pour conserver la Session et évitez de la sérialiser et de la transférer à la couche de présentation (i.e. Il est préférable de ne pas la conserver dans la session HttpSession .)
11.3.3. Les objets détachés et le versionnage automatique

Chaque interaction avec le système de persistance se fait via une nouvelle Session . Toutefois, les mêmes instances d'objets persistants sont réutilisées pour chacune de ces interactions. L'application doit pouvoir manipuler l'état des instances détachées ayant été chargées antérieurement via une autre session. Pour ce faire, ces objets persistants doivent être rattachés à la Session courante en utilisant Session.update() , Session.saveOrUpdate() , ou Session.merge() .

            // foo est une instance chargée antérieurement par une autre session

            foo.setProperty("bar");
            session = factory.openSession();
            Transaction t = session.beginTransaction();
            session.saveOrUpdate(foo);  //Utiliser merge() si "foo" pourrait avoir été chargé précédement
            t.commit();
            session.close(); 

Encore une fois, Hibernate vérifiera la version des instances devant être actualisées durant le flush(). Une exception sera lancée si des conflits sont détectés.

Vous pouvez également utiliser lock() au lieu de update() et utiliser le mode LockMode.READ (qui lancera une vérification de version, en ignorant tous les niveaux de mémoire cache) si vous êtes certain que l'objet n'a pas été modifié.
11.3.4. Personnaliser le versionnage automatique

Vous pouvez désactiver l'incrémentation automatique du numéro de version de certains attributs et collections en mettant la valeur du paramètre de mapping optimistic-lock à false. Hibernate cessera ainsi d'incrémenter leur numéro de version s'ils sont mis à jour.

Certaines entreprises possèdent de vieux systèmes dont les schémas de bases de données sont statiques et ne peuvent être modifiés. Il existe aussi des cas où plusieurs applications doivent accéder à la même base de données, mais certaines d'entre elles ne peuvent gérer les numéros de version ou les champs horodatés. Dans les deux cas, le versionnage ne peut être implanté par le rajout d'une colonne dans la base de données. Afin de forcer la vérification de version dans un système sans en faire le mapping, mais en forçant une comparaison des états de tous les attributs d'une entité, vous pouvez utiliser l'attribut optimistic- lock="all" sous l'élément <class> . Veuillez noter que cette manière de gérer le versionnage ne peut être utilisée que si l'application utilises de longues sessions, lui permettant de comparer l'ancien état et le nouvel état d'une entité. L'utilisation d'un pattern session-per-request-with-detached- objects devient alors impossible.

Il peut être souhaitable de permettre les modifications concurrentes lorsque des champs distincts sont modifiés. En mettant la propriété optimistic-lock="dirty" dans l'élément <class> , Hibernate ne fera la comparaison que des champs devant être actualisés lors du flush().

Dans les deux cas: en utilisant une colonne de version/horodatée ou via la comparaison de l'état complet de l'objet ou de ses champs modifiés, Hibernate ne créera qu'une seule commande d'UPDATE par entité avec la clause WHERE appropriée pour mettre à jour l'entité ET en vérifier la version. Si vous utilisez la persistance transitive pour propager l'évènement de rattachement à des entités associées, il est possible qu'Hibernate génère des commandes d'UPDATE inutiles. Ceci n'est généralement pas un problème, mais certains déclencheurs on update dans la base de données pourraient être activés même si aucun changement n'était réellement persisté sur des objets associés. Vous pouvez personnaliser ce comportement en indiquant select-before- update="true" dans l'élément de mapping <class> . Ceci forcera Hibernate à faire le SELECT de l'instance afin de s'assurer que l'entité doit réellement être actualisée avant de lancer la commande d'UPDATE.
11.4. Verouillage pessimiste

Il n'est nécessaire de s'attarder à la stratégie de verrouillage des entités dans une application utilisant Hibernate. Il est généralement suffisant de définir le niveau d'isolation pour les connexions JDBC et de laisser ensuite la base de donnée effectuer son travail. Toutefois, certains utilisateurs avancés peuvent vouloir obtenir un verrouillage pessimiste exclusif sur un enregistrement et le réobtenir au lancement d'une nouvelle transaction.

Hibernate utilisera toujours le mécanisme de verrouillage de la base de données et ne verrouillera jamais les objets en mémoire!

La classe LockMode définit les différents niveaux de verrouillage pouvant être obtenus par Hibernate. Le verrouillage est obtenu par les mécanismes suivants:

    *

      LockMode.WRITE est obtenu automatiquement quand Hibernate actualise ou insert un enregistrement.
    *

      LockMode.UPGRADE peut être obtenu de manière explicite via la requête en utilisant SELECT ... FOR UPDATE sur une base de données supportant cette syntaxe.
    *

      LockMode.UPGRADE_NOWAIT peut être obtenu de manière explicite en utilisant SELECT ... FOR UPDATE NOWAIT sur Oracle.
    *

      LockMode.READ est obtenu automatiquement quand Hibernate lit des données dans un contexte d'isolation Repeatable Read ou Serializable . Peut être réobtenu explicitement via une requête.
    *

      LockMode.NONE représente l'absence de verouillage. Tous les objets migrent vers ce mode a la fin d'une Transaction . Les objets associés à une session via un appel à saveOrUpdate() commencent également leur cycle de vie dans cet état. 

Les niveaux de verrouillage peuvent être explicitement obtenus de l'une des manières suivantes:

    *

      Un appel à Session.load() , en spécifiant un niveau verrouillage LockMode .
    *

      Un appel à Session.lock() .
    *

      Une appel à Query.setLockMode() . 

Si Session.load() est appelé avec le paramètre de niveau de verouillage UPGRADE ou UPGRADE_NOWAIT et que l'objet demandé n'est pas présent dans la session, celui-ci sera chargé à l'aide d'une requête SELECT ... FOR UPDATE . Si la méthode load() est appelée pour un objet déjà en session avec un verrouillage moindre que celui demandé, Hibernate appellera la méthode lock() pour cet objet.

Session.lock() effectue une vérification de version si le niveau de verrouillage est READ , UPGRADE ou UPGRADE_NOWAIT . (Dans le cas des niveaux UPGRADE ou UPGRADE_NOWAIT , une requête SELECT ... FOR UPDATE sera utilisée.)

Si une base de données ne supporte pas le niveau de verrouillage demandé, Hibernate utilisera un niveau alternatif convenable au lieux de lancer une exception. Ceci assurera la portabilité de votre application.
11.5. Mode de libération de Connection

Le comportement original (2.x) d'Hibernate pour la gestion des connexions JDBC était que la Session obtenait une connexion dès qu'elle en avait besoin et la libérait une fois la session fermée. Hibernate 3 a introduit les modes de libération de connexion pour indiquer à la session comment gérer les transactions JDBC. Notez que la discussion suivante n'est pertinente que pour des connexions fournies par un ConnectionProvider, celles gérées par l'utilisateur sont en dehors du scope de cette discussion. Les différents modes sont définies par org.hibernate.ConnectionReleaseMode:

    *

      ON_CLOSE - est essentiellement le comportement passé. La session Hibernate obtient une connexion lorsqu'elle en a besoin et la garde jusqu'à ce que la session se ferme.
    *

      AFTER_TRANSACTION - indique de relacher la connexion après qu'une org.hibernate.Transaction se soit achevée.
    *

      AFTER_STATEMENT (aussi appelé libération brutale) - indique de relacher les connexions après chaque exécution d'un statement. Ce relachement aggressif est annulé si ce statement laisse des ressources associées à une session donnée ouvertes, actuellement ceci n'arrive que lors de l'utilisation de org.hibernate.ScrollableResults. 

Le paramètre de configuration hibernate.connection.release_mode est utilisé pour spécifier quel mode de libération doit être utiliser. Les valeurs possibles sont:

    *

      auto (valeur par défaut) - ce choix délègue le choix de libération à la méthode org.hibernate.transaction.TransactionFactory.getDefaultReleaseMode() Pour la JTATransactionFactory, elle retourne ConnectionReleaseMode.AFTER_STATEMENT; pour JDBCTransactionFactory, elle retourne ConnectionReleaseMode.AFTER_TRANSACTION. C'est rarement une bonne idée de changer ce comportement par défaut puisque les erreurs soulevées par ce paramétrage tend à prouver une erreur dans le code de l'utilisateur.
    *

      on_close - indique d'utiliser ConnectionReleaseMode.ON_CLOSE. Ce paramétrage existe pour garantir la compatibilité avec les versions précédentes, mais ne devrait plus être utilisé.
    *

      after_transaction - indique d'utiliser ConnectionReleaseMode.AFTER_TRANSACTION. Ne devrait pas être utilisé dans les environnements JTA. Notez aussi qu'avec ConnectionReleaseMode.AFTER_TRANSACTION, si une session est considérée comme étant en mode auto-commit les connexions seront relachées comme si le mode était AFTER_STATEMENT.
    *

      after_statement - indique d'utiliser ConnectionReleaseMode.AFTER_STATEMENT. Additonnellement, le ConnectionProvider utilisé est consulté pour savoir s'il supporte ce paramétrage (supportsAggressiveRelease()). Si ce n'est pas le cas, le mode de libération est ré initialisé à ConnectionReleaseMode.AFTER_TRANSACTION. Ce paramétrage n'est sûr que dans les environnements où il est possible d'obtenir à nouveau la même connexion JDBC à chaque fois que l'on fait un appel de ConnectionProvider.getConnection() ou dans les envrionnements auto-commit où il n'est pas important d'obtenir plusieurs fois la même connexion. 

Chapitre 12. Les intercepteurs et les événements

Il est souvent utile pour l'application de réagir à certains événements qui surviennent dans Hibernate. Cela autorise l'implémentation de certaines sortes de fonctionnalités génériques, et d'extensions de fonctionnalités d'Hibernate.
12.1. Intercepteurs

L'interface Interceptor fournit des "callbacks" de la session vers l'application et permettent à l'application de consulter et/ou de manipuler des propriétés d'un objet persistant avant qu'il soit sauvegardé, mis à jour, supprimé ou chargé. Une utilisation possible de cette fonctionnalité est de tracer l'accès à l'information. Par exemple, l'Interceptor suivant positionne createTimestamp quand un Auditable est créé et met à jour la propriété lastUpdateTimestamp quand un Auditable est mis à jour.

Vous pouvez soit implémenter Interceptor directement ou (mieux) étendre EmptyInterceptor.

package org.hibernate.test;

import java.io.Serializable;
import java.util.Date;
import java.util.Iterator;

import org.hibernate.EmptyInterceptor;
import org.hibernate.Transaction;
import org.hibernate.type.Type;

public class AuditInterceptor extends EmptyInterceptor {

    private int updates;
    private int creates;
    private int loads;

    public void onDelete(Object entity,
                         Serializable id,
                         Object[] state,
                         String[] propertyNames,
                         Type[] types) {
        // ne fait rien
    }

    public boolean onFlushDirty(Object entity,
                                Serializable id,
                                Object[] currentState,
                                Object[] previousState,
                                String[] propertyNames,
                                Type[] types) {

        if ( entity instanceof Auditable ) {
            updates++;
            for ( int i=0; i < propertyNames.length; i++ ) {
                if ( "lastUpdateTimestamp".equals( propertyNames[i] ) ) {
                    currentState[i] = new Date();
                    return true;
                }
            }
        }
        return false;
    }

    public boolean onLoad(Object entity,
                          Serializable id,
                          Object[] state,
                          String[] propertyNames,
                          Type[] types) {
        if ( entity instanceof Auditable ) {
            loads++;
        }
        return false;
    }

    public boolean onSave(Object entity,
                          Serializable id,
                          Object[] state,
                          String[] propertyNames,
                          Type[] types) {

        if ( entity instanceof Auditable ) {
            creates++;
            for ( int i=0; i<propertyNames.length; i++ ) {
                if ( "createTimestamp".equals( propertyNames[i] ) ) {
                    state[i] = new Date();
                    return true;
                }
            }
        }
        return false;
    }

    public void postFlush(Iterator entities) {
        System.out.println("Creations: " + creates + ", Updates: " + updates);
    }

    public void afterTransactionCompletion(Transaction tx) {
        if ( tx.wasCommitted() ) {
            System.out.println("Creations: " + creates + ", Updates: " + updates, "Loads: " + loads);
        }
        updates=0;
        creates=0;
        loads=0;
    }

}

L'intercepteur doit être spécifié quand une session est créée.

Session session = sf.openSession( new AuditInterceptor() );

Vous pouvez aussi mettre un intercepteur au niveau global, en utilisant l'objet Configuration. Dans ce cas, l'intercepteur doit être "threadsafe".

new Configuration().setInterceptor( new AuditInterceptor() );

12.2. Système d'événements

Si vous devez réagir à des événements particuliers dans votre couche de persistance, vous pouvez aussi utiliser l'architecture d'événements d'Hibernate3. Le système d'événements peut être utilisé en supplément ou en remplacement des interceptors.

Essentiellement toutes les méthodes de l'interface Session sont corrélées à un événement. Vous avez un LoadEvent, un FlushEvent, etc (consultez la DTD du fichier de configuration XML ou le paquet org.hibernate.event pour avoir la liste complète des types d'événement définis). Quand une requête est faite à partir d'une de ces méthodes, la Session Hibernate génère un événement approprié et le passe au listener configuré pour ce type. Par défaut, ces listeners implémentent le même traitement dans lequel ces méthodes aboutissent toujours. Cependant, vous êtes libre d'implémenter une version personnalisée d'une de ces interfaces de listener (c'est-à-dire, le LoadEvent est traité par l'implémentation de l'interface LoadEventListener déclarée), dans quel cas leur implémentation devrait être responsable du traitement des requêtes load() faites par la Session.

Les listeners devraient effectivement être considérés comme des singletons ; dans le sens où ils sont partagés entre des requêtes, et donc ne devraient pas sauvegarder des états de variables d'instance.

Un listener personnalisé devrait implémenter l'interface appropriée pour l'événement qu'il veut traiter et/ou étendre une des classes de base (ou même l'événement prêt à l'emploi utilisé par Hibernate comme ceux déclarés non-finaux à cette intention). Les listeners personnalisés peuvent être soit inscrits par programmation à travers l'objet Configuration, ou spécifiés la configuration XML d'Hibernate (la configuration déclarative à travers le fichier de propriétés n'est pas supportée). Voici un exemple de listener personnalisé pour l'événement de chargement :

public class MyLoadListener implements LoadEventListener {
    // C'est une simple méthode définie par l'interface LoadEventListener
    public void onLoad(LoadEvent event, LoadEventListener.LoadType loadType)
            throws HibernateException {
        if ( !MySecurity.isAuthorized( event.getEntityClassName(), event.getEntityId() ) ) {
            throw MySecurityException("Unauthorized access");
        }
    }
}

Vous avez aussi besoin d'une entrée de configuration disant à Hibernate d'utiliser ce listener en plus du listener par défaut :

<hibernate-configuration>
    <session-factory>
        ...
        <event type="load">
            <listener class="com.eg.MyLoadListener"/>
            <listener class="org.hibernate.event.def.DefaultLoadEventListener"/>
        </event>
    </session-factory>
</hibernate-configuration>

Vous pouvez aussi l'inscrire par programmation :

Configuration cfg = new Configuration();
LoadEventListener[] stack = { new MyLoadListener(), new DefaultLoadEventListener() };
cfg.EventListeners().setLoadEventListeners(stack);

Les listeners inscrits déclarativement ne peuvent pas partager d'instances. Si le même nom de classe est utilisée dans plusieurs éléments <listener/>, chaque référence sera une instance distincte de cette classe. Si vous avez besoin de la faculté de partager des instances de listener entre plusieurs types de listener, vous devez utiliser l'approche d'inscription par programmation.

Pourquoi implémenter une interface et définir le type spécifique durant la configuration ? Une implémentation de listener pourrait implémenter plusieurs interfaces de listener d'événements. Avoir en plus le type défini durant l'inscription rend plus facile l'activation ou la désactivation pendant la configuration.
12.3. Sécurité déclarative d'Hibernate

Généralement, la sécurité déclarative dans les applications Hibernate est gérée dans la couche de session. Maintenant, Hibernate3 permet à certaines actions d'être approuvées via JACC, et autorisées via JAAS. Cette fonctionnalité optionnelle est construite au dessus de l'architecture d'événements.

D'abord, vous devez configurer les listeners d'événements appropriés pour permettre l'utilisation d'autorisations JAAS.

<listener type="pre-delete" class="org.hibernate.secure.JACCPreDeleteEventListener"/>
<listener type="pre-update" class="org.hibernate.secure.JACCPreUpdateEventListener"/>
<listener type="pre-insert" class="org.hibernate.secure.JACCPreInsertEventListener"/>
<listener type="pre-load" class="org.hibernate.secure.JACCPreLoadEventListener"/>

Notez que <listener type="..." class="..."/> est juste un raccourci pour <event type="..."><listener class="..."/></event> quand il y a exactement un listener pour un type d'événement particulier.

Ensuite, toujours dans hibernate.cfg.xml, lier les permissions aux rôles :

<grant role="admin" entity-name="User" actions="insert,update,read"/>
<grant role="su" entity-name="User" actions="*"/>

Les noms de rôle sont les rôles compris par votre fournisseur JAAC.
Chapitre 13. Traitement par paquet

Une approche naïve pour insérer 100 000 lignes dans la base de données en utilisant Hibernate pourrait ressembler à ça :

Session session = sessionFactory.openSession();
Transaction tx = session.beginTransaction();
for ( int i=0; i<100000; i++ ) {
    Customer customer = new Customer(.....);
    session.save(customer);
}
tx.commit();
session.close();

Ceci devrait s'écrouler avec une OutOfMemoryException quelque part aux alentours de la 50 000ème ligne. C'est parce qu'Hibernate cache toutes les instances de Customer nouvellement insérées dans le cache de second niveau.

Dans ce chapitre nous montrerons comment éviter ce problème. D'abord, cependant, si vous faites des traitements par batch, il est absolument critique que vous activiez l'utilisation ds paquet JDBC (NdT : JDBC batching), si vous avez l'intention d'obtenir des performances raisonnables. Configurez la taille du paquet JDBC avec un nombre raisonnable (disons, 10-50) :

hibernate.jdbc.batch_size 20

Vous pourriez aussi vouloir faire cette sorte de travail dans un traitement où l'interaction avec le cache de second niveau est complètement désactivé :

hibernate.cache.use_second_level_cache false

13.1. Insertions en paquet

Lorsque vous rendez des nouveaux objets persistants, vous devez régulièrement appeler flush() et puis clear() sur la session, pour contrôler la taille du cache de premier niveau.

Session session = sessionFactory.openSession();
Transaction tx = session.beginTransaction();

for ( int i=0; i<100000; i++ ) {
    Customer customer = new Customer(.....);
    session.save(customer);
    if ( i % 20 == 0 ) { //20, même taille que la taille du paquet JDBC
        //flush un paquet d'insertions et libère la mémoire :
        session.flush();
        session.clear();
    }
}

tx.commit();
session.close();

13.2. Paquet de mises à jour

Pour récupérer et mettre à jour des données les mêmes idées s'appliquent. En plus, vous avez besoin d'utiliser scroll() pour tirer partie des curseurs côté serveur pour les requêtes qui retournent beaucoup de lignes de données.

Session session = sessionFactory.openSession();
Transaction tx = session.beginTransaction();

ScrollableResults customers = session.getNamedQuery("GetCustomers")
    .setCacheMode(CacheMode.IGNORE)
    .scroll(ScrollMode.FORWARD_ONLY);
int count=0;
while ( customers.next() ) {
    Customer customer = (Customer) customers.get(0);
    customer.updateStuff(...);
    if ( ++count % 20 == 0 ) {
        //flush un paquet de mises à jour et libère la mémoire :
        session.flush();
        session.clear();
    }
}

tx.commit();
session.close();

13.3. L'interface StatelessSession

Alternativement, Hibernate fournit une API orientée commande qui peut être utilisée avec des flux de données pour et en provenance de la base de données sous la forme d'objets détachés. Une StatelessSession n'a pas de contexte de persistance associé et ne fournit pas beaucoup de sémantique de durée de vie de haut niveau. En particulier, une session sans état n'implémente pas de cache de premier niveau et n'interagit pas non plus avec un cache de seconde niveau ou un cache de requêtes. Elle n'implémente pas les transactions ou la vérification sale automatique (NdT : automatic dirty checking). Les opérations réalisées avec une session sans état ne sont jamais répercutées en cascade sur les instances associées. Les collections sont ignorées par une session sans état. Les opérations exécutées via une session sans état outrepasse le modèle d'événements d'Hibernate et les intercepteurs. Les sessions sans état sont vulnérables aux effets de modification des données, ceci est dû au manque de cache de premier niveau. Une session sans état est une abstraction bas niveau, plus proche de la couche JDBC sous-jacente.

StatelessSession session = sessionFactory.openStatelessSession();
Transaction tx = session.beginTransaction();

ScrollableResults customers = session.getNamedQuery("GetCustomers")
    .scroll(ScrollMode.FORWARD_ONLY);
while ( customers.next() ) {
    Customer customer = (Customer) customers.get(0);
    customer.updateStuff(...);
    session.update(customer);
}

tx.commit();
session.close();

Notez que dans le code de l'exemple, les intances de Customer retournées par la requête sont immédiatement détachées. Elles ne sont jamais associées à un contexte de persistance.

Les opérations insert(), update() et delete() définies par l'interface StatelessSession sont considérées comme des opérations d'accès direct aux lignes de la base de données, ce qui résulte en une exécution immédiate du SQL INSERT, UPDATE ou DELETE respectif. De là, elles ont des sémantiques tres différentes des opérations save(), saveOrUpdate() et delete() définies par l'interface Session.
13.4. Opérations de style DML

Comme déjà discuté avant, le mapping objet/relationnel automatique et transparent est intéressé par la gestion de l'état de l'objet. Ceci implique que l'état de l'objet est disponible en mémoire, d'où manipuler (en utilisant des expressions du langage de manipulation de données - Data Manipulation Language (DML) - SQL) les données directement dans la base n'affectera pas l'état en mémoire. Pourtant, Hibernate fournit des méthodes pour l'exécution d'expression DML de style SQL lesquelles sont réalisées à travers le langage de requête d'Hibernate (Chapitre 14, HQL: Langage de requêtage d'Hibernate).

La pseudo-syntaxe pour les expressions UPDATE et DELETE est : ( UPDATE | DELETE ) FROM? EntityName (WHERE where_conditions)?. Certains points sont à noter :

    *

      Dans la clause from, le mot-clef FROM est optionnel
    *

      Il ne peut y avoir qu'une seule entité nommée dans la clause from ; elle peut optionnellement avoir un alias. Si le nom de l'entité a un alias, alors n'importe quelle référence de propriété doit être qualifiée en ayant un alias ; si le nom de l'entité n'a pas d'alias, alors il est illégal pour n'importe quelle référence de propriété d'être qualifiée.
    *

      Aucune jointure (implicite ou explicite) ne peut être spécifiée dans une requête HQL. Les sous-requêtes peuvent être utilisées dans la clause where ; les sous-requêtes, elles-mêmes, peuvent contenir des jointures.
    *

      La clause where est aussi optionnelle. 

Par exemple, pour exécuter un UPDATE HQL, utilisez la méthode Query.executeUpdate() (la méthode est données pour ceux qui sont familiers avec PreparedStatement.executeUpdate() de JDBC) :

Session session = sessionFactory.openSession();
Transaction tx = session.beginTransaction();

String hqlUpdate = "update Customer c set c.name = :newName where c.name = :oldName";
// ou String hqlUpdate = "update Customer set name = :newName where name = :oldName";
int updatedEntities = s.createQuery( hqlUpdate )
        .setString( "newName", newName )
        .setString( "oldName", oldName )
        .executeUpdate();
tx.commit();
session.close();

Pour exécuter un DELETE HQL, utilisez la même méthode Query.executeUpdate() :

Session session = sessionFactory.openSession();
Transaction tx = session.beginTransaction();

String hqlDelete = "delete Customer c where c.name = :oldName";
// or String hqlDelete = "delete Customer where name = :oldName";
int deletedEntities = s.createQuery( hqlDelete )
        .setString( "oldName", oldName )
        .executeUpdate();
tx.commit();
session.close();

La valeur du int retourné par la méthode Query.executeUpdate() indique le nombre d'entités affectées par l'opération. Considérez que cela peut ou pas corréler le nombre de lignes affectés dans la base de données. Une opération HQL pourrait entraîner l'exécution de multiples expressions SQL réelles, pour des classes filles mappées par jointure (NdT: join-subclass), par exemple. Le nombre retourné indique le nombre d'entités réelles affectées par l'expression. Retour à l'exemple de la classe fille mappée par jointure, un effacement d'une des classes filles peut réellement entraîner des suppressions pas seulement dans la table qui mappe la classe fille, mais aussi dans la table "racine" et potentillement dans les tables des classes filles plus bas dans la hiérarchie d'héritage.

La pseudo-syntaxe pour l'expression INSERT est : INSERT INTO EntityName properties_list select_statement. Quelques points sont à noter :

    *

      Seule la forme INSERT INTO ... SELECT ... est supportée ; pas la forme INSERT INTO ... VALUES ... .

      La properties_list est analogue à la spécification de la colonne The properties_list is analogous to the column speficiation dans l'expression SQL INSERT. Pour les entités impliquées dans un héritage mappé, seules les propriétés directement définies à ce niveau de classe donné peuvent être utilisées dans properties_list. Les propriétés de la classe mère ne sont pas permises ; et les propriétés des classes filles n'ont pas de sens. En d'autres mots, les expressions INSERT par nature non polymorphiques.
    *

      select_statement peut être n'importe quelle requête de sélection HQl valide, avec l'avertissement que les types de retour doivent correspondre aux types attendus par l'insertion. Actuellement, c'est vérifié durant la compilation de la requête plutôt que la vérification soit reléguée à la base de données. Notez cependant que cela pourrait poser des problèmes entre les Types d'Hibernate qui sont équivalents opposé à égaux. Cela pourrait poser des problèmes avec des disparités entre une propriété définie comme un org.hibernate.type.DateType et une propriété définie comme un org.hibernate.type.TimestampType, même si la base de données ne ferait pas de distinction ou ne serait pas capable de gérer la conversion.
    *

      Pour la propriéte id, l'expression d'insertion vous donne deux options. Vous pouvez soit spécifier explicitement la propriété id dans properties_list (auquel cas sa valeur est extraite de l'expression de sélection correspondante), soit l'omettre de properties_list (auquel cas une valeur générée est utilisée). Cette dernière option est seulement disponible en utilisant le générateur d'identifiant qui opère dans la base de données ; tenter d'utiliser cette option avec n'importe quel type de générateur "en mémoire" causera une exception durant l'analyse. Notez que pour les buts de cette discussion, les générateurs "en base" sont considérés être org.hibernate.id.SequenceGenerator (et ses classes filles) et n'importe quelles implémentations de org.hibernate.id.PostInsertIdentifierGenerator. L'exception la plus notable ici est org.hibernate.id.TableHiLoGenerator, qu ne peut pas être utilisée parce qu'il ne propose pas un moyen de d'exposer ses valeurs par un select.
    *

      Pour des propriétés mappées comme version ou timestamp, l'expression d'insertion vous donne deux options. Vous pouvez soit spécifier la propriété dans properties_list (auquel cas sa valeur est extraite des expressions select correspondantes), soit l'omettre de properties_list (auquel cas la valeur de graine (NdT : seed value) définie par le org.hibernate.type.VersionType est utilisée). 

Un exemple d'exécution d'une expression INSERT HQL :

Session session = sessionFactory.openSession();
Transaction tx = session.beginTransaction();

String hqlInsert = "insert into DelinquentAccount (id, name) select c.id, c.name from Customer c where ...";
int createdEntities = s.createQuery( hqlInsert )
        .executeUpdate();
tx.commit();
session.close();

Chapitre 14. HQL: Langage de requêtage d'Hibernate

Hibernate fourni un langage d'interrogation extrêmement puissant qui ressemble (et c'est voulu) au SQL. Mais ne soyez pas distraits par la syntaxe ; HQL est totalement orienté objet, comprenant des notions d'héritage, de polymorphisme et d'association.
14.1. Sensibilité à la casse

Les requêtes sont insensibles à la casse, à l'exception des noms des classes Java et des propriétés. Ainsi, SeLeCT est identique à sELEct et à SELECT mais net.sf.hibernate.eg.FOO n'est pas identique net.sf.hibernate.eg.Foo et foo.barSet n'est pas identique à foo.BARSET.

Ce guide utilise les mots clés HQL en minuscule. Certains utilisateurs trouvent les requêtes écrites avec les mots clés en majuscule plus lisibles, mais nous trouvons cette convention pénible lorsqu'elle est lue dans du code Java.
14.2. La clause from

La requête Hibernate la plus simple est de la forme :

from eg.Cat

qui retourne simplement toutes les instances de la classe eg.Cat. Nous n'avons pas besoin d'habitude de qualifier le nom de la classe, puisque auto-import est la valeur par défaut. Donc nous écrivons presque toujours :

from Cat

La plupart du temps, vous devrez assigner un alias puisque vous voudrez faire référence à Cat dans d'autres parties de la requête.

from Cat as cat

Cette requête assigne l'alias cat à l'instance Cat, nous pouvons donc utiliser cet alias ailleurs dans la requête. Le mot clé as est optionnel ; nous aurions pu écrire :

from Cat cat

Plusieurs classes peuvent apparaître, ce qui conduira à un produit cartésien (encore appelé jointures croisées).

from Formula, Parameter

from Formula as form, Parameter as param

C'est une bonne pratique que de nommer les alias dans les requêtes en utilisant l'initiale en miniscule, ce qui a le mérite d'être en phase avec les standards de nommage Java pour les variables locales (domesticCat).
14.3. Associations et jointures

On peut aussi assigner des alias à des entités associées, ou même aux éléments d'une collection de valeurs, en utilisant un join (jointure).

from Cat as cat
    inner join cat.mate as mate
    left outer join cat.kittens as kitten

from Cat as cat left join cat.mate.kittens as kittens

from Formula form full join form.parameter param

Les types de jointures supportées sont celles de ANSI SQL

    *

      inner join (jointure fermée)
    *

      left outer join (jointure ouverte par la gauche)
    *

      right outer join (jointure ouverte par la droite)
    *

      full join (jointure ouverte totalement - généralement inutile) 

Les constructions des jointures inner join, left outer join et right outer join peuvent être abbrégées.

from Cat as cat
    join cat.mate as mate
    left join cat.kittens as kitten

Nous pouvons soumettre des conditions de jointure supplémentaires en utilisant le mot-clef HQL with.

from Cat as cat
    left join cat.kittens as kitten
        with kitten.bodyWeight > 10.0

Par ailleurs, une jointure "fetchée" (rapportée) permet d'initialiser les associations ou collections de valeurs en même temps que leur objet parent, le tout n'utilisant qu'un seul Select. Ceci est particulièrement utile dans le cas des collections. Ce système permet de surcharger les déclarations "lazy" et "outer-join" des fichiers de mapping pour les associations et collections. Voir Section 19.1, « Stratégies de chargement » pour plus d'informations.

from Cat as cat
    inner join fetch cat.mate
    left join fetch cat.kittens

Une jointure "fetchée" (rapportée) n'a généralement pas besoin de se voir assigner un alias puisque les objets associés n'ont pas à être utilisés dans les autres clauses. Notez aussi que les objets associés ne sont pas retournés directement dans le résultat de la requête mais l'on peut y accéder via l'objet parent. La seule raison pour laquelle nous pourrions avoir besoin d'un alias est si nous récupérions récursivement une collection supplémentaire :

from Cat as cat
    inner join fetch cat.mate
    left join fetch cat.kittens child
    left join fetch child.kittens

Notez que la construction de fetch ne peut pas être utilisée dans les requêtes appelées par scroll() ou iterate(). fetch ne devrait pas non plus être utilisé avec setMaxResults() ou setFirstResult(). fetch ne peut pas non plus être utilisé avec une condition with ad hoc. Il est possible de créer un produit cartésien par jointure en récupérant plus d'une collection dans une requête, donc faites attention dans ce cas. Récupérer par jointure de multiples collections donne aussi parfois des résultats inattendus pour des mappings de bag, donc soyez prudent lorsque vous formulez vos requêtes dans de tels cas. Finalement, notez que full join fetch et right join fetch ne sont pas utiles en général.

Si vous utilisez un chargement retardé pour les propriétés (avec une instrumentation par bytecode), il est possible de forcer Hibernate à récupérer les propriétés non encore chargées immédiatement (dans la première requête) en utilisant fetch all properties.

from Document fetch all properties order by name

from Document doc fetch all properties where lower(doc.name) like '%cats%'

14.4. Formes de syntaxes pour les jointures

HQL supporte deux formes pour joindre les associations: implicite et explicite.

Les requêtes présentes dans la section précédente utilisent la forme explicite où le mode clé join est explicitement utilisé dans la clause from. C'est la forme recommandée.

La forme implicite n'utilise pas le mot clé join. A la place, les associations sont "déréférencées" en utilisant le notation '.'. Ces jointures peuvent apparaitre dans toutes les clauses. Les jointures implicites résultent en des inner join dans le SQL généré.

from Cat as cat where cat.mate.name like '%s%'

14.5. La clause select

La clause select sélectionne les objets et propriétés qui doivent être retournés dans le résultat de la requête. Soit :

select mate
from Cat as cat
    inner join cat.mate as mate

La requête recherchera les mates liés aux Cats. Vous pouvez explimer la requête d'une manière plus compacte :

select cat.mate from Cat cat

Les requêtes peuvent retourner des propriétés de n'importe quel type, même celles de type composant (component) :

select cat.name from DomesticCat cat
where cat.name like 'fri%'

select cust.name.firstName from Customer as cust

Les requêtes peuvent retourner plusieurs objets et/ou propriétés sous la forme d'un tableau du type Object[],

select mother, offspr, mate.name
from DomesticCat as mother
    inner join mother.mate as mate
    left outer join mother.kittens as offspr

ou sous la forme d'une List,

select new list(mother, offspr, mate.name)
from DomesticCat as mother
    inner join mother.mate as mate
    left outer join mother.kittens as offspr

ou sous la forme d'un objet Java typé,

select new Family(mother, mate, offspr)
from DomesticCat as mother
    join mother.mate as mate
    left join mother.kittens as offspr

à condition que la classe Family possède le constructeur approprié.

Vous pouvez assigner des alias aux expressions sélectionnées en utilisant as :

select max(bodyWeight) as max, min(bodyWeight) as min, count(*) as n
from Cat cat

C'est surtout utile lorsque c'est utilisé avec select new map :

select new map( max(bodyWeight) as max, min(bodyWeight) as min, count(*) as n )
from Cat cat

Cette requête retourne une Map à partir des alias vers les valeurs sélectionnées.
14.6. Fonctions d'aggrégation

Les requêtes HQL peuvent aussi retourner le résultat de fonctions d'aggrégation sur les propriétés :

select avg(cat.weight), sum(cat.weight), max(cat.weight), count(cat)
from Cat cat

Les fonctions supportées sont

    *

      avg(...), sum(...), min(...), max(...)
    *

      count(*)
    *

      count(...), count(distinct ...), count(all...) 

Vous pouvez utiliser des opérateurs arithmétiques, la concaténation, et des fonctions SQL reconnues dans la clause select :

select cat.weight + sum(kitten.weight)
from Cat cat
    join cat.kittens kitten
group by cat.id, cat.weight

select firstName||' '||initial||' '||upper(lastName) from Person

Les mots clé distinct et all peuvent être utilisés et ont la même signification qu'en SQL.

select distinct cat.name from Cat cat

select count(distinct cat.name), count(cat) from Cat cat

14.7. Requêtes polymorphiques

Une requête comme:

from Cat as cat

retourne non seuleument les instances de Cat, mais aussi celles des sous classes comme DomesticCat. Les requêtes Hibernate peuvent nommer n'importe quelle classe ou interface Java dans la clause from. La requête retournera les instances de toutes les classes persistantes qui étendent cette classe ou implémente cette interface. La requête suivante retournera tous les objets persistants :

from java.lang.Object o

L'interface Named peut être implémentée par plusieurs classes persistantes :

from Named n, Named m where n.name = m.name

Notez que ces deux dernières requêtes nécessitent plus d'un SELECT SQL. Ce qui signifie que la clause order by ne trie pas correctement la totalité des résultats (cela signifie aussi que vous ne pouvez exécuter ces requêtes en appelant Query.scroll()).
14.8. La clause where

La clause where vous permet de réduire la liste des instances retournées. Si aucun alias n'existe, vous pouvez vous référer aux propriétés par leur nom :

from Cat where name='Fritz'

S'il y a un alias, utilisez un nom de propriété qualifié :

from Cat as cat where cat.name='Fritz'

retourne les instances de Cat dont name est égale à 'Fritz'.

select foo
from Foo foo, Bar bar
where foo.startDate = bar.date

retournera les instances de Foo pour lesquelles il existe une instance de bar avec la propriété date est égale à la propriété startDate de Foo. Les expressions utilisant la navigation rendent la clause where extrêmement puissante. Soit :

from Cat cat where cat.mate.name is not null

Cette requête se traduit en SQL par une jointure interne à une table. Si vous souhaitez écrire quelque chose comme :

from Foo foo
where foo.bar.baz.customer.address.city is not null

vous finiriez avec une requête qui nécessiterait quatre jointures en SQL.

L'opérateur = peut être utilisé pour comparer aussi bien des propriétés que des instances :

from Cat cat, Cat rival where cat.mate = rival.mate

select cat, mate
from Cat cat, Cat mate
where cat.mate = mate

La propriété spéciale (en minuscule) id peut être utilisée pour faire référence à l'identifiant d'un objet (vous pouvez aussi utiliser le nom de cette propriété).

from Cat as cat where cat.id = 123

from Cat as cat where cat.mate.id = 69

La seconde requête est particulièrement efficace. Aucune jointure n'est nécessaire !

Les propriétés d'un identifiant composé peuvent aussi être utilisées. Supposez que Person ait un identifiant composé de country et medicareNumber.

from bank.Person person
where person.id.country = 'AU'
    and person.id.medicareNumber = 123456

from bank.Account account
where account.owner.id.country = 'AU'
    and account.owner.id.medicareNumber = 123456

Une fois de plus, la seconde requête ne nécessite pas de jointure.

De même, la propriété spéciale class interroge la valeur discriminante d'une instance dans le cas d'une persistance polymorphique. Le nom d'une classe Java incorporée dans la clause where sera traduite par sa valeur discriminante.

from Cat cat where cat.class = DomesticCat

Vous pouvez aussi spécifier les propriétés des composants ou types utilisateurs composés (components, composite user types etc). N'essayez jamais d'utiliser un expression de navigation qui se terminerait par une propriété de type composant (qui est différent d'une propriété d'un composant). Par exemple, si store.owner est une entité avec un composant address

store.owner.address.city    // okay
store.owner.address         // error!

Un type "any" possède les propriétés spéciales id et class, qui nous permettent d'exprimer une jointure de la manière suivante (où AuditLog.item est une propriété mappée avec <any>).

from AuditLog log, Payment payment
where log.item.class = 'Payment' and log.item.id = payment.id

Dans la requête précédente, notez que log.item.class et payment.class feraient référence à des valeurs de colonnes de la base de données complètement différentes.
14.9. Expressions

Les expressions permises dans la clause where incluent la plupart des choses que vous pouvez utiliser en SQL :

    *

      opérateurs mathématiques +, -, *, /
    *

      opérateur de comparaison binaire =, >=, <=, <>, !=, like
    *

      opérateurs logiques and, or, not
    *

      Parenthèses ( ), indiquant un regroupement
    *

      in, not in, between, is null, is not null, is empty, is not empty, member of and not member of
    *

      "Simple" case, case ... when ... then ... else ... end, and "searched" case, case when ... then ... else ... end
    *

      concatenation de chaîne de caractères ...||... ou concat(...,...)
    *

      current_date(), current_time(), current_timestamp()
    *

      second(...), minute(...), hour(...), day(...), month(...), year(...),
    *

      N'importe quel fonction ou opérateur défini par EJB-QL 3.0 : substring(), trim(), lower(), upper(), length(), locate(), abs(), sqrt(), bit_length(), mod()
    *

      coalesce() et nullif()
    *

      str() pour convertir des valeurs numériques ou temporelles vers une chaîne de caractères lisible
    *

      cast(... as ...), où le second argument est le nom d'un type Hibernate, et extract(... from ...) si le cast() ANSI et extract() sont supportés par la base de données sous-jacente
    *

      La fonction HQL index(), qui s'applique aux alias d'une collection indexée jointe
    *

      Les fonctions HQL qui s'appliquent expressions représentant des collections : size(), minelement(), maxelement(), minindex(), maxindex(), ainsi que les fonctions spéciales elements() et indices qui peuvent être quantifiées en utilisant some, all, exists, any, in.
    *

      N'importe quelle fonction scalaire supportée par la base de données comme sign(), trunc(), rtrim(), sin()
    *

      Les paramètres positionnels de JDBC ?
    *

      paramètres nommés :name, :start_date, :x1
    *

      littéral SQL 'foo', 69, '1970-01-01 10:00:01.0'
    *

      Constantes Java public static final eg.Color.TABBY 

in et between peuvent être utilisés comme suit :

from DomesticCat cat where cat.name between 'A' and 'B'

from DomesticCat cat where cat.name in ( 'Foo', 'Bar', 'Baz' )

et la forme négative peut être écrite

from DomesticCat cat where cat.name not between 'A' and 'B'

from DomesticCat cat where cat.name not in ( 'Foo', 'Bar', 'Baz' )

De même, is null et is not null peuvent être utilisés pour tester les valeurs nulle.

Les booléens peuvent être facilement utilisés en déclarant les substitutions de requêtes dans la configuration Hibernate :

<property name="hibernate.query.substitutions">true 1, false 0</property>

Ce qui remplacera les mots clés true et false par 1 et 0 dans la traduction SQL du HQL suivant :

from Cat cat where cat.alive = true

Vous pouvez tester la taille d'une collection par la propriété spéciale size, ou la fonction spéciale size().

from Cat cat where cat.kittens.size > 0

from Cat cat where size(cat.kittens) > 0

Pour les collections indexées, vous pouvez faire référence aux indices minimum et maximum en utilisant les fonctions minindex and maxindex. De manière similaire, vous pouvez faire référence aux éléments minimum et maximum d'une collection de type basiques en utilisant les fonctions minelement et maxelement.

from Calendar cal where maxelement(cal.holidays) > current date

from Order order where maxindex(order.items) > 100

from Order order where minelement(order.items) > 10000

Les fonctions SQL any, some, all, exists, in supportent que leur soient passées l'élément, l'index d'une collection (fonctions elements et indices) ou le résultat d'une sous requête (voir ci dessous).

select mother from Cat as mother, Cat as kit
where kit in elements(foo.kittens)

select p from NameList list, Person p
where p.name = some elements(list.names)

from Cat cat where exists elements(cat.kittens)

from Player p where 3 > all elements(p.scores)

from Show show where 'fizard' in indices(show.acts)

Notez que l'écriture de - size, elements, indices, minindex, maxindex, minelement, maxelement - peuvent seulement être utilisée dans la clause where dans Hibernate3.

Les éléments de collections indexées (arrays, lists, maps) peuvent être référencés via index (dans une clause where seulement) :

from Order order where order.items[0].id = 1234

select person from Person person, Calendar calendar
where calendar.holidays['national day'] = person.birthDay
    and person.nationality.calendar = calendar

select item from Item item, Order order
where order.items[ order.deliveredItemIndices[0] ] = item and order.id = 11

select item from Item item, Order order
where order.items[ maxindex(order.items) ] = item and order.id = 11

L'expression entre [] peut même être une expression arithmétique.

select item from Item item, Order order
where order.items[ size(order.items) - 1 ] = item

HQL propose aussi une fonction index() interne, pour les éléments d'une association one-to-many ou d'une collections de valeurs.

select item, index(item) from Order order
    join order.items item
where index(item) < 5

Les fonctions SQL scalaires supportées par la base de données utilisée peuvent être utilisées

from DomesticCat cat where upper(cat.name) like 'FRI%'

Si vous n'êtes pas encore convaincu par tout cela, imaginez la taille et l'illisibilité qui caractériseraient la transformation SQL de la requête HQL suivante :

select cust
from Product prod,
    Store store
    inner join store.customers cust
where prod.name = 'widget'
    and store.location.name in ( 'Melbourne', 'Sydney' )
    and prod = all elements(cust.currentOrder.lineItems)

Un indice : cela donnerait quelque chose comme

SELECT cust.name, cust.address, cust.phone, cust.id, cust.current_order
FROM customers cust,
    stores store,
    locations loc,
    store_customers sc,
    product prod
WHERE prod.name = 'widget'
    AND store.loc_id = loc.id
    AND loc.name IN ( 'Melbourne', 'Sydney' )
    AND sc.store_id = store.id
    AND sc.cust_id = cust.id
    AND prod.id = ALL(
        SELECT item.prod_id
        FROM line_items item, orders o
        WHERE item.order_id = o.id
            AND cust.current_order = o.id
    )

14.10. La clause order by

La liste retounée par la requête peut être triée par n'importe quelle propriété de la classe ou du composant retourné :

from DomesticCat cat
order by cat.name asc, cat.weight desc, cat.birthdate

Le mot optionnel asc ou desc indique respectivement si le tri doit être croissant ou décroissant.
14.11. La clause group by

Si la requête retourne des valeurs aggrégées, celles ci peuvent être groupées par propriété ou composant :

select cat.color, sum(cat.weight), count(cat)
from Cat cat
group by cat.color

select foo.id, avg(name), max(name)
from Foo foo join foo.names name
group by foo.id

Une clause having est aussi permise.

select cat.color, sum(cat.weight), count(cat)
from Cat cat
group by cat.color
having cat.color in (eg.Color.TABBY, eg.Color.BLACK)

Les fonctions SQL et les fonctions d'aggrégations sont permises dans les clauses having et order by, si elles sont supportées par la base de données (ce que ne fait pas MySQL par exemple).

select cat
from Cat cat
    join cat.kittens kitten
group by cat
having avg(kitten.weight) > 100
order by count(kitten) asc, sum(kitten.weight) desc

Notez que ni la clause group by ni la clause order by ne peuvent contenir d'expressions arithmétiques.
14.12. Sous-requêtes

Pour les bases de données le supportant, Hibernate supporte les sous requêtes dans les requêtes. Une sous requête doit être entre parenthèses (souvent pour un appel à une fonction d'agrégation SQL) Même les sous requêtes corrélées (celles qui font référence à un alias de la requête principale) sont supportées.

from Cat as fatcat
where fatcat.weight > (
    select avg(cat.weight) from DomesticCat cat
)

from DomesticCat as cat
where cat.name = some (
    select name.nickName from Name as name
)

from Cat as cat
where not exists (
    from Cat as mate where mate.mate = cat
)

from DomesticCat as cat
where cat.name not in (
    select name.nickName from Name as name
)

select cat.id, (select max(kit.weight) from cat.kitten kit)
from Cat as cat

Notez que les sous-requêtes HQL peuvent arriver seulememnt dans les clauses select ou where.

Pour des sous-requêtes avec plus d'une expression dans le select, vous pouvez utiliser un constructeur de tuples :

from Cat as cat
where not ( cat.name, cat.color ) in (
    select cat.name, cat.color from DomesticCat cat
)

Notez que sur certaines bases de données (mais par Oracle ou HSQL), vous pouvez utiliser des constructeurs de tuples dans d'autres contextes, par exemple lors du requêtage de composants ou de types utilisateur composites :

from Person where name = ('Gavin', 'A', 'King')

Ce qui est équivalent à la forme plus verbeuse suivante :

from Person where name.first = 'Gavin' and name.initial = 'A' and name.last = 'King')

Il y a deux bonnes raisons que vous ne puissiez ne pas vouloir faire cette sorte de choses : d'abord, ce n'est pas complètement portable entre les plateformes de base de données ; deuxièmement, la requête est maintenant dépendante de l'ordre des propriétés dans le document de mapping.
14.13. Exemples HQL

Les requêtes Hibernate peuvent être relativement puissantes et complexes. En fait, la puissance du langage de requêtage est l'un des avantages principaux d'Hibernate. Voici quelques exemples très similaires aux requêtes que nous avons utilisées lors d'un récent projet. Notez que la plupart des requêtes que vous écrirez seront plus simples que les exemples suivantes !

La requête suivante retourne l'id de commande (order), le nombre d'articles (items) et la valeur totale de la commande (order) pour toutes les commandes non payées d'un client (customer) particulier pour un total minimum donné, le tout trié par la valeur totale. La requête SQL générée sur les tables ORDER, ORDER_LINE, PRODUCT, CATALOG et PRICE est composée de quatre jointures interne ainsi que d'une sous-requête (non corrélée).

select order.id, sum(price.amount), count(item)
from Order as order
    join order.lineItems as item
    join item.product as product,
    Catalog as catalog
    join catalog.prices as price
where order.paid = false
    and order.customer = :customer
    and price.product = product
    and catalog.effectiveDate < sysdate
    and catalog.effectiveDate >= all (
        select cat.effectiveDate
        from Catalog as cat
        where cat.effectiveDate < sysdate
    )
group by order
having sum(price.amount) > :minAmount
order by sum(price.amount) desc

Quel monstre ! En principe, nous ne sommes pas très fan des sous-requêtes, la requête ressemblait donc plutôt à cela :

select order.id, sum(price.amount), count(item)
from Order as order
    join order.lineItems as item
    join item.product as product,
    Catalog as catalog
    join catalog.prices as price
where order.paid = false
    and order.customer = :customer
    and price.product = product
    and catalog = :currentCatalog
group by order
having sum(price.amount) > :minAmount
order by sum(price.amount) desc

La requête suivante compte le nombre de paiements (payments) pour chaque status, en excluant les paiements dans le status AWAITING_APPROVAL où le changement de status le plus récent à été fait par l'utilisateur courant. En SQL, cette requête effectue deux jointures internes et des sous requêtes corrélées sur les tables PAYMENT, PAYMENT_STATUS et PAYMENT_STATUS_CHANGE.

select count(payment), status.name
from Payment as payment
    join payment.currentStatus as status
    join payment.statusChanges as statusChange
where payment.status.name <> PaymentStatus.AWAITING_APPROVAL
    or (
        statusChange.timeStamp = (
            select max(change.timeStamp)
            from PaymentStatusChange change
            where change.payment = payment
        )
        and statusChange.user <> :currentUser
    )
group by status.name, status.sortOrder
order by status.sortOrder

Si nous avions mappé la collection statusChanges comme une liste, au lieu d'un ensemble, la requête aurait été plus facile à écrire.

select count(payment), status.name
from Payment as payment
    join payment.currentStatus as status
where payment.status.name <> PaymentStatus.AWAITING_APPROVAL
    or payment.statusChanges[ maxIndex(payment.statusChanges) ].user <> :currentUser
group by status.name, status.sortOrder
order by status.sortOrder

La requête qui suit utilise la fonction de MS SQL isNull() pour retourner tous les comptes (accounts) et paiements (payments) impayés pour l'organisation à laquelle l'uilisateur (user) courant appartient. Elle est traduite en SQL par trois jointures internes, une jointure externe ainsi qu'une sous requête sur les tables ACCOUNT, PAYMENT, PAYMENT_STATUS, ACCOUNT_TYPE, ORGANIZATION et ORG_USER.

select account, payment
from Account as account
    left outer join account.payments as payment
where :currentUser in elements(account.holder.users)
    and PaymentStatus.UNPAID = isNull(payment.currentStatus.name, PaymentStatus.UNPAID)
order by account.type.sortOrder, account.accountNumber, payment.dueDate

Pour d'autres base de données, nous aurions dû faire sans la sous-requête (corrélée).

select account, payment
from Account as account
    join account.holder.users as user
    left outer join account.payments as payment
where :currentUser = user
    and PaymentStatus.UNPAID = isNull(payment.currentStatus.name, PaymentStatus.UNPAID)
order by account.type.sortOrder, account.accountNumber, payment.dueDate

14.14. Mise à jour et suppression

HQL supporte maintenant les expressions update, delete et insert ... select .... Voir Section 13.4, « Opérations de style DML » pour les détails.
14.15. Trucs & Astuces

Vous pouvez compter le nombre de résultats d'une requête sans les retourner :

( (Integer) session.iterate("select count(*) from ....").next() ).intValue()

Pour trier les résultats par la taille d'une collection, utilisez la requête suivante :

select usr.id, usr.name
from User as usr
    left join usr.messages as msg
group by usr.id, usr.name
order by count(msg)

Si votre base de données supporte les sous-requêtes, vous pouvez placer des conditions sur la taille de la sélection dans la clause where de votre requête:

from User usr where size(usr.messages) >= 1

Si votre base de données ne supporte pas les sous-requêtes, utilisez la requête suivante :

select usr.id, usr.name
from User usr.name
    join usr.messages msg
group by usr.id, usr.name
having count(msg) >= 1

Cette solution ne peut pas retourner un User avec zéro message à cause de la jointure interne, la forme suivante peut donc être utile :

select usr.id, usr.name
from User as usr
    left join usr.messages as msg
group by usr.id, usr.name
having count(msg) = 0

Les propriétés d'un JavaBean peuvent être injectées dans les paramètres nommés d'un requête :

Query q = s.createQuery("from foo Foo as foo where foo.name=:name and foo.size=:size");
q.setProperties(fooBean); // fooBean has getName() and getSize()
List foos = q.list();

Les collections sont paginables via l'utilisation de l'interface Query avec un filtre :

Query q = s.createFilter( collection, "" ); // the trivial filter
q.setMaxResults(PAGE_SIZE);
q.setFirstResult(PAGE_SIZE * pageNumber);
List page = q.list();

Les éléments d'une collection peuvent être triés ou groupés en utilisant un filtre de requête :

Collection orderedCollection = s.filter( collection, "order by this.amount" );
Collection counts = s.filter( collection, "select this.type, count(this) group by this.type" );

Vous pouvez récupérer la taille d'une collection sans l'initialiser :

( (Integer) session.iterate("select count(*) from ....").next() ).intValue();

Chapitre 15. Requêtes par critères

Hibernate offre une API d'interrogation par critères intuitive et extensible.
15.1. Créer une instance de Criteria

L'interface net.sf.hibernate.Criteria représente une requête sur une classe persistente donnée. La Session fournit les instances de Criteria.

Criteria crit = sess.createCriteria(Cat.class);
crit.setMaxResults(50);
List cats = crit.list();

15.2. Restriction du résultat

Un criterion (critère de recherche) est une instance de l'interface org.hibernate.criterion.Criterion. La classe org.hibernate.criterion.Restrictions définit des méthodes pour obtenir des types de Criterion pré-définis.

List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.like("name", "Fritz%") )
    .add( Restrictions.between("weight", minWeight, maxWeight) )
    .list();

Les restrictions peuvent être goupées de manière logique.

List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.like("name", "Fritz%") )
    .add( Restrictions.or(
        Restrictions.eq( "age", new Integer(0) ),
        Restrictions.isNull("age")
    ) )
    .list();

List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.in( "name", new String[] { "Fritz", "Izi", "Pk" } ) )
    .add( Restrictions.disjunction()
        .add( Restrictions.isNull("age") )
        .add( Restrictions.eq("age", new Integer(0) ) )
        .add( Restrictions.eq("age", new Integer(1) ) )
        .add( Restrictions.eq("age", new Integer(2) ) )
    ) )
    .list();

Il y a plusieurs types de criterion pré-définis (sous classes de Restriction), mais l'une d'entre elle particulièrement utile vous permet de spécifier directement du SQL.

List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.sql("lower({alias}.name) like lower(?)", "Fritz%", Hibernate.STRING) )
    .list();

La zone {alias} sera remplacée par l'alias de colonne de l'entité que l'on souhaite intérroger.

Une autre approche pour obtenir un criterion est de le récupérer d'une instance de Property. Vous pouvez créer une Property en appelant Property.forName().

Property age = Property.forName("age");
List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.disjunction()
        .add( age.isNull() )
        .add( age.eq( new Integer(0) ) )
        .add( age.eq( new Integer(1) ) )
        .add( age.eq( new Integer(2) ) )
    ) )
    .add( Property.forName("name").in( new String[] { "Fritz", "Izi", "Pk" } ) )
    .list();

15.3. Trier les résultats

Vous pouvez trier les résultats en utilisant org.hibernate.criterion.Order.

List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.like("name", "F%")
    .addOrder( Order.asc("name") )
    .addOrder( Order.desc("age") )
    .setMaxResults(50)
    .list();

List cats = sess.createCriteria(Cat.class)
    .add( Property.forName("name").like("F%") )
    .addOrder( Property.forName("name").asc() )
    .addOrder( Property.forName("age").desc() )
    .setMaxResults(50)
    .list();

15.4. Associations

Vous pouvez facilement spécifier des contraintes sur des entités liées, par des associations en utilisant createCriteria().

List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.like("name", "F%")
    .createCriteria("kittens")
        .add( Restrictions.like("name", "F%")
    .list();

Notez que la seconde createCriteria() retourne une nouvelle instance de Criteria, qui se rapporte aux éléments de la collection kittens.

La forme alternative suivante est utile dans certains cas.

List cats = sess.createCriteria(Cat.class)
    .createAlias("kittens", "kt")
    .createAlias("mate", "mt")
    .add( Restrictions.eqProperty("kt.name", "mt.name") )
    .list();

(createAlias() ne crée pas de nouvelle instance de Criteria.)

Notez que les collections kittens contenues dans les instances de Cat retournées par les deux précédentes requêtes ne sont pas pré-filtrées par les critères ! Si vous souhaitez récupérer uniquement les kittens qui correspondent à la criteria, vous devez utiliser ResultTransformer.

List cats = sess.createCriteria(Cat.class)
    .createCriteria("kittens", "kt")
        .add( Restrictions.eq("name", "F%") )
    .setResultTransformer(Criteria.ALIAS_TO_ENTITY_MAP)
    .list();
Iterator iter = cats.iterator();
while ( iter.hasNext() ) {
    Map map = (Map) iter.next();
    Cat cat = (Cat) map.get(Criteria.ROOT_ALIAS);
    Cat kitten = (Cat) map.get("kt");
}

15.5. Peuplement d'associations de manière dynamique

Vous pouvez spéficier au moment de l'exécution le peuplement d'une association en utilisant setFetchMode() (c'est-à-dire le chargement de celle-ci). Cela permet de surcharger les valeurs "lazy" et "outer-join" du mapping.

List cats = sess.createCriteria(Cat.class)
    .add( Restrictions.like("name", "Fritz%") )
    .setFetchMode("mate", FetchMode.EAGER)
    .setFetchMode("kittens", FetchMode.EAGER)
    .list();

Cette requête recherchera mate et kittens via les jointures externes. Voir Section 19.1, « Stratégies de chargement » pour plus d'informations.
15.6. Requêtes par l'exemple

La classe org.hibernate.criterion.Example vous permet de construire un critère suivant une instance d'objet donnée.

Cat cat = new Cat();
cat.setSex('F');
cat.setColor(Color.BLACK);
List results = session.createCriteria(Cat.class)
    .add( Example.create(cat) )
    .list();

Les propriétés de type version, identifiant et association sont ignorées. Par défaut, les valeurs null sont exclues.

Vous pouvez ajuster la stratégie d'utilisation de valeurs de l'Exemple.

Example example = Example.create(cat)
    .excludeZeroes()           //exclude zero valued properties
    .excludeProperty("color")  //exclude the property named "color"
    .ignoreCase()              //perform case insensitive string comparisons
    .enableLike();             //use like for string comparisons
List results = session.createCriteria(Cat.class)
    .add(example)
    .list();

Vous pouvez utiliser les "exemples" pour des critères sur les objets associés.

List results = session.createCriteria(Cat.class)
    .add( Example.create(cat) )
    .createCriteria("mate")
        .add( Example.create( cat.getMate() ) )
    .list();

15.7. Projections, agrégation et regroupement

La classe org.hibernate.criterion.Projections est une fabrique d'instances de Projection. Nous appliquons une projection sur une requête en appelant setProjection().

List results = session.createCriteria(Cat.class)
    .setProjection( Projections.rowCount() )
    .add( Restrictions.eq("color", Color.BLACK) )
    .list();

List results = session.createCriteria(Cat.class)
    .setProjection( Projections.projectionList()
        .add( Projections.rowCount() )
        .add( Projections.avg("weight") )
        .add( Projections.max("weight") )
        .add( Projections.groupProperty("color") )
    )
    .list();

Il n'y a pas besoin de "group by" explicite dans une requête par critère. Certains types de projection sont définis pour être des projections de regroupement, lesquels apparaissent aussi dans la clause group by SQL.

Un alias peut optionnellement être assigné à une projection, ainsi la valeur projetée peut être référencée dans des restrictions ou des tris. Voici deux façons différentes de faire ça :

List results = session.createCriteria(Cat.class)
    .setProjection( Projections.alias( Projections.groupProperty("color"), "colr" ) )
    .addOrder( Order.asc("colr") )
    .list();

List results = session.createCriteria(Cat.class)
    .setProjection( Projections.groupProperty("color").as("colr") )
    .addOrder( Order.asc("colr") )
    .list();

Les méthodes alias() et as() enveloppe simplement une instance de projection dans une autre instance (aliasée) de Projection. Comme un raccourci, vous pouvez assignez un alias lorsque vous ajoutez la projection à la liste de projections :

List results = session.createCriteria(Cat.class)
    .setProjection( Projections.projectionList()
        .add( Projections.rowCount(), "catCountByColor" )
        .add( Projections.avg("weight"), "avgWeight" )
        .add( Projections.max("weight"), "maxWeight" )
        .add( Projections.groupProperty("color"), "color" )
    )
    .addOrder( Order.desc("catCountByColor") )
    .addOrder( Order.desc("avgWeight") )
    .list();

List results = session.createCriteria(Domestic.class, "cat")
    .createAlias("kittens", "kit")
    .setProjection( Projections.projectionList()
        .add( Projections.property("cat.name"), "catName" )
        .add( Projections.property("kit.name"), "kitName" )
    )
    .addOrder( Order.asc("catName") )
    .addOrder( Order.asc("kitName") )
    .list();

Vous pouvez aussi utiliser Property.forName() pour formuler des projections :

List results = session.createCriteria(Cat.class)
    .setProjection( Property.forName("name") )
    .add( Property.forName("color").eq(Color.BLACK) )
    .list();

List results = session.createCriteria(Cat.class)
    .setProjection( Projections.projectionList()
        .add( Projections.rowCount().as("catCountByColor") )
        .add( Property.forName("weight").avg().as("avgWeight") )
        .add( Property.forName("weight").max().as("maxWeight") )
        .add( Property.forName("color").group().as("color" )
    )
    .addOrder( Order.desc("catCountByColor") )
    .addOrder( Order.desc("avgWeight") )
    .list();

15.8. Requêtes et sous-requêtes détachées

La classe DetachedCriteria vous laisse créer une requête en dehors de la portée de la session, et puis l'exécuter plus tard en utilisant n'importe quelle Session arbitraire.

DetachedCriteria query = DetachedCriteria.forClass(Cat.class)
    .add( Property.forName("sex").eq('F') );

Session session = ....;
Transaction txn = session.beginTransaction();
List results = query.getExecutableCriteria(session).setMaxResults(100).list();
txn.commit();
session.close();

Une DetachedCriteria peut aussi être utilisée pour exprimer une sous-requête. Des instances de criterion impliquant des sous-requêtes peuvent être obtenues via Subqueries ou Property.

DetachedCriteria avgWeight = DetachedCriteria.forClass(Cat.class)
    .setProjection( Property.forName("weight").avg() );
session.createCriteria(Cat.class)
    .add( Property.forName("weight).gt(avgWeight) )
    .list();

DetachedCriteria weights = DetachedCriteria.forClass(Cat.class)
    .setProjection( Property.forName("weight") );
session.createCriteria(Cat.class)
    .add( Subqueries.geAll("weight", weights) )
    .list();

Même des requêtes corrélées sont possibles :

DetachedCriteria avgWeightForSex = DetachedCriteria.forClass(Cat.class, "cat2")
    .setProjection( Property.forName("weight").avg() )
    .add( Property.forName("cat2.sex").eqProperty("cat.sex") );
session.createCriteria(Cat.class, "cat")
    .add( Property.forName("weight).gt(avgWeightForSex) )
    .list();

15.9. Requêtes par identifiant naturel

Pour la plupart des requêtes, incluant les requêtes par critère, le cache de requêtes n'est pas très efficace, parce que l'invalidation du cache de requêtes arrive trop souvent. Cependant, il y a une sorte spéciale de requête où nous pouvons optimiser l'algorithme d'invalidation du cache : les recherches sur une clef naturelle constante. Dans certaines applications, cette sorte de requête se produit fréquemment. L'API de critère fournit une provision spéciale pour ce cas d'utilisation.

D'abord vous devriez mapper la clef naturelle de votre entité en utilisant <natural-id>, et activer l'utilisation du cache de second niveau.

<class name="User">
    <cache usage="read-write"/>
    <id name="id">
        <generator class="increment"/>
    </id>
    <natural-id>
        <property name="name"/>
        <property name="org"/>
    </natural-id>
    <property name="password"/>
</class>

Notez que cette fonctionnalité n'est pas prévue pour l'utilisation avec des entités avec des clefs naturelles mutables.

Ensuite, activez le cache de requête d'Hibernate.

Maintenant Restrictions.naturalId() nous permet de rendre l'utilisation de l'algorithme de cache plus efficace.

session.createCriteria(User.class)
    .add( Restrictions.naturalId()
        .set("name", "gavin")
        .set("org", "hb")
    ).setCacheable(true)
    .uniqueResult();

Chapitre 16. SQL natif

Vous pouvez aussi écrire vos requêtes dans le dialecte SQL natif de votre base de données. Ceci est utile si vous souhaitez utiliser les fonctionnalités spécifiques de votre base de données comme le mot clé CONNECT d'Oracle. Cette fonctionnalité offre par ailleurs un moyen de migration plus propre et doux d'une application basée sur SQL/JDBC vers une application Hibernate.

Hibernate3 vous permet de spécifier du SQL écrit à la main (incluant les procédures stockées) pour toutes les opérations de création, mise à jour, suppression et chargement.
16.1. Utiliser une SQLQuery

L'exécution des requêtes en SQL natif est contrôlée par l'interface SQLQuery, laquelle est obtenue en appelant Session.createSQLQuery(). Dans des cas extrêmement simples, nous pouvons utiliser la forme suivante :

List cats = sess.createSQLQuery("select * from cats")
    .addEntity(Cat.class)
    .list();

Cette requête a spécifié :

    *

      la requête SQL
    *

      l'entité retournée par la requête

Ici, les noms de colonne des résultats sont supposés être les mêmes que les noms de colonne spécifiés dans le document de mapping. Cela peut être problématique pour des requêtes SQL qui joignent de multiple tables, puisque les mêmes noms de colonne peuvent apparaître dans plus d'une table. La forme suivante n'est pas vulnérable à la duplication des noms de colonne :

List cats = sess.createSQLQuery("select {cat.*} from cats cat")
    .addEntity("cat", Cat.class)
    .list();

Cette requête a spécifié :

    *

      la requête SQL, avec un paramètre fictif pour Hibernate pour injecter les alias de colonne
    *

      l'entité retournée par la requête, et son alias de table SQL

La méthode addEntity() associe l'alias de la table SQL avec la classe de l'entité retournée, et détermine la forme de l'ensemble des résultats de la requête.

La méthode addJoin() peut être utilisée pour charger des associations vers d'autres entités et collections.

List cats = sess.createSQLQuery(
        "select {cat.*}, {kitten.*} from cats cat, cats kitten where kitten.mother = cat.id"
    )
    .addEntity("cat", Cat.class)
    .addJoin("kitten", "cat.kittens")
    .list();

Une requête SQL native pourrait retourner une simple valeur scalaire ou une combinaison de scalaires et d'entités.

Double max = (Double) sess.createSQLQuery("select max(cat.weight) as maxWeight from cats cat")
        .addScalar("maxWeight", Hibernate.DOUBLE);
        .uniqueResult();

Vous pouvez alternativement décrire les informations de mapping des résultats dans vos fichiers hbm et les utiliser pour vos requêtes.

List cats = sess.createSQLQuery(
        "select {cat.*}, {kitten.*} from cats cat, cats kitten where kitten.mother = cat.id"
    )
    .setResultSetMapping("catAndKitten")
    .list();

16.2. Alias et références de propriété

La notation {cat.*} utilisée au-dessus est un raccourci pour "toutes les propriétés". Alternativement, vous pouvez lister explicitement les colonnes, mais même ce cas que nous laissons à Hibernate injecte des alias de colonne SQL pour chaque propriété. Le remplaçant pour un alias de colonne est juste le nom de la propriété qualifié par l'alias de la table. Dans l'exemple suivant, nous récupérons des Cats à partir d'une table différente (cat_log) de celle déclarée dans les méta-données de mapping. Notez que nous pouvons même utiliser les alias de propriété dans la clause "where" si nous le souhaitons.

La syntaxe {} n'est pas requise pour le requêtes nommées. Voir Section 16.3, « Requêtes SQL nommées ».

String sql = "select cat.originalId as {cat.id}, " +
    "cat.mateid as {cat.mate}, cat.sex as {cat.sex}, " +
    "cat.weight*10 as {cat.weight}, cat.name as {cat.name} " +
    "from cat_log cat where {cat.mate} = :catId"

List loggedCats = sess.createSQLQuery(sql)
    .addEntity("cat", Cat.class)
    .setLong("catId", catId)
    .list();

À noter : si vous listez chaque propriété explicitement, vous devez inclure toutes les propriétés de la classe et ses sous-classes !

La table suivante montre les différentes possibilités d'utilisation de l'injection d'alias. À noter : les noms des alias dans le résultat sont des exemples, chaque alias aura un nom unique et probablement différent lors de l'utilisation.

Tableau 16.1. Noms d'injection d'alias
Description	Syntaxe	Exemple	 
Une simple propriété	{[aliasname].[propertyname]}	A_NAME as {item.name}	 
Une propriété composée	{[aliasname].[componentname].[propertyname]}	CURRENCY as {item.amount.currency}, VALUE as {item.amount.value}	 
Discriminant d'une entité	{[aliasname].class}	DISC as {item.class}	 
Toutes les propriétés d'une entité	{[aliasname].*}	{item.*}	 
Une clef de collection	{[aliasname].key}	ORGID as {coll.key}	 
L'identifiant d'une collection	{[aliasname].id}	EMPID as {coll.id}	 
L'élément d'une collection	{[aliasname].element}	XID as {coll.element}	 
Propriété de l'élément dans la collection	{[aliasname].element.[propertyname]}	NAME as {coll.element.name}	 
Toutes les propriétés de l'élément dans la collection	{[aliasname].element.*}	{coll.element.*}	 
Toutes les propriétés de la collection	{[aliasname].*}	{coll.*}	 
16.3. Requêtes SQL nommées

Les requêtes SQL nommées peuvent être définies dans le document de mapping et appelées exactement de la même manière qu'un requête HQL nommée. Dans ce cas, nous n'avons pas besoin d'appeler addEntity().

<sql-query name="persons">
    <return alias="person" class="eg.Person"/>
    SELECT person.NAME AS {person.name},
           person.AGE AS {person.age},
           person.SEX AS {person.sex}
    FROM PERSON person
    WHERE person.NAME LIKE :namePattern
</sql-query>

List people = sess.getNamedQuery("persons")
    .setString("namePattern", namePattern)
    .setMaxResults(50)
    .list();

Les éléments <return-join> et <load-collection> sont respectivement utilisés pour lier des associations et définir des requêtes qui initialisent des collections.

<sql-query name="personsWith">
    <return alias="person" class="eg.Person"/>
    <return-join alias="address" property="person.mailingAddress"/>
    SELECT person.NAME AS {person.name},
           person.AGE AS {person.age},
           person.SEX AS {person.sex},
           adddress.STREET AS {address.street},
           adddress.CITY AS {address.city},
           adddress.STATE AS {address.state},
           adddress.ZIP AS {address.zip}
    FROM PERSON person
    JOIN ADDRESS adddress
        ON person.ID = address.PERSON_ID AND address.TYPE='MAILING'
    WHERE person.NAME LIKE :namePattern
</sql-query>

Une requête SQL nommée peut retourner une valeur scalaire. Vous devez spécifier l'alias de colonne et le type Hibernate utilisant l'élément <return-scalar> :

<sql-query name="mySqlQuery">
    <return-scalar column="name" type="string"/>
    <return-scalar column="age" type="long"/>
    SELECT p.NAME AS name,
           p.AGE AS age,
    FROM PERSON p WHERE p.NAME LIKE 'Hiber%'
</sql-query>

Vous pouvez externaliser les informations de mapping des résultats dans un élément <resultset> pour soit les réutiliser dans différentes requêtes nommées, soit à travers l'API setResultSetMapping().

<resultset name="personAddress">
    <return alias="person" class="eg.Person"/>
    <return-join alias="address" property="person.mailingAddress"/>
</resultset>

<sql-query name="personsWith" resultset-ref="personAddress">
    SELECT person.NAME AS {person.name},
           person.AGE AS {person.age},
           person.SEX AS {person.sex},
           adddress.STREET AS {address.street},
           adddress.CITY AS {address.city},
           adddress.STATE AS {address.state},
           adddress.ZIP AS {address.zip}
    FROM PERSON person
    JOIN ADDRESS adddress
        ON person.ID = address.PERSON_ID AND address.TYPE='MAILING'
    WHERE person.NAME LIKE :namePattern
</sql-query>

16.3.1. Utilisation de return-property pour spécifier explicitement les noms des colonnes/alias

Avec <return-property> vous pouvez explicitement dire à Hibernate quels alias de colonne utiliser, plutot que d'employer la syntaxe {} pour laisser Hibernate injecter ses propres alias.

<sql-query name="mySqlQuery">
    <return alias="person" class="eg.Person">
        <return-property name="name" column="myName"/>
        <return-property name="age" column="myAge"/>
        <return-property name="sex" column="mySex"/>
    </return>
    SELECT person.NAME AS myName,
           person.AGE AS myAge,
           person.SEX AS mySex,
    FROM PERSON person WHERE person.NAME LIKE :name
</sql-query>

<return-property> fonctionne aussi avec de multiple colonnes. Cela résout une limitation de la syntaxe {} qui ne peut pas permettre une bonne granularité des propriétés multi-colonnes.

<sql-query name="organizationCurrentEmployments">
    <return alias="emp" class="Employment">
        <return-property name="salary">
            <return-column name="VALUE"/>
            <return-column name="CURRENCY"/>
        </return-property>
        <return-property name="endDate" column="myEndDate"/>
    </return>
        SELECT EMPLOYEE AS {emp.employee}, EMPLOYER AS {emp.employer},
        STARTDATE AS {emp.startDate}, ENDDATE AS {emp.endDate},
        REGIONCODE as {emp.regionCode}, EID AS {emp.id}, VALUE, CURRENCY
        FROM EMPLOYMENT
        WHERE EMPLOYER = :id AND ENDDATE IS NULL
        ORDER BY STARTDATE ASC
</sql-query>

Notez que dans cet exemple nous avons utilisé <return-property> en combinaison avec la syntaxe {} pour l'injection. Cela autorise les utilisateurs à choisir comment ils veulent référencer les colonnes et les propriétés.

Si votre mapping a un discriminant vous devez utiliser <return-discriminator> pour spécifier la colonne discriminante.
16.3.2. Utilisation de procédures stockées pour les requêtes

Hibernate 3 introduit le support des requêtes via procédures stockées et les fonctions. La documentation suivante est valable pour les deux. Les procédures stockées/fonctions doivent retourner l'ensemble de résultats en tant que premier paramètre sortant (NdT: "out-parameter") pour être capable de fonctionner avec Hibernate. Un exemple d'une telle procédure stockée en Oracle 9 et version supérieure :

CREATE OR REPLACE FUNCTION selectAllEmployments
    RETURN SYS_REFCURSOR
AS
    st_cursor SYS_REFCURSOR;
BEGIN
    OPEN st_cursor FOR
 SELECT EMPLOYEE, EMPLOYER,
 STARTDATE, ENDDATE,
 REGIONCODE, EID, VALUE, CURRENCY
 FROM EMPLOYMENT;
      RETURN  st_cursor;
 END;

Pour utiliser cette requête dans Hibernate vous avez besoin de la mapper via une requête nommée.

<sql-query name="selectAllEmployees_SP" callable="true">
    <return alias="emp" class="Employment">
        <return-property name="employee" column="EMPLOYEE"/>
        <return-property name="employer" column="EMPLOYER"/>
        <return-property name="startDate" column="STARTDATE"/>
        <return-property name="endDate" column="ENDDATE"/>
        <return-property name="regionCode" column="REGIONCODE"/>
        <return-property name="id" column="EID"/>
        <return-property name="salary">
            <return-column name="VALUE"/>
            <return-column name="CURRENCY"/>
        </return-property>
    </return>
    { ? = call selectAllEmployments() }
</sql-query>

Notez que les procédures stockées retournent, pour le moment, seulement des scalaires et des entités. <return-join> et <load-collection> ne sont pas supportés.
16.3.2.1. Règles/limitations lors de l'utilisation des procédures stockées

Pur utiliser des procédures stockées avec Hibernate, les procédures doivent suivre certaines règles. Si elles ne suivent pas ces règles, elles ne sont pas utilisables avec Hibernate. Si vous voulez encore utiliser ces procédures vous devez les exécuter via session.connection(). Les règles sont différentes pour chaque base de données, puisque les vendeurs de base de données ont des sémantiques/syntaxes différentes pour les procédures stockées.

Les requêtes de procédures stockées ne peuvent pas être paginées avec setFirstResult()/setMaxResults().

Pour Oracle les règles suivantes s'appliquent :

    *

      La procédure doit retourner un ensemble de résultats. Le prmeier paramètre d'une procédure doit être un OUT qui retourne un ensemble de résultats. Ceci est fait en retournant un SYS_REFCURSOR dans Oracle 9 ou 10. Dans Oracle vous avez besoin de définir un type REF CURSOR.

Pour Sybase ou MS SQL server les règles suivantes s'appliquent :

    *

      La procédure doit retourner un ensemble de résultats. Notez que comme ces serveurs peuvent retourner de multiples ensembles de résultats et mettre à jour des compteurs, Hibernate itérera les résultats et prendra le premier résultat qui est un ensemble de résultat comme valeur de retour. Tout le reste sera ignoré.
    *

      Si vous pouvez activer SET NOCOUNT ON dans votre procédure, elle sera probablement plus efficace, mais ce n'est pas une obligation.

16.4. SQL personnalisé pour créer, mettre à jour et effacer

Hibernate3 peut utiliser des expression SQL personnalisées pour des opérations de création, de mise à jour, et de suppression. Les objets persistants les classes et les collections dans Hibernate contiennent déjà un ensemble de chaînes de caractères générées lors de la configuration (insertsql, deletesql, updatesql, etc). Les tages de mapping <sql-insert>, <sql-delete>, et <sql-update> surchargent ces chaînes de caractères :

<class name="Person">
    <id name="id">
        <generator class="increment"/>
    </id>
    <property name="name" not-null="true"/>
    <sql-insert>INSERT INTO PERSON (NAME, ID) VALUES ( UPPER(?), ? )</sql-insert>
    <sql-update>UPDATE PERSON SET NAME=UPPER(?) WHERE ID=?</sql-update>
    <sql-delete>DELETE FROM PERSON WHERE ID=?</sql-delete>
</class>

Le SQL est directement exécuté dans votre base de données, donc vous êtes libre d'utiliser le dialecte que vous souhaitez. Cela réduira bien sûr la portabilité de votre mapping si vous utilisez du SQL spécifique à votre base de données.

Les procédures stockées sont supportées si l'attribut callable est paramétré :

<class name="Person">
    <id name="id">
        <generator class="increment"/>
    </id>
    <property name="name" not-null="true"/>
    <sql-insert callable="true">{call createPerson (?, ?)}</sql-insert>
    <sql-delete callable="true">{? = call deletePerson (?)}</sql-delete>
    <sql-update callable="true">{? = call updatePerson (?, ?)}</sql-update>
</class>

L'ordre des paramètres positionnels est actuellement vital, car ils doivent être dans la même séquence qu'Hibernate les attend.

Vous pouvez voir l'ordre attendu en activant les journaux de debug pour le niveau org.hibernate.persister.entity level. Avec ce niveau activé, Hibernate imprimera le SQL statique qui est utilisé pour créer, mettre à jour, supprimer, etc. des entités. (Pour voir la séquence attendue, rappelez-vous de ne pas inclure votre SQL personnalisé dans les fichiers de mapping de manière à surcharger le SQL statique généré par Hibernate.)

Les procédures stockées sont dans la plupart des cas (lire : il vaut mieux le faire) requises pour retourner le nombre de lignes insérées/mises à jour/supprimées, puisque Hibernate fait quelques vérifications de succès lors de l'exécution de l'expression. Hibernate inscrit toujours la première expression comme un paramètre de sortie numérique pour les opérations CUD :

CREATE OR REPLACE FUNCTION updatePerson (uid IN NUMBER, uname IN VARCHAR2)
    RETURN NUMBER IS
BEGIN

    update PERSON
    set
        NAME = uname,
    where
        ID = uid;

    return SQL%ROWCOUNT;

END updatePerson;

16.5. SQL personnalisé pour le chargement

Vous pouvez aussi déclarer vos propres requêtes SQL (ou HQL) pour le chargement d'entité :

<sql-query name="person">
    <return alias="pers" class="Person" lock-mode="upgrade"/>
    SELECT NAME AS {pers.name}, ID AS {pers.id}
    FROM PERSON
    WHERE ID=?
    FOR UPDATE
</sql-query>

Ceci est juste une déclaration de requête nommée, comme vu plus tôt. Vous pouvez référencer cette requête nommée dans un mapping de classe :

<class name="Person">
    <id name="id">
        <generator class="increment"/>
    </id>
    <property name="name" not-null="true"/>
    <loader query-ref="person"/>
</class>

Ceci fonctionne même avec des procédures stockées.

Vous pouvez même définir une requête pour le chargement d'une collection :

<set name="employments" inverse="true">
    <key/>
    <one-to-many class="Employment"/>
    <loader query-ref="employments"/>
</set>

<sql-query name="employments">
    <load-collection alias="emp" role="Person.employments"/>
    SELECT {emp.*}
    FROM EMPLOYMENT emp
    WHERE EMPLOYER = :id
    ORDER BY STARTDATE ASC, EMPLOYEE ASC
</sql-query>

Vous pourriez même définir un chargeur d'entité qui charge une collection par jointure :

<sql-query name="person">
    <return alias="pers" class="Person"/>
    <return-join alias="emp" property="pers.employments"/>
    SELECT NAME AS {pers.*}, {emp.*}
    FROM PERSON pers
    LEFT OUTER JOIN EMPLOYMENT emp
        ON pers.ID = emp.PERSON_ID
    WHERE ID=?
</sql-query>

Chapitre 17. Filtrer les données

Hibernate3 fournit une nouvelle approche innovatrice pour gérer des données avec des règles de "visibilité". Un filtre Hibernate est un filtre global, nommé, paramétré qui peut être activé ou désactivé pour une session Hibernate particulière.
17.1. Filtres Hibernate

Hibernate3 ajoute la capacité de prédéfinir des critères de filtre et d'attacher ces filtres à une classe ou à une collection. Un critère de filtre est la faculté de définir une clause de restriction très similaire à l'attribut "where" existant disponible sur une classe et divers éléments d'une collection. Mis à part que ces conditions de filtre peuvent être paramétrées. L'application peut alors prendre la décision à l'exécution si des filtres donnés devraient être activés et quels devraient être leurs paramètres. Des filtres peuvent être utilisés comme des vues de base de données, mais paramétrées dans l'application.

Afin d'utiliser des filtres, ils doivent d'abord être définis, puis attachés aux éléments de mapping appropriés. Pour définir un filtre, utilisez l'élément <filter-def/> dans un élément <hibernate-mapping/> :

<filter-def name="myFilter">
    <filter-param name="myFilterParam" type="string"/>
</filter-def>

Puis, ce filtre peut être attaché à une classe :

<class name="myClass" ...>
    ...
    <filter name="myFilter" condition=":myFilterParam = MY_FILTERED_COLUMN"/>
</class>

ou à une collection :

<set ...>
    <filter name="myFilter" condition=":myFilterParam = MY_FILTERED_COLUMN"/>
</set>

ou même aux deux (ou à plusieurs de chaque) en même temps.

Les méthodes sur Session sont : enableFilter(String filterName), getEnabledFilter(String filterName), et disableFilter(String filterName). Par défaut, les filtres ne sont pas activés pour une session donnée ; ils doivent être explicitement activés en appelant la méthode Session.enabledFilter(), laquelle retourne une instance de l'interface Filter. Utiliser le simple filtre défini au-dessus ressemblerait à :

session.enableFilter("myFilter").setParameter("myFilterParam", "some-value");

Notez que des méthodes sur l'interface org.hibernate.Filter autorisent le chaînage de beaucoup de méthodes communes d'Hibernate.

Un exemple complet, utilisant des données temporelles avec une structure de date d'enregistrement effectif :

<filter-def name="effectiveDate">
    <filter-param name="asOfDate" type="date"/>
</filter-def>

<class name="Employee" ...>
...
    <many-to-one name="department" column="dept_id" class="Department"/>
    <property name="effectiveStartDate" type="date" column="eff_start_dt"/>
    <property name="effectiveEndDate" type="date" column="eff_end_dt"/>
...
    <!--
        Note that this assumes non-terminal records have an eff_end_dt set to
        a max db date for simplicity-sake
    -->
    <filter name="effectiveDate"
            condition=":asOfDate BETWEEN eff_start_dt and eff_end_dt"/>
</class>

<class name="Department" ...>
...
    <set name="employees" lazy="true">
        <key column="dept_id"/>
        <one-to-many class="Employee"/>
        <filter name="effectiveDate"
                condition=":asOfDate BETWEEN eff_start_dt and eff_end_dt"/>
    </set>
</class>

Puis, afin de s'assurer que vous pouvez toujours récupérer les enregistrements actuellement effectifs, activez simplement le filtre sur la session avant de récupérer des données des employés :

Session session = ...;
session.enabledFilter("effectiveDate").setParameter("asOfDate", new Date());
List results = session.createQuery("from Employee as e where e.salary > :targetSalary")
         .setLong("targetSalary", new Long(1000000))
         .list();

Dans le HQL ci-dessus, bien que nous ayons seulement mentionné une contrainte de salaire sur les resultats, à cause du filtre activé, la requête retournera seulement les employés actuellement actifs qui ont un salaire supérieur à un million de dollars.

A noter : si vous prévoyez d'utiliser des filtres avec des jointures externes (soit à travers HQL, soit par le chargement) faites attention à la direction de l'expression de condition. Il est plus sûr de la positionner pour les jointures externes à gauche ; en général, placez le paramètre d'abord, suivi du(des) nom(s) de colonne après l'opérateur.
Chapitre 18. Mapping XML

Notez que cette fonctionnalité est expérimentale dans Hibernate 3.0 et est en développement extrêmement actif.
18.1. Travailler avec des données XML

Hibernate vous laisse travailler avec des données XML persistantes de la même manière que vous travaillez avec des POJOs persistants. Un arbre XML peut être vu comme une autre manière de représenter les données relationnelles au niveau objet, à la place des POJOs.

Hibernate supporte dom4j en tant qu'API pour la manipulation des arbres XML. Vous pouvez écrire des requêtes qui récupèrent des arbres dom4j à partie de la base de données, et avoir toutes les modifications que vous faites sur l'arbre automatiquement synchronisées dans la base de données. Vous pouvez même prendre un document XML, l'analyser en utilisant dom4j, et l'écrire dans la base de données via les opérations basiques d'Hibernate : persist(), saveOrUpdate(), merge(), delete(), replicate() (merge() n'est pas encore supporté).

Cette fonctionnalité a plusieurs applications dont l'import/export de données, l'externalisation d'entités via JMS ou SOAP et les rapports XSLT.

Un simple mapping peut être utilisé pour simultanément mapper les propriétés d'une classe et les noeuds d'un document XML vers la base de données, ou, si il n'y a pas de classe à mapper, il peut être utilisé juste pour mapper le XML.
18.1.1. Spécifier le mapping XML et le mapping d'une classe ensemble

Voici un exemple de mapping d'un POJO et du XML simultanément :

<class name="Account"
        table="ACCOUNTS"
        node="account">

    <id name="accountId"
            column="ACCOUNT_ID"
            node="@id"/>

    <many-to-one name="customer"
            column="CUSTOMER_ID"
            node="customer/@id"
            embed-xml="false"/>

    <property name="balance"
            column="BALANCE"
            node="balance"/>

    ...

</class>

18.1.2. Spécifier seulement un mapping XML

Voici un exemple dans lequel il n'y a pas de class POJO :

<class entity-name="Account"
        table="ACCOUNTS"
        node="account">

    <id name="id"
            column="ACCOUNT_ID"
            node="@id"
            type="string"/>

    <many-to-one name="customerId"
            column="CUSTOMER_ID"
            node="customer/@id"
            embed-xml="false"
            entity-name="Customer"/>

    <property name="balance"
            column="BALANCE"
            node="balance"
            type="big_decimal"/>

    ...

</class>

Ce mapping vous permet d'accéder aux données comme un arbre dom4j, ou comme un graphe de paire nom de propriété/valeur (Maps java). Les noms des propriétés sont des constructions purement logiques qui peuvent être référées des dans requêtes HQL.
18.2. Métadonnées du mapping XML

Plusieurs éléments du mapping Hibernate acceptent l'attribut node. Ceci vous permet de spécifier le nom d'un attribut XML ou d'un élément qui contient la propriété ou les données de l'entité. Le format de l'attribut node doit être un des suivants :

    *

      "element-name" - mappe vers l'élément XML nommé
    *

      "@attribute-name" - mappe vers l'attribut XML nommé
    *

      "." - mappe vers le parent de l'élément
    *

      "element-name/@attribute-name" - mappe vers l'élément nommé de l'attribut nommé 

Pour des collections et de simples associations valuées, il y a un attribut embed-xml supplémentaire. Si embed-xml="true", qui est la valeur par défaut, l'arbre XML pour l'entité associée (ou la collection des types de valeurs) sera embarquée directement dans l'arbre XML pour l'entité qui possède l'association. Sinon, si embed-xml="false", alors seule la valeur de l'identifiant référencé apparaîtra dans le XML pour de simples associations de points, et les collections n'appraîtront simplement pas.

Vous devriez faire attention à ne pas laisser embed-xml="true" pour trop d'associations, puisque XML ne traite pas bien les liens circurlaires.

<class name="Customer"
        table="CUSTOMER"
        node="customer">

    <id name="id"
            column="CUST_ID"
            node="@id"/>

    <map name="accounts"
            node="."
            embed-xml="true">
        <key column="CUSTOMER_ID"
                not-null="true"/>
        <map-key column="SHORT_DESC"
                node="@short-desc"
                type="string"/>
        <one-to-many entity-name="Account"
                embed-xml="false"
                node="account"/>
    </map>

    <component name="name"
            node="name">
        <property name="firstName"
                node="first-name"/>
        <property name="initial"
                node="initial"/>
        <property name="lastName"
                node="last-name"/>
    </component>

    ...

</class>

dans ce cas, nous avons décidé d'embarquer la collection d'identifiants de compte, mais pas les données actuelles du compte. La requête HQL suivante :

from Customer c left join fetch c.accounts where c.lastName like :lastName

devrait retourner l'ensemble de données suivant :

<customer id="123456789">
    <account short-desc="Savings">987632567</account>
    <account short-desc="Credit Card">985612323</account>
    <name>
        <first-name>Gavin</first-name>
        <initial>A</initial>
        <last-name>King</last-name>
    </name>
    ...
</customer>

Si vous positionnez embed-xml="true" sur le mapping <one-to-many>, les données pourraient ressembler plus à ça :

<customer id="123456789">
    <account id="987632567" short-desc="Savings">
        <customer id="123456789"/>
        <balance>100.29</balance>
    </account>
    <account id="985612323" short-desc="Credit Card">
        <customer id="123456789"/>
        <balance>-2370.34</balance>
    </account>
    <name>
        <first-name>Gavin</first-name>
        <initial>A</initial>
        <last-name>King</last-name>
    </name>
    ...
</customer>

18.3. Manipuler des données XML

Relisons et mettons à jour des documents XML dans l'application. Nous faisons ça en obtenant une session dom4j :

Document doc = ....;

Session session = factory.openSession();
Session dom4jSession = session.getSession(EntityMode.DOM4J);
Transaction tx = session.beginTransaction();

List results = dom4jSession
    .createQuery("from Customer c left join fetch c.accounts where c.lastName like :lastName")
    .list();
for ( int i=0; i<results.size(); i++ ) {
    //add the customer data to the XML document
    Element customer = (Element) results.get(i);
    doc.add(customer);
}

tx.commit();
session.close();

Session session = factory.openSession();
Session dom4jSession = session.getSession(EntityMode.DOM4J);
Transaction tx = session.beginTransaction();

Element cust = (Element) dom4jSession.get("Customer", customerId);
for ( int i=0; i<results.size(); i++ ) {
    Element customer = (Element) results.get(i);
    //change the customer name in the XML and database
    Element name = customer.element("name");
    name.element("first-name").setText(firstName);
    name.element("initial").setText(initial);
    name.element("last-name").setText(lastName);
}

tx.commit();
session.close();

Il est extrêmement utile de combiner cette fonctionnalité avec l'opération replicate() d'Hibernate pour implémenter des imports/exports de données XML.
Chapitre 19. Améliorer les performances
19.1. Stratégies de chargement

Une stratégie de chargement est une stratégie qu'Hibernate va utiliser pour récupérer des objets associés si l'application à besoin de naviguer à travers une association. Les stratégies de chargement peuvent être déclarées dans les méta-données de l'outil de mapping objet relationnel ou surchargées par une requête de type HQL ou Criteria particulière.

Hibernate3 définit les stratégies de chargement suivantes :

    *

      Chargement par jointure - Hibernate récupère l'instance associée ou la collection dans un même SELECT, en utilisant un OUTER JOIN.
    *

      Chargement par select - Un second SELECT est utilisé pour récupérer l'instance associée ou la collection. A moins que vous ne désactiviez explicitement le chargement tardif en spécifiant lazy="false", ce second select ne sera exécuté que lorsque vous accéderez réellement à l'association.
    *

      Chargement par sous-select - Un second SELECT est utilisé pour récupérer les associations pour toutes les entités récupérées dans une requête ou un chargement préalable. A moins que vous ne désactiviez explicitement le chargement tardif en spécifiant lazy="false", ce second select ne sera exécuté que lorsque vous accéderez réellement à l'association.
    *

      Chargement par lot - Il s'agit d'une stratégie d'optimisation pour le chargement par select - Hibernate récupère un lot d'instances ou de collections en un seul SELECT en spécifiant une liste de clé primaire ou de clé étrangère. 

Hibernate fait également la distinction entre :

    *

      Chargement immédiat - Une association, une collection ou un attribut est chargé immédiatement lorsque l'objet auquel appartient cet élément est chargé.
    *

      Chargement tardif d'une collection - Une collection est chargée lorque l'application invoque une méthode sur cette collection (il s'agit du mode de chargement par défaut pour les collections).
    *

      Chargement "super tardif" d'une collection - les éléments de la collection sont récupérés individuellement depuis la base de données lorsque nécessaire. Hibernate essaie de ne pas charger toute la collection en mémoire sauf si cela est absolument nécessaire (bien adapté aux très grandes collections).
    *

      Chargement par proxy - une association vers un seul objet est chargée lorsqu'une méthode autre que le getter sur l'identifiant est appelée sur l'objet associé.
    *

      Chargement "sans proxy" - une association vers un seul objet est chargée lorsque l'on accède à cet objet. Par rapport au chargement par proxy, cette approche est moins tardif (l'association est quand même chargée même si on n'accède qu'à l'identifiant) mais plus transparente car il n'y a pas de proxy visible dans l'application. Cette approche requiert une instrumentation du bytecode à la compilation et est rarement nécessaire.
    *

      Chargement tardif des attributs - Un attribut ou un objet associé seul est chargé lorsque l'on y accède. Cette approche requiert une instrumentation du bytecode à la compilation et est rarement nécessaire. 

Nous avons ici deux notions orthogonales : quand l'association est chargée et comment (quelle requête SQL est utilisée). Il ne faut pas confondre les deux. Le mode de chargement est utilisé pour améliorer les performances. On peut utiliser le mode tardif pour définir un contrat sur quelles données sont toujours accessibles sur une instance détachée d'une classe particulière.
19.1.1. Travailler avec des associations chargées tardivement

Par défaut, Hibernate3 utilise le chargement tardif par select pour les collections et le chargement tardif par proxy pour les associations vers un seul objet. Ces valeurs par défaut sont valables pour la plupart des associations dans la plupart des applications.

Note : si vous définissez hibernate.default_batch_fetch_size, Hibernate va utiliser l'optimisation du chargement par lot pour le chargement tardif (cette optimisation peut aussi être activée à un niveau de granularité plus fin).

Cependant, le chargement tardif pose un problème qu'il faut connaitre. L'accès à une association définie comme "tardive", hors du contexte d'une session hibernate ouverte, va conduire à une exception. Par exemple :

s = sessions.openSession();
Transaction tx = s.beginTransaction();
            
User u = (User) s.createQuery("from User u where u.name=:userName")
    .setString("userName", userName).uniqueResult();
Map permissions = u.getPermissions();

tx.commit();
s.close();

Integer accessLevel = (Integer) permissions.get("accounts");  // Error!

Etant donné que la collection des permissions n'a pas été initialisée avant que la Session soit fermée, la collection n'est pas capable de se charger. Hibernate ne supporte pas le chargement tardif pour des objets détachés. La solution à ce problème est de déplacer le code qui lit la collection avant le "commit" de la transaction.

Une autre alternative est d'utiliser une collection ou une association non "tardive" en spécifiant lazy="false" dans le mapping de l'association. Cependant il est prévu que le chargement tardif soit utilisé pour quasiment toutes les collections ou associations. Si vous définissez trop d'associtions non "tardives" dans votre modèle objet, Hibernate va finir par devoir charger toute la base de données en mémoire à chaque transaction !

D'un autre côté, on veut souvent choisir un chargement par jointure (qui est par défaut non tardif) à la place du chargement par select dans une transaction particulière. Nous allons maintenant voir comment adapter les stratégies de chargement. Dans Hibernate3 les mécanismes pour choisir une stratégie de chargement sont identiques que l'on ait une association vers un objet simple ou vers une collection.
19.1.2. Personnalisation des stratégies de chargement

Le chargement par select (mode par défaut) est très vulnérable au problème du N+1 selects, du coup vous pouvez avoir envie d'activer le chargement par jointure dans les fichiers de mapping :

<set name="permissions" 
            fetch="join">
    <key column="userId"/>
    <one-to-many class="Permission"/>
</set

<many-to-one name="mother" class="Cat" fetch="join"/>

La stratégie de chargement définie à l'aide du mot fetch dans les fichiers de mapping affecte :

    *

      La récupération via get() ou load()
    *

      La récupération implicite lorsque l'on navigue à travers une association
    *

      Les requêtes de type Criteria
    *

      Les requêtes HQL si l'on utilise le chargement par subselect 

Quelle que soit la stratégie de chargement que vous utilisez, la partie du graphe d'objets qui est définie comme non "tardive" sera chargée en mémoire. Cela peut mener à l'exécution de plusieurs selects successifs pour une seule requête HQL.

On n'utilise pas souvent les documents de mapping pour adapter le chargement. Au lieu de cela, on conserve le comportement par défaut et on le surcharge pour une transaction particulière en utilisant left join fetch dans les requêtes HQL. Cela indique à hibernate à Hibernate de charger l'association de manière agressive lors du premier select en utilisant une jointure externe. Dans l'API Criteria vous pouvez utiliser la méthode setFetchMode(FetchMode.JOIN)

Si vous ne vous sentez pas prêt à modifier la stratégie de chargement utilisé par get() ou load(), vous pouvez juste utiliser une requête de type Criteria comme par exemple :

User user = (User) session.createCriteria(User.class)
                .setFetchMode("permissions", FetchMode.JOIN)
                .add( Restrictions.idEq(userId) )
                .uniqueResult();

(Il s'agit de l'équivalent pour Hibernate de ce que d'autres outils de mapping appellent un "fetch plan" ou "plan de chargement")

Une autre manière complètement différente d'éviter le problème des N+1 selects est d'utiliser le cache de second niveau.
19.1.3. Proxys pour des associations vers un seul objet

Le chargement tardif des collections est implémenté par Hibernate en utilisant ses propres implémentations pour des collections persistantes. Si l'on veut un chargement tardif pour des associations vers un seul objet métier il faut utiliser un autre mécanisme. L'entité qui est pointée par l'association doit être masquée derrière un proxy. Hibernate implémente l'initialisation tardive des proxys sur des objets persistents via une mise à jour à chaud du bytecode (à l'aide de l'excellente librairie CGLIB).

Par défaut, Hibernate génère des proxys (au démarrage) pour toutes les classes persistantes et les utilise pour activer le chargement tardif des associations many-to-one et one-to-one.

Le fichier de mapping peut déclarer une interface qui sera utilisée par le proxy d'interfaçage pour cette classe à l'aide de l'attribut proxy. Par défaut Hibernate utilises une sous classe de la classe persistante. Il faut que les classes pour lesquelles on ajoute un proxy implémentent un constructeur par défaut de visibilité au moins package. Ce constructeur est recommandé pour toutes les classes persistantes !

Il y a quelques précautions à prendre lorsque l'on étend cette approche à des classes polymorphiques, exemple :

<class name="Cat" proxy="Cat">
        ......
        <subclass name="DomesticCat" proxy="DomesticCat">
            .....
        </subclass>
    </class>

Tout d'abord, les instances de Cat ne pourront jamais être "castées" en DomesticCat, même si l'instance sous jacente est une instance de DomesticCat :

Cat cat = (Cat) session.load(Cat.class, id);  // instancie un proxy (n'interroge pas la base de données)
if ( cat.isDomesticCat() ) {                  // interroge la base de données pour initialiser le proxy
    DomesticCat dc = (DomesticCat) cat;       // Erreur !
    ....
}

Deuxièmement, il est possible de casser la notion d'== des proxy.

Cat cat = (Cat) session.load(Cat.class, id);            // instancie un proxy Cat
DomesticCat dc = 
    (DomesticCat) session.load(DomesticCat.class, id);  // acquiert un nouveau proxy DomesticCat
System.out.println(cat==dc);                            // faux

Cette situation n'est pas si mauvaise qu'il n'y parait. Même si nous avons deux références à deux objets proxys différents, l'instance de base sera quand même le même objet :

cat.setWeight(11.0);  // interroge la base de données pour initialiser le proxy
System.out.println( dc.getWeight() );  // 11.0

Troisièmement, vous ne pourrez pas utiliser un proxy CGLIB pour une classe final ou pour une classe contenant la moindre méthode final.

Enfin, si votre objet persistant obtient une ressource à l'instanciation (par example dans les initialiseurs ou dans le contructeur par défaut), alors ces ressources seront aussi obtenues par le proxy. La classe proxy est vraiment une sous classe de la classe persistante.

Ces problèmes sont tous dus aux limitations fondamentales du modèle d'héritage unique de Java. Si vous souhaitez éviter ces problèmes, vos classes persistantes doivent chacune implémenter une interface qui déclare ses méthodes métier. Vous devriez alors spécifier ces interfaces dans le fichier de mapping :

<class name="CatImpl" proxy="Cat">
    ......
    <subclass name="DomesticCatImpl" proxy="DomesticCat">
        .....
    </subclass>
</class>

où CatImpl implémente l'interface Cat et DomesticCatImpl implémente l'interface DomesticCat. Ainsi, des proxys pour les instances de Cat et DomesticCat pourraient être retournées par load() ou iterate() (Notez que list() ne retourne généralement pas de proxy).

Cat cat = (Cat) session.load(CatImpl.class, catid);
Iterator iter = session.iterate("from CatImpl as cat where cat.name='fritz'");
Cat fritz = (Cat) iter.next();

Les relations sont aussi initialisées tardivement. Ceci signifie que vous devez déclarer chaque propriété comme étant de type Cat, et non CatImpl.

Certaines opérations ne nécessitent pas l'initialisation du proxy

    *

      equals(), si la classe persistante ne surcharge pas equals()
    *

      hashCode(), si la classe persistante ne surcharge pas hashCode()
    *

      Le getter de l'identifiant 

Hibernate détectera les classes qui surchargent equals() ou hashCode().

Eh choisissant lazy="no-proxy" au lieu de lazy="proxy" qui est la valeur par défaut, il est possible d'éviter les problèmes liés au transtypage. Il faudra alors une instrumentation du bytecode à la compilation et toutes les opérations résulterons immédiatement en une initialisation du proxy.
19.1.4. Initialisation des collections et des proxys

Une exception de type LazyInitializationException sera renvoyée par hibernate si une collection ou un proxy non initialisé est accédé en dehors de la portée de la Session, e.g. lorsque l'entité à laquelle appartient la collection ou qui a une référence vers le proxy est dans l'état "détachée".

Parfois, nous devons nous assurer qu'un proxy ou une collection est initialisée avant de fermer la Session. Bien sûr, nous pouvons toujours forcer l'initialisation en appelant par exemple cat.getSex() ou cat.getKittens().size(). Mais ceci n'est pas très lisible pour les personnes parcourant le code et n'est pas très générique.

Les méthodes statiques Hibernate.initialize() et Hibernate.isInitialized() fournissent à l'application un moyen de travailler avec des proxys ou des collections initialisés. Hibernate.initialize(cat) forcera l'initialisation d'un proxy de cat, si tant est que sa Session est ouverte. Hibernate.initialize( cat.getKittens() ) a le même effet sur la collection kittens.

Une autre option est de conserver la Session ouverte jusqu'à ce que toutes les collections et tous les proxys aient été chargés. Dans certaines architectures applicatives, particulièrement celles ou le code d'accès aux données via hiberante et le code qui utilise ces données sont dans des couches applicatives différentes ou des processus physiques différents, il peut devenir problématique de garantir que la Session est ouverte lorsqu'une collection est initialisée. Il y a deux moyens de traiter ce problème :

    *

      Dans une application web, un filtre de servlet peut être utilisé pour fermer la Session uniquement lorsque la requête a été entièrement traitée, lorsque le rendu de la vue est fini (il s'agit du pattern Open Session in View). Bien sûr, cela demande plus d'attention à la bonne gestion des exceptions de l'application. Il est d'une importance vitale que la Session soit fermée et la transaction terminée avant que l'on rende la main à l'utilisateur même si une exception survient durant le traitement de la vue. Voir le wiki Hibernate pour des exemples sur le pattern "Open Session in View".
    *

      Dans une application avec une couche métier séparée, la couche contenant la logique métier doit "préparer" toutes les collections qui seront nécessaires à la couche web avant de retourner les données. Cela signifie que la couche métier doit charger toutes les données et retourner toutes les données déjà initialisées à la couche de présentation/web pour un cas d'utilisation donné. En général l'application appelle la méthode Hibernate.initialize() pour chaque collection nécessaire dans la couche web (cet appel doit être fait avant la fermeture de la session) ou bien récupère les collections de manière agressive à l'aide d'une requête HQL avec une clause FETCH ou à l'aide du mode FetchMode.JOIN pour une requête de type Criteria. Cela est en général plus facile si vous utilisez le pattern Command plutôt que Session Facade.
    *

      Vous pouvez également attacher à une Session un objet chargé au préalable à l'aide des méthodes merge() ou lock() avant d'accéder aux collections (ou aux proxys) non initialisés. Non, Hibernate ne fait pas, et ne doit pas faire, cela automatiquement car cela pourrait introduire une sémantique transactionnelle ad hoc. 

Parfois, vous ne voulez pas initialiser une grande collection mais vous avez quand même besoin d'informations sur elle (comme sa taille) ou un sous ensemble de ses données

Vous pouvez utiliser un filtre de collection pour récupérer sa taille sans l'initialiser :

( (Integer) s.createFilter( collection, "select count(*)" ).list().get(0) ).intValue()

La méthode createFilter() est également utilisée pour récupérer de manière efficace des sous ensembles d'une collection sans avoir besoin de l'initialiser dans son ensemble.

s.createFilter( lazyCollection, "").setFirstResult(0).setMaxResults(10).list();

19.1.5. Utiliser le chargement par lot

Pour améliorer les performances, Hibernate peut utiliser le chargement par lot ce qui veut dire qu'Hibernate peut charger plusieurs proxys (ou collections) non initialisés en une seule requête lorsque l'on accède à l'un de ces proxys. Le chargement par lot est une optimisation intimement liée à la stratégie de chargement tardif par select. Il y a deux moyens d'activer le chargement par lot : au niveau de la classe et au niveau de la collection.

Le chargement par lot pour les classes/entités est plus simple à comprendre. Imaginez que vous ayez la situation suivante à l'exécution : vous avez 25 instances de Cat chargées dans une Session, chaque Cat a une référence à son owner, une Person. La classe Person est mappée avec un proxy, lazy="true". Si vous itérez sur tous les cats et appelez getOwner() sur chacun d'eux, Hibernate exécutera par défaut 25 SELECT, pour charger les owners (initialiser le proxy). Vous pouvez paramétrer ce comportement en spécifiant une batch-size (taille du lot) dans le mapping de Person :

<class name="Person" batch-size="10">...</class>

Hibernate exécutera désormais trois requêtes, en chargeant respectivement 10, 10, et 5 entités.

Vous pouvez aussi activer le chargement par lot pour les collections. Par exemple, si chaque Person a une collection chargée tardivement de Cats, et que 10 personnes sont actuellement chargées dans la Session, itérer sur toutes les persons générera 10 SELECTs, un pour chaque appel de getCats(). Si vous activez le chargement par lot pour la collection cats dans le mapping de Person, Hibernate pourra précharger les collections :

<class name="Person">
    <set name="cats" batch-size="3">
        ...
    </set>
</class>

Avec une taille de lot (batch-size) de 8, Hibernate chargera respectivement 3, 3, 3, et 1 collections en quatre SELECTs. Encore une fois, la valeur de l'attribut dépend du nombre de collections non initialisées dans une Session particulière.

Le chargement par lot de collections est particulièrement utile si vous avez des arborescenses récursives d'éléments (typiquement, le schéma facture de matériels). (Bien qu'un sous ensemble ou un chemin matérialisé est sans doute une meilleure option pour des arbres principalement en lecture.)
19.1.6. Utilisation du chargement par sous select

Si une collection ou un proxy vers un objet doit être chargé, Hibernate va tous les charger en ré-exécutant la requête orignial dans un sous select. Cela fonctionne de la même manière que le chargement par lot sans la possibilité de fragmenter le chargement.
19.1.7. Utiliser le chargement tardif des propriétés

Hibernate3 supporte le chargement tardif de propriétés individuelles. La technique d'optimisation est également connue sous le nom de fetch groups (groupes de chargement). Il faut noter qu'il s'agit principalement d'une fonctionnalité marketing car en pratique l'optimisation de la lecture d'un enregistrement est beaucoup plus importante que l'optimisation de la lecture d'une colonne. Cependant, la restriction du chargement à certaines colonnes peut être pratique dans des cas extrèmes, lorsque des tables "legacy" possèdent des centaines de colonnes et que le modèle de données ne peut pas être amélioré.

Pour activer le chargement tardif d'une propriété, il faut mettre l'attribut lazy sur une propriété particulière du mapping :

<class name="Document">
       <id name="id">
        <generator class="native"/>
    </id>
    <property name="name" not-null="true" length="50"/>
    <property name="summary" not-null="true" length="200" lazy="true"/>
    <property name="text" not-null="true" length="2000" lazy="true"/>
</class>

Le chargement tardif des propriétés requiert une instrumentation du bytecode lors de la compilation ! Si les classes persistantes ne sont pas instrumentées, Hibernate ignorera de manière silencieuse le mode tardif et retombera dans le mode de chargement immédiat.

Pour l'instrumentation du bytecode vous pouvez utiliser la tâche Ant suivante :

<target name="instrument" depends="compile">
    <taskdef name="instrument" classname="org.hibernate.tool.instrument.InstrumentTask">
        <classpath path="${jar.path}"/>
        <classpath path="${classes.dir}"/>
        <classpath refid="lib.class.path"/>
    </taskdef>

    <instrument verbose="true">
        <fileset dir="${testclasses.dir}/org/hibernate/auction/model">
            <include name="*.class"/>
        </fileset>
    </instrument>
</target>

Une autre façon (meilleure ?) pour éviter de lire plus de colonnes que nécessaire au moins pour des transactions en lecture seule est d'utiliser les fonctionnalités de projection des requêtes HQL ou Criteria. Cela évite de devoir instrumenter le bytecode à la compilation et est certainement une solution préférable.

Vous pouvez forcer le mode de chargement agressif des propriétés en utilisant fetch all properties dans les requêts HQL.
19.2. Le cache de second niveau

Une Session Hibernate est un cache de niveau transactionnel des données persistantes. Il est possible de configurer un cache de cluster ou de JVM (de niveau SessionFactory pour être exact) défini classe par classe et collection par collection. Vous pouvez même utiliser votr choix de cache en implémentant le pourvoyeur (provider) associé. Faites attention, les caches ne sont jamais avertis des modifications faites dans la base de données par d'autres applications (ils peuvent cependant être configurés pour régulièrement expirer les données en cache).

Par défaut, Hibernate utilise EHCache comme cache de niveau JVM (le support de JCS est désormais déprécié et sera enlevé des futures versions d'Hibernate). Vous pouvez choisir une autre implémentation en spécifiant le nom de la classe qui implémente org.hibernate.cache.CacheProvider en utilisant la propriété hibernate.cache.provider_class.

Tableau 19.1. Fournisseur de cache
Cache	Classe pourvoyeuse	Type	Support en Cluster	Cache de requêtes supporté
Hashtable (ne pas utiliser en production)	org.hibernate.cache.HashtableCacheProvider	mémoire	 	oui
EHCache	org.hibernate.cache.EhCacheProvider	mémoire, disque	 	oui
OSCache	org.hibernate.cache.OSCacheProvider	mémoire, disque	 	oui
SwarmCache	org.hibernate.cache.SwarmCacheProvider	en cluster (multicast ip)	oui (invalidation de cluster)	 
JBoss TreeCache	org.hibernate.cache.TreeCacheProvider	en cluster (multicast ip), transactionnel	oui (replication)	oui (horloge sync. nécessaire)
19.2.1. Mapping de Cache

L'élément <cache> d'une classe ou d'une collection à la forme suivante :

<cache 
    usage="transactional|read-write|nonstrict-read-write|read-only"  (1)
    region="RegionName"                                              (2)
    include="all|non-lazy"                                           (3)
/>

(1)	

usage (requis) spécifie la stratégie de cache : transactionel, lecture-écriture, lecture-écriture non stricte ou lecture seule
(2)	

region (optionnel, par défaut il s'agit du nom de la classe ou du nom de role de la collection) spécifie le nom de la région du cache de second niveau
(3)	

include (optionnel, par défaut all) non-lazy spécifie que les propriétés des entités mappées avec lazy="true" ne doivent pas être mises en cache lorsque le chargement tardif des attributs est activé.

Alternativement (voir préférentiellement), vous pouvez spécifier les éléments <class-cache> et <collection-cache> dans hibernate.cfg.xml.

L'attribut usage spécifie une stratégie de concurrence d'accès au cache.
19.2.2. Strategie : lecture seule

Si votre application a besoin de lire mais ne modifie jamais les instances d'une classe, un cache read-only peut être utilisé. C'est la stratégie la plus simple et la plus performante. Elle est même parfaitement sûre dans un cluster.

<class name="eg.Immutable" mutable="false">
    <cache usage="read-only"/>
    ....
</class>

19.2.3. Stratégie : lecture/écriture

Si l'application a besoin de mettre à jour des données, un cache read-write peut être approprié. Cette stratégie ne devrait jamais être utilisée si votre application nécessite un niveau d'isolation transactionnelle sérialisable. Si le cache est utilisé dans un environnement JTA, vous devez spécifier hibernate.transaction.manager_lookup_class, fournissant une stratégie pour obtenir le TransactionManager JTA. Dans d'autres environnements, vous devriez vous assurer que la transation est terminée à l'appel de Session.close() ou Session.disconnect(). Si vous souhaitez utiliser cette stratégie dans un cluster, vous devriez vous assurer que l'implémentation de cache utilisée supporte le vérrouillage. Ce que ne font pas les pourvoyeurs caches fournis.

<class name="eg.Cat" .... >
    <cache usage="read-write"/>
    ....
    <set name="kittens" ... >
        <cache usage="read-write"/>
        ....
    </set>
</class>

19.2.4. Stratégie : lecture/écriture non stricte

Si l'application besoin de mettre à jour les données de manière occasionnelle (qu'il est très peu probable que deux transactions essaient de mettre à jour le même élément simultanément) et qu'une isolation transactionnelle stricte n'est pas nécessaire, un cache nonstrict-read-write peut être approprié. Si le cache est utilisé dans un environnement JTA, vous devez spécifier hibernate.transaction.manager_lookup_class. Dans d'autres environnements, vous devriez vous assurer que la transation est terminée à l'appel de Session.close() ou Session.disconnect()
19.2.5. Stratégie : transactionelle

La stratégie de cache transactional supporte un cache complètement transactionnel comme, par exemple, JBoss TreeCache. Un tel cache ne peut être utilisé que dans un environnement JTA et vous devez spécifier hibernate.transaction.manager_lookup_class.

Aucun des caches livrés ne supporte toutes les stratégies de concurrence. Le tableau suivant montre quels caches sont compatibles avec quelles stratégies de concurrence.

Tableau 19.2. Stratégie de concurrence du cache
Cache	read-only (lecture seule)	nonstrict-read-write (lecture-écriture non stricte)	read-write (lecture-ériture)	transactional (transactionnel)
Hashtable (ne pas utilser en production)	oui	oui	oui	 
EHCache	oui	oui	oui	 
OSCache	oui	oui	oui	 
SwarmCache	oui	oui	 	 
JBoss TreeCache	oui	 	 	oui
19.3. Gérer les caches

A chaque fois que vous passez un objet à la méthode save(), update() ou saveOrUpdate() et à chaque fois que vous récupérez un objet avec load(), get(), list(), iterate() or scroll(), cet objet est ajouté au cache interne de la Session.

Lorsqu'il y a un appel à la méthode flush(), l'état de cet objet va être synchronisé avec la base de données. Si vous ne voulez pas que cette synchronisation ait lieu ou si vous traitez un grand nombre d'objets et que vous avez besoin de gérer la mémoire de manière efficace, vous pouvez utiliser la méthode evict() pour supprimer l'objet et ses collections dépendantes du cache de la session

ScrollableResult cats = sess.createQuery("from Cat as cat").scroll(); //a huge result set
while ( cats.next() ) {
    Cat cat = (Cat) cats.get(0);
    doSomethingWithACat(cat);
    sess.evict(cat);
}

La Session dispose aussi de la méthode contains() pour déterminer si une instance appartient au cache de la session.

Pour retirer tous les objets du cache session, appelez Session.clear()

Pour le cache de second niveau, il existe des méthodes définies dans SessionFactory pour retirer des instances du cache, la classe entière, une instance de collection ou le rôle entier d'une collection.

sessionFactory.evict(Cat.class, catId); //evict a particular Cat
sessionFactory.evict(Cat.class);  //evict all Cats
sessionFactory.evictCollection("Cat.kittens", catId); //evict a particular collection of kittens
sessionFactory.evictCollection("Cat.kittens"); //evict all kitten collections

Le CacheMode contrôle comme une session particulière interragit avec le cache de second niveau

    *

      CacheMode.NORMAL - lit et écrit les items dans le cache de second niveau
    *

      CacheMode.GET - lit les items dans le cache de second niveau mais ne les écrit pas sauf dans le cache d'une mise à jour d'une donnée
    *

      CacheMode.PUT - écrit les items dans le cache de second niveau mais ne les lit pas dans le cache de second niveau
    *

      CacheMode.REFRESH - écrit les items dans le cache de second niveau mais ne les lit pas dans le cache de second niveau, outrepasse l'effet dehibernate.cache.use_minimal_puts, en forçant un rafraîchissement du cache de second niveau pour chaque item lu dans la base 

Pour parcourir le contenu du cache de second niveau ou la région du cache dédiée au requêtes, vous pouvez utiliser l'API Statistics API:

Map cacheEntries = sessionFactory.getStatistics()
        .getSecondLevelCacheStatistics(regionName)
        .getEntries();

Vous devez pour cela activer les statistiques et optionnellement forcer Hibernate à conserver les entrées dans le cache sous un format plus compréhensible pour l'utilisateur :

hibernate.generate_statistics true
hibernate.cache.use_structured_entries true

19.4. Le cache de requêtes

Les résultats d'une requête peuvent aussi être placés en cache. Ceci n'est utile que pour les requêtes qui sont exécutées avec les mêmes paramètres. Pour utiliser le cache de requêtes, vous devez d'abord l'activer :

hibernate.cache.use_query_cache true

Ce paramètre amène la création de deux nouvelles régions dans le cache, une qui va conserver le résultat des requêtes mises en cache (org.hibernate.cache.StandardQueryCache) et l'autre qui va conserver l'horodatage des mises à jour les plus récentes effectuées sur les tables requêtables (org.hibernate.cache.UpdateTimestampsCache). Il faut noter que le cache de requête ne conserve pas l'état des entités, il met en cache uniquement les valeurs de l'identifiant et les valeurs de types de base (?). Le cache de requête doit toujours être utilisé avec le cache de second niveau pour être efficace.

La plupart des requêtes ne retirent pas de bénéfice pas du cache, donc par défaut les requêtes ne sont pas mises en cache. Pour activer le cache, appelez Query.setCacheable(true). Cet appel permet de vérifier si les résultats sont en cache ou non, voire d'ajouter ces résultats si la requête est exécutée.

Si vous avez besoin de contrôler finement les délais d'expiration du cache, vous pouvez spécifier une région de cache nommée pour une requête particulière en appelant Query.setCacheRegion().

List blogs = sess.createQuery("from Blog blog where blog.blogger = :blogger")
    .setEntity("blogger", blogger)
    .setMaxResults(15)
    .setCacheable(true)
    .setCacheRegion("frontpages")
    .list();

Si une requête doit forcer le rafraîchissement de sa région de cache, vous devez appeler Query.setCacheMode(CacheMode.REFRESH). C'est particulièrement utile lorsque les données peuvent avoir été mises à jour par un processus séparé (e.g. elles n'ont pas été modifiées par Hibernate). Cela permet à l'application de rafraîchir de manière sélective les résultats d'une requête particulière. Il s'agit d'une alternative plus efficace à l'éviction d'une région du cache à l'aide de la méthode SessionFactory.evictQueries().
19.5. Comprendre les performances des Collections

Nous avons déjà passé du temps à discuter des collections. Dans cette section, nous allons traiter du comportement des collections à l'exécution.
19.5.1. Classification

Hibernate définit trois types de collections :

    *

      les collections de valeurs
    *

      les associations un-vers-plusieurs
    *

      les associations plusieurs-vers-plusieurs

Cette classification distingue les différentes relations entre les tables et les clés étrangères mais ne nous apprend rien de ce que nous devons savoir sur le modèle relationnel. Pour comprendre parfaitement la structure relationnelle et les caractéristiques des performances, nous devons considérer la structure de la clé primaire qui est utilisée par Hibernate pour mettre à jour ou supprimer les éléments des collections. Celà nous amène aux classifications suivantes :

    *

      collections indexées
    *

      sets
    *

      bags

Toutes les collections indexées (maps, lists, arrays) ont une clé primaire constituée des colonnes clé (<key>) et <index>. Avec ce type de clé primaire, la mise à jour de collection est en général très performante - la clé primaire peut être indexées efficacement et un élément particulier peut être localisé efficacement lorsqu'Hibernate essaie de le mettre à jour ou de le supprimer.

Les Sets ont une clé primaire composée de <key> et des colonnes représentant l'élément. Elle est donc moins efficace pour certains types de collections d'éléments, en particulier les éléments composites, les textes volumineux ou les champs binaires ; la base de données peut ne pas être capable d'indexer aussi efficacement une clé primaire aussi complexe. Cependant, pour les associations un-vers-plusieurs ou plusieurs-vers-plusieurs, spécialement lorsque l'on utilise des entités ayant des identifiants techniques, il est probable que cela soit aussi efficace (note : si vous voulez que SchemaExport créé effectivement la clé primaire d'un <set> pour vous, vous devez déclarer toutes les colonnes avec not-null="true").

Le mapping à l'aide d'<idbag> définit une clé de substitution ce qui leur permet d'être très efficaces lors de la mise à jour. En fait il s'agit du meilleur cas de mise à jour d'une collection

Le pire cas intervient pour les Bags. Dans la mesure où un bag permet la duplications des éléments et n'a pas de colonne d'index, aucune clé primaire ne peut être définie. Hibernate n'a aucun moyen de distinguer des enregistrements dupliqués. Hibernate résout ce problème en supprimant complètement les enregistrements (via un simple DELETE), puis en recréant la collection chaque fois qu'elle change. Ce qui peut être très inefficace.

Notez que pour une relation un-vers-plusieurs, la "clé primaire" peut ne pas être la clé primaire de la table en base de données - mais même dans ce cas, la classification ci-dessus reste utile (Elle explique comment Hibernate "localise" chaque enregistrement de la collection).
19.5.2. Les lists, les maps, les idbags et les sets sont les collections les plus efficaces pour la mise à jour

La discussion précédente montre clairement que les collections indexées et (la plupart du temps) les sets, permettent de réaliser le plus efficacement les opérations d'ajout, de suppression ou de modification d'éléments.

Il existe un autre avantage qu'ont les collections indexées sur les Sets dans le cadre d'une association plusieurs vers plusieurs ou d'une collection de valeurs. A cause de la structure inhérente d'un Set, Hibernate n'effectue jamais d'UPDATE quand un enregistrement est modifié. Les modifications apportées à un Set se font via un INSERT et DELETE (de chaque enregistrement). Une fois de plus, ce cas ne s'applique pas aux associations un vers plusieurs.

Après s'être rappelé que les tableaux ne peuvent pas être chargés tardivement, nous pouvons conclure que les lists, les maps et les idbags sont les types de collections (non inversées) les plus performants, avec les sets pas loin derrières. Les sets son le type de collection le plus courant dans les applications Hibernate. Cela est du au fait que la sémantique des "set" est la plus naturelle dans le modèle relationnel.

Cependant, dans des modèles objet bien conçus avec Hibernate, on voit souvent que la plupart des collections sont en fait des associations "un-vers-plusieurs" avec inverse="true". Pour ces associations, les mises à jour sont gérées au niveau de l'association "plusieurs-vers-un" et les considérations de performance de mise à jour des collections ne s'appliquent tout simplement pas dans ces cas là.
19.5.3. Les Bags et les lists sont les plus efficaces pour les collections inverse

Avant que vous n'oubliez les bags pour toujours, il y a un cas précis où les bags (et les lists) sont bien plus performants que les sets. Pour une collection marquée comme inverse="true" (le choix le plus courant pour un relation un vers plusieurs bidirectionnelle), nous pouvons ajouter des éléments à un bag ou une list sans avoir besoin de l'initialiser (fetch) les éléments du sac! Ceci parce que Collection.add() ou Collection.addAll() doit toujours retourner vrai pour un bag ou une List (contrairement au Set). Cela peut rendre le code suivant beaucoup plus rapide.

Parent p = (Parent) sess.load(Parent.class, id);
    Child c = new Child();
    c.setParent(p);
    p.getChildren().add(c);  //pas besoin de charger la collection !
    sess.flush();

19.5.4. Suppression en un coup

Parfois, effacer les éléments d'une collection un par un peut être extrêmement inefficace. Hibernate n'est pas totalement stupide, il sait qu'il ne faut pas le faire dans le cas d'une collection complètement vidée (lorsque vous appellez list.clear(), par exemple). Dans ce cas, Hibernate fera un simple DELETE et le travail est fait !

Supposons que nous ajoutions un élément dans une collection de taille vingt et que nous enlevions ensuite deux éléments. Hibernate effectuera un INSERT puis deux DELETE (à moins que la collection ne soit un bag). Ce qui est souhaitable.

Cependant, supposons que nous enlevions dix huit éléments, laissant ainsi deux éléments, puis que nous ajoutions trois nouveaux éléments. Il y a deux moyens de procéder.

    *

      effacer dix huit enregistrements un à un puis en insérer trois
    *

      effacer la totalité de la collection (en un DELETE SQL) puis insérer les cinq éléments restant un à un

Hibernate n'est pas assez intelligent pour savoir que, dans ce cas, la seconde méthode est plus rapide (Il plutôt heureux qu'Hibernate ne soit pas trop intelligent ; un tel comportement pourrait rendre l'utilisation de triggers de bases de données plutôt aléatoire, etc...).

Heureusement, vous pouvez forcer ce comportement lorsque vous le souhaitez, en liberant (c'est-à-dire en déréférençant) la collection initiale et en retournant une collection nouvellement instanciée avec les éléments restants. Ceci peut être très pratique et très puissant de temps en temps.

Bien sûr, la suppression en un coup ne s'applique pas pour les collections qui sont mappées avec inverse="true".
19.6. Moniteur de performance

L'optimisation n'est pas d'un grand intérêt sans le suivi et l'accès aux données de performance. Hibernate fournit toute une panoplie de rapport sur ses opérations internes. Les statistiques dans Hibernate sont fournies par SessionFactory.
19.6.1. Suivi d'une SessionFactory

Vous pouvez accéder au métriques d'une SessionFactory de deux manières. La première option est d'appeler sessionFactory.getStatistics() et de lire ou d'afficher les Statistics vous même.

Hibernate peut également utiliser JMX pour publier les métriques si vous activez le MBean StatisticsService. Vous pouvez activer un seul MBean pour toutes vos SessionFactory ou un par factory. Voici un code qui montre un exemple de configuration minimaliste :

// MBean service registration for a specific SessionFactory
Hashtable tb = new Hashtable();
tb.put("type", "statistics");
tb.put("sessionFactory", "myFinancialApp");
ObjectName on = new ObjectName("hibernate", tb); // MBean object name

StatisticsService stats = new StatisticsService(); // MBean implementation
stats.setSessionFactory(sessionFactory); // Bind the stats to a SessionFactory
server.registerMBean(stats, on); // Register the Mbean on the server

// MBean service registration for all SessionFactory's
Hashtable tb = new Hashtable();
tb.put("type", "statistics");
tb.put("sessionFactory", "all");
ObjectName on = new ObjectName("hibernate", tb); // MBean object name

StatisticsService stats = new StatisticsService(); // MBean implementation
server.registerMBean(stats, on); // Register the MBean on the server

TODO: Cela n'a pas de sens : dans le premier cs on récupère et on utilise le MBean directement. Dans le second, on doit fournir le nom JNDI sous lequel est retenu la fabrique de session avant de l'utiliser. Pour cela il faut utiliser hibernateStatsBean.setSessionFactoryJNDIName("my/JNDI/Name")

Vous pouvez (dés)activer le suivi pour une SessionFactory

    *

      au moment de la configuration en mettant hibernate.generate_statistics à false 

    *

      à chaud avec sf.getStatistics().setStatisticsEnabled(true) ou hibernateStatsBean.setStatisticsEnabled(true) 

Les statistiques peuvent être remises à zéro de manière programmatique à l'aide de la méthode clear() Un résumé peut être envoyé à un logger (niveau info) à l'aide de la méthode logSummary()
19.6.2. Métriques

Hibernate fournit un certain nombre de métriques, qui vont des informations très basiques aux informations très spécialisées qui ne sont appropriées que dans certains scenarii. Tous les compteurs accessibles sont décrits dans l'API de l'interface Statistics dans trois catégories :

    *

      Les métriques relatives à l'usage général de la Session comme le nombre de sessions ouvertes, le nombre de connexions JDBC récupérées, etc...
    *

      Les métriques relatives aux entités, collections, requêtes et caches dans leur ensemble (métriques globales),
    *

      Les métriques détaillées relatives à une entité, une collection, une requête ou une région de cache particulière. 

Par exemple, vous pouvez vérifier l'accès au cache ainsi que le taux d'éléments manquants et de mise à jour des entités, collections et requêtes et le temps moyen que met une requête. Il faut faire attention au fait que le nombre de millisecondes est sujet à approximation en Java. Hibernate est lié à la précision de la machine virtuelle, sur certaines plateformes, cela n'offre qu'une précision de l'ordre de 10 secondes.

Des accesseurs simples sont utilisés pour accéder aux métriques globales (e.g. celles qui ne sont pas liées à une entité, collection ou région de cache particulière). Vous pouvez accéder aux métriques d'une entité, collection, région de cache particulière à l'aide de son nom et à l'aide de sa représentation HQL ou SQL pour une requête. Référez vous à la javadoc des APIS Statistics, EntityStatistics, CollectionStatistics, SecondLevelCacheStatistics, and QueryStatistics pour plus d'informations. Le code ci-dessous montre un exemple simple :

Statistics stats = HibernateUtil.sessionFactory.getStatistics();

double queryCacheHitCount  = stats.getQueryCacheHitCount();
double queryCacheMissCount = stats.getQueryCacheMissCount();
double queryCacheHitRatio =
  queryCacheHitCount / (queryCacheHitCount + queryCacheMissCount);

log.info("Query Hit ratio:" + queryCacheHitRatio);

EntityStatistics entityStats =
  stats.getEntityStatistics( Cat.class.getName() );
long changes =
        entityStats.getInsertCount()
        + entityStats.getUpdateCount()
        + entityStats.getDeleteCount();
log.info(Cat.class.getName() + " changed " + changes + "times"  );

Pour travailler sur toutes les entités, collections, requêtes et régions de cache, vous pouvez récupérer la liste des noms des entités, collections, requêtes et régions de cache avec les méthodes : getQueries(), getEntityNames(), getCollectionRoleNames(), et getSecondLevelCacheRegionNames().
Chapitre 20. Guide des outils

Des outils en ligne de commande, des plugins Eclipse ainsu que des tâches Ant permettent de gérer de cycles de développement complet de projets utilisant Hibernate.

Les outils Hibernate actuels incluent des plugins pour l'IDE Eclipse ainsi que des tâches Ant pour l'ingénierie inverse de bases de données existantes :

    *

      Mapping Editor : un éditeur pour les fichiers de mapping XML Hibernate, supportant l'auto-complétion et la mise en valeur de la syntaxe. Il supporte aussi l'auto-complétion automatique pour les noms de classes et les noms de propriété/champ, le rendant beaucoup plus polyvalent qu'un éditeurXML normal.
    *

      Console : la console est une nouvelle vue d'Eclipse. En plus de la vue d'ensemble arborescente de vos configurations de console, vous obtenez aussi une vue interactive de vos classes persistantes et de leurs relations. La console vous permet d'exécuter des requête HQL dans votre base de données et de parcourir les résultats directement dans Eclipse.
    *

      Development Wizards : plusieurs assistants sont fournis avec les outils d'Hibernate pour Eclipse ; vous pouvez utiliser un assistant pour générer rapidement les fichiers de configuration d'Hibernate (cfg.xml), ou vous pouvez même complètement générer les fichiers de mapping Hibernate et les sources des POJOs à partir d'un schéma de base de données existant. L'assistant d'ingénierie inverse supporte les modèles utilisateur.
    *

      Tâches Ant : 

Veuillez-vous référer au paquet outils Hibernate et sa documentation pour plus d'informations.

Pourtant, le paquet principal d'Hibernate arrive avec un lot d'outils intégrés (il peut même être utilisé de "l'intérieur" d'Hibernate à la volée) : SchemaExport aussi connu comme hbm2ddl.
20.1. Génération automatique du schéma

La DDL peut être générée à partir de vos fichiers de mapping par un utilitaire d'Hibernate. Le schéma généré inclut les contraintes d'intégrité référentielle (clefs primaires et étrangères) pour les tables d'entités et de collections. Les tables et les séquences sont aussi créées pour les générateurs d'identifiant mappés.

Vous devez spécifier un Dialect SQL via la propriété hibernate.dialect lors de l'utilisation de cet outils, puisque la DDL est fortement dépendante de la base de données.

D'abord, personnalisez vos fichiers de mapping pour améliorer le schéma généré.
20.1.1. Personnaliser le schéma

Plusieurs éléments du mapping hibernate définissent des attributs optionnels nommés length, precision et scale. Vous pouvez paramétrer la longueur, la précision,... d'une colonne avec ces attributs.

<property name="zip" length="5"/>

<property name="balance" precision="12" scale="2"/>

Certains éléments acceptent aussi un attribut not-null (utilisé pour générer les contraintes de colonnes NOT NULL) et un attribut unique (pour générer une contrainte de colonne UNIQUE).

<many-to-one name="bar" column="barId" not-null="true"/>

<element column="serialNumber" type="long" not-null="true" unique="true"/>

Un attribut unique-key peut être utilisé pour grouper les colonnes en une seule contrainte d'unicité. Actuellement, la valeur spécifiée par l'attribut unique-key n'est pas utilisée pour nommer la contrainte dans le DDL généré, elle sert juste à grouper les colonnes dans le fichier de mapping.

<many-to-one name="org" column="orgId" unique-key="OrgEmployeeId"/>
            <property name="employeeId" unique-key="OrgEmployee"/>

Un attribut index indique le nom d'un index qui sera créé en utilisant la ou les colonnes mappées. Plusieurs colonnes peuvent être groupées dans un même index, en spécifiant le même nom d'index.

<property name="lastName" index="CustName"/>
<property name="firstName" index="CustName"/>

Un attribut foreign-key peut être utilisé pour surcharger le nom des clés étrangères générées.

<many-to-one name="bar" column="barId" foreign-key="FKFooBar"/>

Plusieurs éléments de mapping acceptent aussi un élément fils <column>. Ceci est utile pour les type multi-colonnes:

<property name="name" type="my.customtypes.Name"/>
    <column name="last" not-null="true" index="bar_idx" length="30"/>
    <column name="first" not-null="true" index="bar_idx" length="20"/>
    <column name="initial"/>
</property>

L'attribut default vous laisse spécifier une valeur par défaut pour une colonnes (vous devriez assigner la même valeur à la propriété mappée avant de sauvegarder une nouvelle instance de la classe mappée).

<property name="credits" type="integer" insert="false">
    <column name="credits" default="10"/>
</property>

<version name="version" type="integer" insert="false">
    <column name="version" default="0"/>
</property>

L'attribut sql-type laisse l'utilisateur surcharger le mapping par défaut du type Hibernate vers un type SQL.

<property name="balance" type="float">
    <column name="balance" sql-type="decimal(13,3)"/>
</property>

L'attribut check permet de spécifier une contrainte de vérification.

<property name="foo" type="integer">
    <column name="foo" check="foo > 10"/>
</property>

<class name="Foo" table="foos" check="bar < 100.0">
    ...
    <property name="bar" type="float"/>
</class>

Tableau 20.1. Summary
Attribut	Valeur	Interprétation
length	numérique	taille d'une colonne
precision	numérique	précision décimale de la colonne
scale	numérique	scale décimale de la colonne
not-null	true|false	spécifie que la colonne doit être non-nulle
unique	true|false	spécifie que la colonne doit avoir une contrainte d'unicité
index	index_name	spécifie le nom d'un index (multi-colonnes)
unique-key	unique_key_name	spécifie le nom d'une contrainte d'unicité multi-colonnes
foreign-key	foreign_key_name	spécifie le nom d'une contrainte de clé étrangère générée pour une association, utilisez-la avec les éléments de mapping <one-to-one>, <many-to-one>, <key>, et <many-to-many> Notez que les extrêmités inverse="true" se seront pas prises en compte par SchemaExport.
sql-type	SQL column_type	surcharge le type par défaut (attribut de l'élément <column> uniquement)
default	expression SQL	spécifie une valeur par défaut pour la colonne
check	SQL expression	crée une contrainte de vérification sur la table ou la colonne

L'élément <comment> vous permet de spécifier un commentaire pour le schéma généré.

<class name="Customer" table="CurCust">
    <comment>Current customers only</comment>
    ...
</class>

<property name="balance">
    <column name="bal">
        <comment>Balance in USD</comment>
    </column>
</property>

Ceci a pour résultat une expression comment on table ou comment on column dans la DDL générée (où supportée).
20.1.2. Exécuter l'outil

L'outil SchemaExport génère un script DDL vers la sortie standard et/ou exécute les ordres DDL.

java -cp classpath_hibernate net.sf.hibernate.tool.hbm2ddl.SchemaExport options fichiers_de_mapping

Tableau 20.2. SchemaExport Options de la ligne de commande
Option	Description
--quiet	ne pas écrire le script vers la sortie standard
--drop	supprime seuleument les tables
--create	ne créé que les tables
--text	ne pas exécuter sur la base de données
--output=my_schema.ddl	écrit le script ddl vers un fichier
--naming=eg.MyNamingStrategy	sélectionne une NamingStrategy
--config=hibernate.cfg.xml	lit la configuration Hibernate à partir d'un fichier XML
--properties=hibernate.properties	lit les propriétés de la base de données à partir d'un fichier
--format	formatte proprement le SQL généré dans le script
--delimiter=x	paramètre un délimiteur de fin de ligne pour le script

Vous pouvez même intégrer SchemaExport dans votre application :

Configuration cfg = ....;
new SchemaExport(cfg).create(false, true);

20.1.3. Propriétés

Les propriétés de la base de données peuvent être spécifiées

    *

      comme propriétés système avec -D<property>
    *

      dans hibernate.properties
    *

      dans un fichier de propriétés déclaré avec --properties

Les propriétés nécessaires sont :

Tableau 20.3. SchemaExport Connection Properties
Nom de la propriété	Description
hibernate.connection.driver_class	classe du driver JDBC
hibernate.connection.url	URL JDBC
hibernate.connection.username	utilisateur de la base de données
hibernate.connection.password	mot de passe de l'utilisateur
hibernate.dialect	dialecte
20.1.4. Utiliser Ant

Vous pouvez appeler SchemaExport depuis votre script de construction Ant :

<target name="schemaexport">
    <taskdef name="schemaexport"
        classname="org.hibernate.tool.hbm2ddl.SchemaExportTask"
        classpathref="class.path"/>

    <schemaexport
        properties="hibernate.properties"
        quiet="no"
        text="no"
        drop="no"
        delimiter=";"
        output="schema-export.sql">
        <fileset dir="src">
            <include name="**/*.hbm.xml"/>
        </fileset>
    </schemaexport>
</target>

20.1.5. Mises à jour incrémentales du schéma

L'outil SchemaUpdate mettra à jour un schéma existant en effectuant les changement par "incrément". Notez que SchemaUpdate dépends beaucoup de l'API JDBC metadata, il ne fonctionnera donc pas avec tous les drivers JDBC.

java -cp classpath_hibernate net.sf.hibernate.tool.hbm2ddl.SchemaUpdate options fichiers_de_mapping

Tableau 20.4. SchemaUpdate Options de ligne de commande
Option	Description
--quiet	ne pas écrire vers la sortie standard
--text	ne pas exporter vers la base de données
--naming=eg.MyNamingStrategy	choisit une NamingStrategy
--properties=hibernate.properties	lire les propriétés de la base de données à partir d'un fichier

Vous pouvez intégrer SchemaUpdate dans votre application :

Configuration cfg = ....;
new SchemaUpdate(cfg).execute(false);

20.1.6. Utiliser Ant pour des mises à jour de schéma par incrément

Vous pouvez appeler SchemaUpdate depuis le script Ant :

<target name="schemaupdate">
    <taskdef name="schemaupdate"
        classname="org.hibernate.tool.hbm2ddl.SchemaUpdateTask"
        classpathref="class.path"/>

    <schemaupdate
        properties="hibernate.properties"
        quiet="no">
        <fileset dir="src">
            <include name="**/*.hbm.xml"/>
        </fileset>
    </schemaupdate>
</target>

20.1.6.1. Validation du schéma

L'outil SchemaValidator validera que le schéma existant correspond à vos documents de mapping. Notez que le SchemaValidator dépends de l'API metadata de JDBC, il ne fonctionnera donc pas avec tous les drivers JDBC. Cet outil est extrêmement utile pour tester.

java -cp hibernate_classpaths org.hibernate.tool.hbm2ddl.SchemaValidator options mapping_files

Tableau 20.5. SchemaValidator Options de ligne de commande
Option	Description
--naming=eg.MyNamingStrategy	Indique une NamingStrategy
--properties=hibernate.properties	lit les propriétés dela base de données depuis un fichier de propriétés
--config=hibernate.cfg.xml	indique un fichier .cfg.xml

Vous pouvez inclure SchemaValidator dans votre application:

Configuration cfg = ....;
new SchemaValidator(cfg).validate();

20.1.7. Utiliser Ant pour la validation du Schéma

Vous pouvez appeler SchemaValidator depuis le script Ant:

<target name="schemavalidate">
    <taskdef name="schemavalidator"
        classname="org.hibernate.tool.hbm2ddl.SchemaValidatorTask"
        classpathref="class.path"/>
    
    <schemavalidator
        properties="hibernate.properties">
        <fileset dir="src">
            <include name="**/*.hbm.xml"/>
        </fileset>
    </schemaupdate>
</target>

Chapitre 21. Exemple : Père/Fils

L'une des premières choses que les nouveaux utilisateurs essaient de faire avec Hibernate est de modéliser une relation père/fils. Il y a deux approches différentes pour cela. Pour un certain nombre de raisons, la méthode la plus courante, en particulier pour les nouveaux utilisateurs, est de modéliser les deux relations Père et Fils comme des classes entités liées par une association <one-to-many> du Père vers le Fils (l'autre approche est de déclarer le Fils comme un <composite-element>). Il est évident que le sens de l'association un vers plusieurs (dans Hibernate) est bien moins proche du sens habituel d'une relation père/fils que ne l'est celui d'un élément cmposite. Nous allons vous expliquer comment utiliser une association un vers plusieurs bidirectionnelle avec cascade afin de modéliser efficacement et élégamment une relation père/fils, ce n'est vraiment pas difficile !
21.1. Une note à propos des collections

Les collections Hibernate sont considérées comme étant une partie logique de l'entité dans laquelle elles sont contenues ; jamais des entités qu'elle contient. C'est une distinction crutiale ! Les conséquences sont les suivantes :

    *

      Quand nous ajoutons / retirons un objet d'une collection, le numéro de version du propriétaire de la collection est incrémenté.
    *

      Si un objet qui a été enlevé d'une collection est une instance de type valeur (ex : élément composite), cet objet cessera d'être persistant et son état sera complètement effacé de la base de données. Par ailleurs, ajouter une instance de type valeur dans une collection aura pour conséquence que son état sera immédiatement persistant.
    *

      Si une entité est enlevée d'une collection (association un-vers-plusieurs ou plusieurs-vers-plusieurs), par défaut, elle ne sera pas effacée. Ce comportement est complètement logique - une modification de l'un des états internes d'une entité ne doit pas causer la disparition de l'entité associée ! De même, l'ajout d'une entité dans une collection n'engendre pas, par défaut, la persistence de cette entité. 

Le comportement par défaut est donc que l'ajout d'une entité dans une collection créé simplement le lien entre les deux entités, et qu'effacer une entité supprime ce lien. C'est le comportement le plus approprié dans la plupart des cas. Ce comportement n'est cependant pas approprié lorsque la vie du fils est liée au cycle de vie du père.
21.2. un-vers-plusieurs bidirectionnel

Supposons que nous ayons une simple association <one-to-many> de Parent vers Child.

<set name="children">
                <key column="parent_id"/>
                <one-to-many class="Child"/>
            </set>

Si nous executions le code suivant

Parent p = .....;
Child c = new Child();
p.getChildren().add(c);
session.save(c);
session.flush();

Hibernate exécuterait deux ordres SQL:

    *

      un INSERT pour créer l'enregistrement pour c
    *

      un UPDATE pour créer le lien de p vers c 

Ceci est non seuleument inefficace, mais viole aussi toute contrainte NOT NULL sur la colonne parent_id. Nous pouvons réparer la contrainte de nullité en spécifiant not-null="true" dans le mapping de la collection :

<set name="children">
    <key column="parent_id" not-null="true"/>
    <one-to-many class="Child"/>
</set>

Cependant ce n'est pas la solution recommandée.

La cause sous jacente à ce comportement est que le lien (la clé étrangère parent_id) de p vers c n'est pas considérée comme faisant partie de l'état de l'objet Child et n'est donc pas créé par l'INSERT. La solution est donc que ce lien fasse partie du mapping de Child.

<many-to-one name="parent" column="parent_id" not-null="true"/>

(Nous avons aussi besoin d'ajouter la propriété parent dans la classe Child).

Maintenant que l'état du lien est géré par l'entité Child, nous spécifions à la collection de ne pas mettre à jour le lien. Nous utilisons l'attribut inverse.

<set name="children" inverse="true">
    <key column="parent_id"/>
    <one-to-many class="Child"/>
</set>

Le code suivant serait utilisé pour ajouter un nouveau Child

Parent p = (Parent) session.load(Parent.class, pid);
Child c = new Child();
c.setParent(p);
p.getChildren().add(c);
session.save(c);
session.flush();

Maintenant, seul un INSERT SQL est nécessaire !

Pour alléger encore un peu les choses, nous devrions créer une méthode addChild() dans Parent.

public void addChild(Child c) {
    c.setParent(this);
    children.add(c);
}

Le code d'ajout d'un Child serait alors

Parent p = (Parent) session.load(Parent.class, pid);
Child c = new Child();
p.addChild(c);
session.save(c);
session.flush();

21.3. Cycle de vie en cascade

L'appel explicite de save() est un peu fastidieux. Nous pouvons simplifier cela en utilisant les cascades.

<set name="children" inverse="true" cascade="all">
    <key column="parent_id"/>
    <one-to-many class="Child"/>
</set>

Simplifie le code précédent en

Parent p = (Parent) session.load(Parent.class, pid);
Child c = new Child();
p.addChild(c);
session.flush();

De la même manière, nous n'avons pas à itérer sur les fils lorsque nous sauvons ou effacons un Parent. Le code suivant efface p et tous ses fils de la base de données.

Parent p = (Parent) session.load(Parent.class, pid);
session.delete(p);
session.flush();

Par contre, ce code

Parent p = (Parent) session.load(Parent.class, pid);
Child c = (Child) p.getChildren().iterator().next();
p.getChildren().remove(c);
c.setParent(null);
session.flush();

n'effacera pas c de la base de données, il enlèvera seulement le lien vers p (et causera une violation de contrainte NOT NULL, dans ce cas). Vous devez explicitement utiliser delete() sur Child.

Parent p = (Parent) session.load(Parent.class, pid);
Child c = (Child) p.getChildren().iterator().next();
p.getChildren().remove(c);
session.delete(c);
session.flush();

Dans notre cas, un Child ne peut pas vraiment exister sans son père. Si nous effacons un Child de la collection, nous voulons vraiment qu'il soit effacé. Pour cela, nous devons utiliser cascade="all-delete-orphan".

<set name="children" inverse="true" cascade="all-delete-orphan">
    <key column="parent_id"/>
    <one-to-many class="Child"/>
</set>

A noter : même si le mapping de la collection spécifie inverse="true", les cascades sont toujours assurées par l'itération sur les éléments de la collection. Donc, si vous avez besoin qu'un objet soit enregistré, effacé ou mis à jour par cascade, vous devez l'ajouter dans la colleciton. Il ne suffit pas d'appeler explicitement setParent().
21.4. Cascades et unsaved-value

Supposons que nous ayons chargé un Parent dans une Session, que nous l'ayons ensuite modifié et que voulions persiter ces modifications dans une nouvelle session en appelant update(). Le Parent contiendra une collection de fils et, puisque la cascade est activée, Hibernate a besoin de savoir quels fils viennent d'être instanciés et quels fils proviennent de la base de données. Supposons aussi que Parent et Child ont tous deux des identifiants du type Long. Hibernate utilisera la propriété de l'identifiant et la propriété de la version/horodatage pour déterminer quels fils sont nouveaux (vous pouvez aussi utiliser la propriété version ou timestamp, voir ???). Dans Hibernate3, il n'est plus nécessaire de spécifier une unsaved-value explicitement.

Le code suivant mettra à jour parent et child et insérera newChild.

//parent et child ont été chargés dans une session précédente
parent.addChild(child);
Child newChild = new Child();
parent.addChild(newChild);
session.update(parent);
session.flush();

Ceci est très bien pour des identifiants générés, mais qu'en est-il des identifiants assignés et des identifiants composés ? C'est plus difficile, puisqu'Hibernate ne peut pas utiliser la propriété de l'identifiant pour distinguer un objet nouvellement instancié (avec un identifiant assigné par l'utilisateur) d'un objet chargé dans une session précédente. Dans ce cas, Hibernate utilisera soit la propriété de version ou d'horodatage, soit effectuera vraiment une requête au cache de second niveau, soit, dans le pire des cas, à la base de données, pour voir si la ligne existe.
21.5. Conclusion

Il y a quelques principes à maîtriser dans ce chapitre et tout cela peut paraître déroutant la première fois. Cependant, dans la pratique, tout fonctionne parfaitement. La plupart des applications Hibernate utilisent le pattern père / fils.

Nous avons évoqué une alternative dans le premier paragraphe. Aucun des points traités précédemment n'existe dans le cas d'un mapping <composite-element> qui possède exactement la sémantique d'une relation père / fils. Malheureusement, il y a deux grandes limitations pour les classes éléments composites : les éléments composites ne peuvent contenir de collections, et ils ne peuvent être les fils d'entités autres que l'unique parent.
Chapitre 22. Exemple : application Weblog
22.1. Classes persistantes

Les classes persistantes representent un weblog, et un article posté dans un weblog. Il seront modélisés comme une relation père/fils standard, mais nous allons utiliser un "bag" trié au lieu d'un set.

package eg;

import java.util.List;

public class Blog {
    private Long _id;
    private String _name;
    private List _items;

    public Long getId() {
        return _id;
    }
    public List getItems() {
        return _items;
    }
    public String getName() {
        return _name;
    }
    public void setId(Long long1) {
        _id = long1;
    }
    public void setItems(List list) {
        _items = list;
    }
    public void setName(String string) {
        _name = string;
    }
}

package eg;

import java.text.DateFormat;
import java.util.Calendar;

public class BlogItem {
    private Long _id;
    private Calendar _datetime;
    private String _text;
    private String _title;
    private Blog _blog;

    public Blog getBlog() {
        return _blog;
    }
    public Calendar getDatetime() {
        return _datetime;
    }
    public Long getId() {
        return _id;
    }
    public String getText() {
        return _text;
    }
    public String getTitle() {
        return _title;
    }
    public void setBlog(Blog blog) {
        _blog = blog;
    }
    public void setDatetime(Calendar calendar) {
        _datetime = calendar;
    }
    public void setId(Long long1) {
        _id = long1;
    }
    public void setText(String string) {
        _text = string;
    }
    public void setTitle(String string) {
        _title = string;
    }
}

22.2. Mappings Hibernate

Le mapping XML doit maintenant être relativement simple à vos yeux.

<?xml version="1.0"?>
<!DOCTYPE hibernate-mapping PUBLIC
    "-//Hibernate/Hibernate Mapping DTD 3.0//EN"
    "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd">

<hibernate-mapping package="eg">

    <class
        name="Blog"
        table="BLOGS">

        <id
            name="id"
            column="BLOG_ID">

            <generator class="native"/>

        </id>

        <property
            name="name"
            column="NAME"
            not-null="true"
            unique="true"/>

        <bag
            name="items"
            inverse="true"
            order-by="DATE_TIME"
            cascade="all">

            <key column="BLOG_ID"/>
            <one-to-many class="BlogItem"/>

        </bag>

    </class>

</hibernate-mapping>

<?xml version="1.0"?>
<!DOCTYPE hibernate-mapping PUBLIC
    "-//Hibernate/Hibernate Mapping DTD 3.0//EN"
    "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd">

<hibernate-mapping package="eg">

    <class
        name="BlogItem"
        table="BLOG_ITEMS"
        dynamic-update="true">

        <id
            name="id"
            column="BLOG_ITEM_ID">

            <generator class="native"/>

        </id>

        <property
            name="title"
            column="TITLE"
            not-null="true"/>

        <property
            name="text"
            column="TEXT"
            not-null="true"/>

        <property
            name="datetime"
            column="DATE_TIME"
            not-null="true"/>

        <many-to-one
            name="blog"
            column="BLOG_ID"
            not-null="true"/>

    </class>

</hibernate-mapping>

22.3. Code Hibernate

La classe suivante montre quelques utilisations que nous pouvons faire de ces classes.

package eg;

import java.util.ArrayList;
import java.util.Calendar;
import java.util.Iterator;
import java.util.List;

import org.hibernate.HibernateException;
import org.hibernate.Query;
import org.hibernate.Session;
import org.hibernate.SessionFactory;
import org.hibernate.Transaction;
import org.hibernate.cfg.Configuration;
import org.hibernate.tool.hbm2ddl.SchemaExport;

public class BlogMain {

    private SessionFactory _sessions;

    public void configure() throws HibernateException {
        _sessions = new Configuration()
            .addClass(Blog.class)
            .addClass(BlogItem.class)
            .buildSessionFactory();
    }

    public void exportTables() throws HibernateException {
        Configuration cfg = new Configuration()
            .addClass(Blog.class)
            .addClass(BlogItem.class);
        new SchemaExport(cfg).create(true, true);
    }

    public Blog createBlog(String name) throws HibernateException {

        Blog blog = new Blog();
        blog.setName(name);
        blog.setItems( new ArrayList() );

        Session session = _sessions.openSession();
        Transaction tx = null;
        try {
            tx = session.beginTransaction();
            session.persist(blog);
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
        return blog;
    }

    public BlogItem createBlogItem(Blog blog, String title, String text)
                        throws HibernateException {

        BlogItem item = new BlogItem();
        item.setTitle(title);
        item.setText(text);
        item.setBlog(blog);
        item.setDatetime( Calendar.getInstance() );
        blog.getItems().add(item);

        Session session = _sessions.openSession();
        Transaction tx = null;
        try {
            tx = session.beginTransaction();
            session.update(blog);
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
        return item;
    }

    public BlogItem createBlogItem(Long blogid, String title, String text)
                        throws HibernateException {

        BlogItem item = new BlogItem();
        item.setTitle(title);
        item.setText(text);
        item.setDatetime( Calendar.getInstance() );

        Session session = _sessions.openSession();
        Transaction tx = null;
        try {
            tx = session.beginTransaction();
            Blog blog = (Blog) session.load(Blog.class, blogid);
            item.setBlog(blog);
            blog.getItems().add(item);
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
        return item;
    }

    public void updateBlogItem(BlogItem item, String text)
                    throws HibernateException {

        item.setText(text);

        Session session = _sessions.openSession();
        Transaction tx = null;
        try {
            tx = session.beginTransaction();
            session.update(item);
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
    }

    public void updateBlogItem(Long itemid, String text)
                    throws HibernateException {

        Session session = _sessions.openSession();
        Transaction tx = null;
        try {
            tx = session.beginTransaction();
            BlogItem item = (BlogItem) session.load(BlogItem.class, itemid);
            item.setText(text);
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
    }

    public List listAllBlogNamesAndItemCounts(int max)
                    throws HibernateException {

        Session session = _sessions.openSession();
        Transaction tx = null;
        List result = null;
        try {
            tx = session.beginTransaction();
            Query q = session.createQuery(
                "select blog.id, blog.name, count(blogItem) " +
                "from Blog as blog " +
                "left outer join blog.items as blogItem " +
                "group by blog.name, blog.id " +
                "order by max(blogItem.datetime)"
            );
            q.setMaxResults(max);
            result = q.list();
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
        return result;
    }

    public Blog getBlogAndAllItems(Long blogid)
                    throws HibernateException {

        Session session = _sessions.openSession();
        Transaction tx = null;
        Blog blog = null;
        try {
            tx = session.beginTransaction();
            Query q = session.createQuery(
                "from Blog as blog " +
                "left outer join fetch blog.items " +
                "where blog.id = :blogid"
            );
            q.setParameter("blogid", blogid);
            blog  = (Blog) q.uniqueResult();
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
        return blog;
    }

    public List listBlogsAndRecentItems() throws HibernateException {

        Session session = _sessions.openSession();
        Transaction tx = null;
        List result = null;
        try {
            tx = session.beginTransaction();
            Query q = session.createQuery(
                "from Blog as blog " +
                "inner join blog.items as blogItem " +
                "where blogItem.datetime > :minDate"
            );

            Calendar cal = Calendar.getInstance();
            cal.roll(Calendar.MONTH, false);
            q.setCalendar("minDate", cal);

            result = q.list();
            tx.commit();
        }
        catch (HibernateException he) {
            if (tx!=null) tx.rollback();
            throw he;
        }
        finally {
            session.close();
        }
        return result;
    }
}

Chapitre 23. Exemple : quelques mappings

Ce chapitre montre quelques mappings plus complexes.
23.1. Employeur/Employé (Employer/Employee)

Le modèle suivant de relation entre Employer et Employee utilise une vraie classe entité (Employment) pour représenter l'association. On a fait cela parce qu'il peut y avoir plus d'une période d'emploi pour les deux mêmes parties. Des composants sont utilisés pour modéliser les valeurs monétaires et les noms des employés.

Voici un document de mapping possible :

<hibernate-mapping>

    <class name="Employer" table="employers">
        <id name="id">
            <generator class="sequence">
                <param name="sequence">employer_id_seq</param>
            </generator>
        </id>
        <property name="name"/>
    </class>

    <class name="Employment" table="employment_periods">

        <id name="id">
            <generator class="sequence">
                <param name="sequence">employment_id_seq</param>
            </generator>
        </id>
        <property name="startDate" column="start_date"/>
        <property name="endDate" column="end_date"/>

        <component name="hourlyRate" class="MonetaryAmount">
            <property name="amount">
                <column name="hourly_rate" sql-type="NUMERIC(12, 2)"/>
            </property>
            <property name="currency" length="12"/>
        </component>

        <many-to-one name="employer" column="employer_id" not-null="true"/>
        <many-to-one name="employee" column="employee_id" not-null="true"/>

    </class>

    <class name="Employee" table="employees">
        <id name="id">
            <generator class="sequence">
                <param name="sequence">employee_id_seq</param>
            </generator>
        </id>
        <property name="taxfileNumber"/>
        <component name="name" class="Name">
            <property name="firstName"/>
            <property name="initial"/>
            <property name="lastName"/>
        </component>
    </class>

</hibernate-mapping>

Et voici le schéma des tables générées par SchemaExport.

create table employers (
    id BIGINT not null,
    name VARCHAR(255),
    primary key (id)
)

create table employment_periods (
    id BIGINT not null,
    hourly_rate NUMERIC(12, 2),
    currency VARCHAR(12),
    employee_id BIGINT not null,
    employer_id BIGINT not null,
    end_date TIMESTAMP,
    start_date TIMESTAMP,
    primary key (id)
)

create table employees (
    id BIGINT not null,
    firstName VARCHAR(255),
    initial CHAR(1),
    lastName VARCHAR(255),
    taxfileNumber VARCHAR(255),
    primary key (id)
)

alter table employment_periods
    add constraint employment_periodsFK0 foreign key (employer_id) references employers
alter table employment_periods
    add constraint employment_periodsFK1 foreign key (employee_id) references employees
create sequence employee_id_seq
create sequence employment_id_seq
create sequence employer_id_seq

23.2. Auteur/Travail (Author/Work)

Soit le modèle de la relation entre Work, Author et Person. Nous représentons la relation entre Work et Author comme une association plusieurs-vers-plusieurs. Nous avons choisi de représenter la relation entre Author et Person comme une association un-vers-un. Une autre possibilité aurait été que Author hérite de Person.

Le mapping suivant représente exactement ces relations :

<hibernate-mapping>

    <class name="Work" table="works" discriminator-value="W">

        <id name="id" column="id">
            <generator class="native"/>
        </id>
        <discriminator column="type" type="character"/>

        <property name="title"/>
        <set name="authors" table="author_work">
            <key column name="work_id"/>
            <many-to-many class="Author" column name="author_id"/>
        </set>

        <subclass name="Book" discriminator-value="B">
            <property name="text"/>
        </subclass>

        <subclass name="Song" discriminator-value="S">
            <property name="tempo"/>
            <property name="genre"/>
        </subclass>

    </class>

    <class name="Author" table="authors">

        <id name="id" column="id">
            <!-- The Author must have the same identifier as the Person -->
            <generator class="assigned"/>
        </id>

        <property name="alias"/>
        <one-to-one name="person" constrained="true"/>

        <set name="works" table="author_work" inverse="true">
            <key column="author_id"/>
            <many-to-many class="Work" column="work_id"/>
        </set>

    </class>

    <class name="Person" table="persons">
        <id name="id" column="id">
            <generator class="native"/>
        </id>
        <property name="name"/>
    </class>

</hibernate-mapping>

Il y a quatre tables dans ce mapping. works, authors et persons qui contiennent respectivement les données de work, author et person. author_work est une table d'association qui lie authors à works. Voici le schéma de tables, généré par SchemaExport.

create table works (
    id BIGINT not null generated by default as identity,
    tempo FLOAT,
    genre VARCHAR(255),
    text INTEGER,
    title VARCHAR(255),
    type CHAR(1) not null,
    primary key (id)
)

create table author_work (
    author_id BIGINT not null,
    work_id BIGINT not null,
    primary key (work_id, author_id)
)

create table authors (
    id BIGINT not null generated by default as identity,
    alias VARCHAR(255),
    primary key (id)
)

create table persons (
    id BIGINT not null generated by default as identity,
    name VARCHAR(255),
    primary key (id)
)

alter table authors
    add constraint authorsFK0 foreign key (id) references persons
alter table author_work
    add constraint author_workFK0 foreign key (author_id) references authors
alter table author_work
    add constraint author_workFK1 foreign key (work_id) references works

23.3. Client/Commande/Produit (Customer/Order/Product)

Imaginons maintenant le modèle de relation entre Customer, Order, LineItem et Product. Il y a une association un-vers-plusieurs entre Customer et Order, mais comment devrions nous représenter Order / LineItem / Product? J'ai choisi de mapper LineItem comme une classe d'association représentant l'association plusieurs-vers-plusieurs entre Order et Product. Dans Hibernate, on appelle cela un élément composite.

Le document de mapping :

<hibernate-mapping>

    <class name="Customer" table="customers">
        <id name="id">
            <generator class="native"/>
        </id>
        <property name="name"/>
        <set name="orders" inverse="true">
            <key column="customer_id"/>
            <one-to-many class="Order"/>
        </set>
    </class>

    <class name="Order" table="orders">
        <id name="id">
            <generator class="native"/>
        </id>
        <property name="date"/>
        <many-to-one name="customer" column="customer_id"/>
        <list name="lineItems" table="line_items">
            <key column="order_id"/>
            <list-index column="line_number"/>
            <composite-element class="LineItem">
                <property name="quantity"/>
                <many-to-one name="product" column="product_id"/>
            </composite-element>
        </list>
    </class>

    <class name="Product" table="products">
        <id name="id">
            <generator class="native"/>
        </id>
        <property name="serialNumber"/>
    </class>

</hibernate-mapping>

customers, orders, line_items et products contiennent les données de customer, order, order line item et product. line_items est aussi la table d'association liant orders à products.

create table customers (
    id BIGINT not null generated by default as identity,
    name VARCHAR(255),
    primary key (id)
)

create table orders (
    id BIGINT not null generated by default as identity,
    customer_id BIGINT,
    date TIMESTAMP,
    primary key (id)
)

create table line_items (
    line_number INTEGER not null,
    order_id BIGINT not null,
    product_id BIGINT,
    quantity INTEGER,
    primary key (order_id, line_number)
)

create table products (
    id BIGINT not null generated by default as identity,
    serialNumber VARCHAR(255),
    primary key (id)
)

alter table orders
    add constraint ordersFK0 foreign key (customer_id) references customers
alter table line_items
    add constraint line_itemsFK0 foreign key (product_id) references products
alter table line_items
    add constraint line_itemsFK1 foreign key (order_id) references orders

23.4. Divers mappings d'exemple

Ces exemples sont tous pris de la suite de tests d'Hibernate. Vous en trouverez beaucoup d'autres. Regardez dans le dossier test de la distribution d'Hibernate.

TODO: put words around this stuff
23.4.1. "Typed" one-to-one association

<class name="Person">
    <id name="name"/>
    <one-to-one name="address"
            cascade="all">
        <formula>name</formula>
        <formula>'HOME'</formula>
    </one-to-one>
    <one-to-one name="mailingAddress"
            cascade="all">
        <formula>name</formula>
        <formula>'MAILING'</formula>
    </one-to-one>
</class>

<class name="Address" batch-size="2"
        check="addressType in ('MAILING', 'HOME', 'BUSINESS')">
    <composite-id>
        <key-many-to-one name="person"
                column="personName"/>
        <key-property name="type"
                column="addressType"/>
    </composite-id>
    <property name="street" type="text"/>
    <property name="state"/>
    <property name="zip"/>
</class>

23.4.2. Exemple de clef composée

<class name="Customer">

    <id name="customerId"
        length="10">
        <generator class="assigned"/>
    </id>

    <property name="name" not-null="true" length="100"/>
    <property name="address" not-null="true" length="200"/>

    <list name="orders"
            inverse="true"
            cascade="save-update">
        <key column="customerId"/>
        <index column="orderNumber"/>
        <one-to-many class="Order"/>
    </list>

</class>

<class name="Order" table="CustomerOrder" lazy="true">
    <synchronize table="LineItem"/>
    <synchronize table="Product"/>

    <composite-id name="id"
            class="Order$Id">
        <key-property name="customerId" length="10"/>
        <key-property name="orderNumber"/>
    </composite-id>

    <property name="orderDate"
            type="calendar_date"
            not-null="true"/>

    <property name="total">
        <formula>
            ( select sum(li.quantity*p.price)
            from LineItem li, Product p
            where li.productId = p.productId
                and li.customerId = customerId
                and li.orderNumber = orderNumber )
        </formula>
    </property>

    <many-to-one name="customer"
            column="customerId"
            insert="false"
            update="false"
            not-null="true"/>

    <bag name="lineItems"
            fetch="join"
            inverse="true"
            cascade="save-update">
        <key>
            <column name="customerId"/>
            <column name="orderNumber"/>
        </key>
        <one-to-many class="LineItem"/>
    </bag>

</class>

<class name="LineItem">

    <composite-id name="id"
            class="LineItem$Id">
        <key-property name="customerId" length="10"/>
        <key-property name="orderNumber"/>
        <key-property name="productId" length="10"/>
    </composite-id>

    <property name="quantity"/>

    <many-to-one name="order"
            insert="false"
            update="false"
            not-null="true">
        <column name="customerId"/>
        <column name="orderNumber"/>
    </many-to-one>

    <many-to-one name="product"
            insert="false"
            update="false"
            not-null="true"
            column="productId"/>

</class>

<class name="Product">
    <synchronize table="LineItem"/>

    <id name="productId"
        length="10">
        <generator class="assigned"/>
    </id>

    <property name="description"
        not-null="true"
        length="200"/>
    <property name="price" length="3"/>
    <property name="numberAvailable"/>

    <property name="numberOrdered">
        <formula>
            ( select sum(li.quantity)
            from LineItem li
            where li.productId = productId )
        </formula>
    </property>

</class>

23.4.3. Many-to-many avec une clef composée partagée

<class name="User" table="`User`">
    <composite-id>
        <key-property name="name"/>
        <key-property name="org"/>
    </composite-id>
    <set name="groups" table="UserGroup">
        <key>
            <column name="userName"/>
            <column name="org"/>
        </key>
        <many-to-many class="Group">
            <column name="groupName"/>
            <formula>org</formula>
        </many-to-many>
    </set>
</class>

<class name="Group" table="`Group`">
    <composite-id>
        <key-property name="name"/>
        <key-property name="org"/>
    </composite-id>
    <property name="description"/>
    <set name="users" table="UserGroup" inverse="true">
        <key>
            <column name="groupName"/>
            <column name="org"/>
        </key>
        <many-to-many class="User">
            <column name="userName"/>
            <formula>org</formula>
        </many-to-many>
    </set>
</class>

23.4.4. Contenu basé sur une discrimination

<class name="Person"
    discriminator-value="P">

    <id name="id"
        column="person_id"
        unsaved-value="0">
        <generator class="native"/>
    </id>


    <discriminator
        type="character">
        <formula>
            case
                when title is not null then 'E'
                when salesperson is not null then 'C'
                else 'P'
            end
        </formula>
    </discriminator>

    <property name="name"
        not-null="true"
        length="80"/>

    <property name="sex"
        not-null="true"
        update="false"/>

    <component name="address">
        <property name="address"/>
        <property name="zip"/>
        <property name="country"/>
    </component>

    <subclass name="Employee"
        discriminator-value="E">
            <property name="title"
                length="20"/>
            <property name="salary"/>
            <many-to-one name="manager"/>
    </subclass>

    <subclass name="Customer"
        discriminator-value="C">
            <property name="comments"/>
            <many-to-one name="salesperson"/>
    </subclass>

</class>

23.4.5. Associations sur des clefs alternées

<class name="Person">

    <id name="id">
        <generator class="hilo"/>
    </id>

    <property name="name" length="100"/>

    <one-to-one name="address"
        property-ref="person"
        cascade="all"
        fetch="join"/>

    <set name="accounts"
        inverse="true">
        <key column="userId"
            property-ref="userId"/>
        <one-to-many class="Account"/>
    </set>

    <property name="userId" length="8"/>

</class>

<class name="Address">

    <id name="id">
        <generator class="hilo"/>
    </id>

    <property name="address" length="300"/>
    <property name="zip" length="5"/>
    <property name="country" length="25"/>
    <many-to-one name="person" unique="true" not-null="true"/>

</class>

<class name="Account">
    <id name="accountId" length="32">
        <generator class="uuid"/>
    </id>

    <many-to-one name="user"
        column="userId"
        property-ref="userId"/>

    <property name="type" not-null="true"/>

</class>

Chapitre 24. Meilleures pratiques

Découpez finement vos classes et mappez les en utilisant <component>.

    Utilisez une classe Adresse pour encapsuler Rue, Region, CodePostal. Ceci permet la réutilisation du code et simplifie la maintenance. 
Déclarez des propriétés d'identifiants dans les classes persistantes.

    Hibernate rend les propriétés d'identifiants optionnelles. Il existe beaucoup de raisons pour lesquelles vous devriez les utiliser. Nous recommandons que vous utilisiez des identifiants techniques (générés, et sans connotation métier). 
Identifiez les clefs naturelles.

    Identifiez les clefs naturelles pour toutes les entités, et mappez les avec <natural-id>. Implémentez equals() et hashCode() pour comparer les propriétés qui composent la clef naturelle. 
Placez chaque mapping de classe dans son propre fichier.

    N'utilisez pas un unique document de mapping. Mappez com.eg.Foo dans le fichier com/eg/Foo.hbm.xml. Cela prend tout son sens lors d'un travail en équipe. 
Chargez les mappings comme des ressources.

    Déployez les mappings en même temps que les classes qu'ils mappent. 
Pensez à externaliser les chaînes de caractères.

    Ceci est une bonne habitude si vos requêtes appellent des fonctions SQL qui ne sont pas au standard ANSI. Cette externalisation dans les fichiers de mapping rendra votre application plus portable. 
Utilisez les variables "bindées".

    Comme en JDBC, remplacez toujours les valeurs non constantes par "?". N'utilisez jamais la manipulation des chaînes de caractères pour remplacer des valeurs non constantes dans une requête ! Encore mieux, utilisez les paramètres nommés dans les requêtes. 
Ne gérez pas vous même les connexions JDBC.

    Hibernate laisse l'application gérer les connexions JDBC. Vous ne devriez gérer vos connexions qu'en dernier recours. Si vous ne pouvez pas utiliser les systèmes de connexions livrés, réfléchissez à l'idée de fournir votre propre implémentation de org.hibernate.connection.ConnectionProvider. 
Pensez à utiliser les types utilisateurs.

    Supposez que vous ayez une type Java, de telle bibliothèque, qui a besoin d'être persisté mais qui ne fournit pas les accesseurs nécessaires pour le mapper comme composant. Vous devriez implémenter org.hibernate.UserType.Cette approche libère le code de l'application de l'implémentation des transformations vers / depuis les types Hibernate. 
Utilisez du JDBC pur dans les goulets d'étranglement.

    Dans certaines parties critiques de votre système d'un point de vue performance, quelques opérations peuvent tirer partie d'un appel JDBC natif. Mais attendez de savoir que c'est un goulet d'étranglement. Ne supposez jamais qu'un appel JDBC sera forcément plus rapide. Si vous avez besoin d'utiliser JDBC directement, ouvrez une Session Hibernate et utilisez la connexion SQL sous-jacente. Ainsi vous pourrez utiliser la même stratégie de transation et la même gestion des connexions. 
Comprendre le flush de Session.

    De temps en temps la Session synchronise ses états persistants avec la base de données. Les performances seront affectées si ce processus arrive trop souvent. Vous pouvez parfois minimiser les flush non nécessaires en désactivant le flush automatique ou même en changeant l'ordre des opérations menées dans une transaction particulière. 
Dans une architecture à trois couches, pensez à utiliser saveOrUpdate().

    Quand vous utilisez une architecture à base de servlet / session bean, vous pourriez passer des objets chargés dans le bean session vers et depuis la couche servlet / JSP. Utilisez une nouvelle session pour traiter chaque requête. Utilisez Session.merge() ou Session.saveOrUpdate() pour synchroniser les objets avec la base de données. 
Dans une architecture à deux couches, pensez à utiliser la déconnexion de session.

    Les transactions de bases de données doivent être aussi courtes que possible pour une meilleure montée en charge.Cependant, il est souvent nécessaire d'implémenter de longues transactions applicatives, une simple unité de travail du point de vue de l'utilisateur. Une transaction applicative peut s'étaler sur plusieurs cycles de requêtes/réponses du client. Il est commun d'utiliser des objets détachés pour implémenter des transactions applicatives. Une alternative, extrêmement appropriée dans une architecture à 2 couches, est de maintenir un seul contact de persistance ouvert (session) pour toute la durée de vie de la transaction applicative et simplement se déconnecter de la connexion JDBC à la fin de chaque requête, et se reconnecter au début de la requête suivante. Ne partagez jamais une seule session avec plus d'une transaction applicative, ou vous travaillerez avec des données périmées. 
Considérez que les exceptions ne sont pas rattrapables.

    Il s'agit plus d'une pratique obligatoire que d'une "meilleure pratique". Quand une exception intervient, il faut faire un rollback de la Transaction et fermer la Session. Sinon, Hibernate ne peut garantir l'intégrité des états persistants en mémoire. En particulier, n'utilisez pas Session.load() pour déterminer si une instance avec un identifiant donné existe en base de données, utilisez Session.get() ou un requête. 
Préférez le chargement tardif des associations.

    Utilisez le chargement complet avec modération. Utilisez les proxies et les collections chargées tardivement pour la plupart des associations vers des classes qui ne sont pas susceptibles d'être complètement retenues dans le cache de second niveau. Pour les assocations de classes en cache, où il y a une extrêmement forte probabilité que l'élément soit en cache, désactivez explicitement le chargement par jointures ouvertes en utilisant outer-join="false". Lorsqu'un chargement par jointure ouverte est approprié pour un cas d'utilisation particulier, utilisez une requête avec un left join fetch. 
Utilisez le pattern d'une ouverture de session dans une vue, ou une phase d'assemblage disciplinée pour éviter des problèmes avec des données non rapatriées.

    Hibernate libère les développeurs de l'écriture fastidieuse des objets de transfert de données (NdT : Data Transfer Objects) (DTO). Dans une architecture EJB traditionnelle, les DTOs ont deux buts : premièrement, ils contournent le problème des "entity bean" qui ne sont pas sérialisables ; deuxièmement, ils définissent implicitement une phase d'assemblage où toutes les données utilisées par la vue sont rapatriées et organisées dans les DTOs avant de retourner sous le contrôle de la couche de présentation. Hibernate élimine le premier but. Pourtant, vous aurez encore besoin d'une phase d'assemblage (pensez vos méthodes métier comme ayant un contrat strict avec la couche de présentation à propos de quelles données sont disponibles dans les objets détachés) à moins que vous soyez préparés à garder le contexte de persistance (la session) ouvert à travers tout le processus de rendu de la vue. 
Pensez à abstraite votre logique métier d'Hibernate.

    Cachez le mécanisme d'accès aux données (Hibernate) derrière une interface. Combinez les patterns DAO et Thread Local Session. Vous pouvez même avoir quelques classes persistées par du JDBC pur, associées à Hibernate via un UserType (ce conseil est valable pour des applications de taille respectables ; il n'est pas valable pour une application avec cinq tables). 
N'utilisez pas d'associations de mapping exotiques.

    De bons cas d'utilisation pour de vraies associations plusieurs-vers-plusieurs sont rares. La plupart du temps vous avez besoin d'informations additionnelles stockées dans la table d'association. Dans ce cas, il est préférable d'utiliser deux associations un-vers-plusieurs vers une classe de liaisons intermédiaire. En fait, nous pensons que la plupart des associations sont de type un-vers-plusieurs ou plusieurs-vers-un, vous devez être très attentifs lorsque vous utilisez autre chose et vous demander si c'est vraiment nécessaire. 
Préférez les associations bidirectionnelles.

    Les associations unidirectionnelles sont plus difficiles à questionner. Dans une grande application, la plupart des associations devraient être navigables dans les deux directions dans les requêtes. 